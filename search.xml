<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[blog]]></title>
    <url>%2F2018%2F11%2F04%2Fblog%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Mac版百度网盘飞速下载]]></title>
    <url>%2F2018%2F10%2F31%2F%E5%B7%A5%E5%85%B7%2FMac%E7%89%88%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98%E9%A3%9E%E9%80%9F%E4%B8%8B%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[引：百度网盘上有很多资源，之前在Mac上一直没有找到好的加速方法或者破解软件，这次终于找到了，请速速戳进来！！ 项目地址Proxyee Down Proxyee Down 是一款开源的免费 HTTP 高速下载器，底层使用netty开发，支持自定义 HTTP 请求下载且支持扩展功能，可以通过安装扩展实现特殊的下载需求。 最近视频教程以后也可能就不新了！！ 快快保存，2018最新百度云不限制方法proxyee down-2018.9.19，亲测速度达10M]]></content>
  </entry>
  <entry>
    <title><![CDATA[JDK源码分析——ReentrantReadWriteLock]]></title>
    <url>%2F2018%2F09%2F13%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E2%80%94%E2%80%94ReentrantReadWriteLock%2F</url>
    <content type="text"><![CDATA[引：读写分离是解决并发瓶颈的常用策略，在Java中也有其实现——ReentrantReadWriteLock，它能够有效的提高读比写多的场景下的程序性能。 概览ReentrantReadWriteLock是通过两把锁实现读写分离的，分别是读锁和写锁。它的源码如下：12345678public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable &#123; // 读锁 private final ReentrantReadWriteLock.ReadLock readerLock; // 写锁 private final ReentrantReadWriteLock.WriteLock writerLock; // 同步器 final Sync sync; 写锁写锁主要是通过重写同步器的tryAcquire和tryRelease实现，其他逻辑都可以参考AQS的解析。 tryAcquire123456789101112131415161718192021222324252627282930313233343536// Syncstatic final int SHARED_SHIFT = 16;// 重入最大次数static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1;// 独占锁（写锁）掩码static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); // 用 state &amp; 65535 得到低 16 位的值 int w = exclusiveCount(c); if (c != 0) &#123; // (Note: if c != 0 and w == 0 then shared count != 0) // 如果 state 不是0，且低16位是0，说明写锁是空闲的，读锁被霸占了。那么也不能拿锁，返回 fasle。保证了读的时候不能写。 // 如果低 16 位不是0，说明写锁被霸占了，此时如果持有锁的不是当前线程，那么这次拿锁是失败的。返回 fasle。 if (w == 0 || current != getExclusiveOwnerThread()) return false; // 这里时候应该是写重入锁，如果写重入次数超过最大值 65535，就会溢出 if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error("Maximum lock count exceeded"); // Reentrant acquire setState(c + acquires); return true; &#125; // writerShouldBlock 判断是否应该阻塞 // 1. 公平锁情况下，如果队列中有等待锁的线程，则返回ture，应该阻塞 // 2. 非公平锁情况下，返回false，不应该阻塞，直接参与竞争 if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; // 竞争到锁，设置独占线程 setExclusiveOwnerThread(current); return true;&#125; tryRelease12345678910111213protected final boolean tryRelease(int releases) &#123; // 是否持有锁 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); // 设置state状态 int nextc = getState() - releases; // 计算写锁的状态（低16位），如果是0，说明是否成功 boolean free = exclusiveCount(nextc) == 0; if (free) setExclusiveOwnerThread(null); setState(nextc); return free;&#125; 读锁写锁主要是通过重写同步器的tryAcquireShared和tryReleaseShared实现，其他逻辑都可以参考AQS的解析。 tryAcquireShared12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// Sync// 共享（读锁）重入次数基数static final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT);// 第一个获得读锁的线程private transient Thread firstReader = null;// 第一个获得读锁的线程的重入次数计数器private transient int firstReaderHoldCount;// 最后一个获取读锁的线程的计数器，存放在ThreadLocal中private transient HoldCounter cachedHoldCounter;protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); int c = getState(); // 用 state &amp; 65535 得到低 16 位的值 不等于0，写锁被霸占了 // 且 // 持有锁的不是当前线程 // 保证了写的时候不能读 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) // 获取锁失败 return -1; // 如果写锁没有被霸占，则将高16位移到低16位 int r = sharedCount(c); // readerShouldBlock判断是否应该阻塞 和写锁逻辑一致 // 写锁重入次数不超过最大值 65535 // 设置state成功 (相当于高16位加1) if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; // 读锁空闲 if (r == 0) &#123; firstReader = current; // 计数器为1 firstReaderHoldCount = 1; // 第一个读线程是当前线程 &#125; else if (firstReader == current) &#123; // 计数器加1 firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; // 如果最后一个线程计数器是 null 或者不是当前线程 if (rh == null || rh.tid != getThreadId(current)) // 新建一个 HoldCounter 对象 cachedHoldCounter = rh = readHolds.get(); // 如果不是 null，且 count 是 0 else if (rh.count == 0) // 就将上个线程的 HoldCounter 覆盖本地的（性能考虑，相当于缓存） readHolds.set(rh); // 计数器加1 rh.count++; &#125; // 获得锁成功 return 1; &#125; // 死循环获取读锁，和tryReleaseShared逻辑类似，只有多了死循环 return fullTryAcquireShared(current);&#125; 锁降级在tryAcquireShared还体现了锁降级的概念。概念如下： 重入还允许从写入锁降级为读取锁，其实现方式是：先获取写入锁，然后获取读取锁，最后释放写入锁。但是，从读取锁升级到写入锁是不可能的。 体现在代码中如下：1234// tryAcquireShared 或者 fullTryAcquireShared中if (exclusiveCount(c) != 0) &#123; if (getExclusiveOwnerThread() != current) return -1; 上面的代码就体现出：当写锁被持有的时候，如果当前是线程是持有写锁的那个线程，可以继续获得读锁。 总得来说就提高了性能。 tryReleaseShared123456789101112131415161718192021222324252627282930313233343536373839// 当前线程重入次数计数器private transient ThreadLocalHoldCounter readHolds;protected final boolean tryReleaseShared(int unused) &#123; Thread current = Thread.currentThread(); // 如果是第一个线程 if (firstReader == current) &#123; // 如果是 1，将第一个线程设置成 null if (firstReaderHoldCount == 1) firstReader = null; // 如果不是 1，减一操作 else firstReaderHoldCount--; // 如果不是当前线程 &#125; else &#123; HoldCounter rh = cachedHoldCounter; // 如果最后一个线程计数器是 null 或者缓存所属线程不是当前线程 if (rh == null || rh.tid != getThreadId(current)) // 获取当前线程的计数器 rh = readHolds.get(); int count = rh.count; // 如果计数器小于等于一，就直接删除计数器 if (count &lt;= 1) &#123; readHolds.remove(); if (count &lt;= 0) throw unmatchedUnlockException(); &#125; // 对计数器减一 --rh.count; &#125; // 死循环使用 CAS 修改状态 for (;;) &#123; int c = getState(); int nextc = c - SHARED_UNIT; if (compareAndSetState(c, nextc)) // 修改成功后，如果是 0，表示读锁和写锁都空闲，则可以唤醒后面的等待线程 return nextc == 0; &#125;&#125; 总结关于读写锁，它其实就是一个读锁一个写锁，读锁是共享的，写锁是独占的。然后我们再理解锁降级的相关概念就行了，当然这一切都是需要建立在读AQS的理解之上。 参考 JDK源码分析——AbstractQueuedSynchronizer 并发编程之——写锁源码分析 并发编程之——读锁源码分析(解释关于锁降级的争议)]]></content>
      <categories>
        <category>JDK源码分析</category>
      </categories>
      <tags>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK源码分析——ReentrantLock]]></title>
    <url>%2F2018%2F09%2F13%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E2%80%94%E2%80%94ReentrantLock%2F</url>
    <content type="text"><![CDATA[引：虽然有了synchronized这种内置的锁功能，但是在JDK5之后又新增了Lock接口，它的实现类可比内置的锁强大多了。今天我们主要看看它的实现类之一ReentrantLock。 概览在看之前，我们一定要对AbstractQueuedSynchronizer熟悉，不熟悉的可以参考我这篇文章——JDK源码分析——AbstractQueuedSynchronizer 我们先看看他的定义：1234567891011121314151617181920public class ReentrantLock implements Lock, java.io.Serializable &#123; // 同步器(可选择公平同步器或者非公平同步器) private final Sync sync; // 默认非公平锁 public ReentrantLock() &#123; sync = new NonfairSync(); &#125; // fair为true时，采用公平锁策略 public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); &#125; public void lock() &#123; sync.lock(); &#125; public void unlock() &#123; sync.release(1); &#125;&#125; 同步器抽象类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647abstract static class Sync extends AbstractQueuedSynchronizer &#123; abstract void lock(); // 非公平的TryAcquire final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 为0，则可获得锁，进行CAS操作设置state，并设置当前线程为独占线程 if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 重入锁的体现 // 如果当前线程为独占线程，则可重入 else if (current == getExclusiveOwnerThread()) &#123; // 重入次数增加 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; // 获取失败 return false; &#125; // 释放锁 protected final boolean tryRelease(int releases) &#123; // 截取释放次数 int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 重入次数要减到0，才是真正得释放了锁 if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; // 维护了一个条件队列 final ConditionObject newCondition() &#123; return new ConditionObject(); &#125;&#125; 公平锁公平锁是指如果同步器的队列中有线程在等待，后来的线程则直接加入到队列中公平同步器实现：123456789101112131415161718192021222324252627282930static final class FairSync extends Sync &#123; final void lock() &#123; // AQS分析逻辑 acquire(1); &#125; // 公平实现 protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 可获得锁 if (c == 0) &#123; // 如果同步器的队列中没有线程在等待 或者 CAS成功 或者设置独占线程成功 // 公平的体现 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 可重入 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125;&#125; 非公平锁非公平锁是指后来的线程也有同样的优先级。 非公平同步器实现：1234567891011121314151617static final class NonfairSync extends Sync &#123; final void lock() &#123; // 利用CAS把state从0设置为1 // 成功则获得锁 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else // 进入AQS分析逻辑 acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; // 非公平获取 return nonfairTryAcquire(acquires); &#125;&#125; 条件变量ConditionSynchronized中，所有的线程都在同一个object的条件队列上等待。而ReentrantLock中，每个condition都维护了一个条件队列。我们先看看在同步器定义的ConditionObject对象。123456public class ConditionObject implements Condition, java.io.Serializable &#123; // 条件队列的头节点 private transient Node firstWaiter; // 条件队列的尾节点 private transient Node lastWaiter;&#125; 我们关注它的两个核心方法(条件变量Condition为了解决Object.wait/notify/notifyAll难以使用的问题)：12void await() throws InterruptedException;void signal(); await阻塞线程12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public final void await() throws InterruptedException &#123; // 如果线程被中断，则抛出异常 if (Thread.interrupted()) throw new InterruptedException(); // 1. 将线程添加到条件等待队列 Node node = addConditionWaiter(); // 2. 释放持有的锁 int savedState = fullyRelease(node); int interruptMode = 0; // 是否在AQS的同步队列中 while (!isOnSyncQueue(node)) &#123; // 3. 不是则挂起该线程 LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; // 4. 被唤醒后，通过acquireQueued方法重新竞争锁，参考AQS if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; // 清理取消节点 if (node.nextWaiter != null) unlinkCancelledWaiters(); // 报告中断信息 if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125;// 1. 将线程添加到条件等待队列private Node addConditionWaiter() &#123; Node t = lastWaiter; // 如果最后一个节点是取消状态 if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; // 从队列删除取消节点 unlinkCancelledWaiters(); t = lastWaiter; &#125; // 线程包装成节点 Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node;&#125;// 2. 释放持有的锁final int fullyRelease(Node node) &#123; // 标记是否失败，失败则将节点设为取消状态 boolean failed = true; try &#123; int savedState = getState(); // release可以参考AQS的解析 if (release(savedState)) &#123; failed = false; return savedState; &#125; else &#123; throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; if (failed) node.waitStatus = Node.CANCELLED; &#125;&#125; signal唤醒线程1234567891011121314151617181920212223242526272829303132public final void signal() &#123; // 当前线程是否持有锁 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first);&#125;private void doSignal(Node first) &#123; do &#123; if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; // 找到底部个非取消节点，遇到取消节点就进行删除 &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null);&#125;final boolean transferForSignal(Node node) &#123; // 将状态设置为0，不行就取消该节点 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; // 将节点放入到同步队列中 Node p = enq(node); int ws = p.waitStatus; if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) // 唤醒线程 LockSupport.unpark(node.thread); return true;&#125; 总结ReetrantLock还提供了其它功能，包括定时的锁等待、可中断的锁等待、公平性、以及实现非块结构的加锁、Condition，对线程的等待和唤醒等操作更加灵活。但是内置锁（Synchronized）与ReentrantLock相比有例外一个优点就是在线程转储中能给出在哪些调用帧中获得了哪些锁，并能够检测和识别发生死锁的线程。因为Reentrant的非块状特性意味着获取锁的操作不能与特定的栈帧关联起来。相比之下内置锁是JVM的内置属性，所以未来更可能提升synchronized而不是ReentrantLock的性能，而照目前的趋势来看确实如此。 参考 JDK源码分析——AbstractQueuedSynchronizer 深入浅出ReentrantLock]]></content>
      <categories>
        <category>JDK源码分析</category>
      </categories>
      <tags>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK源码分析——AbstractQueuedSynchronizer]]></title>
    <url>%2F2018%2F09%2F11%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E2%80%94%E2%80%94AbstractQueuedSynchronizer%2F</url>
    <content type="text"><![CDATA[引：java.util.concurrent.locks包中有很多Lock的实现类，内部实现都依赖AbstractQueuedSynchronizer（AQS）类，今天我们就看看AQS如何完成代码块的并发访问控制。 概览抽象队列同步器AQS是用来构建锁或其他同步组件的基础框架，内部使用一个int成员变量state表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作，其中内部同步状态state，等待队列的头节点head和尾节点head，都是通过volatile修饰，保证了多线程之间的可见，同时这些状态上的操作都用通过CAS操作来保持同步。 核心成员变量如下：123456// 等待队列头节点，懒加载private transient volatile Node head;// 等待队列尾节点，懒加载private transient volatile Node tail;// 同步状态private volatile int state; 整个AQS的示意图如下： 等待队列上面说到AQS是通过内置的队列(LH lock实现，不懂的在后面参考中找到解释)来完成同步的，我们就先看看队列的定义：123456789101112131415161718192021222324252627282930/** * +------+ prev +-----+ +-----+ * head | | &lt;---- | | &lt;---- | | tail * +------+ +-----+ +-----+ */static final class Node &#123; // 标记表示节点正在共享模式中等待 static final Node SHARED = new Node(); // 标记表示节点正在独占模式下等待 static final Node EXCLUSIVE = null; // waitStatus值表示线程取消 static final int CANCELLED = 1; // waitStatus值表示当前线程的后继线程需要被唤醒 // 一般发生情况是：当前线程的后继线程处于阻塞状态，而当前线程被release或cancel static final int SIGNAL = -1; // waitStatus值表示线程等待Condition唤醒 static final int CONDITION = -2; // waitStatus值表示下一个acquireShared应该无条件传播,都获得共享锁 static final int PROPAGATE = -3; // 表示节点状态值，SIGNAL，CANCELLED，CONDITION，PROPAGATE，0 volatile int waitStatus; // 前驱节点 volatile Node prev; // 后继节点 volatile Node next; // 对应线程 volatile Thread thread; // 资源共享方式：SHARED、独占模式 Node nextWaiter;&#125; 使用不同的自定义同步器(后面会挑几种进行源码分析)争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法： 12345678910// 该线程是否正在独占资源。只有用到condition才需要去实现它isHeldExclusively();// 独占方式。尝试获取资源，成功则返回true，失败则返回false。tryAcquire(int arg);// 独占方式。尝试释放资源，成功则返回true，失败则返回false。tryRelease(int arg);// 共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源tryAcquireShared(int arg);// 共享方式。尝试释放资源，成功则返回true，失败则返回false。tryReleaseShared(int arg) 一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。下面我将分别对独占锁的管理流程 acquire-release 和 共享锁管理流程 acquireShared-releaseShare 进行分析。 acquire-releaseacquireacquire方法是独占模式下线程获取共享资源的顶层入口。如果获取到资源，线程直接返回，否则进入等待队列，直到获取到资源为止，且整个过程忽略中断的影响。它将被Lock接口的lock方法调用。源码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;// 1. 当前线程通过tryAcquire()尝试获取锁。获取成功的话，直接返回；尝试失败的话，进入到等待队列排序等待。// 交由自定义同步器去实现，主要是设置同步State，获取成功返回true，失败返回falseprotected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125;// 2. 当前线程在尝试失败的情况下，先通过addWaiter(Node.EXCLUSIVE)来将当前线程加入到CLH队列末尾。// 根据当前线程和模式创建节点并入队private Node addWaiter(Node mode) &#123; // 根据当前线程和模式创建节点 Node node = new Node(Thread.currentThread(), mode); // tail节点不为空，尝试快速方式直接放到队尾 Node pred = tail; if (pred != null) &#123; node.prev = pred; // 利用Unsafe的CAS操作，下面将不再提 if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // tail节点为空，调用enq方法 enq(node); return node;&#125;// 将节点入队，如果有必要初始化队列private Node enq(final Node node) &#123; // CAS自旋，直到成功加入队尾 for (;;) &#123; Node t = tail; // 末端节点为空 if (t == null) &#123; // Must initialize // 创建头节点，并利用CAS操作设置头节点 if (compareAndSetHead(new Node())) // 将尾节点指针也指向头节点 tail = head; &#125; else &#123; // 正常入队 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125;// 3. 当前线程执行完addWaiter(Node.EXCLUSIVE)之后，调用acquireQueued()来获取锁，因为这个时候可能前面的线程已经释放了锁。// 如果当前线程获取到了锁，则返回；否则，当前线程被挂起，直到唤醒并重新获取锁了才返回。final boolean acquireQueued(final Node node, int arg) &#123; //标记是否成功拿到资源 boolean failed = true; try &#123; //标记等待过程中是否被中断过 boolean interrupted = false; // 自旋 for (;;) &#123; // 拿到前驱节点 final Node p = node.predecessor(); // 如果前驱节点是head节点 并且 获取锁成功 // 这里涉及到锁的公平性问题，体现了非公平性 if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 将当前节点设置为head节点 // head所指的结点，就是当前获取到锁的那个结点或null(初始化时) setHead(node); p.next = null; // help GC failed = false; // 返回等待过程中是否被中断过 return interrupted; &#125; // 如果上面的条件不成立，则挂起当前线程，等待被唤醒或者中断 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; // 如果获取锁出错，则设置为取消状态 if (failed) cancelAcquire(node); &#125;&#125;// 在获取锁失败之后检查和更新节点的状态，返回当前线程是否应该阻塞(被唤醒)private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; // 拿到前驱节点的等待状态 int ws = pred.waitStatus; // 等待状态为SIGNAL（-1） if (ws == Node.SIGNAL) return true; // 等待状态为CANCELLED(1) if (ws &gt; 0) &#123; // 往前找到最近有效的节点 do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; // 等待状态为其他情况 &#125; else &#123; // 将状态设置为SIGNAL compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125;// 4. 当前线程在执行acquireQueued()时，会进入到CLH队列中休眠等待，直到获取锁了才返回！// 阻塞并检查是否中断，直到当前线程被唤醒才从parkAndCheckInterrupt()中返回private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); // 返回中断状态，并清除中断标志，中断并不会取消锁，如果中断会再次被阻塞 return Thread.interrupted();&#125;// 5. 如果当前线程在休眠等待过程中被中断过，acquireQueued会返回true，此时当前线程会调用selfInterrupt()来自己给自己产生一个中断。static void selfInterrupt() &#123; // 记录中断标志 Thread.currentThread().interrupt();&#125; releaserelease方法是独占模式线程释放资源的入口。它将被Lock接口的release方法调用。源码如下：123456789101112131415161718192021222324252627282930313233343536public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; // 找到头节点 Node h = head; // 头节点不为空 且 头节点等待状态不为0 if (h != null &amp;&amp; h.waitStatus != 0) // 唤醒等待队列的下一个线程 unparkSuccessor(h); return true; &#125; return false;&#125;// 1. 当前线程通过tryRelease(arg)尝试释放锁，成功则返回true，失败则返回false。protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125;// 2. 当前线程释放锁成功后，唤醒等待队列的下一个线程private void unparkSuccessor(Node node) &#123; // 获取当前线程状态 int ws = node.waitStatus; // 如果状态 &lt; 0，则设置状态为0 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; // 节点为空 或者 waitStatus &gt; 0 ，从最后开始向前寻找，找到waitStatus小于等于0的节点 // 涉及到了弱一致性的问题（next指针在有个短暂瞬间不一定存在） if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; // 唤醒后继节点对应的线程 if (s != null) LockSupport.unpark(s.thread);&#125; acquireShared-releaseShareacquireSharedacquireShared(int arg)是共享模式下线程获取共享资源的顶层入口。它会获取指定量的资源，获取成功则直接返回，获取失败则进入等待队列，直到获取到资源为止，整个过程忽略中断。源码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125;// 1. 当前线程通过tryAcquireShared(int arg)尝试获取锁，负值代表获取失败；0代表获取成功，但没有剩余资源；正数表示获取成功，还有剩余资源，其他线程还可以去获取// 交由自定义同步器去实现，主要是设置同步Stateprotected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException();&#125;// 2. 当前线程通过doAcquireShared(int arg)将当前线程加入等待队列尾部休息，直到其他线程释放资源唤醒自己，自己成功拿到相应量的资源后才返回private void doAcquireShared(int arg) &#123; // 加入队列尾部 final Node node = addWaiter(Node.SHARED); // 标记是否成功 boolean failed = true; try &#123; // 标记是否被中断 boolean interrupted = false; // 自旋 for (;;) &#123; // 拿到前驱节点 final Node p = node.predecessor(); // 此时node节点被唤醒 if (p == head) &#123; // 尝试获得资源 int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; //将head指向自己，还有剩余资源可以再唤醒之后的线程 setHeadAndPropagate(node, r); p.next = null; // help GC // 如果等待过程中被中断过，记录中断标记 if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; // 与独占模式类似 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;private void setHeadAndPropagate(Node node, int propagate) &#123; // 将head指针指向自己 Node h = head; setHead(node); // 唤醒后继节点 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) // 关注这里 doReleaseShared(); &#125;&#125; releaseSharedoReleaseShared()是共享模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源。源码如下：12345678910111213141516171819202122232425262728293031323334public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125;// 1. 当前线程通过tryReleaseShared(int arg)尝试释放锁，成功返回true，失败返回false// 交由自定义同步器去实现，主要是设置同步Stateprotected boolean tryReleaseShared(int arg) &#123; throw new UnsupportedOperationException();&#125;// 2. 当前线程通过doReleaseShared()唤醒后继节点private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // 唤醒线程 unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; 总结知道了AQS的原理，锁的原理应该也就不难了。这次我们再一次见到CAS的威力。当然这次有些还是有一点迷惑，后面有机会再来补充！ 参考 CLH锁 、MCS锁 Java多线程：AQS源码分析]]></content>
      <categories>
        <category>JDK源码分析</category>
      </categories>
      <tags>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK源码分析——ThreadPoolExecutor]]></title>
    <url>%2F2018%2F09%2F07%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E2%80%94%E2%80%94ThreadPoolExecutor%2F</url>
    <content type="text"><![CDATA[引：相信大家已经收到了Executor框架以及线程池带来的好处，它有着神奇的能力，那我们来看看它是怎么实现这种神奇的能力的！ 详细注释：源码分析地址 概述用过的人应该都很熟悉了，不过还想回顾一下的还是可以看看自己之前看《Java并发实战编程》总结的几章笔记： Java并发5任务执行 Java并发7线程池的使用 例子JDK自带的哪几种线程池类型，就不多展示了，这里我们来看看自定义线程池。1234567891011121314151617181920212223public class ExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService executorService = new ThreadPoolExecutor(5,20, 0, TimeUnit.MILLISECONDS ,new LinkedBlockingDeque&lt;&gt;(1024), Executors.defaultThreadFactory(), new ThreadPoolExecutor.AbortPolicy()); for (int i = 0; i &lt; 10; i++) &#123; executorService.execute(new MyTask()); &#125; &#125;&#125;class MyTask implements Runnable &#123; @Override public void run() &#123; System.out.println("Thread ID：" + Thread.currentThread().getId()); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 输出：12345678910Thread ID：10Thread ID：12Thread ID：11Thread ID：14Thread ID：13Thread ID：10Thread ID：11Thread ID：12Thread ID：14Thread ID：13 结合设置的参数，大家是不是隐隐发现了什么？模糊的请往下看。 构造我们主要还是记住这7个参数的含义：123456789101112131415161718192021222324252627// 保障线程池运行的最少的线程数private volatile int corePoolSize;// 最大线程数，它收到CAPACITY((2^29)-1)的限制private volatile int maximumPoolSize;// 当线程总数超多corePoolSize时，如果线程空闲超过这个时间(结合unit时间单位)，将被回收private volatile long keepAliveTime;// 当线程池来不及执行任务时，会将任务暂时放在队列中，等待后续处理private final BlockingQueue&lt;Runnable&gt; workQueue;// 线程工厂private volatile ThreadFactory threadFactory;// 当线程池饱和或者优雅关闭的时候调用private volatile RejectedExecutionHandler handler;public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; execute最为一个Executor，execute是他最核心的方法，我们看看它是如何实现的？123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137/** * ctl（线程池控制状态）包含了两个概念 * 1. workerCount：代表有效的线程数 * 2. runState：代表了运行状态 */private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));// 保存工作线程private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;();public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * 主要有下面三个步骤: * * 1. 判断当前的线程数是否小于corePoolSize * 如果是，使用传进来的任务通过addWord方法创建一个新线程，如果能完成新线程创建exexute方法结束，成功提交任务 * * 2. 在第一步没有完成任务提交；状态为运行并且能否成功加入任务到工作队列后，再进行一次check * 如果状态在任务加入队列后变为了非运行（有可能是在执行到这里线程池shutdown了），非运行状态下当然是需要reject；然后再判断当前线程数是否为0（有可能这个时候线程数变为了0），如是，新增一个线程； * * 3. 如果不能加入任务到工作队列，将尝试使用任务新增一个线程 * 如果失败，则是线程池已经shutdown或者线程池已经达到饱和状态，所以reject这个他任务 */ int c = ctl.get(); // 实际线程数小于核心线程数 if (workerCountOf(c) &lt; corePoolSize) &#123; // 增加一个线程 if (addWorker(command, true)) return; // 更新线程池状态 c = ctl.get(); &#125; // 当线程池处于运行状态 且 添加进队列成功 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; // 再次对线程池状态检查 int recheck = ctl.get(); // 线程池状态不是运行状态，且从队列删除该任务成功 if (! isRunning(recheck) &amp;&amp; remove(command)) // 拒绝任务 reject(command); // 如果当前工作线程数量为0（线程池已关闭） else if (workerCountOf(recheck) == 0) // 添加一个 null 到队列中 addWorker(null, false); &#125; // 如果添加队列失败，则创建一个任务线程 else if (!addWorker(command, false)) // 如果失败（饱和），则拒绝 reject(command);&#125;// 新增线程private boolean addWorker(Runnable firstTask, boolean core) &#123; // Java标签 retry: // 死循环 for (;;) &#123; int c = ctl.get(); // 获取当前线程池状态 int rs = runStateOf(c); // Check if queue empty only if necessary. // 下面的逻辑可以改为这样 // rs &gt;= shutdown &amp;&amp; (rs != shutdown || firstTask != null || workQueue.isEmpty()) // 表示下面这几种情况均不接受新任务 // 1. rs &gt; shutdown // 2. rs &gt;= shutdown &amp;&amp; firstTask != null // 3. rs &gt;= shutdown &amp;&amp; workQueue.isEmppty if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; // 获取线程池中线程数量 int wc = workerCountOf(c); // 如果超出容量或者超出核心线程数或最大线程数(由core决定) if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 线程安全增加工作线程数 if (compareAndIncrementWorkerCount(c)) // / 跳出retry break retry; c = ctl.get(); // Re-read ctl // 如果线程池状态发生变化，重新循环 if (runStateOf(c) != rs) continue retry; &#125; &#125; // 线程添加成功 boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; // Worker代理了任务对象，可以看其构造方法 w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 拿到线程池状态 int rs = runStateOf(ctl.get()); // RUNNING状态 || SHUTDONW状态下清理队列中剩余的任务 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 将新创建的线程放进线程Set里 workers.add(w); // 更新线程池线程数且不超过最大值 int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // 启动新添加的线程，这个线程首先执行firstTask，然后不停的从队列中取任务执行 if (workerAdded) &#123; // 在下一节worker中分析 t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; // 线程启动失败，则从wokers中移除w并递减wokerCount if (! workerStarted) // 递减wokerCount会触发tryTerminate方法 addWorkerFailed(w); &#125; return workerStarted;&#125; workerworker对象代理了任务，我们看看它的实现：1234567891011121314151617181920212223242526272829// 代理任务执行的线程final Thread thread;// 第一个任务Runnable firstTask;Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; // 这里就用到我们在例子中的传入的工厂（注意是这个this，将worker自己作为一个Runnabel） this.thread = getThreadFactory().newThread(this);&#125;// DefaultThreadFactorypublic Thread newThread(Runnable r) &#123; // 创建一个线程，后面就是线程名了，在构造工厂的时候就确定了 Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t;&#125;// work执行任务public void run() &#123; // 这个方法太核心，单独拿出来 runWorker(this);&#125; runWorker主要的工作就是第一次启动会执行初始化传进来的任务firstTask；然后会循环从workQueue中取任务执行，如果队列为空则等待keepAliveTime这么长时间。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); // 拿到firstTask Runnable task = w.firstTask; // 等待gc w.firstTask = null; // 允许中断 w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; // task不为空 或 队列不为空 关注getTask方法解析 while (task != null || (task = getTask方法解析()) != null) &#123; w.lock(); // 中断处理 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; // 执行前钩子 beforeExecute(wt, task); Throwable thrown = null; try &#123; // 调用任务的run方法 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; // 执行后钩子 afterExecute(task, thrown); &#125; &#125; finally &#123; // 等待gc task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; // Worker的善后，从线程池中移除超时或者出现异常的线程 processWorkerExit(w, completedAbruptly); &#125;&#125;// 取任务，这里关注超时问题以及keepAliveTime起作用的代码段private Runnable getTask() &#123; // 超时标志位 boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; // 获取线程池状态 int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. // 有下面两种情况成立 // 1. rs &gt; SHUTDOWN 所以rs至少等于STOP,这时不再处理队列中的任务 // 2. rs = SHUTDOWN 所以rs&gt;=STOP肯定不成立，这时还需要处理队列中的任务除非队列为空 if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; // 介绍之前，递减workerCount值 decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // 标记从队列中取任务时是否设置超时时间 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; // 1. 如果运行线程数超过了最大线程数，但是缓存队列已经空了，这时递减worker数量 // 2. 如果设置有核心线程有超时时间要求或者线程数远大于核心线程数 且 缓存队列已经空了这时递减worker数量 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; // 没有设置核心线程有超时时间要求或者线程数远小于核心线程数就take，否则就带keepAliveTime得poll try &#123; Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; // 超时 timedOut = true; &#125; catch (InterruptedException retry) &#123; // 线程被中断重试 timedOut = false; &#125; &#125;&#125; submit当我们对于线程执行不需要返回结果时，直接调用线程的execute方法来提交任务就好了。然而很多时候我们需要线程执行的返回结果，这个时候就需要调用submit方法来提交任务。虽然它最后也会调用到execute方法，但是他们具体不同在哪里，我们来看看：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970// submit方法来自于AbstractExecutorServicepublic Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); // 将task进行了封装 RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); // 剩下的就一样了 execute(ftask); return ftask;&#125;// AbstractExecutorServiceprotected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; // 将Runnable封装成FutureTask return new FutureTask&lt;T&gt;(runnable, value);&#125;// FutureTaskpublic FutureTask(Runnable runnable, V result) &#123; // 将Runnable封装成callable this.callable = Executors.callable(runnable, result); // 确保callable的可见性 this.state = NEW;&#125;// 根据前面的execute方法的分析，我们知道最后的执行会调用到FutureTask的run方法public void run() &#123; // 状态不为NEW或者UNSAFE不成功，则运行失败 if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; // 最终又调用到了FutureTask保证的Callable对象 Callable&lt;V&gt; c = callable; // callable不为空且状态为NEW if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; // 得到返回值 result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; // 如果有异常，设置异常 setException(ex); &#125; if (ran) // 设置返回值， set(result); &#125; &#125; finally &#123; runner = null; int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125;&#125;protected void set(V v) &#123; // 设置返回值，也将状态NEW变为COMPLETING if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = v; // 完成之后将状态设置为NORMAl UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state // 进行变量清理工作 finishCompletion(); &#125;&#125; 在我们submit之后会得到一个Future，我们要想到返回值，我们只要调用get方法：1234567891011121314151617181920public V get() throws InterruptedException, ExecutionException &#123; // 拿到状态 int s = state; // 未完成，则阻塞等待完成，这里可以设置超时时间 if (s &lt;= COMPLETING) s = awaitDone(false, 0L); // 还需要根据状态判断是否返回值 return report(s);&#125;private V report(int s) throws ExecutionException &#123; Object x = outcome; // 如果状态为NORMAL，则返回值 if (s == NORMAL) return (V)x; // 如果状态为CACELLED，则代表任务呗取消，抛出异常 if (s &gt;= CANCELLED) throw new CancellationException(); throw new ExecutionException((Throwable)x);&#125; 这里基本就覆盖了运行时的过程，我们就可以很好得理解我们，当任务未完成的时候，会发生阻塞等待的情况。 总结通过上面我们基本知道了线程池的实现原理。然后就是运用这些原理对线程池进行调优了。这里关键还是调整哪些构造时的参数。 参考 Java并发5任务执行 Java并发7线程池的使用]]></content>
      <categories>
        <category>JDK源码分析</category>
      </categories>
      <tags>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK源码分析——ThreadLocal]]></title>
    <url>%2F2018%2F09%2F07%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E2%80%94%E2%80%94ThreadLocal%2F</url>
    <content type="text"><![CDATA[引：可能大家对ThreadLocal这个类既熟悉又陌生，看到得多用到得少。 详细注释：源码分析地址 概览该类提供了线程局部 (thread-local) 变量。ThreadLocal 实例通常是类中的 private static 字段，它们希望将状态与某一个线程（例如，用户 ID 或事务 ID）相关联。 每个线程都保持对其线程局部变量副本的隐式引用，只要线程是活动的并且 ThreadLocal 实例是可访问的；在线程消失之后，其线程局部实例的所有副本都会被垃圾回收（除非存在对这些副本的其他引用） 应用：在单线程应用程序中可能会维持一个全局的数据库连接，并在程序启动时初始化这个连接对象，从而避免在调用每个方法时都要传递一个Connection对象。由于JDBC的连接对象不一定是线程安全的，因此，当多线程应用程序在没有协同的情况下使用全局变量时，就不是线程安全的。通过将JDBC的连接保存到ThreadLocal对象中，每个线程都会拥有属于自己的连接。 使用12345678910111213141516171819202122232425public class ThreadLocalTest &#123; public static void main(String[] args) &#123; ThreadLocal&lt;String&gt; myThreadLocal = new MyThreadLocal&lt;String&gt;(); // 输出leonard System.out.println(myThreadLocal.get()); myThreadLocal.set("rex"); // 输出rex System.out.println(myThreadLocal.get()); myThreadLocal.remove(); // 输出leonard System.out.println(myThreadLocal.get()); &#125;&#125;class MyThreadLocal&lt;T&gt; extends ThreadLocal&lt;T&gt; &#123; @Override protected T initialValue() &#123; return (T) "leonard"; &#125;&#125; get返回线程局部变量的当前线程副本中的值。如果当前线程中保存的变量副本没有值，则先将调用 initialValue() 方法初始化然后返回值。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public T get() &#123; // 拿到当前线程 Thread t = Thread.currentThread(); // 拿到 ThreadLocalMap 这个Map ThreadLocalMap map = getMap(t); if (map != null) &#123; // 拿到节点 ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") // 返回保存的值 T result = (T)e.value; return result; &#125; &#125; // 不存在这样的map，则设置初始化，然后返回值 return setInitialValue();&#125;// 拿到与ThreadLocal关联的MapThreadLocalMap getMap(Thread t) &#123; // 与当前线程绑定 return t.threadLocals;&#125;// ThreadLocal的数据结构是一个HashMap// 节点是继承了 WeakReference(弱引用)// 如果一个对象具有弱引用，在GC线程扫描内存区域的过程中，不管当前内存空间足够与否，都会回收内存// 我们关注getEntry方法private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; // 拿到数组下标 int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; // Hash值没有冲突 if (e != null &amp;&amp; e.get() == key) return e; // Hash值冲突 else return getEntryAfterMiss(key, i, e);&#125;private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; // 拿到节点对应的ThreadLocal(key) 弱引用 ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) // 清理数组 expungeStaleEntry(i); // 存储到下一个下标里（处理Hash冲突采用的是线性探测法） else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125;// 设置初始化的值，然后返回private T setInitialValue() &#123; // 拿到初始值 T value = initialValue(); // 拿到当前线程 Thread t = Thread.currentThread(); // 拿到当前线程的ThreadLocalMap ThreadLocalMap map = getMap(t); // Map已经存在 if (map != null) // 设置ThreadLocal对应的值 map.set(this, value); // Map不存在，创建Map else createMap(t, value); // 返回该值 return value;&#125; Set将线程局部变量在当前线程副本中的值设置为指定值。大部分子类不需要重写此方法，它们只依靠 initialValue() 方法来设置线程局部变量的值。12345678910111213141516171819202122232425262728293031323334public void set(T value) &#123; // 拿到当前线程 Thread t = Thread.currentThread(); // 拿到当前线程的ThreadLocalMap ThreadLocalMap map = getMap(t); // 如果Map不为空，则直接设置值 if (map != null) map.set(this, value); // 如果Map为空，则创建Map，然后设置值 else createMap(t, value);&#125;void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125;ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; // 设置初始容量，默认16 table = new Entry[INITIAL_CAPACITY]; // 找到下标 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); // 设置值 table[i] = new Entry(firstKey, firstValue); // 设置size size = 1; // 设置阈值 setThreshold(INITIAL_CAPACITY);&#125;private void setThreshold(int len) &#123; // 设置阈值为 16 * 2 / 3 = 10 threshold = len * 2 / 3;&#125; 我们再来看看Map的set方法：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; // 根据 ThreadLocal 的 HashCode 得到对应的下标 int i = key.threadLocalHashCode &amp; (len-1); // 首先通过下标找对应的entry对象 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); // 改变其值 if (k == key) &#123; e.value = value; return; &#125; // 如果key被 GC 回收了，就会变为null（因为是软引用），则创建一个新的 entry 对象填充该槽 if (k == null) &#123; // 这个方法可以好好看看 replaceStaleEntry(key, value, i); return; &#125; &#125; // 对象不存在，则创建一个新的 entry对象 tab[i] = new Entry(key, value); // size + 1 int sz = ++size; // 如果没有清除多余的entry 并且数组长度达到了阀值，则扩容 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) // 扩容 rehash();&#125;private void rehash() &#123; // 清楚陈旧的节点 expungeStaleEntries(); // Use lower threshold for doubling to avoid hysteresis // 如果size大于0.75倍阈值。原来是2/3， 则负载因子相当于为0.5，这是在第一次的时候 // 在首次扩容之后，负载因子还是0.75 if (size &gt;= threshold - threshold / 4) resize();&#125;private void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; // 扩容为原来的两倍 int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; for (int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; // Help the GC &#125; else &#123; int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; setThreshold(newLen); size = count; table = newTab;&#125; romove移除此线程局部变量在当前线程的值。12345678910111213141516171819202122232425public void remove() &#123; // 得到当前线程的Map ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125;// 调用ThreadLocalMap的remove方法private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); // 通过线性探测法找到 key 对应的 entry for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; // 将ThreadLocal设置为null e.clear(); // 清理所有的 key 为 null 的 entry expungeStaleEntry(i); return; &#125; &#125;&#125; 总结ThreadLocal无限好，但是也会有问题，比如内存泄漏的问题（可以在后面的参考理解这个问题），为了防止这个问题，我们需要每次使用完ThreadLocal，都调用它的remove()方法，清除数据。 参考 并发编程之 ThreadLocal 源码剖析 深入分析 ThreadLocal 内存泄漏问题 使用ThreadLocal不当可能会导致内存泄露]]></content>
      <categories>
        <category>JDK源码分析</category>
      </categories>
      <tags>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK源码分析——LinkedHashMap]]></title>
    <url>%2F2018%2F09%2F06%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E2%80%94%E2%80%94LinkedHashMap%2F</url>
    <content type="text"><![CDATA[引：如果有这样一种情形，我们需要按照元素插入的顺序来访问元素，这个时候LinkedHashMap大展身手了，它保存着元素插入的顺序，并且可以按照我们插入的顺序进行访问。 详细注释：源码分析地址 概览LinkedHashMap 继承自 HashMap，在 HashMap 基础上，通过维护一条双向链表，解决了 HashMap 不能随时保持遍历顺序和插入顺序一致的问题。除此之外，LinkedHashMap 对访问顺序也提供了相关支持。在一些场景下，该特性很有用，比如缓存。在实现上，LinkedHashMap 很多方法直接继承自 HashMap，仅为维护双向链表覆写了部分方法。 它的结构示意图如下： 构造主要就是设置初始容量、负载因子和迭代顺序1234567891011121314// 双向链表的头，最久访问的transient LinkedHashMap.Entry&lt;K,V&gt; head;// 双向链表的尾，最新访问的transient LinkedHashMap.Entry&lt;K,V&gt; tail;// 默认为false，迭代顺序是按照插入顺序，当为true时，迭代顺序是按照访问信息，最近访问在尾部final boolean accessOrder;public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; // 后面和HashMap一样 super(initialCapacity, loadFactor); this.accessOrder = accessOrder;&#125; 增LinkedHashMap 本身并没有覆写父类的 put 方法，而是直接使用了父类的实现。但在 HashMap 中，put 方法插入的是 HashMap 内部类 Node 类型的节点，该类型的节点并不具备与 LinkedHashMap 内部类 Entry 及其子类型节点组成链表的能力。下面将展示建立链表的逻辑，其中和HashMap相同的代码这里就不多说，不知道的可以在先阅读在后面参考提到的HashMap解析。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 1. 调用HashMap的put方法public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;// 2. 调用HashMap的putVal方法final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; // ... // 关键就在这里，这里会触发多态，去调用LinkedHashMap的方法 tab[i] = newNode(hash, key, value, null); // ...&#125;// 3. 多态调用LinkedHashMap的newNode方法Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; e) &#123; // 生成LinkedHashMap需要的节点 LinkedHashMap.Entry&lt;K,V&gt; p = new LinkedHashMap.Entry&lt;K,V&gt;(hash, key, value, e); // 将 Entry 接在双向链表的尾部 linkNodeLast(p); return p;&#125;// 我们可以看一下这种节点的数据结构static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123; // 拥有前后指针 Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125;&#125;// 4. 将新建的节点接在双向链表的尾部private void linkNodeLast(LinkedHashMap.Entry&lt;K,V&gt; p) &#123; // 拿到为节点 LinkedHashMap.Entry&lt;K,V&gt; last = tail; tail = p; // 如果尾节点不存在，则代表了链表未生成 if (last == null) head = p; // 设置指针 else &#123; p.before = last; last.after = p; &#125;&#125;// 5. 后面的内容就和HashMap一毛一样了 删与插入操作一样，LinkedHashMap 删除操作相关的代码也是直接用父类的实现。在删除节点时，父类的删除逻辑并不会修复 LinkedHashMap 所维护的双向链表。维护操作都在删除及节点后的回调方法 afterNodeRemoval 中。LinkedHashMap 覆写该方法，并在该方法中完成了移除被删除节点的操作。分析方法同上。123456789101112131415161718192021222324252627282930313233343536373839404142434445// 1. 调用HashMap的remove方法public boolean remove(Object key, Object value) &#123; return removeNode(hash(key), key, value, true, true) != null;&#125;// 2. 调用HashMap的removeNode方法final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; // ... // 对应各种类型的节点删除。这些都不会改变链表的结构 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; // 关键的来了，这个操作在HashMap是没有实现的，但是在LinkedHashMap中实现了 afterNodeRemoval(node); return node; // ...&#125;// 3. 调用LinkedHashMap方法的afterNodeRemoval操作来调整链表结构void afterNodeRemoval(Node&lt;K,V&gt; e) &#123; // unlink // 拿到删除节点以及它的前驱节点和后继节点 LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; // 将这两个指针置空 p.before = p.after = null; // 如果前驱节点为空，则为头节点 if (b == null) head = a; else // 连接前后两个界定啊 b.after = a; // 如果前驱节点为空，则为尾节点 if (a == null) tail = b; else a.before = b;&#125; 改与插入操作一样，LinkedHashMap 改操作相关的代码也是直接用父类的实现。分析方法同上。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// 1. 调用HashMap的replace方法public V replace(K key, V value) &#123; Node&lt;K,V&gt; e; // 前面的操作都和HashMap一致 if ((e = getNode(hash(key), key)) != null) &#123; V oldValue = e.value; e.value = value; // 重点在修改之后会执行这样一个回调操作 afterNodeAccess(e); return oldValue; &#125; return null;&#125;// 2. 调用LinkedHashMap的afterNodeAccess访问回调方法来调整链表位置// 将最近访问的节点，放在链表最后void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMap.Entry&lt;K,V&gt; last; // 当accessOrder为ture 且 访问的不是尾部节点时才进行下面的一顿操作 if (accessOrder &amp;&amp; (last = tail) != e) &#123; // 拿到访问节点以及它的前驱节点和后继节点 LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; // 后继节点置空 p.after = null; // 前驱节点为头节点 if (b == null) head = a; else b.after = a; // 这里的if/else感觉也都没用，因为都确定不是尾节点了 if (a != null) a.before = b; else last = b; // 表示不会会空，因为都访问到元素了 if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125; // 将访问节点放到尾部 tail = p; ++modCount; &#125;&#125; 查查操作覆盖了HashMap的方法，但是也只是添加afterNodeAccess操作判断。123456789public V get(Object key) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return null; // 唯一不同的地方，当accessOrder为true时，则调整链表，和在改操作的分析一样 if (accessOrder) afterNodeAccess(e); return e.value;&#125; 实现 LRU 缓存LRU 缓存：LRU（Least Recently Used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。 大家看到上面的定义就能想到就是在一定条件下删除Head节点嘛，因为最近访问过的都会被放在链表尾部，最近最少使用的一定是投节点。那么LinkedHashMap在哪里为我们留下了实现的接口，我们看看下面的源码：1234567891011121314151617181920212223// 可用于实现LRU缓存，evict就表示删除的意思void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; // 根据条件判断是否移除最近最少被访问的节点，主要就是removeEldestEntry方法 if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; // 删除节点 removeNode(hash(key), key, null, false, true); &#125;&#125;// 默认返会false，就是不删除protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125;// 当然在源码注释中也为我们重写提供了例子private static final int MAX_ENTRIES = 100;protected boolean removeEldestEntry(Map.Entry eldest) &#123; // 当大于某个阈值，就移除最老的 return size() &gt; MAX_ENTRIES;&#125; 参考 LinkedHashMap 源码详细分析（JDK1.8） JDK源码分析——HashMap Java 中最大的数据结构：LinkedHashMap 了解一下？]]></content>
      <categories>
        <category>JDK源码分析</category>
      </categories>
      <tags>
        <tag>LinkedHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK源码分析——TreeMap]]></title>
    <url>%2F2018%2F09%2F06%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E2%80%94%E2%80%94TreeMap%2F</url>
    <content type="text"><![CDATA[引：你想利用的Map高效的查找效率，又想拥有一个有序的Map，这个时候就需要用到TreeMap了! 详细注释：源码分析地址 概览TreeMap集合是基于红黑树（Red-Black tree）的 NavigableMap实现。该Map根据其键的自然顺序进行排序，或者根据创建Map时提供的 Comparator 进行排序，具体取决于使用的构造方法。你可以根据自己的需要选择排序的方式。 关于不同步都和之前解析的非同步容器类似。 构造在概览中说到我们可以在它构造时传递Comparator来决定排序的方法，所以我们就看看这个构造方法。12345678910// 比较器private final Comparator&lt;? super K&gt; comparator;// 根节点private transient Entry&lt;K,V&gt; root;// 集合大小private transient int size = 0;public TreeMap(Comparator&lt;? super K&gt; comparator) &#123; this.comparator = comparator;&#125; 增我们看出在构造方法中只是设置了属性，并没有真正构建红黑树，那么它一定在第一次put操作里。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public V put(K key, V value) &#123; // 获取根节点 Entry&lt;K,V&gt; t = root; // 如果根节点为空，则该元素置为根节点 if (t == null) &#123; compare(key, key); // type (and possibly null) check // 新建节点 root = new Entry&lt;&gt;(key, value, null); // 改变集合大小和修改次数 size = 1; modCount++; return null; &#125; int cmp; Entry&lt;K,V&gt; parent; // split comparator and comparable paths // 获得key比较器 Comparator&lt;? super K&gt; cpr = comparator; // 如果比较器对象不为空，也就是自定义了比较器 if (cpr != null) &#123; do &#123; // 循环比较并确定元素应插入的位置(也就是找到该元素的父节点) parent = t; cmp = cpr.compare(key, t.key); // 待插入元素的key小于当前位置元素的key，则查询左子树 if (cmp &lt; 0) t = t.left; // 待插入元素的key大于当前位置元素的key，则查询右子树 else if (cmp &gt; 0) t = t.right; // 相等则替换其value else return t.setValue(value); &#125; while (t != null); &#125; // 如果比较器对象为空，使用默认的比较机制 else &#123; // 默认机制下不允许设置 null key if (key == null) throw new NullPointerException(); @SuppressWarnings("unchecked") Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; // 和上面的循环做同样的事 do &#123; parent = t; cmp = k.compareTo(t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; // 根据key找到父节点后新建一个节点 Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent); if (cmp &lt; 0) parent.left = e; else parent.right = e; // 调整红黑树 fixAfterInsertion(e); size++; modCount++; return null;&#125; 大概的流程如下： 判断根节点是否为空，为空，则该节点就是根节点 根据比较器(可能是外部传进来的，也可能是默认的)，找到父节点。 插入节点之后，就需要用红黑树的修正了。 删12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public V remove(Object key) &#123; // 利用比较器二分查找 Entry&lt;K,V&gt; p = getEntry(key); if (p == null) return null; V oldValue = p.value; // 红黑树删除 deleteEntry(p); return oldValue;&#125;final Entry&lt;K,V&gt; getEntry(Object key) &#123; // Offload comparator-based version for sake of performance if (comparator != null) return getEntryUsingComparator(key); if (key == null) throw new NullPointerException(); @SuppressWarnings("unchecked") Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; Entry&lt;K,V&gt; p = root; // 普通的二分查找 while (p != null) &#123; int cmp = k.compareTo(p.key); if (cmp &lt; 0) p = p.left; else if (cmp &gt; 0) p = p.right; else return p; &#125; return null;&#125;final Entry&lt;K,V&gt; getEntryUsingComparator(Object key) &#123; @SuppressWarnings("unchecked") K k = (K) key; Comparator&lt;? super K&gt; cpr = comparator; // 普通的二分查找 if (cpr != null) &#123; Entry&lt;K,V&gt; p = root; while (p != null) &#123; int cmp = cpr.compare(k, p.key); if (cmp &lt; 0) p = p.left; else if (cmp &gt; 0) p = p.right; else return p; &#125; &#125; return null;&#125; 改找到该key对应的节点，然后替换该值1234567891011public V replace(K key, V value) &#123; // 找到节点 Entry&lt;K,V&gt; p = getEntry(key); // 替换值 if (p!=null) &#123; V oldValue = p.value; p.value = value; return oldValue; &#125; return null;&#125; 查一批以getFirstEntry()，getLastEntry()为基础的获取头和尾元素的方法，其中包括：firstKey()，lastKey()；firstEntry()，lastEntry()；pollFirstEntry()，pollLastEntry()12345678910111213141516171819// 返回第一个节点(值最小的节点)final Entry&lt;K,V&gt; getFirstEntry() &#123; Entry&lt;K,V&gt; p = root; if (p != null) // 一直遍历左子树 while (p.left != null) p = p.left; return p;&#125;// 返回最后一个节点(值最大的节点)final Entry&lt;K,V&gt; getLastEntry() &#123; Entry&lt;K,V&gt; p = root; if (p != null) // 一直遍历右子树 while (p.right != null) p = p.right; return p;&#125;]]></content>
      <categories>
        <category>JDK源码分析</category>
      </categories>
      <tags>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK源码分析——HashSet]]></title>
    <url>%2F2018%2F09%2F06%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E2%80%94%E2%80%94HashSet%2F</url>
    <content type="text"><![CDATA[引：如果用来有个去重的需求，你肯定会想到用HashSet，那我们看看它的实现！ 详细注释：源码分析地址 概览它是由哈希表（实际上是一个HashMap实例）支持，是不是有点意思？它不保证set的迭代顺序，有且只允许一个null元素，当然其他元素不能重复。 它不是同步容器。如果多个线程同时访问一个哈希set，而其中至少一个线程修改了该 set，那么它必须保持外部同步。这通常是通过对自然封装该set的对象执行同步操作来完成的。如果不存在这样的对象，则应该使用 Collections.synchronizedSet 方法来“包装” set。最好在创建时完成这一操作，以防止对该set进行意外的不同步访问。 所有这个类的方法返回的迭代器都是快速失败的 ：如果映射在迭代器创建之后的任何时间被结构地修改，除了通过迭代器自己的remove方法之外，迭代器将抛出一个ConcurrentModificationException。（老生长谈） 构造关于HashSet的操作(下面都是)，基本上都是直接调用底层HashMap的相关方法来完成。所以在后面参考找到自己关于HashMap的文章。123456789// 真的操作的执行者private transient HashMap&lt;E,Object&gt; map;// 定义一个"虚拟"的Object对象作为HashMap的valueprivate static final Object PRESENT = new Object();// 构造HashMappublic HashSet(int initialCapacity) &#123; map = new HashMap&lt;&gt;(initialCapacity);&#125; 增在HashMap新增一个键值对123public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; 删在HashMap删除一个键值对123public boolean remove(Object o) &#123; return map.remove(o)==PRESENT;&#125; 查在HashMap查找key是否存在123public boolean contains(Object o) &#123; return map.containsKey(o);&#125; 总结水文一篇，只要记住一点，就是只要理解了HashMap，HashSet is so easy！！ 参考 JDK源码分析——HashMap]]></content>
      <categories>
        <category>JDK源码分析</category>
      </categories>
      <tags>
        <tag>HashSet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK源码分析——ConcurrentHashMap]]></title>
    <url>%2F2018%2F09%2F04%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E2%80%94%E2%80%94ConcurrentHashMap%2F</url>
    <content type="text"><![CDATA[引：HashMap是我们平时开发过程中用的比较多的集合，但它是非线程安全的。解决方案有Hashtable和Collections.synchronizedMap(hashMap)，不过这两个方案基本上是对读写进行加锁操作，性能可想而知。所以感谢Doug Lea给我们带来了并发安全的ConcurrentHashMap。 详细注释：源码分析地址 概览ConcurrentHashMap 是一个并发散列映射表的实现，它允许完全并发的读取，并且支持给定数量的并发更新。它采用CAS操作和内置锁synchronized来实现同步 构造主要就是设置初始容量和负载因子。（很多在HashMap中介绍过的变量和常量，这里就不再次介绍了）12345678910111213141516171819202122// 默认为null，初始化发生在第一次插入操作，默认大小为16的数组，用来存储Node节点数据，扩容时大小总是2的幂次方transient volatile Node&lt;K,V&gt;[] table;// 默认为null，扩容时新生成的数组，其大小为原数组的两倍private transient volatile Node&lt;K,V&gt;[] nextTable;// 默认为0，用来控制table的初始化和扩容操作// -1：表示table正在初始化// -N：表示有N-1个线程正在进行扩容操作// 非负情况// 如果table未初始化，表示table需要初始化的大小// 如果table初始化完成，表示table的阈值，默认是table大小的0.75倍private transient volatile int sizeCtl;// 根据initialCapacity初始化// initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)没看懂，知道的请call me（难道和0.75有关系？）public ConcurrentHashMap(int initialCapacity) &#123; // ... int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); // 复制给 sizeCtl this.sizeCtl = cap;&#125; 增新增节点，可能会（并发）扩容123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219// 通过Unsafe拿到sizeCtl的地址private static final long SIZECTL;// 通过Unsafe拿到baseCount的地址private static final long BASECOUNT;// 移动节点的hash值，只在transfer(扩容方法中)新建ForwardingNode设置static final int MOVED = -1;public V put(K key, V value) &#123; return putVal(key, value, false);&#125;final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); // 对hashCode进行再散列 // 算法为(h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS(0x7fffffff) int hash = spread(key.hashCode()); // 准备遍历table int binCount = 0; // 这边加了一个循环，就是不断的尝试 for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) // 初始化table tab = initTable(); // 获取对应下标节点，如果是空，直接插入 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; // CAS 进行插入 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; // 如果 hash 冲突了 // 且 hash 值为 -1(MOVED)，说明是 ForwardingNode 对象（这是一个占位符对象，保存了扩容后的容器） // 表示了正在扩容，需要帮助 Map 进行扩容，以加快速度 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); // 如果 hash 冲突了，且 hash 值不为 -1 else &#123; V oldVal = null; // 同步 f 节点，防止增加链表的时候导致链表成环(会出现死循环) synchronized (f) &#123; // 如果对应的下标位置 的节点没有改变 if (tabAt(tab, i) == f) &#123; // 并且 f 节点的hash 值 大于0 if (fh &gt;= 0) &#123; // 链表长度 binCount = 1; // 死循环，直到将值添加到链表尾部，并计算链表的长度 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; // 遇到重复的key，根据标志位覆盖 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; // 尾部插入 if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; // 如果 f 节点的 has 小于0 并且f 是 树类型 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; // 插入树中 if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; // 链表长度大于等于8时，将该节点改成红黑树树 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; // 判断是否需要扩容CAS addCount(1L, binCount); return null;&#125;// 初始化tableprivate final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; // 如果一个线程发现sizeCtl&lt;0，意味着另外的线程执行CAS操作成功 // 当前线程只需要让出cpu时间片 if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin // CAS 修改 sizeCtl 的值为-1 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; // sc 在初始化的时候用户可能会自定义，如果没有自定义，则是默认的16 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; // 计算后作为扩容的阀值(相当于乘以0.75) sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125;/** * Helps transfer if a resize is in progress. * 如果正在扩容，则帮助扩容 */final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; // 如果 table 不是空 且 node 节点是转移节点 // // 且 node 节点的 nextTable（新 table） 不是空 if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; // 根据 length 得到一个标识符号 int rs = resizeStamp(tab.length); // 如果 nextTab 没有被并发修改 且 tab 也没有被并发修改 且 sizeCtl &lt; 0 （说明还在扩容） while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; // 如果 sizeCtl 无符号右移 16 不等于 rs （ sc前 16 位如果不等于标识符，则标识符变化了） // 或者 sizeCtl == rs + 1 （扩容结束了，不再有线程进行扩容）（默认第一个线程设置 sc ==rs 左移 16 位 + 2，当第一个线程结束扩容了，就会将 sc 减一。这个时候，sc 就等于 rs + 1） // 或者 sizeCtl == rs + 65535 （如果达到最大帮助线程的数量，即 65535） // 或者转移下标正在调整 （扩容结束） // 结束循环，返回 table if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; // 如果以上都不是, 将 sizeCtl + 1, （表示增加了一个线程帮助其扩容） if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; // 扩容 transfer(tab, nextTab); break; &#125; &#125; return nextTab; &#125; return table;&#125;// 判断是否需要扩容，需要则进行扩容private final void addCount(long x, int check) &#123; CounterCell[] as; long b, s; // 如果计数盒子不是空 或者 修改 baseCount 失败 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; long v; int m; boolean uncontended = true; // 如果计数盒子是空（尚未出现并发）或者 随机取余一个数组位置为空 // 或者 修改这个槽位的变量失败（出现并发了） if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; // CAS增加 fullAddCount(x, uncontended); return; &#125; if (check &lt;= 1) return; // 统计size s = sumCount(); &#125; // 如果需要检查,检查是否需要扩容，在 putVal 方法调用时，默认就是要检查的。 if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; // 如果map.size() 大于 sizeCtl（达到扩容阈值需要扩容） // 且table 不是空；且 table 的长度小于 1 &lt;&lt; 30。（可以扩容） while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; int rs = resizeStamp(n // 如果正在扩容 if (sc &lt; 0) &#123; // 如果 sc 的低 16 位不等于 标识符（校验异常 sizeCtl 变化了） // 如果 sc == 标识符 + 1 （扩容结束了，不再有线程进行扩容）（默认第一个线程设置 sc ==rs 左移 16 位 + 2，当第一个线程结束扩容了，就会将 sc 减一。这个时候，sc 就等于 rs + 1） // 如果 sc == 标识符 + 65535（帮助线程数已经达到最大） // 如果 nextTable == null（结束扩容了） // 如果 transferIndex &lt;= 0 (转移状态变化了) // 结束循环 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; // 如果可以帮助扩容，那么将 sc 加 1. 表示多了一个线程在帮助扩容 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) // 扩容(有点复杂，设计到并发扩容，可以在后面的参考找到文章，这里就不分析了) transfer(tab, nt); &#125; // 如果不在扩容，将 sc 更新：标识符左移 16 位 然后 + 2. 也就是变成一个负数。高 16 位是标识符，低 16 位初始是 2. else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) // 更新 sizeCtl 为负数后，开始扩容。 transfer(tab, null); // 统计size s = sumCount(); &#125; &#125;&#125; 删根据key删除键值对，如果key不存在，什么也不做123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990public V remove(Object key) &#123; return replaceNode(key, null, null);&#125;// 用新cv取代原来的value，如果value是null，就代表删除final V replaceNode(Object key, V value, Object cv) &#123; // 计算key的hash值 int hash = spread(key.hashCode()); for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; // table为空 或 容量为0 或 不存在 if (tab == null || (n = tab.length) == 0 || (f = tabAt(tab, i = (n - 1) &amp; hash)) == null) break; // 正在扩容 else if ((fh = f.hash) == MOVED) // 协助扩容 tab = helpTransfer(tab, f); else &#123; V oldVal = null; boolean validated = false; // 同步删除 synchronized (f) &#123; // 桶中的第一个结点没有发生变化 if (tabAt(tab, i) == f) &#123; // 替换链表中的节点 if (fh &gt;= 0) &#123; validated = true; for (Node&lt;K,V&gt; e = f, pred = null;;) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; V ev = e.val; if (cv == null || cv == ev || (ev != null &amp;&amp; cv.equals(ev))) &#123; oldVal = ev; // value不为null，替换 if (value != null) e.val = value; // value为null，删除 else if (pred != null) // 前驱的后继为e的后继，即删除了e结点 pred.next = e.next; else setTabAt(tab, i, e.next); &#125; break; &#125; pred = e; if ((e = e.next) == null) break; &#125; &#125; // 替换红黑树中的节点 else if (f instanceof TreeBin) &#123; validated = true; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; r, p; if ((r = t.root) != null &amp;&amp; (p = r.findTreeNode(hash, key, null)) != null) &#123; V pv = p.val; if (cv == null || cv == pv || (pv != null &amp;&amp; cv.equals(pv))) &#123; oldVal = pv; // value不为null，替换 if (value != null) p.val = value; // value为null，删除 else if (t.removeTreeNode(p)) // 返回为true，去树化 setTabAt(tab, i, untreeify(t.first)); &#125; &#125; &#125; &#125; &#125; if (validated) &#123; if (oldVal != null) &#123; if (value == null) // 总数-1 addCount(-1L, -1); return oldVal; &#125; break; &#125; &#125; &#125; return null;&#125; 改123456public boolean replace(K key, V oldValue, V newValue) &#123; if (key == null || oldValue == null || newValue == null) throw new NullPointerException(); // 对于replaceNode方法在删除操作中已经解析过了 return replaceNode(key, newValue, oldValue) != null;&#125; 查根据key获取value12345678910111213141516171819202122232425public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; // 计算key的hash int h = spread(key.hashCode()); // table不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; // 判断头节点是否符合 if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; // 在树中查找，小于0的代表了树的根节点，因为树的根节点的哈希值为TREEBIN（-2） else if (eh &lt; 0) // 调用红黑树的查找方法 return (p = e.find(h, key)) != null ? p.val : null; // 在链表中查找 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; 总结ConcurrentHashMap 是 Doug Lea 的神作，可以说是精彩绝伦，总的来说，使用了 CAS（扩容并发） 和 synchronized 来保证了 put 操作并发时的危险（特别是链表，防止了死循环的发生），在读方法完全没有锁，完全并发，相比其他线程安全的Map，它的性能真是杠杠滴。写完才发现自己只是打了注释，还没有概括性的话语，缺少了总结，以后需要注意。除此之外，ConcurrentHashMap肯定不是一遍文章就能说完了，以后还需要基础回顾，继续补充。 参考 java内存模型 java中的Unsafe 深入浅出CAS 深入浅出java同步器AQS 深入浅出ReentrantLock Java并发容器ConcurrentHashMap原理及HashMap死循环原因的分析 ConcurrentHashMap 源码阅读小结 深入浅出ConcurrentHashMap1.8]]></content>
      <categories>
        <category>JDK源码分析</category>
      </categories>
      <tags>
        <tag>ConcurrentHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK源码分析——HashMap]]></title>
    <url>%2F2018%2F09%2F03%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E2%80%94%E2%80%94HashMap%2F</url>
    <content type="text"><![CDATA[引：在Collection接口中用的最多的是ArrayList，在Map接口中用的最多的一定是HashMap，我们今天就来看看HashMap！ 详细注释：源码分析地址 概览它是基于哈希表实现的Map接口，允许null的值和null键。 HashMap的一个实例有两个影响其性能的参数： 初始容量和负载因子。容量是哈希表中的桶数，初始容量只是创建哈希表时的容量。 负载因子是在容量自动增加之前允许哈希表充满程度的度量。 当在散列表中的条目的数量超过了负载因数和容量的乘积，哈希表将被重新散列 （即内部数据结构被重建），使得哈希表具有桶的大约两倍。 作为一般规则，默认负载因子（0.75）提供了时间和空间成本之间的良好折中。 更高的值会降低空间开销，但会增加查找成本（反映在HashMap类的大部分操作中，包括get和put ）。 在设置其初始容量时，应考虑Map中预期的条目数及其负载因子，以便最小化重新散列操作的数量。 如果初始容量大于最大条目数除以负载因子，则不会发生重新散列操作。 注意，HashMap不同步。 如果多个线程同时访问哈希映射，并且至少有一个线程在结构上修改了映射，那么它必须在外部进行同步。 （结构修改是添加或删除一个或多个映射的任何操作;仅改变与实例已经包含的Key相关联的值不是结构修改。）这通常通过对自然地封装映射的一些对象（ConcurrentMap等）进行同步来实现。 如果没有这样的对象存在，应该使用Collections.synchronizedMap方法“包装”。 所有这个类的方法返回的迭代器都是快速失败的 ：如果映射在迭代器创建之后的任何时间被结构地修改，除了通过迭代器自己的remove方法之外，迭代器将抛出一个ConcurrentModificationException 。 构造在构造方法中主要就是设置初始容量和负载因子，如下面：123456789101112131415161718192021222324252627282930313233// 最大容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 默认初始容量，一定是2的n次方，这里是16static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;// 默认负载因子，这里是0.75static final float DEFAULT_LOAD_FACTOR = 0.75f;// 这里是Map存放条目的阈值int threshold;// 初始的节点数组，这里Node是个双向节点链表（下面注释中会直接说table）transient Node&lt;K,V&gt;[] table;public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;public HashMap(int initialCapacity, float loadFactor) &#123; // ... this.loadFactor = loadFactor; // 可能大家觉得阈值应该需要乘以负载因子，先别急，往后看 this.threshold = tableSizeFor(initialCapacity);&#125;// 根据所给的目标容量返回大于或等于2的幂次方// 感觉这里吊炸天，看不懂的可以看后面参考的博客static final int tableSizeFor(int cap) &#123; // 这里一定要减1，不然对于本来就是2的幂次方的数，会变成原来的两倍 int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 这里解答一下为什么要是2的幂次方？首先提一个东西就是散列到HashMap中是通过下面的公式：hash &amp;(cap-1) 假设cap容量为15、16，那么他们减1之后的二进制表达为1110、1111，那么0001、0011、0101、0111, 1001、1011、1101这些桶将永远不会被用到。所以我们需要2的幂次方。 这里既然看到了hash我们就看一下HashMap的hash函数优化：12345static final int hash(Object key) &#123; int h; // 这里叫扰动函数(加入高位特征)，减少hash碰撞，具体的可以看后面参考里的文章 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 增这里会有很多细节，需要耐心慢慢看。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// hash冲突的链表树化阈值（至少为8）static final int TREEIFY_THRESHOLD = 8;// 从树还原为链表阈值（小于6）static final int UNTREEIFY_THRESHOLD = 6;// 增加键值对，如果key已存在，则覆盖public V put(K key, V value) &#123; // 返回生成的节点 return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 初始节点数组table为空或者长度为0 if ((tab = table) == null || (n = tab.length) == 0) // 生成节点数组（这里会涉及到初始化table或扩容，下面会说），并返回长度 n = (tab = resize()).length; // //如果新存放的hash值没有冲突，则放入tab if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; // 否则就是产生了hash冲突 Node&lt;K,V&gt; e; K k; // 如果hash值相等且key值相等, 则令e指向冲突的头节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 如果头节点的key值与新插入的key值不等, 并且头结点是TreeNode类型,说明该hash值冲突是采用红黑树进行处理 else if (p instanceof TreeNode) // 强转为TreeNode，插入黑红树(本篇文章不谈黑红树的操作，具体的黑红树操作看后续博文，下同) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 否则就是采用链表处理hash值冲突 else &#123; // 遍历冲突链表, binCount记录hash值冲突链表中节点个数 for (int binCount = 0; ; ++binCount) &#123; // //当遍历到冲突链表的尾部时 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 冲突链表节点大于8个 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 红黑树化 treeifyBin(tab, hash); break; &#125; //如果在冲突链表中找到相同key值的节点，直接用新的value覆盖原来的value值即可 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; // 判断onlyIfAbsent是否覆盖 // true表示仅当&lt;key,value&gt;不存在时进行插入, 为false表示强制覆盖 if (!onlyIfAbsent || oldValue == null) e.value = value; // 处理访问回调动作 afterNodeAccess(e); return oldValue; &#125; &#125; // 修改次数自增 ++modCount; // 当键值对数量size达到临界值threhold后, 需要进行扩容操作 if (++size &gt; threshold) resize(); // 处理插入回调动作 afterNodeInsertion(evict); return null;&#125; 初始化table或者对table进行扩容(默认2倍)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697final Node&lt;K,V&gt;[] resize() &#123; // //oldTab变量指向原来的数组 Node&lt;K,V&gt;[] oldTab = table; // 用来判断是扩容还是初始化 int oldCap = (oldTab == null) ? 0 : oldTab.length; // oldThr变量保存原来数组的阈值 int oldThr = threshold; int newCap, newThr = 0; // 如果原来就有东西，就进行扩容操作 if (oldCap &gt; 0) &#123; // 当大于最大容量时，不扩容，只是改变阈值 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // &lt;&lt; 表示乘以2，变为原来的2倍（在操作默认大小的情况下） else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // 新阈值也变为原来的2倍 newThr = oldThr &lt;&lt; 1; // double threshold &#125; // oldCap=0, 说明原来的table数组为null，开始初始化 // 新创建的容器容量为原来容器中设定的临界值（16） else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults // 在没有设置阈值的情况下 newCap = DEFAULT_INITIAL_CAPACITY; // 初始阈值=默认负载因子*默认初始化容量 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; // 这里对应的设置了阈值的情况下的初始化，设置阈值 float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; // 给threshold复制，这里应该也就解答了再构造那节提出的疑问了 threshold = newThr; // 创建新数组 @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 如果原来的数组中存在值, 需要将原来数组中的值保存到新数组中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123;、 // 释放的对象及时置空，等待gc回收 oldTab[j] = null; if (e.next == null) // 重新hash进入新的数组 newTab[e.hash &amp; (newCap - 1)] = e; //如果原来这个节点已经转化为红黑树了， //那么我们去将树上的节点rehash之后根据hash值放到新地方 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order // 这说明原来数组中保存的hash值存在冲突, 但是并没有采用红黑树对冲突的Hash值进行管理, 而是采用Node链表进行管理 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 如果为真，表明在扩容后(e.hash &amp; (newCap - 1))还会和e.hash &amp; (oldCap - 1)一样 // 如果为假，表名这些节点将hash在（当前下标 + oldCap）下 // 不懂的可以在思考🤔一下,使用这种操作，可以减少重新Hash计算 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; // //返回新数组的引用 return newTab;&#125; 删123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263//删除key对应的键值对public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;// 删除节点// 参数hash为key的hash值;// 参数key为要删除的key键;// 参数value为key对应的value;// 参数matchValue为true表明只有key在HashMap中对应值为value时才删除; 为false表示强制删除;final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; // 在table中查找对应hash值 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; // 当头节点就匹配到了 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; // 如果头节点是个树节点 if (p instanceof TreeNode) // 从红黑树中找取节点 node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; // 从链表中找取节点 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; // 匹配找到的节点的值 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; // 树中 if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) // 首节点 tab[index] = node.next; else // 链表中 p.next = node.next; ++modCount; --size; afterNodeRemoval(node); // 返回删除的节点 return node; &#125; &#125; return null;&#125; 改改变对应key的值1234567891011121314151617181920212223242526272829303132333435public boolean replace(K key, V oldValue, V newValue) &#123; Node&lt;K,V&gt; e; V v; // 根据key找出节点 if ((e = getNode(hash(key), key)) != null &amp;&amp; ((v = e.value) == oldValue || (v != null &amp;&amp; v.equals(oldValue)))) &#123; e.value = newValue; afterNodeAccess(e); return true; &#125; return false;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // 找出桶的头结点 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 判断头节点 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; // 在树中找 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 在链表中找 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 查根据key查找值12345public V get(Object key) &#123; Node&lt;K,V&gt; e; // 这里的getNode和上面解析的一样 return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; 参考 HashMap源码注解 之 静态工具方法hash()、tableSizeFor()（四） HashMap中的hash函数 强推👍：Java源码分析：关于 HashMap 1.8 的重大更新]]></content>
      <categories>
        <category>JDK源码分析</category>
      </categories>
      <tags>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK源码分析——ArrayList]]></title>
    <url>%2F2018%2F09%2F02%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2FJDK%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E2%80%94%E2%80%94ArrayList%2F</url>
    <content type="text"><![CDATA[引：大家在集合框架中用的最多一定是ArrayList吧，今天我们就来一探究竟！ 详细注释：源码分析地址 概览ArrayList是基于可变数组实现了，允许包括 null 在内的所有元素。 每个 ArrayList 实例都有一个容量。该容量是指用来存储列表元素的数组的大小。它总是至少等于列表的大小。随着向 ArrayList 中不断添加元素，其容量也自动增长。 在添加大量元素前，应用程序可以使用 ensureCapacity 操作来增加 ArrayList 实例的容量。这可以减少递增式再分配的数量。 注意： 此实现不是同步的。如果多个线程同时访问一个 ArrayList 实例，而其中至少一个线程从结构上修改了列表，那么它必须保持外部同步。（结构上的修改是指任何添加或删除一个或多个元素的操作，或者显式调整底层数组的大小；仅仅设置元素的值不是结构上的修改。）这一般通过对自然封装该列表的对象进行同步操作来完成。如果不存在这样的对象，则应该使用 Collections.synchronizedList 方法将该列表“包装”起来。这最好在创建时完成，以防止意外对列表进行不同步的访问。 此类的 iterator 和 listIterator 方法返回的迭代器是快速失败的：在创建迭代器之后，除非通过迭代器自身的 remove 或 add 方法从结构上对列表进行修改，否则在任何时间以任何方式对列表进行修改，迭代器都会抛出 ConcurrentModificationException。 ArrayList从类 java.util.AbstractList 继承了字段 modCount，在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了需要抛出 ConcurrentModificationException。 构造12345678910111213// 默认数组初始大小为10private static final int DEFAULT_CAPACITY = 10;public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; // 返回空数组 this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: " + initialCapacity); &#125;&#125; 增1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// 新增元素public boolean add(E e) &#123; // 确保容量足够 ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;private void ensureCapacityInternal(int minCapacity) &#123; // 如果是默认创建的数组，则和容量默认值比较 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; // 确保容量足够 ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; // 修改操作加1 modCount++; // overflow-conscious code // 如果需要的容量比数组长度大，则进行扩容 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private void grow(int minCapacity) &#123; // overflow-conscious code // 新容量将使原来的1.5倍 int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 1.5倍还不够的话，就将容量设置为需要的大小 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 如果新容量比最大的数组容量（Integer.MAX_VALUE - 8;）还要大，则创建更大的容量（Integer.MAX_VALUE） if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: // Arrays.copyOf() 是把原数组整个复制到新数组，这个代价很高 // 因此最好在创建 ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数 elementData = Arrays.copyOf(elementData, newCapacity);&#125;private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; 删删除需要将 index+1 后面的元素都复制到 index 位置上，该操作的时间复杂度为 O(N)，所以ArrayList 删除元素的代价是非常高的。123456789101112131415161718public E remove(int index) &#123; // 验证index是否超出size大小 rangeCheck(index); modCount++; // 拿到值 E oldValue = elementData(index); // 统计要移动的位数 int numMoved = size - index - 1; if (numMoved &gt; 0) // 调用系统方法开始拷贝 System.arraycopy(elementData, index+1, elementData, index, numMoved); // 即时放开引用，等待GC elementData[--size] = null; // clear to let GC do its work // 返回被删除的元素 return oldValue;&#125; 改12345678910public E set(int index, E element) &#123; // 验证index是否超出size大小 rangeCheck(index); // 拿出原值 E oldValue = elementData(index); // 设置新值 elementData[index] = element; // 返回被替换的值 return oldValue;&#125; 查12345678910public E get(int index) &#123; // 验证index是否超出size大小 rangeCheck(index); return elementData(index);&#125;E elementData(int index) &#123; // 拿出值 return (E) elementData[index];&#125; 序列化ArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 保存元素的数组 elementData 使用 transient 修饰，该关键字声明数组默认不会被序列化transient Object[] elementData;// 序列化private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff // 记录修改次数，后面可以根据他判断结构是否发生了变化 int expectedModCount = modCount; // 写入非静态，非暂时数据到流中 s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() // 写入元素个数 s.writeInt(size); // Write out all elements in the proper order. // 写入元素 for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; // 比较操作前后 modCount 是否改变，如果改变了需要抛出 ConcurrentModificationException。 if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125;&#125;// 反序列化private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff s.defaultReadObject(); // Read in capacity s.readInt(); // ignored if (size &gt; 0) &#123; // be like clone(), allocate array based upon size not capacity ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>JDK源码分析</category>
      </categories>
      <tags>
        <tag>ArrayList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RPC知识]]></title>
    <url>%2F2018%2F08%2F10%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2FRPC%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[引：转自徐靖峰|个人博客的RPC专栏，了解这些才能去看看RPC框架！！！ RPC系列博客 简单了解RPC实现原理 深入理解RPC之序列化篇–Kryo 深入理解RPC之序列化篇–总结篇 深入理解RPC之动态代理篇 深入理解 RPC 之传输篇 Motan中使用异步RPC接口 深入理解RPC之协议篇 深入理解RPC之服务注册与发现篇 深入理解 RPC 之集群篇 设计RPC接口时，你有考虑过这些吗？ 简单RPC可以参考todorex/rex_rpc]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>rpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty源码之编码器]]></title>
    <url>%2F2018%2F08%2F06%2FNetty%E6%BA%90%E7%A0%81%2FNetty%E6%BA%90%E7%A0%81%E4%B9%8B%E7%BC%96%E7%A0%81%E5%99%A8%2F</url>
    <content type="text"><![CDATA[引：上一篇博文讲了解码器对应了读事件，这次就讲一下编码器，对应了写事件。 编码器基类在Netty中解码器的基类是MessageToByteEncoder ，然后我们要明白的是MessageToByteEncoder其实是一个ChannelOutboundHandlerAdapter。 我们在使用的过程中主要就是覆写它的encode方法： 1protected abstract void encode(ChannelHandlerContext ctx, I msg, ByteBuf out) throws Exception; 一个编码器编码的过程主要有如下6个步骤： 匹配对象 分配内存 编码实现 释放对象 传播数据 释放内存 当我们知道MessageToByteEncoder是一个Handler的时候，我们就会去找它对事件的处理方法，主要是写事件，所以我们找到写事件处理方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// step 1public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &#123; ByteBuf buf = null; try &#123; // 判断是否能够处理该对象 // step 2 if (acceptOutboundMessage(msg)) &#123; // 能处理 I cast = (I) msg; // 内存分配(默认分配堆外内存 ) buf = allocateBuffer(ctx, cast, preferDirect); try &#123; // 开始调用我们覆写的encode方法了 encode(ctx, cast, buf); &#125; finally &#123; // 释放对象 ReferenceCountUtil.release(cast); &#125; if (buf.isReadable()) &#123; // 传播数据，一直传播到head节点处理 ctx.write(buf, promise); &#125; else &#123; // 如果编码没有成功，则是否内存 buf.release(); ctx.write(Unpooled.EMPTY_BUFFER, promise); &#125; buf = null; &#125; else &#123; // 不能处理，则继续传播 ctx.write(msg, promise); &#125; &#125; catch(EncoderException e) &#123; throw e; &#125; catch(Throwable e) &#123; throw new EncoderException(e); &#125; finally &#123; if (buf != null) &#123; buf.release(); &#125; &#125;&#125;// step 2private final TypeParameterMatcher matcher;public boolean acceptOutboundMessage(Object msg) throws Exception &#123; // step 3 return matcher.match(msg);&#125;// step 3public boolean match(Object msg) &#123; // 主要就是判断msg是否是MessageToByteEncoder&lt;I&gt;中的I类型 return type.isInstance(msg);&#125; write()之前自己在ChannelPipeline那章分析到HeadContext的write方法，没有继续往下分析，我们在这里分析： 它主要有这么几个过程： direct化ByteBuf 插入写链表 设置写状态 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101// step 1public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &#123; // step 2 unsafe.write(msg, promise);&#125;// step 2public final void write(Object msg, ChannelPromise promise) &#123; // 该对象负责缓冲写进来的数据 估算出需要写入的ByteBuf的size outboundBuffer = this.outboundBuffer; // ... int size; try &#123; // 将待写入的对象过滤,把所有的非直接内存转换成直接内存DirectBuffer // step 3 msg = filterOutboundMessage(msg); // 估算出需要写入的ByteBuf的size size = pipeline.estimatorHandle().size(msg); if (size &lt; 0) &#123; size = 0; &#125; &#125; catch(Throwable t) &#123; safeSetFailure(promise, t); ReferenceCountUtil.release(msg); return; &#125; // 将信息添加到估算出需要写入的ByteBuf的size // step 4 outboundBuffer.addMessage(msg, size, promise);&#125;// step 3protected final Object filterOutboundMessage(Object msg) &#123; if (msg instanceof ByteBuf) &#123; ByteBuf buf = (ByteBuf) msg; if (buf.isDirect()) &#123; return msg; &#125; // 转换成直接内存DirectBuffer return newDirectBuffer(buf); &#125; if (msg instanceof FileRegion) &#123; return msg; &#125;&#125;// step 4 ChannelOutboundBuffer// 一个链表// Entry(flushedEntry) --&gt; ... Entry(unflushedEntry) --&gt; ... Entry(tailEntry)//// 指向第一个已经flush的节点private Entry flushedEntry;// 指向第一个未flush的节点private Entry unflushedEntry;// 指向末尾节点private Entry tailEntry;public void addMessage(Object msg, int size, ChannelPromise promise) &#123; // 关注这三个指针tailEntry、tailEntry、unflushedEntry // 先包装成一个Entry Entry entry = Entry.newInstance(msg, size, total(msg), promise); // 插入链表 if (tailEntry == null) &#123; flushedEntry = null; &#125; else &#123; Entry tail = tailEntry; tail.next = entry; &#125; tailEntry = entry; if (unflushedEntry == null) &#123; unflushedEntry = entry; &#125; // 统计当前需要写入到Socket缓存区的字节 // step 5 incrementPendingOutboundBytes(entry.pendingSize, false);&#125;// step 5private void incrementPendingOutboundBytes(long size, boolean invokeLater) &#123; if (size == 0) &#123; return; &#125; long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, size); // 默认缓冲区不能超过64个字节 if (newWriteBufferSize &gt; channel.config().getWriteBufferHighWaterMark()) &#123; // 设置写状态 setUnwritable(invokeLater); &#125;&#125;// step 6private void setUnwritable(boolean invokeLater) &#123; for (;;) &#123; final int oldValue = unwritable; final int newValue = oldValue | 1; if (UNWRITABLE_UPDATER.compareAndSet(this, oldValue, newValue)) &#123; if (oldValue == 0 &amp;&amp; newValue != 0) &#123; // 传播不能写事件 fireChannelWritabilityChanged(invokeLater); &#125; break; &#125; &#125;&#125; flush()write不能写了就需要flush了，我们同样也从HeadContext的flush方法开始分析： 它主要有这么几个步骤： 添加刷新标志并设置写状态 遍历buffer队列，过滤ByteBuf 调用JDK底层的API进行自旋写 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113// step 1public void flush(ChannelHandlerContext ctx) throws Exception &#123; // step 2 unsafe.flush();&#125;// step 2public final void flush() &#123; ChannelOutboundBuffer outboundBuffer = this.outboundBuffer; // step 3 outboundBuffer.addFlush(); // step 5 flush0();&#125;// step 3public void addFlush() &#123; // 指向unflushedEntry Entry entry = unflushedEntry; if (entry != null) &#123; if (flushedEntry == null) &#123; flushedEntry = entry; &#125; do &#123; // 设置flush的数量 flushed++; if (!entry.promise.setUncancellable()) &#123; int pending = entry.cancel(); // step 4 decrementPendingOutboundBytes(pending, false, true); &#125; entry = entry.next; &#125; while ( entry != null ); // 将unflushedEntry设置为null unflushedEntry = null; &#125;&#125;// step 4private void decrementPendingOutboundBytes(long size, boolean invokeLater, boolean notifyWritability) &#123; long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, -size); // 默认缓冲区低于32个字节，则可设置可写 if (notifyWritability &amp;&amp; newWriteBufferSize &lt; channel.config().getWriteBufferLowWaterMark()) &#123; // 设置可写状态 setWritable(invokeLater); &#125;&#125;// step 5protected void flush0() &#123; final ChannelOutboundBuffer outboundBuffer = this.outboundBuffer; if (outboundBuffer == null || outboundBuffer.isEmpty()) &#123; return; &#125; // ... // step 6 doWrite(outboundBuffer);&#125;// step 6 NioSocketChannelprotected void doWrite(ChannelOutboundBuffer in) throws Exception &#123; // 拿到底层的SocketChannel准备开始底层的操作 SocketChannel ch = javaChannel(); // 获取循环次数，相当于一个自旋锁，默认16 int writeSpinCount = config().getWriteSpinCount(); do &#123; // 如果buffer里空的 if ( in .isEmpty()) &#123; // 清理OP_WRITE，防止Reacotr线程再次处理这个Channel clearOpWrite(); return; &#125; // 获取聚合写的最大字节数，默认Integer.MAX_VALUE int maxBytesPerGatheringWrite = ((NioSocketChannelConfig) config).getMaxBytesPerGatheringWrite(); // 把ByteBuf里的数据写到原生Buffer里 // step 7 ByteBuffer[] nioBuffers = in.nioBuffers(1024, maxBytesPerGatheringWrite); int nioBufferCnt = in.nioBufferCount(); // 对非Buffer对象（FileRegion）的数据进行普通的读写 switch (nioBufferCnt) &#123; case 0: // 没成功，自旋一次 writeSpinCount -= doWrite0( in ); break; case 1: // JDK NIO 支持一次写单个ByteBuffer 以及 一次写多个ByteBuffer的聚集写模式 // 如果只有一个buffer的情况下，直接把这个buffer写进去 ByteBuffer buffer = nioBuffers[0]; int attemptedBytes = buffer.remaining(); // 调用JDK底层的API进行写，完毕 final int localWrittenBytes = ch.write(buffer); if (localWrittenBytes &lt;= 0) &#123; incompleteWrite(true); return; &#125; adjustMaxBytesPerGatheringWrite(attemptedBytes, localWrittenBytes, maxBytesPerGatheringWrite); // 释放缓存对象 in.removeBytes(localWrittenBytes); --writeSpinCount; break; &#125; default: &#123; // 多个buffer的情况下，写nioBufferCnt个buffer进去 long attemptedBytes = in.nioBufferSize(); final long localWrittenBytes = ch.write(nioBuffers, 0, nioBufferCnt); if (localWrittenBytes &lt;= 0) &#123; incompleteWrite(true); return; &#125; adjustMaxBytesPerGatheringWrite((int) attemptedBytes, (int) localWrittenBytes, maxBytesPerGatheringWrite); in .removeBytes(localWrittenBytes); --writeSpinCount; break; &#125; &#125; &#125; while ( writeSpinCount &gt; 0 ); incompleteWrite(writeSpinCount &lt; 0);&#125; 知道write和flush那么就很容易理解writeAndFlush啦！！ 参考 etty源码分析之writeAndFlush全解析 Netty源码分析——flush流程 Netty 源码解析 ——— writeAndFlush流程分析]]></content>
      <categories>
        <category>Netty源码</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty源码之解码器]]></title>
    <url>%2F2018%2F08%2F06%2FNetty%E6%BA%90%E7%A0%81%2FNetty%E6%BA%90%E7%A0%81%E4%B9%8B%E8%A7%A3%E7%A0%81%E5%99%A8%2F</url>
    <content type="text"><![CDATA[引：Netty在帮我们解决性能的同时，也提供了丰富的编解码器来为我们业务上提供便利，这次我们就来看看Netty的解码器。 解码器基类解码：就是将二进制数据流解码为自定义数据包。 在Netty中解码器的基类是ByteToMessageDecoder，然后我们要明白的是ByteToMessageDecoder其实是一个ChannelInboundHandlerAdapter。 一个解码器解码的过程主要有如下三个步骤： 累加字节流 调用子类的decode方法进行解析 将解析到的ByteBuf向下传播 当我们知道ByteToMessageDecoder是一个Handler的时候，我们就会去找它对事件的处理方法，主要是读事件，所以我们找到读事件处理方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102// step 1ByteBuf cumulation;public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; // 解码器是相对于ByteBuf进行解码的(在入站的时候已经封装好了，可以参考自己之前关于Pipeline的博文) if (msg instanceof ByteBuf) &#123; // 存储解码后的数据 List CodecOutputList out = CodecOutputList.newInstance(); try &#123; ByteBuf data = (ByteBuf) msg; // 是否是第一次累加 first = cumulation == null; if (first) &#123; // 第一次 cumulation = data; &#125; else &#123; // 不是第一次，则进行累加 // 我们看看这个累加器的cumulate方法 step 2 cumulation = cumulator.cumulate(ctx.alloc(), cumulation, data); &#125; // 调用子类的decode方法进行解析 // step 3 callDecode(ctx, cumulation, out); &#125; catch(DecoderException e) &#123; throw e; &#125; catch(Exception e) &#123; throw new DecoderException(e); &#125; finally &#123; int size = out.size(); decodeWasNull = !out.insertSinceRecycled(); // 将解析到的对象向下继续传播 // step 5 fireChannelRead(ctx, out, size); // 回收list out.recycle(); &#125; &#125; else &#123; // 不是ByteBuf就直接向下传播 ctx.fireChannelRead(msg); &#125;&#125;// step 2public ByteBuf cumulate(ByteBufAllocator alloc, ByteBuf cumulation, ByteBuf in ) &#123; final ByteBuf buffer; // 当buf的数据大于cumulation的剩余容量时 if (cumulation.writerIndex() &gt; cumulation.maxCapacity() - in.readableBytes() || cumulation.refCnt() &gt; 1 || cumulation.isReadOnly()) &#123; // 进行扩容(扩容其实就是一个内存拷贝操作) buffer = expandCumulation(alloc, cumulation, in.readableBytes()); &#125; else &#123; // 不然就不扩容 buffer = cumulation; &#125; // 将数据写入buf buffer.writeBytes(in); // 释放传入的buf in.release(); return buffer;&#125;// step 3protected void callDecode(ChannelHandlerContext ctx, ByteBuf in , List &lt; Object &gt; out) &#123; while ( in .isReadable()) &#123; int outSize = out.size(); // 看list是否有对象 if (outSize &gt; 0) &#123; // 有对象则将list传播出去 fireChannelRead(ctx, out, outSize); // 并清空list out.clear(); outSize = 0; &#125; // 记录可读长度 int oldInputLength = in.readableBytes(); // 开始调用decode方法了 // step 4 decodeRemovalReentryProtection(ctx, in, out); // 什么都没有解析出来时 if (outSize == out.size()) &#123; // 代表当前的数据不能拼装成一个完整的数据包，break准备等待下一次数据包 if (oldInputLength == in.readableBytes()) &#123; break; &#125; else &#123; continue; &#125; &#125; &#125;&#125;// step 4final void decodeRemovalReentryProtection(ChannelHandlerContext ctx, ByteBuf in , List &lt; Object &gt; out) throws Exception &#123; // ... // 开始调用解码器子类的decode方法了 decode(ctx, in, out); // ...&#125;// step 5static void fireChannelRead(ChannelHandlerContext ctx, CodecOutputList msgs, int numElements) &#123; for (int i = 0; i &lt; numElements; i++) &#123; // msgs.getUnsafe(i)保证成byteBuf // 这里可能就会传播到业务的处理器 ctx.fireChannelRead(msgs.getUnsafe(i)); &#125;&#125; LineBasedFrameDecoder我们挑选了基于分隔符解码器LineBasedFrameDecoder来分析，它可以同时处理 \n以及\r\n两种类型的行分隔符，我们看看它的decode方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// step 1 (解码器模板)protected final void decode(ChannelHandlerContext ctx, ByteBuf in , List &lt; Object &gt; out) throws Exception &#123; // step 2 Object decoded = decode(ctx, in); if (decoded != null) &#123; // 拆除一个数据包就放进List里 out.add(decoded); &#125;&#125;// step 2 LineBasedFrameDecoderprivate boolean discarding;protected Object decode(ChannelHandlerContext ctx, ByteBuf buffer) throws Exception &#123; // 找到换行符位置 final int eol = findEndOfLine(buffer); // 第一次拆包不在丢弃模式下 if (!discarding) &#123; // 非丢弃模式下 // 找到分隔符 if (eol &gt;= 0) &#123; final ByteBuf frame; final int length = eol - buffer.readerIndex(); final int delimLength = buffer.getByte(eol) == '\r' ? 2 : 1; // 判断拆包的长度是否大于允许的最大长度，maxLength构造时传入 if (length &gt; maxLength) &#123; // 超出最大长度则丢弃这段数据，抛出异常 buffer.readerIndex(eol + delimLength); fail(ctx, length); return null; &#125; // 解码数据是否要包含分隔符 if (stripDelimiter) &#123; // 不包含 frame = buffer.readRetainedSlice(length); buffer.skipBytes(delimLength); &#125; else &#123; // 包含 frame = buffer.readRetainedSlice(length + delimLength); &#125; // 返回拆包后封装成的帧 return frame; &#125; else &#123; // 没找到分隔符 final int length = buffer.readableBytes(); if (length &gt; maxLength) &#123; // 如果大于最大长度，进入丢弃模式 // 保存丢弃长度 discardedBytes = length; buffer.readerIndex(buffer.writerIndex()); discarding = true; offset = 0; if (failFast) &#123; fail(ctx, "over " + discardedBytes); &#125; &#125; // 不大于，则返回null return null; &#125; &#125; else &#123; // 丢弃模式下 if (eol &gt;= 0) &#123; // 找到分割符 final int length = discardedBytes + eol - buffer.readerIndex(); final int delimLength = buffer.getByte(eol) == '\r' ? 2 : 1; buffer.readerIndex(eol + delimLength); discardedBytes = 0; discarding = false; if (!failFast) &#123; fail(ctx, length); &#125; &#125; else &#123; // 保存丢弃长度 discardedBytes += buffer.readableBytes(); // 改变读指针位置 buffer.readerIndex(buffer.writerIndex()); &#125; return null; &#125;&#125; 总结其他的解码器也可以根据LineBasedFrameDecoder的思路去分析。当然我们最需要关注的还是整个解码器的设计思想。学会去抽象一类东西。 参考 netty源码分析之拆包器的奥秘]]></content>
      <categories>
        <category>Netty源码</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty源码之ChannelPipeline]]></title>
    <url>%2F2018%2F08%2F06%2FNetty%E6%BA%90%E7%A0%81%2FNetty%E6%BA%90%E7%A0%81%E4%B9%8BChannelPipeline%2F</url>
    <content type="text"><![CDATA[引：其实前面就多次提到了ChannelPipeline，但是都没有详细说明ChannelPipeline是如何工作的，这里我们就具体看看这个管理处理逻辑的抽象以及处理逻辑的抽象ChannelHandler。 ChannelPipeline的创建通过前面的讲解，我们应该还记得一个Channel对应了一个ChannelPipeline，而ChannelPipeline也就是在创建Channel的时候随之创建的。我们就从那里开始。 1234567891011121314151617181920212223// step 1 AbstractChannel的创建protected AbstractChannel(Channel parent) &#123; this.parent = parent; id = newId(); unsafe = newUnsafe(); // step 2 ChannelPipeline的创建 pipeline = newChannelPipeline();&#125;// step 2protected DefaultChannelPipeline newChannelPipeline() &#123; // step 3 return new DefaultChannelPipeline(this);&#125;// step 3protected DefaultChannelPipeline(Channel channel) &#123; // 绑定channel this.channel = ObjectUtil.checkNotNull(channel, "channel"); // 默认创建一个由头尾节点的双向链表，我们可以看一下节点的类型 tail = new TailContext(this); head = new HeadContext(this); head.next = tail; tail.prev = head;&#125; ChannelPipeline创建完毕！！ 节点的添加节点的添加我们必然要从我们见过的ChannelPipeline的addLast(handler)方法开始分析： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// step 1public final ChannelPipeline addLast(ChannelHandler handler) &#123; // step 2 return addLast(null, handler);&#125;// step 2public final ChannelPipeline addLast(String name, ChannelHandler handler) &#123; // step 3 return addLast(null, name, handler);&#125;// step 3public final ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler) &#123; final AbstractChannelHandlerContext newCtx; // 同步 synchronized(this) &#123; // 检查是否有重复节点 checkMultiplicity(handler); // 将handler包装成节点上下文 DefaultChannelHandlerContext // step 4 newCtx = newContext(group, filterName(name, handler), handler); // 添加节点 step 7 addLast0(newCtx); &#125; // 回调处理器被添加的方法 callHandlerAdded0(newCtx); return this;&#125;// step 4private AbstractChannelHandlerContext newContext(EventExecutorGroup group, String name, ChannelHandler handler) &#123; // step 5 return new DefaultChannelHandlerContext(this, childExecutor(group), name, handler);&#125;// step 5DefaultChannelHandlerContext(DefaultChannelPipeline pipeline, EventExecutor executor, String name, ChannelHandler handler) &#123; // step 6 isInBound,isOutBount已经确定了 super(pipeline, executor, name, isInbound(handler), isOutbound(handler)); // 绑定handler this.handler = handler;&#125;// step 6AbstractChannelHandlerContext(DefaultChannelPipeline pipeline, EventExecutor executor, String name, boolean inbound, boolean outbound) &#123; // 设定名字 this.name = ObjectUtil.checkNotNull(name, "name"); // 绑定pipeline this.pipeline = pipeline; // 绑定NioEventLoop this.executor = executor; // 表示自己是inbound处理器还是outbound处理器，后面根据这个值来判断 this.inbound = inbound; this.outbound = outbound;&#125;// step 7private void addLast0(AbstractChannelHandlerContext newCtx) &#123; // 添加到Pipeline的那个双向链表中 AbstractChannelHandlerContext prev = tail.prev; newCtx.prev = prev; newCtx.next = tail; prev.next = newCtx; tail.prev = newCtx;&#125; 节点的删除和ChannelPipeline的addLast(handler)一样，我们可以找到ChannelPipeline的remove(handler)方法： 123456789101112131415161718192021222324252627// step 1public final ChannelPipeline remove(ChannelHandler handler) &#123; // 我们知道节点是保证了handler的AbstractChannelHandlerContext // step 2 remove(getContextOrDie(handler)); return this;&#125;// step 2private AbstractChannelHandlerContext remove(final AbstractChannelHandlerContext ctx) &#123; assert ctx != head &amp;&amp; ctx != tail; // 同步 synchronized(this) &#123; // step 3 remove0(ctx); &#125; // 回调节点的删除方法 callHandlerRemoved0(ctx); return ctx;&#125;// step 3private static void remove0(AbstractChannelHandlerContext ctx) &#123; // 就是双向链表的删除 AbstractChannelHandlerContext prev = ctx.prev; AbstractChannelHandlerContext next = ctx.next; prev.next = next; next.prev = prev;&#125; 入站事件的传播其实我们应该已经经历过了，源头都是在从Unsafe对象(它负责最底层的IO操作)出发的，所以我们从NioEventLoop的这一段代码出发： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192// step 1private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) &#123; // ... if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &#123; // 接受IO事件，这里需要注意的是在SeverSocketChannel和SocketChannel处理的事件是不一样的 // 我们主要分析SocketChannel的读事件，对应的Unsafe对象是NioByteUnSafe // step 2 unsafe.read(); &#125;&#125;// step 2 AbstractNioByteChannel的NioByteUnSafepublic final void read() &#123; final ChannelConfig config = config(); final ChannelPipeline pipeline = pipeline(); // 创建ByteBuf分配器 final ByteBufAllocator allocator = config.getAllocator(); // 控制连接数 final RecvByteBufAllocator.Handle allocHandle = recvBufAllocHandle(); allocHandle.reset(config); ByteBuf byteBuf = null; do &#123; // 分配一个byteBuf byteBuf = allocHandle.allocate(allocator); // 读数据 allocHandle.lastBytesRead(doReadBytes(byteBuf)); allocHandle.incMessagesRead(1); readPending = false; // 触发读事件，这是我们要关注的重点 // step 3 pipeline.fireChannelRead(byteBuf); byteBuf = null; &#125; while ( allocHandle . continueReading ()); allocHandle.readComplete(); // 触发读完成事件 pipeline.fireChannelReadComplete();&#125;// step 3public final ChannelPipeline fireChannelRead(Object msg) &#123; // 出发头节点的读事件 // step 4 AbstractChannelHandlerContext.invokeChannelRead(head, msg); return this;&#125;// step 4static void invokeChannelRead(final AbstractChannelHandlerContext next, Object msg) &#123; final Object m = next.pipeline.touch(ObjectUtil.checkNotNull(msg, "msg"), next); // 调用头节点的channelRead方法 // step 5 next.invokeChannelRead(m);&#125;// step 5private void invokeChannelRead(Object msg) &#123; // 调用头节点的channelRead方法 // step 6 ((ChannelInboundHandler) handler()).channelRead(this, msg);&#125;// step 6public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; // 继续传递读事件 // step 7 ctx.fireChannelRead(msg);&#125;// step 7public ChannelHandlerContext fireChannelRead(final Object msg) &#123; // 找到下一个入站节点 // step 8 findContextInbound // step 9 会重复这个过程，如果消息没有被释放，那么将一直传递到tail节点(最后一个inbound节点public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; onUnhandledInboundMessage(msg);&#125;) invokeChannelRead(findContextInbound(), msg); return this;&#125;// step 8private AbstractChannelHandlerContext findContextInbound() &#123; AbstractChannelHandlerContext ctx = this; do &#123; ctx = ctx.next; // 可以看到是根据标志位来判定的 &#125; while (! ctx . inbound ); return ctx;&#125;// step 9 DefaultChannelPipeline的TailContextpublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; // step 10 onUnhandledInboundMessage(msg);&#125;protected void onUnhandledInboundMessage(Object msg) &#123; // 如果消息一直没有被释放，将在tail节点被释放 ReferenceCountUtil.release(msg);&#125; 出站事件的传播出站事件一般是写事件，有两种写需要区别一下：（来自netty源码中telnet例子） 12ChannelFuture future = ctx.channel().write(response); // 1ChannelFuture future = ctx.write(response); // 2 我们先看第一种： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// step 1public void channelRead0(ChannelHandlerContext ctx, String request) throws Exception &#123; // step 2 ChannelFuture future = ctx.channel().write(response);&#125;// step 2 AbstractChannelpublic ChannelFuture write(Object msg) &#123; // step 3 return pipeline.write(msg);&#125;// step 3 DefaultChannelPipelinepublic final ChannelFuture write(Object msg) &#123; // 直接调用tail的写方法 // step 4 return tail.write(msg);&#125;// step 5 AbstractChannelHandlerContextpublic ChannelFuture write(Object msg) &#123; // step 6 return write(msg, newPromise());&#125;// step 6 AbstractChannelHandlerContextpublic ChannelFuture write(final Object msg, final ChannelPromise promise) &#123; // 加上是否flush的信息 // step 7 write(msg, false, promise);&#125;// step 7private void write(Object msg, boolean flush, ChannelPromise promise) &#123; // 和进站相识，这里找的出站节点 AbstractChannelHandlerContext next = findContextOutbound(); final Object m = pipeline.touch(msg, next); EventExecutor executor = next.executor(); if (flush) &#123; next.invokeWriteAndFlush(m, promise); &#125; else &#123; // 调用下一个出站节点的写方法 next.invokeWrite(m, promise); &#125;&#125;// step 7private void invokeWrite(Object msg, ChannelPromise promise) &#123; // step 8 invokeWrite0(msg, promise);&#125;// step 8private void invokeWrite0(Object msg, ChannelPromise promise) &#123; // step 9 会直接调用到HeadContext的write方法 ((ChannelOutboundHandler) handler()).write(this, msg, promise);&#125;// step 9public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &#123; // 利用unsafe写入(明白流程就好，关于具体怎么写入将放到编码器的博文上) unsafe.write(msg, promise);&#125; 第二种情况： 12345678910// step 1public void channelRead0(ChannelHandlerContext ctx, String request) throws Exception &#123; // step 2 ChannelFuture future = ctx.write(response);&#125;// step 2public ChannelFuture write(final Object msg, final ChannelPromise promise) &#123; // 直接从当前节点写，后面就和第一种情况一样了 write(msg, false, promise);&#125; 参考 netty源码分析之pipeline(一) netty源码分析之pipeline(二)]]></content>
      <categories>
        <category>Netty源码</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty源码之新连接接入]]></title>
    <url>%2F2018%2F08%2F06%2FNetty%E6%BA%90%E7%A0%81%2FNetty%E6%BA%90%E7%A0%81%E4%B9%8B%E6%96%B0%E8%BF%9E%E6%8E%A5%E6%8E%A5%E5%85%A5%2F</url>
    <content type="text"><![CDATA[引：之前对服务端和NioEventLoop都有了一定的分析，相信大家的服务端应该已经虚位以待了。好的，我们现在就开始分析新连接接入。 新连接检测用过NIO的人都会知道新连接检测应该在处理select出来的SelectedKey中出现，所以我们就从这开始： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// step 1private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) &#123; final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe(); eventLoop = ch.eventLoop(); int readyOps = k.readyOps(); if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) &#123; int ops = k.interestOps(); ops &amp;= ~SelectionKey.OP_CONNECT; k.interestOps(ops); unsafe.finishConnect(); &#125; if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) &#123; ch.unsafe().forceFlush(); &#125; // 会进入到这里(接收连接) if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &#123; // step 2 unsafe.read(); &#125;&#125;// step 2 AbstractNioMessageChannelpublic void read() &#123; final ChannelConfig config = config(); final ChannelPipeline pipeline = pipeline(); // 控制读取连接的速率，默认一次读取16个连接 final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle(); allocHandle.reset(config); do &#123; // step 3 int localRead = doReadMessages(readBuf); // 对连接数增加 allocHandle.incMessagesRead(localRead); &#125; while ( allocHandle . continueReading ()); int size = readBuf.size(); for (int i = 0; i &lt; size; i++) &#123; readPending = false; // 触发读事件，绑定到NioEventLoop pipeline.fireChannelRead(readBuf.get(i)); &#125; readBuf.clear(); allocHandle.readComplete(); pipeline.fireChannelReadComplete();&#125;// step 3protected int doReadMessages(List &lt; Object &gt; buf) throws Exception &#123; // 熟悉的accept方法，熟悉的javaChannel()拿到serverSocketChannel // step 4 SocketChannel ch = SocketUtils.accept(javaChannel()); // 封装成NioSocketChannel，进入创建部分 buf.add(new NioSocketChannel(this, ch));&#125;// step 4public static SocketChannel accept(final ServerSocketChannel serverSocketChannel) throws IOException &#123; // 返回SocketChannel(新出来的AccessController还需要研究) return AccessController.doPrivileged(new PrivilegedExceptionAction &lt; SocketChannel &gt; () &#123;@Override public SocketChannel run() throws IOException &#123; return serverSocketChannel.accept(); &#125; &#125;);&#125; 检测完毕！！！ 创建Channel123456789101112131415161718192021222324252627282930// step 1 NioSocketChannelpublic NioSocketChannel(Channel parent, SocketChannel socket) &#123; super(parent, socket); // 同样创建一个config，这里设置了禁止Nagle算法(让数据尽快发出去，而不是让小数据包变大再发) config = new NioSocketChannelConfig(this, socket.socket());&#125;// step 2 AbstractNioByteChannelprotected AbstractNioByteChannel(Channel parent, SelectableChannel ch) &#123; // 这里要准备绑定读事件了 // step 3 super(parent, ch, SelectionKey.OP_READ);&#125;// step 3protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123; // step 4 super(parent); this.ch = ch; // 设定为对读事件感兴趣 this.readInterestOp = readInterestOp; // 设置为非阻塞 ch.configureBlocking(false);&#125;// step 4protected AbstractChannel(Channel parent) &#123; this.parent = parent; // 也给自己分配这些东西 id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline();&#125; Channel注册绑定12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// step 1 DefaultChannelPipelinepublic final ChannelPipeline fireChannelRead(Object msg) &#123; // step 2 AbstractChannelHandlerContext.invokeChannelRead(head, msg); return this;&#125;// step 2static void invokeChannelRead(final AbstractChannelHandlerContext next, Object msg) &#123; final Object m = next.pipeline.touch(ObjectUtil.checkNotNull(msg, "msg"), next); // 还是那个线程生成器 EventExecutor executor = next.executor(); // step 3 next.invokeChannelRead(m);&#125;// step 3private void invokeChannelRead(Object msg) &#123; // step 4 它会一直讲事件传播到再服务端启动过程中添加到Pipeline的ServerBootstrapAcceptor ((ChannelInboundHandler) handler()).channelRead(this, msg);&#125;// step 4 ServerBootstrap里的ServerBootstrapAcceptorpublic void channelRead(ChannelHandlerContext ctx, Object msg) &#123; final Channel child = (Channel) msg; // 设置一系列信息 child.pipeline().addLast(childHandler); setChannelOptions(child, childOptions, logger); for (Entry &lt; AttributeKey &lt; ?&gt;, Object &gt; e: childAttrs) &#123; child.attr((AttributeKey &lt; Object &gt; ) e.getKey()).set(e.getValue()); &#125; // 忽略细节，关注register方法(这里是childGroup) // step 5 childGroup.register(child);&#125;// step 5 MultithreadEventLoopGrouppublic ChannelFuture register(Channel channel) &#123; // 这里的next方法会去拿到之前ServerChannel初始化的EventLoop数组的一个 // step 6 return next().register(channel);&#125;// step 6 SingleThreadEventLooppublic ChannelFuture register(Channel channel) &#123; // 看到这里会发现注册流程基本和ServerSocketChanne是一样的 // step 7 return register(new DefaultChannelPromise(channel, this));&#125;// step 7public ChannelFuture register(final ChannelPromise promise) &#123; // 看到这里，剩下的基本上就可以参考服务端启动流程了 promise.channel().unsafe().register(this, promise);&#125; 总结 ServerSocketChannel绑定的EventLoop轮询到有新的连接进入 通过封装jdk底层的channel创建 NioSocketChannel以及一系列的netty核心组件 将该cahnnel通过chooser，选择一个EventLoop绑定上去 注册读事件，开始新连接的读写（可以参考服务端启动流程） 参考 netty源码分析之新连接接入全解析]]></content>
      <categories>
        <category>Netty源码</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty源码之NioEventLoop]]></title>
    <url>%2F2018%2F08%2F06%2FNetty%E6%BA%90%E7%A0%81%2FNetty%E6%BA%90%E7%A0%81%E4%B9%8BNioEventLoop%2F</url>
    <content type="text"><![CDATA[引：谈到Netty就避免不了去谈Reactor模式，不懂的同学同自行面向搜索引擎。在Netty中的Reactor线程的具体实现就是NioEventLoop。 NioEventLoop创建我们先总结这个过程的流程： 设置EventLoop数量 创建线程创建器 创建NioEventLoop（配置selector和taskQueue等参数） 创建线程选择器 我们回到上一个例子的： 12EventLoopGroup bossGroup = new NioEventLoopGroup(1); // 用于处理serverChannelEventLoopGroup workerGroup = new NioEventLoopGroup(); // 用于处理channel 我们进入到NioEventLoopGroup的构造方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120// step 1public NioEventLoopGroup(int nThreads) &#123; // 没有传递线程数，默认为0 // step 2 this(nThreads, (Executor) null);&#125;// step 2public NioEventLoopGroup(int nThreads, Executor executor) &#123; // 绑定默认的SelectorProvider // step 3 this(nThreads, executor, SelectorProvider.provider());&#125;// step 4public NioEventLoopGroup(int nThreads, Executor executor, final SelectorProvider selectorProvider) &#123; // 绑定默认的Selector策略工厂，可能select()阻塞或者重试 // step 5 this(nThreads, executor, selectorProvider, DefaultSelectStrategyFactory.INSTANCE);&#125;// step 5public NioEventLoopGroup(int nThreads, Executor executor, final SelectorProvider selectorProvider, final SelectStrategyFactory selectStrategyFactory) &#123; // 调用父类MultithreadEventLoopGroup构造方法，绑定RejectedExecutionHandler(？？) // step 6 super(nThreads, executor, selectorProvider, selectStrategyFactory, RejectedExecutionHandlers.reject());&#125;// step 6 MultithreadEventLoopGroupprotected MultithreadEventLoopGroup(int nThreads, Executor executor, Object...args) &#123; // step 7 查看默认线程个数 // step 8 super(nThreads == 0 ? DEFAULT_EVENT_LOOP_THREADS: nThreads, executor, args);&#125;// step 7static &#123; // 我们发现是两倍的CPU核数(当然这里是workGroup) DEFAULT_EVENT_LOOP_THREADS = Math.max(1, SystemPropertyUtil.getInt("io.netty.eventLoopThreads", NettyRuntime.availableProcessors() * 2));&#125;// step 8protected MultithreadEventExecutorGroup(int nThreads, Executor executor, Object...args) &#123; // 绑定了DefaultEventExecutorChooser工厂(该工厂默认轮询策略) // step 9 this(nThreads, executor, DefaultEventExecutorChooserFactory.INSTANCE, args);&#125;// step 9protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object...args) &#123; // ** 创建线程器生成器 // step 10 executor = new ThreadPerTaskExecutor(newDefaultThreadFactory()); // 事件执行器数组 children = new EventExecutor[nThreads]; for (int i = 0; i &lt; nThreads; i++) &#123; // ** 创建 NioEventLoop // step 11 children[i] = newChild(executor, args); &#125; // ** 创建线程选择器 // step 15 chooser = chooserFactory.newChooser(children); Set &lt; EventExecutor &gt; childrenSet = new LinkedHashSet &lt; EventExecutor &gt; (children.length); Collections.addAll(childrenSet, children); readonlyChildren = Collections.unmodifiableSet(childrenSet);&#125;// step 10public final class ThreadPerTaskExecutor implements Executor &#123; private final ThreadFactory threadFactory; public ThreadPerTaskExecutor(ThreadFactory threadFactory) &#123; // 绑定线程工厂 this.threadFactory = threadFactory; &#125; @Override public void execute(Runnable command) &#123; threadFactory.newThread(command).start(); &#125;&#125;// step 11protected EventLoop newChild(Executor executor, Object...args) throws Exception &#123; // 绑定SelectStrategy和RejectedExecutionHandler // step 12 return new NioEventLoop(this, executor, (SelectorProvider) args[0], ((SelectStrategyFactory) args[1]).newSelectStrategy(), (RejectedExecutionHandler) args[2]);&#125;// step 12 NioEventLoopprivate volatile int ioRatio = 50;NioEventLoop(NioEventLoopGroup parent, Executor executor, SelectorProvider selectorProvider, SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler) &#123; super(parent, executor, false, DEFAULT_MAX_PENDING_TASKS, rejectedExecutionHandler); // 保存selectorProvider provider = selectorProvider; // 这里创建selector，里面创建了SelectedSelectionKeySet final SelectorTuple selectorTuple = openSelector(); // 保存selector 一个selector会与一个EventLoop做唯一的绑定 selector = selectorTuple.selector; // 保存unwrappedSelector(这个在前一篇博文的时候用到了) unwrappedSelector = selectorTuple.unwrappedSelector; selectStrategy = strategy;&#125;// step 13 SingleThreadEventLoopprotected SingleThreadEventLoop(EventLoopGroup parent, Executor executor, boolean addTaskWakesUp, int maxPendingTasks, RejectedExecutionHandler rejectedExecutionHandler) &#123; // step 14 super(parent, executor, addTaskWakesUp, maxPendingTasks, rejectedExecutionHandler); // 保存了一个任务队列 tailTasks = newTaskQueue(maxPendingTasks);&#125;// step 14 SingleThreadEventExecutorprotected SingleThreadEventExecutor(EventExecutorGroup parent, Executor executor, boolean addTaskWakesUp, int maxPendingTasks, RejectedExecutionHandler rejectedHandler) &#123; super(parent); this.addTaskWakesUp = addTaskWakesUp; this.maxPendingTasks = Math.max(16, maxPendingTasks); // 保存 线程器生成器 this.executor = ObjectUtil.checkNotNull(executor, "executor"); // 任务队列 taskQueue = newTaskQueue(this.maxPendingTasks); rejectedExecutionHandler = ObjectUtil.checkNotNull(rejectedHandler, "rejectedHandler");&#125;// step 15public EventExecutorChooser newChooser(EventExecutor[] executors) &#123; // 这里根据eventLoop的个数进行了优化(自行了解) if (isPowerOfTwo(executors.length)) &#123; return new PowerOfTwoEventExecutorChooser(executors); &#125; else &#123; return new GenericEventExecutorChooser(executors); &#125;&#125; 创建完成！！！ NioEventLoop启动它的第一次启动还是要回到前一篇博文的这一个步骤中： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879// step 1 AbstractBootstrappublic final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; // 拿到之前绑定的eventLoop AbstractChannel.this.eventLoop = eventLoop; // step 2 进入inEventLoop方法中 if (eventLoop.inEventLoop()) &#123; register0(promise); &#125; else &#123; // 所以进入这里了 // step 4 eventLoop.execute(new Runnable() &#123;@Override public void run() &#123; register0(promise); &#125; &#125;); &#125;&#125;// step 2 AbstractEventExecutorpublic boolean inEventLoop() &#123; // 这个时候当前线程为主线程 // step 3 return inEventLoop(Thread.currentThread());&#125;// step 3 SingleThreadEventExecutorpublic boolean inEventLoop(Thread thread) &#123; // 该类中的thread为null，所有返回false return thread == this.thread;&#125;// step 4public void execute(Runnable task) &#123; // 还是主线程，还是false boolean inEventLoop = inEventLoop(); // 将任务添加到队列 addTask(task); if (!inEventLoop) &#123; // 开启线程 // step 4 startThread(); &#125; if (!addTaskWakesUp &amp;&amp; wakesUpForTask(task)) &#123; wakeup(inEventLoop); &#125;&#125;// step 4private void startThread() &#123; // state 默认为ST_NOT_STARTED没有启动 if (state == ST_NOT_STARTED) &#123; // 原子更新为开始 if (STATE_UPDATER.compareAndSet(this, ST_NOT_STARTED, ST_STARTED)) &#123; // step 5 doStartThread(); &#125; &#125;&#125;// step 5private void doStartThread() &#123; // 还记得那个executor吗，就是那个线程生成器 // step 6 executor.execute(new Runnable() &#123;@Override public void run() &#123; thread = Thread.currentThread(); // 执行自己的run方法 // step 8 SingleThreadEventExecutor.this.run(); &#125;);&#125;// step 6 ThreadPerTaskExecutorpublic void execute(Runnable command) &#123; // 创建线程并开启线程 // step 7 newThread() // start() 返回到run() step 6 threadFactory.newThread(command).start();&#125;// step 7public Thread newThread(Runnable r) &#123; // 这里可以看出两点，1，返回了一个优化过的FastThreadLocalRunnable；2，看到了线程名 // 线程名的由来可以百度 Thread t = newThread(FastThreadLocalRunnable.wrap(r), prefix + nextId.incrementAndGet()); return t;&#125; 启动完毕了！！！ NioEventLoop执行123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243// step 1 这里就是真的reactor线程真正开始干活的地方protected void run() &#123; // 死循环，干三件事 // 1. select // 2. process selected keys // 3. run tasks for (;;) &#123; try &#123; // 还有任务在执行等着，没有了，就开始select switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &#123; case SelectStrategy.CONTINUE: continue; case SelectStrategy.SELECT: // 1. 轮询注册到EventLoop的Selector上的所有channelIO事件 // wakenUp 表示是否应该唤醒正在阻塞的select操作，每次开始都置为false // step 2 select(wakenUp.getAndSet(false)); if (wakenUp.get()) &#123; selector.wakeup(); &#125; // fall through default: &#125; // 2. 处理产生IO事件的channel // step 3 processSelectedKeys(); // 3. 处理任务队列，但是不能超过一个时间 // step 8 runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &#125; &#125;&#125; // step 2 轮询注册到EventLoop的Selector上的所有channelIO事件private void select(boolean oldWakenUp) throws IOException &#123; Selector selector = this.selector; try &#123; int selectCnt = 0; long currentTimeNanos = System.nanoTime(); // 设置截止时间(当前时间 + 定时任务的将要截止的时间) // netty里面定时任务队列是按照延迟时间从小到大进行排序 // delayNanos(currentTimeNanos)方法即取出第一个定时任务的延迟时间 long selectDeadLineNanos = currentTimeNanos + delayNanos(currentTimeNanos); for (;;) &#123; long timeoutMillis = (selectDeadLineNanos - currentTimeNanos + 500000L) / 1000000L; // 如果超出截止时间0.5ms if (timeoutMillis &lt;= 0) &#123; if (selectCnt == 0) &#123; // 如果在跳出之前发现还没有进行过select操作就执行一次selectNow()(不会阻塞) selector.selectNow(); selectCnt = 1; &#125; break; &#125; // 轮询过程中发现有任务加入，中断本次轮询 if (hasTasks() &amp;&amp; wakenUp.compareAndSet(false, true)) &#123; selector.selectNow(); selectCnt = 1; break; &#125; // 阻塞时轮询 int selectedKeys = selector.select(timeoutMillis); selectCnt++; if (selectedKeys != 0 || oldWakenUp || wakenUp.get() || hasTasks() || hasScheduledTasks()) &#123; // 这里还提供了4种方式来中断轮询 // - 轮询到io事件, // - 用户主动唤醒 // - 任务队列有任务 // - 有定时任务需要被处理 break; &#125; // 这里就很重要了，看看Netty是怎么解决JDK NIO的空轮训bug的 long time = System.nanoTime(); if (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) &gt;= currentTimeNanos) &#123; // 有效轮询，重置标志位 selectCnt = 1; &#125; else if (SELECTOR_AUTO_REBUILD_THRESHOLD &gt; 0 &amp;&amp; selectCnt &gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) &#123; // 当空轮训的次数超过SELECTOR_AUTO_REBUILD_THRESHOLD(默认512)时，就开始重建Selector // step 3 rebuildSelector(); selector = this.selector; // Select again to populate selectedKeys. selector.selectNow(); selectCnt = 1; break; &#125; currentTimeNanos = time; &#125; &#125;&#125; // step 3public void rebuildSelector() &#123; // step 4 rebuildSelector0();&#125;// step 4private void rebuildSelector0() &#123; final Selector oldSelector = selector; final SelectorTuple newSelectorTuple; // 创建一个新的selector newSelectorTuple = openSelector(); int nChannels = 0; for (SelectionKey key: oldSelector.keys()) &#123; Object a = key.attachment(); int interestOps = key.interestOps(); // 取消key在旧的selector上的事件注册 key.cancel(); // 将所有channel重新注册到新的selector上 SelectionKeynewKey = key.channel().register(newSelectorTuple.unwrappedSelector, interestOps, a); nChannels++; &#125; // eventLoop绑定新的seletor selector = newSelectorTuple.selector; unwrappedSelector = newSelectorTuple.unwrappedSelector;&#125;// step 5private void processSelectedKeys() &#123; // 可定不为空，因为在NioEventLoop 的 openSelector方法中创建了 if (selectedKeys != null) &#123; // 为什么说SelectedKeys是优化过的，是因为原生的SelectedKeys是Set，添加一个事件为O(logn) // 优化过后使用数组来操作，添加一个事件为O(1) // 具体的可以参考闪电侠的博客，我这里就不多说了 // step 6 processSelectedKeysOptimized(); &#125; else &#123; processSelectedKeysPlain(selector.selectedKeys()); &#125;&#125;// step 6private void processSelectedKeysOptimized() &#123; for (int i = 0; i &lt; selectedKeys.size; ++i) &#123; final SelectionKey k = selectedKeys.keys[i]; // 让对象可以被GC selectedKeys.keys[i] = null; final Object a = k.attachment(); if (a instanceof AbstractNioChannel) &#123; // 拿到携带的channel // step 7 processSelectedKey(k, (AbstractNioChannel) a); &#125; else &#123;@SuppressWarnings("unchecked") NioTask &lt; SelectableChannel &gt; task = (NioTask &lt; SelectableChannel &gt; ) a; processSelectedKey(k, task); &#125; if (needsToSelectAgain) &#123; selectedKeys.reset(i + 1); selectAgain(); i = -1; &#125; &#125;&#125;// step 7private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) &#123; // 拿到NioEventLoop的Unsafe对象 final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe(); // 拿到NioEventLoop的eventLoop对象 eventLoop = ch.eventLoop(); // 拿到事件 int readyOps = k.readyOps(); // 连接事件处理 if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) &#123; int ops = k.interestOps(); // 获得感兴趣的事件 ops &amp;= ~SelectionKey.OP_CONNECT; // 重新注册 k.interestOps(ops); // 完成链接 unsafe.finishConnect(); &#125; // 写事件处理 if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) &#123; ch.unsafe().forceFlush(); &#125; // 读事件(work)或者建立连接事件（boss）处理 if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &#123; // 都是read方法，只是实现不同 unsafe.read(); &#125;&#125;// step 8 处理任务队列protected boolean runAllTasks(long timeoutNanos) &#123; // 将定时任务放入普通任务队列(它是一个多生产者单消费者队列) // step 9 fetchFromScheduledTaskQueue(); // 拿出一个普通任务 Runnable task = pollTask(); if (task == null) &#123; // 运行收尾任务队列tailTasks afterRunningAllTasks(); return false; &#125; // 计算出本次循环的能够运行的最多时间 final long deadline = ScheduledFutureTask.nanoTime() + timeoutNanos; long runTasks = 0; long lastExecutionTime; for (;;) &#123; // 执行任务(这里一定要多调试几次才会有感觉，任务队列的感觉一下子就出来了) // step 10 safeExecute(task); runTasks++; // 由于ScheduledFutureTask.nanoTime()比较耗时，所以没64次比较一次是否超时 if ((runTasks &amp; 0x3F) == 0) &#123; lastExecutionTime = ScheduledFutureTask.nanoTime(); if (lastExecutionTime &gt;= deadline) &#123; break; &#125; &#125; task = pollTask(); if (task == null) &#123; lastExecutionTime = ScheduledFutureTask.nanoTime(); break; &#125; &#125; afterRunningAllTasks(); this.lastExecutionTime = lastExecutionTime; return true;&#125;// step 9private boolean fetchFromScheduledTaskQueue() &#123; long nanoTime = AbstractScheduledEventExecutor.nanoTime(); // 定时任务队列是一个优先级队列，并且任务实现了compareTo方法，可以返回快需要被执行的定时任务 Runnable scheduledTask = pollScheduledTask(nanoTime); while (scheduledTask != null) &#123; if (!taskQueue.offer(scheduledTask)) &#123; // 如果普通队列满了，就又放回去 scheduledTaskQueue().add((ScheduledFutureTask &lt; ?&gt;) scheduledTask); return false; &#125; // 拿到定时任务 scheduledTask = pollScheduledTask(nanoTime); &#125; return true;&#125;// step 10protected static void safeExecute(Runnable task) &#123; // 就只是运行这个任务，但是一个出错了，也会继续进行下去 task.run();&#125; 执行完毕！！！ 总结虽然还是有很多细节没有调试到，但是大概的流程应该都走了一遍，希望多调试，然后才会深感EventLoop的吊！！ 参考 netty源码分析之揭开reactor线程的面纱（一） netty源码分析之揭开reactor线程的面纱（二） netty源码分析之揭开reactor线程的面纱（三）]]></content>
      <categories>
        <category>Netty源码</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty源码之服务端启动]]></title>
    <url>%2F2018%2F08%2F06%2FNetty%E6%BA%90%E7%A0%81%2FNetty%E6%BA%90%E7%A0%81%E4%B9%8B%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[引：Netty启动啦！开心脸！但是这又可能是一篇又臭又长由绕的文章，需要点耐心，需要点动手能力。无奈脸！！！ Netty Example我选择了Netty源码中的EchoServer来作为例子，它在io.netty.example.echo包下，代码如下所示（忽略细节，专注核心）： 1234567891011121314151617181920212223242526272829303132333435363738394041public final class EchoServer &#123; public static void main(String[] args) throws Exception &#123; static final int PORT = Integer.parseInt(System.getProperty("port", "8007")); // 配置Server端 // AbstractBootstrap的group EventLoopGroup bossGroup = new NioEventLoopGroup(1); // ServerBootstrap的childGroup EventLoopGroup workerGroup = new NioEventLoopGroup(); final EchoServerHandler serverHandler = new EchoServerHandler(); try &#123; // 在它创建的过程中会绑定一个ServerBootstrapConfig保存它的属性 ServerBootstrap b = new ServerBootstrap(); // 方法链配置类，可以学习 // 服务端的Bootstrap才有两个参数的group方法 b.group(bossGroup, workerGroup) // 设置AbstractBootstrap的channelFactory参数 .channel(NioServerSocketChannel.class) // 设置AbstractBootstrap的options参数(常量池实现，ConcurrentMap),可以学习 .option(ChannelOption.SO_BACKLOG, 100) // 设置AbstractBootstrap的handler参数，这里配置了一个日志处理类 .handler(new LoggingHandler(LogLevel.INFO)) // 设置ServerBootstrap的childHandler参数 .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline p = ch.pipeline(); p.addLast(serverHandler); &#125; &#125;); // 服务端启动(一切分析的源头) ChannelFuture f = b.bind(PORT).sync(); // 等待服务端关闭socket f.channel().closeFuture().sync(); &#125; finally &#123; // 优雅关闭两组死循环 bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125;&#125; 源码分析上面的例子的注释已经很清楚了，在启动之前主要就是在配置启动类ServerBootstrap。现在我就下面的启动方法开始深入分析(debug，代码展示会忽略细节)： 1ChannelFuture f = b.bind(PORT).sync(); Bootstrap相关我们可以看看这个类干了什么： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109// step 1public ChannelFuture bind(int inetPort) &#123; // 通过端口生成一个InetSocketAddress // step 2 return bind(new InetSocketAddress(inetPort));&#125;// step 2public ChannelFuture bind(SocketAddress localAddress) &#123; // 验证group和channelFactory是否传进来了 validate(); // 非空判断，这里只说一次，大的工程项目，必须通过防御性编程来增强鲁棒性 if (localAddress == null) &#123; throw new NullPointerException("localAddress"); &#125; // step 3 return doBind(localAddress);&#125;// step 3private ChannelFuture doBind(final SocketAddress localAddress) &#123; // 初始化serverChannel，并将eventloop注册到serverChannel上 // step 4 final ChannelFuture regFuture = initAndRegister(); // 获取刚刚创建的serverChannel，由于之后都不会改变，所以这里可以用final修饰 final Channel channel = regFuture.channel(); // 绑定地址 doBind0(regFuture, channel, localAddress, promise);&#125;// step 4final ChannelFuture initAndRegister() &#123; Channel channel = null; // 生成一个serverChannel // 这里的channelFactory我们在例子介绍过，其实就是在工厂中利用反射生成对应的channel // 这里我们会在NioServerSocketChannel类中分析它构造时会发生什么(可以直接跳过去看) channel = channelFactory.newChannel(); // 初始化serverChannel // step 5 init(channel); // config().group()就是通过ServerBootstrapConfig拿到bossGroup没什么好说的，我们重点关注register方法，我们可以进入EventLoopGroup分析(可以直接跳过去看) // MultithreadEventLoopGroup的 step 1 ChannelFuture regFuture = config().group().register(channel); return regFuture;&#125;// step 5 ServerBootstrap具体实现private final Map &lt; ChannelOption &lt; ?&gt;,Object &gt; childOptions;private final Map &lt; AttributeKey &lt; ?&gt;,Object &gt; childOptions;private final ServerBootstrapConfig config = new ServerBootstrapConfig(this);private volatile EventLoopGroup childGroup;private volatile ChannelHandler childHandler;void init(Channel channel) throws Exception &#123; // 拿到设置的AbstractBootstrap的options final Map &lt; ChannelOption &lt; ?&gt;, Object &gt; options = options0(); // 同步 synchronized(options) &#123; // 设置options，跟下去我们会发现将options放入NioServerSocketChannelConfig中 setChannelOptions(channel, options, logger); &#125; // 同options设置 final Map &lt; AttributeKey &lt; ?&gt;, Object &gt; attrs = attrs0(); synchronized(attrs) &#123; for (Entry &lt; AttributeKey &lt; ?&gt;, Object &gt; e: attrs.entrySet()) &#123;@SuppressWarnings("unchecked") AttributeKey &lt; Object &gt; key = (AttributeKey &lt; Object &gt; ) e.getKey(); channel.attr(key).set(e.getValue()); &#125; &#125; // 拿到ChannelPipeline ChannelPipeline p = channel.pipeline(); // 拿到之前注入的childGroup和childHandler final EventLoopGroup currentChildGroup = childGroup; final ChannelHandler currentChildHandler = childHandler; // 设置childOptions和childOptions，这些是应用于以后新接入的channel final Entry &lt; ChannelOption &lt; ?&gt;, Object &gt; [] currentChildOptions; final Entry &lt; AttributeKey &lt; ?&gt;, Object &gt; [] currentChildAttrs; synchronized(childOptions) &#123; currentChildOptions = childOptions.entrySet().toArray(newOptionArray(0)); &#125; synchronized(childAttrs) &#123; currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(0)); &#125; // 加入新连接处理器 p.addLast(new ChannelInitializer &lt; Channel &gt; () &#123;@Override public void initChannel(final Channel ch) throws Exception &#123; final ChannelPipeline pipeline = ch.pipeline(); // 将会获得最早之前设置的new LoggingHandler(LogLevel.INFO) ChannelHandler handler = config.handler(); // 新增一个新连接接入器ServerBootstrapAcceptor，具体的可以看之后的博文 ch.eventLoop().execute(new Runnable() &#123;@Override public void run() &#123; pipeline.addLast(new ServerBootstrapAcceptor(ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &#125; &#125;); &#125; &#125;);&#125;// step 6private static void doBind0(final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise) &#123; // 又是异步任务，Netty随处可见 channel.eventLoop().execute(new Runnable() &#123;@Override public void run() &#123; if (regFuture.isSuccess()) &#123; // AbstractChannel step 11 channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); &#125; else &#123; promise.setFailure(regFuture.cause()); &#125; &#125; &#125;);&#125; Channel相关创建一个NioServerSocketChannel对象会发生什么： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149private static final SelectorProvider DEFAULT_SELECTOR_PROVIDER = SelectorProvider.provider();// ServerSocketChannel的一系列配置属性private final ServerSocketChannelConfig config;// step 1(默认构造函数)public NioServerSocketChannel() &#123; // step 2，step 3 this(newSocket(DEFAULT_SELECTOR_PROVIDER));&#125;// step 2private static ServerSocketChannel newSocket(SelectorProvider provider) &#123; // 利用JDK NIO 创建的SeveSocketrChannel return provider.openServerSocketChannel();&#125;// step 3public NioServerSocketChannel(ServerSocketChannel channel) &#123; // step 4 super(null, channel, SelectionKey.OP_ACCEPT); // 配置NioServerSocketChannelConfig(初始化会用到) config = new NioServerSocketChannelConfig(this, javaChannel().socket());&#125;// step 4 AbstractNioMessageChannelprotected AbstractNioMessageChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123; // step 5 super(parent, ch, readInterestOp);&#125;// step 5 AbstractNioChannelprivate final SelectableChannel ch;protected final int readInterestOp;protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123; // step 6 super(parent); // 保存原生的ServerSocketChannel this.ch = ch; // 保存感兴趣的事件(SelectionKey.OP_ACCEPT，1&lt;&lt;4) this.readInterestOp = readInterestOp; // 将Channel设置为非阻塞 ch.configureBlocking(false);&#125;// step 6 AbstractChannelprivate final Channel parent;private final ChannelId id;private final Unsafe unsafe;private final DefaultChannelPipeline pipeline;protected AbstractChannel(Channel parent) &#123; this.parent = parent; // 生成channel的唯一标识，自己可以去看看实现 id = newId(); // 生成unsafe对象(进行底层的IO操作)，一个抽象方法，需要具体实现，它的抽象类也在AbstractChannel中 unsafe = newUnsafe(); // 生成ChannelPipeline // step 7 pipeline = newChannelPipeline();&#125;// step 7protected DefaultChannelPipeline newChannelPipeline() &#123; // 我们将在DefaultChannelPipeline分析 return new DefaultChannelPipeline(this);&#125;// step 8 AbstractChannelpublic final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; // 绑定了eventLoop AbstractChannel.this.eventLoop = eventLoop; // ... 专注于核心 // step 9 register0(promise); // ...&#125;// step 9private void register0(ChannelPromise promise) &#123; // 当然是第一次注册，true boolean firstRegistration = neverRegistered; // step 10 doRegister(); // 注册之后设置标志位 neverRegistered = false; registered = true; // pipeline之后的博文会说 pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); // 触发注册完成事件，还会传播pipeline.fireChannelActive(); pipeline.fireChannelRegistered(); // 判断是否绑定，会调用底层NIO创建的channel，应该为false // 那么什么时候建立连接的呢，怎么找，可以参考后面列出的闪电侠的博文，这个函数分析完了 // 我们应该回到AbstractBootstrap的 step 6 继续分析 if (isActive()) &#123; if (firstRegistration) &#123; pipeline.fireChannelActive(); &#125; else if (config().isAutoRead()) &#123; beginRead(); &#125; &#125;&#125;// step 10protected void doRegister() throws Exception &#123; // 利用jdk底层将channel注册到selector上，0表示不关心任何事件，this是为了当NIO检测到事件时可以对netty的channel进行操作 selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this);&#125;// step 11public ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) &#123; // DefaultChannelPipeline step 2 return pipeline.bind(localAddress, promise);&#125;// step 12public final void bind(final SocketAddress localAddress, final ChannelPromise promise) &#123; // 肯定还没有建立连接 boolean wasActive = isActive(); // step 13 doBind(localAddress); // 这里isActive()应该要返回true了 if (!wasActive &amp;&amp; isActive()) &#123; invokeLater(new Runnable() &#123;@Override public void run() &#123; // 触发端口绑定事件，我们将会触发HeadContext的channelActive方法 // ChannelPipeline step 5 pipeline.fireChannelActive(); &#125; &#125;); &#125; safeSetSuccess(promise);&#125;// step 13protected void doBind(SocketAddress localAddress) throws Exception &#123; // 到这里就是进行底层的绑定 if (PlatformDependent.javaVersion() &gt;= 7) &#123; javaChannel().bind(localAddress, config.getBacklog()); &#125; else &#123; javaChannel().socket().bind(localAddress, config.getBacklog()); &#125;&#125;// step 14 AbstractChannelpublic Channel read() &#123; // DefaultChannelPipeline step 7 pipeline.read(); return this;&#125;// step 16 AbstractNioChannel的AbstractNioUnsafeprotected void doBeginRead() throws Exception &#123; // 还记得在初始化AbstractNioChannel时保存的readInterestOp和在channel注册过程中的selectionKey吗，不记得往上看一看 final SelectionKey selectionKey = this.selectionKey; // 需要读 readPending = true; // 拿到具体的值，1&lt;&lt;4=16 final int interestOps = selectionKey.interestOps(); if ((interestOps &amp; readInterestOp) == 0) &#123; // 准备告诉Selector需要关注SelectionKey.OP_ACCEPT事件 selectionKey.interestOps(interestOps | readInterestOp); &#125;&#125; ChannelPipeline相关12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576// step 1 DefaultChannelPipelinefinal AbstractChannelHandlerContext head;final AbstractChannelHandlerContext tail;private final Channel channel;protected DefaultChannelPipeline(Channel channel) &#123; // 绑定channel(如果为空则抛出异常，学习写工具类) this.channel = ObjectUtil.checkNotNull(channel, "channel"); // 默认的两个节点 tail = new TailContext(this); head = new HeadContext(this); // 形成双向链表 head.next = tail; tail.prev = head;&#125;// step 2 DefaultChannelPipelinepublic final ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) &#123; // 这个tail之前就设置过了 // step 3 return tail.bind(localAddress, promise);&#125;// step 3 AbstractChannelHandlerContextpublic ChannelFuture bind(final SocketAddress localAddress, final ChannelPromise promise) &#123; // 寻找tail之前的一个节点 final AbstractChannelHandlerContext next = findContextOutbound(); EventExecutor executor = next.executor(); if (executor.inEventLoop()) &#123; // 调用下一个AbstractChannelHandlerContext的invokeBind方法，一直到找到HeadContext // step 4 next.invokeBind(localAddress, promise); &#125; else &#123; safeExecute(executor, new Runnable() &#123;@Override public void run() &#123; next.invokeBind(localAddress, promise); &#125; &#125;, promise, null); &#125; return promise;&#125;// step 4public void bind(ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) throws Exception &#123; // 看到unsafe就知道要进行底层操作的 // 进入 AbstractChannel的Unsafe step 12 unsafe.bind(localAddress, promise);&#125;// step 5 DefaultChannelPipeline的HeadContextpublic void channelActive(ChannelHandlerContext ctx) throws Exception &#123; // 绑定时间将会一直传播下去 ctx.fireChannelActive(); // step 6 深入分析 readIfIsAutoRead();&#125;// step 6 DefaultChannelPipeline的HeadContextprivate void readIfIsAutoRead() &#123; // 我们很容易看到isAutoRead()方法默认返回为1 if (channel.config().isAutoRead()) &#123; // 进入 AbstractChannel step 14 // 对于服务端channel的读来说就说可以绑定连接了 channel.read(); &#125;&#125;// step 7 DefaultChannelPipelinepublic final ChannelPipeline read() &#123; // 从tail节点一直追寻到head，找到 unsafe.beginRead() // step 8 tail.read(); return this;&#125;// step 8 DefaultChannelPipeline的HeadContextpublic final void beginRead() &#123; // 会一直找到AbstractNioChannel的AbstractNioUnsafe的doBeginRead step 16 doBeginRead();&#125; EventLoop相关123456789101112131415161718192021// step 1 MultithreadEventLoopGroup@Overridepublic ChannelFuture register(Channel channel) &#123; // next()将会通过选择器（之后的博文会讲到）拿到一个EventLoop // step 2 return next().register(channel);&#125;// step2 SingleThreadEventLooppublic ChannelFuture register(Channel channel) &#123; // step 3 return register(new DefaultChannelPromise(channel, this));&#125;// step 3public ChannelFuture register(final ChannelPromise promise) &#123; // 通过unsafe()方法得到Unsafe对象（绑定在channel上的那个）我们可以知道，它要开始底层操作注册了 // 我们我们又要回到AbstractChannel去了，看看它的register注册方法 // Channel step 8 promise.channel().unsafe().register(this, promise); return promise;&#125; 总结 设置启动类参数 创建服务端Channel，同时创建ChannelConfig,ChannelId,ChannelPipeline,ChannelHandler,Unsafe等 初始化服务端Channel，设置一些attr，option，以及设置子channel的attr，option，给服务端channel添加新channel接入器 将Channel注册到Selector，并触发addHandler,register等事件 进行端口绑定，并触发active事件，同时注册ACCEPT事件 参考 netty源码分析之服务端启动全解析]]></content>
      <categories>
        <category>Netty源码</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[摆脱烂代码之Effective Java Third Edition]]></title>
    <url>%2F2018%2F07%2F23%2F%E6%91%86%E8%84%B1%E7%83%82%E4%BB%A3%E7%A0%81%2F%E6%91%86%E8%84%B1%E7%83%82%E4%BB%A3%E7%A0%81%E4%B9%8BEffective-Java-Third-Edition%2F</url>
    <content type="text"><![CDATA[引：越学越迷茫，有所谓的重点吗？我反正现在还弄不清楚，既然弄不清楚，那就好好专注于脚下吧。我曾经看过一遍Effective Java第二版，可能那个时候的代码量还不够吧，不能理解其精髓，现在看看才能回味一点。刚好今年年初第三版（英文版）也出来，新增了Java7、8、9的一些条目，这里也就想列一些第三版的目录，供自己查找与实践，希望自己能够看到条目就能说出所以然来，也想翻译一下新增的一些条目。大家也可以互相交流。 第一章 引言（重要）第二章 创建和销毁对象第1条 考虑用静态工厂方法代替构造器（Java8，9 更新）第2条 遇到多个构造器参数时要考虑用建造者模式第3条 通过私有构造器或者枚举类型强化单例属性第4条 通过私有构造器强化不可实例化的能力第5条 依赖注入优先硬连接资源（新增）第6条 避免创建不必要的对象（Java9 更新）第7条 消除过期的对象引用第8条 避免使用总结方法和清理器（Java 7，9 更新）第9条 try-with-resources优先try-finally（Java 7 新增）第三章 所有对象通用的方法第10条 覆写equals时候请遵守通用规定第11条 覆写equals时候总要覆写hashCode第12条 始终覆写toString第13条 谨慎得覆写clone第14条 考虑实现Comparable接口第四章 类和接口第15条 使类和成员可访问性最小化（Java9 更新）第16条 在公有类中使用访问方法而非公有域第17条 使可变性最小化第18条 复合优先于继承第19条 要么为继承而设计并提供文档，要么禁止继承（Java8，9 更新）第20条 接口优先于抽象类第21条 为后代设计接口（Java8 新增）第22条 接口只用于定义类型第23条 类层次优先于标签类第24条 优先考虑静态成员类而不是非静态成员类第25条 将源文件限制为单个顶层类（新增）第五章 泛型第26条 不要使用原生类型第27条 消除非首检警告第28条 列表优先于数组第29条 优先考虑泛型第30条 优先考虑泛型方法第31条 使用有界通配符提升API灵活性第32条 谨慎组合泛型和可变参数（Java 7，9 新增）第33条 优先考虑类型安全的异构容器第六章 枚举和注解第34条 用enum代替int常量第35条 用实例域代替序数第36条 用EnumSet代替位域第37条 用EnumMap代替序数索引第38条 用接口模拟可扩展的枚举第39条 注解优于命名模式第40条 坚持使用Override注解第41条 标记接口定义类型第七章 Lambda表达式和流第42条 Lambda表达式优于匿名类（Java8 新增）第43条 方法引用优于Lambda表达式（Java8 新增）第44条 优先使用标准的函数式接口（Java8 新增）第45条 谨慎使用流（Java8 新增）第46条 在流中优先使用无副作用的函数（Java8 新增）第47条 在返回类型中Collection优先于Stream（Java8 新增）第48条 使用并行流的时候要小心（Java8 新增）第八章 方法第49条 检查参数的有效性（Java7 更新）第50条 必要时进行保护性拷贝（Java8 更新）第51条 谨慎设计方法签名第52条 慎用重载第53条 慎用可变参数第54条 返回空集合或者数组，而不是null第55条 谨慎返回Optional（Java8 新增）第56条 为所有导出的API元素写文档注释（Java7，8，9 更新）第九章 通用程序设计第57条 将局部变量的作用域最小化第58条 for-each循环优先于传统for循环第59条 了解和使用类库（Java7，9 更新）第60条 如果需要精确的答案，请避免使用float和double第61条 基本类型优先于装箱基本类型第62条 如果有其他类型更合适，则尽量避免使用String第63条 当心String连接的性能第64条 通过接口引用对象第65条 接口优先于反射机制第66条 谨慎使用本地方法第67条 谨慎地进行优化第68条 遵守普遍接受的命名惯例第十章 异常第69条 只针对异常的情况才使用异常第70条 对可恢复的情况使用受检异常，对编程错误使用运行时异常第71条 避免不必要地使用受检异常第72条 优先使用标准的异常第73条 抛出与抽象相对应的异常第74条 每个方法抛出的异常都要有文档第75条 在细节消息中包含能捕获失败的信息第76条 努力使失败保持原子性第77条 不要顾略异常第十一章 并发第78条 同步访问共享的可变数据第79条 避免过度同步第80条 executors，task，stream优先于线程（Java7，8更新）第81条 并发工具优先于wait和notify第82条 线程安全文档化第83条 慎用延迟初始化第84条 不要依赖线程调度器（Java7 更新）第十二章 序列化第85条 其他选择优先于Java序列化（新增）第86条 谨慎实现Serializable接口第87条 考虑使用自定义的序列化形式第88条 保护性编写readObject方法第89条 对于实例控制，枚举类型优先于readResolve第90条 考虑用序列化代理代替序列化实例参考 Effective Java 第三版有什么新料 译 《Effective Java 第三版》新条目介绍]]></content>
      <categories>
        <category>摆脱烂代码</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot+Git+Jenkins+Docker实现CI/CD]]></title>
    <url>%2F2018%2F07%2F18%2F%E8%BF%90%E7%BB%B4%2FSpringBoot-Git-Jenkins-Docker%E5%AE%9E%E7%8E%B0CI-CD%2F</url>
    <content type="text"><![CDATA[引：现在DevOps这么运行，你没有理由不去了解，不去实践，这次就以Springboot为底，利用Git，jenkins，Docker实现持续集成和持续部署！ 开发流程下面是常用的开发流程图： 我们简单说说这张图：首先我们会将代码文件、测试文件以及Dockerfile都存在代码仓库里，版本控制利用git，这里代码仓库有很多选择，比如github、码云(本次使用)、Coding以及自己搭建的gitlab。然后由持续集成工具进行自动化构建，包括了测试、编译、打包、构建镜像、推送镜像到仓库（有很多选择，如docker官方仓库，时速运、自己搭建的Registry）、启动服务等操作，持续集成工具也有很多选择，比如Jenkins(这次使用)、Gitlab CI、Trivas CI。这里使用的容器是Docker，这里Docker的编排工具可以选择Swarm，也可以是K8S。 本次实现流程如下： push代码到码云触发WebHook Jenkins从码云拉取代码 maven构建代码 build镜像 push镜像到镜像仓库 部署服务 配置关于Jdk、Git、Maven的配置这里就不说，自己面向搜索引擎。这里主要说Jenkins和码云的配置。 Jenkins安装配置 下载Jenkins（采用war包安装） 将war包放入Tomcat的webapps目录下 进入YourHostIp:8080/jenkins路径下进行Jenkins的初始化，我们进入 用户自定义插件 安装界面，你可以根据自己的构建方式选择需要安装的插件，本次使用的Pipelines方式进行构建，Pipelines方式是Jenkins2推荐的方式，所以我们构建Pipelines相关的插件进行安装，当然待会进入Jenkins安装也行。 配置用户名和密码 全局工具配置（从系统管理进入全局工具配置，配置Jdk、Git、Maven） 安全配置（从系统管理进入全局安全配置）,如下图： Jenkins构建任务 新建任务，构建一个流水线任务（Pipeline） 在配置里构建触发器，如下图： 构建Pipeline脚本（Pipeline脚本写法见参考） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758 #!groovy pipeline&#123; agent any //定义仓库地址 environment &#123; REPOSITORY=&quot;https://gitee.com/todorex/springboot_docker_git_jenkins_demo.git&quot; &#125; stages &#123; stage(&apos;获取代码&apos;)&#123; steps &#123; echo &quot;start fetch code from git:$&#123;REPOSITORY&#125;&quot; // 清空当前目录 deleteDir() // 拉取代码 git &quot;$&#123;REPOSITORY&#125;&quot; // 清空之前的容器 sh &apos;docker stop $(docker ps -a -q)&apos; sh &apos;docker rm $(docker ps -a -q)&apos; &#125; &#125; stage(&apos;Maven 构建&apos;)&#123; steps &#123; echo &quot;start compile&quot; // 切换目录 dir(&apos;demo&apos;) &#123; // 重新打包 sh &apos;mvn -Dmaven.test.skip=true -U clean install&apos; &#125; &#125; &#125; stage(&apos;构建镜像&apos;)&#123; steps &#123; echo &quot;start build image&quot; dir(&apos;demo&apos;) &#123; // build镜像 sh &apos;docker build -t todorex/springboot_docker_git_jenkins_demo:1.0 .&apos; // 登录镜像仓库 sh &apos;docker login -u your_username -p your_password&apos; // 推送镜像到镜像仓库 sh &apos;docker push todorex/springboot_docker_git_jenkins_demo:1.0&apos; &#125; &#125; &#125; stage(&apos;启动服务&apos;)&#123; steps &#123; echo &quot;start demo&quot; // 部署服务 sh &apos;docker run -d -p 8888:8888 --name=demo todorex/springboot_docker_git_jenkins_demo:1.0&apos; &#125; &#125; &#125;&#125; SSH的配置为了避免jenkins拉取代码时需要输入密码，这里需要配置SSH免密码拉取。如下图： WebHooks配置当你每次对代码仓库进行push操作时，会自动通知jenkins进行构建 测试这次项目的代码仓库为：springboot_docker_git_jenkins_demo 关于Dockerfile以及docker-compose.yml的编写，自己也去面向搜索引擎看看吧。 当我们push代码之后，jenkins就会自动帮我们进行构建。如下图： PS：第一次比较慢是因为要安装Maven依赖，后面就好了。 总结这里只是展示了一个CI/CD的开发流程，关于具体技术细节，无论是Jenkins还是Docker都需要深入学习，加油，骚年！ 参考 SpringBoot+Docker+Git+Jenkins实现简易的持续集成和持续部署 Jenkins pipeline：pipeline 语法详解]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Git</tag>
        <tag>Jenkins</tag>
        <tag>Docker</tag>
        <tag>CI</tag>
        <tag>CD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven使用整理]]></title>
    <url>%2F2018%2F07%2F06%2F%E5%B7%A5%E5%85%B7%2FMaven%E4%BD%BF%E7%94%A8%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[引：使用Java语言来开发你的项目，基本上都少不了Maven，因为有了它真是太方便了！ 什么是MavenMaven是一种用来管理Java项目的工具、但不是那种那种用来管理资源规划和调度的工具。相反，它处理的时一个具体的项目所涉及的各种任务，如编译、测试、打包以及部署。 Maven包括以下几个部分： 一组用于处理管理依赖(从中央仓库拉取的jar包)、目录结构以及构建工作流的约定。 基于这些约定实现的标准化可以极大地简化开发过程。例如，一个常用的目录结构使得开发者可以更加容易跟上不熟悉的项目的节奏。 一个用于项目配置的XML Schema：项目对象模型(Project Object Model)，简称POM。 每一个Maven项目都拥有一个POM文件，并命名为pom.xml，包含Maven用于管理该项目的所有的配置信息。 一个委托外部组件来执行项目任务的插件结构。 这简化了更新一集扩展Maven能力的过程。 Maven安装PS： 上面提到了Maven帮我们管理依赖，是通过从中央仓库拉取jar包(依赖)来实现，但是由于Maven的中央仓库在国外，拉取会比较慢，所以我们一般会通过配置阿里云镜像来加快速度，当然你也可以Nexus搭建自己的私有仓库。 Maven安装教程 配置阿里云镜像仓库 POMPOM文件大纲如下：12345678910&lt;project&gt; // 根元素 &lt;groupId/&gt; &lt;artifactId/&gt; &lt;version/&gt; // 上面三个(GAV坐标)唯一地定义Maven项目的值 &lt;packaging/&gt; // 项目打包方式，默认值是jar &lt;properties/&gt; // 在POM中引用的属性，一般会放版本信息 &lt;dependencies/&gt; //构建当前项目所需要的其他Maven项目 &lt;build/&gt; // 构建改项目所需要执行的任务的配置 &lt;profiles/&gt; // 为不同的用例自定义POM，一般用来配置环境的切换&lt;/project&gt; Maven构件任何可以被Maven的坐标系统(GAV)唯一标识的对象都是一个Maven构件。 Maven构件的类型由pom文件的元素指定。最常用的值是pom、jar、ear、war以及maven-plugin。 POM文件使用方式 默认的：用于构建一个构件 父POM：提供一个由子项目继承的单个配置信息源，子项目通过声明这个pom文件作为它们的元素值 聚合器：用于构建一组声明为的项目，这些子项目位于其当前聚合器项目的文件夹中，每个都包含有他自己的pom文件 PS： 作为父pom或者聚合器的pom文件的元素的值将是pom。 GAV坐标POM定义了5种称为坐标的元素，用于标识Maven构件，首字母缩写GAV指的是必须始终指定的3个坐标、、 的首字母。 下面的坐标是按照他们在坐标表达式中出现的顺序列出： 是项目或者项目组的全局唯一标识符。这通常是Java源代码使员工的全限定的Java包名。例如，io.netty、com.google。 用于标识和某个相关的不同的构件。例如，netty-all、netty-handler。 是指和项目相关的主要构件的类型(对应于构件的POM文件中的值)。它的默认值是jar，此外还有pom、ear。 标识了构件的版本、例如1.1、2.0-SNAPSHOT、4.1.9.Final。 用于区分属于相同的POM但是却被以不同方式构建的构件。例如，javadock、sources、jdk16、jdk17。 一个完整的坐标表达式具有如下格式：1actifactId:groupId:packaging:version:classifier POM文件必须声明它所管理的构件的坐标，一个具有如下坐标的项目：1234&lt;groupId&gt;io.netty&lt;/groupId&gt;&lt;artifactId&gt;netty-all&lt;/artifactId&gt;&lt;version&gt;4.1.9.Final&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt; 将会产生一个具有以下格式的名称的构件：artifactId-&lt;version&gt;.&lt;packaging&gt; 依赖依赖引入项目的依赖是指编译和执行它所需要的外部构件。在大多数情况下，你的项目的依赖项也会有它自己的依赖。我们称这些依赖为你的项目的传递依赖。一个负责的项目可能会有一个深层级的依赖树。Maven 提供了各种用于帮助理解和管理它的工具，如执行mvn dependency:tree。 Maven的声明在POM的元素中：12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId/&gt; &lt;artifactId/&gt; &lt;version/&gt; &lt;type/&gt; &lt;scope/&gt; &lt;systemPath/&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在声明中，GAV坐标是必不可少的。type和scope元素对于那些值不分别是默认值jar和compile的依赖来说也是必须的。 关于scope指的是依赖范围，即classpath，Maven里有3类依赖范围： 编译 测试 运行 元素具有以下值（依赖范围）： compile：编译（默认） runtime：运行 provided：对于编译和测试有效，运行时无效 test：测试 import：使用在中，导入其他项目的 systemPath：与provided一直，但是需要指定依赖文件的绝对位置 依赖管理POM的元素可以包含被其他项目使用的声明（但不拉取），这样的POM的子项目会自动继承这些声明，其他项目可以用过使用元素值来导入他们。 引用了元素的项目可以使用它所声明的依赖，而不需要指定他们的坐标，如果中的在稍后改变，则所有应用它的pom都会改变。 最佳实践：在原POM中的所有版本都利用元素控制。 构件的生命周期Maven的生命周期就是为了对所有的构建过程进行抽象和统一。这个生命周期包含了项目的清理、初始化、编译、测试、打包、集成测试、验证、部署和站点生成等几乎所有构建步骤。也就是说，几所所有的项目的构建，都能映射到这样一个生命周期上。 Maven拥有三套相互独立生命周期，他们分别为clean、default和site。clean生命周期的目的是清理项目、default生命周期的目的是构建项目、site生命周期的目的是建立项目站点。每个生命周期包含一些阶段，这些阶段是有顺序的，并且后面的阶段依赖于前面的阶段。但是三套生命周期本身是相互独立的。我们按照日常的需求，我们只说前两个。 clean生命周期它包含三个阶段： pre-clean：执行清理前要完成的工作。 clean：清理上一次构建生成的文件。 post-clean：执行一些清理后需要完成的工作。 default生命周期default生命周期定义了真正构建时所需要执行的而所有步骤，这里也只是列出重要的阶段： validate：检查项目是否正确 compile：编译项目的源代码 test：使用单元测试框架进行测试，测试代码不会被打包部署 package：将编译的代码打包为可发布的格式，如jar verify：验证软件包是否有效 install：将包安装到本地仓库中，可以供本地其他Maven项目使用 deploy：将包复制到远程仓库中，可以供其他开发人员使用 插件虽然Maven协调了所有构建生命周期阶段的执行，但是他并没有直接实现它们，而是将他们委托给了插件。这些插件是maven-plugin类型的构件(打包为JAR文件)。Maven为标准构件生命周期所定义的所有任务都提供了插件，但更多的是由第三方生产的，用于处理各种自定义的任务。 插件目标每个插件都有很多功能，每个插件功能对应了插件一个目标。如我们之前分析依赖的maven-dependency-plugin，它就有十多个目标，如下：1234// 命令行冒号前面是插件，冒号后面是目标（功能）mvn dependency:analyzemvn dependency:treemvn dependency:list 插件绑定Maven的生命周期与插件相互绑定，用以完成实际的构建任务。 内置绑定为了让用户几乎不用任何配置就能构建Maven项目，Maven为一些主要的生命周期阶段绑定了很多插件的目标，如： maven-clean-plugin:clean绑定了clean maven-compiler-plugin:compile绑定了compile maven-surefire-plugin:test绑定了test maven-jar-plugin:jar绑定package默认 maven-install-plugin:install绑定了install 自定义绑定除了内置绑定之外，用户还能够自己选择将某个插件目标绑定到生命周期的某个阶段上。如下：12345678910111213141516171819202122&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;!--引入插件--&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;!--构建任务--&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-source&lt;/id&gt; &lt;!--绑定阶段--&gt; &lt;phase&gt;verify&lt;/phase&gt; &lt;!--绑定目标--&gt; &lt;goals&gt; &lt;goal&gt;jar-no-fork&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 很多插件的目标在编写是就已经定义了默认绑定阶段，可以利用maven-help-plugin查看插件详细信息，了解插件目标的默认绑定阶段。运行命令如下：1mvn help:describe -Dplugin=org.apache.maven.plugins:maven-source-plugin:3.0.1 如果多个目标被绑定到同一个阶段的时候，这些插件声明的先后顺序决定了目标的执行顺序。 插件配置命令行插件配置很多插件目标的参数都是支持命令行配置的，用户可以在Maven命令中使用-D参数，并伴随参数键=参数值的形式来配置插件目标的参数，如上mvn help。 POM中插件全局配置为了避免插件参数重复书写，我们可以在pom进行全局配置，如下：1234567891011&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;configuration&gt; &lt;!--编译Java1.8版本的源文件--&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;!--生成与JVM1.8兼容的字节码文件--&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt;&lt;/plugin&gt; 插件管理POM的元素可以包含被其他项目使用的声明（但不拉取），这样的POM的子项目会自动继承这些声明。 引用了元素的项目可以使用它所声明的依赖，而不需要指定他们的坐标，如果中的在稍后改变，则所有应用它的pom都会改变。 最佳实践：在原POM中的所有版本都利用元素控制。 聚合和继承聚合如果我们想要一次构建两个项目，而不是到两个模块的目录下分别执行mvn命令，那么我们可以使用Maven聚合。 我们先创建一个聚合构件（除了pom文件（packaging需要为pom），其他可以都不要），然后在聚合构件目录下创建两个构件，并在聚合构件下利用来声明，每个module的值都是一个当前目录的相对目录，如下：1234&lt;modules&gt; &lt;module&gt;email&lt;/module&gt; &lt;module&gt;user&lt;/module&gt;&lt;/modules&gt; 继承如果两个项目有重复的依赖或插件，我们可以使用继承。 我们先创建一个父构件（除了pom文件（packaging需要为pom），其他可以都不要），然后在父构件目录下创建两个子构件，并在子构件下利用来声明继承关系，如下：123456&lt;parent&gt; &lt;groupId/&gt; &lt;artifactId/&gt; &lt;version/&gt; &lt;relativePath&gt;父pom的相对路径&lt;/relativePath&gt;&lt;/parent&gt; 参考 Maven安装教程 配置阿里云镜像仓库 《Maven实战》 Maven 标签]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git使用整理]]></title>
    <url>%2F2018%2F07%2F05%2F%E5%B7%A5%E5%85%B7%2FGit%E4%BD%BF%E7%94%A8%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[引：虽然日常使用git，但是有些时候总是会忘记一些操作，难免会面向搜索引擎查找。所以这里就总结一下。 版本控制系统谈到Git，就需要先说说版本控制系统。版本控制系统就是能自动帮我们记录每次文件的改动的一个软件，而Git就是它的一种实现。想想我们写论文还是写代码，是不是有了他就很方便了，再也不用自己手动备份每一次修改了。版本控制系统又分为集中式和分布式。 集中式（SVN） 集中式版本控制系统的版本库是集中存放在中央服务器的，而我们在干活的时候，用的都是自己的电脑，所以要先从中央服务器取得最新的版本，然后开始干活，干完活了，再把自己的活推送给中央服务器。 问题：必须联网才能工作；中央服务器要是出了问题，所有人都没法干活了 分布式（Git） 每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。在双方协作的时候，如果你在自己电脑上改了文件A，你的同事也在他的电脑上改了文件A，这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。 在实际使用分布式版本控制系统的时候，其实很少在两人之间的电脑上推送版本库的修改，而且如果你们俩不在一个局域网内，两台电脑也互相访问不了。所以分布式版本控制系统通常也有一台充当“中央服务器”的电脑，但这个服务器的作用仅仅是用来方便“交换”大家的修改，没有它大家也一样干活，只是交换修改不方便而已。 Git使用Git安装这里就不多说了，推荐廖雪峰的官方网站安装教程。 Git区域 工作区（Workspace）：在计算机能看到的目录。 缓存区（Index/Stage）：临时保存我们的改动。 版本库（Repository）：工作区有一个隐藏的目录.git，它是Git的本地版本库。 远程仓库（Remote）：“Git中央服务器”，托管在网络中的项目的版本库，可供多人协作开发。（国外有基佬俱乐部Github，国内有码云、Coding、还有可个人或者公司定制的GitLab，请按需选择） Git个人操作在上面的区域图中，其实我们已经看到很多操作，这里我再总结一下： 新建仓库 在当前目录新建一个Git仓库 1git init 在当前目录克隆一个仓库 1git clone [url] 增加文件 添加指定文件/目录到暂存区 1git add [file]/[dir] 添加当前目录的所有文件到暂存区（慎用，尤其在IDE中，因为它会包含IDE的配置文件，如IDEA的.idea和iml文件） 1git add . 提交文件 提交缓存区的文件到仓库区 1git commit -m [改变信息] 查看信息 显示有变更的文件 1git status 显示当前分支的版本历史 1git log 根据关键词搜索提交历史 1git log -S [keyword] 显示暂存区与工作区的差异 1git diff 显示工作区与当前分支最新的commit之间的差异 git diff HEAD(当前最新commit) 上传本地指定分支到远程仓库 1git push [remote] [branch] 远程同步 下载远程仓库的变动 1git fetch [remote远程仓库名] [分支]:[本地新分支] 显示所有远程仓库 1git remote -v 显示某个远程仓库的信息 1git remote show [branch] 增加一个远程仓库并命名 git remote add [shortname=remote] [url] 上传本地指定分支到远程仓库 1git push [remote] [branch] 强行推送当前分支到远程仓库，即使有冲突 git push [remote] --force 推送所有分支到远程仓库 git push [remote] -all 撤销 恢复暂存区的指定文件到工作区 1git checkout [file] 恢复某个commit的指定文件到暂存区与工作区 1git checkout [commit] [file] 恢复暂存区的所有文件到工作区 1git checkout . 重置暂存区与工作区，与上一次commit保持一致 git reset --hard 重置当前分支的HEAD（指针，指向commit-id）为指定commit，同时重置暂存区和工作区，与指定commit一致 git reset --hard [commit] 后者的所有变化都将被前者抵消，并应用当前分支 git revert [commit] 暂时将未提交的变化移除，稍后再移入 git stash git stash pop Git多人协作多人协作就会涉及到分支的概念（其实单人开发也会遇到，只是多人会更常见） 我们先看看下面的图： 这张图可以很清楚让我们认识到在工作中使用git工作流的开发流程。Master分支是线上分支，我们在开发新功能的时候不会去动它，Hotfix分支是如果出了bug就拉一条bug分支快速修复合并到master分支里。我们平时开发都是先从Master分支拉出一条Develop分支，在这个分支上进行开发。每个人一般都会负责项目的一个特性功能，所以我们又会从Develop分支拉出几个Feature分支。在开发测试完成后我们形成Release分支，再次检验后将它与Master分支合并，然后我们之后Release分支拉出Develop分支进行新一轮的开发。 Git分支 列出所有本地分支 1git branch 列出所有远程分支 1git branch -r 列出所有本地分支和远程分支 1git branch -a 新建一个分支，但依然停留在当前分支 1git branch [branch-name] 新建一个分支，并切换到该分支 1git checkout -b [branch] 切换到当前指定分支，并指定工作区 1git checkout [branch-name] 切换到上一个分支 1git checkout - 建立追踪关系，在现有分支与指定的远程分支之间 1git branch --set-upstream [branch] [remote-branch] 合并指定分支到当前分支 1git merge [branch] 删除远程分支 1git branch -d [branch-name] 协作冲突在多人协作的过程中肯定会碰到这样的问题：如果你的小伙伴已经向一个分支推送了他的提交，而碰巧你也对同个分支的同样的文件作了修改，并试图推送，那么就会提交被拒绝，这个时候就需要先：1git pull 等价于：12git fetch temp(临时分支)git merge temp 这个时候合git会将你们两个人对文件的修改都呈现在同一个文件中，你需要在与你的小伙伴商量出一个最终版，修改之后再提交上去。 IDEA与Git可能大家对使用命令行并不感冒，所以这里也为大家找了一份IDEA的git使用教程，至此大家只要点点点就好了。当然这里还会有很多我没有涉及到的地方，就需要平时多积累了。 别急，别急！！还要最后一点就是 .gitignore 了！ 我们发现在使用IDEA的时候，他默认会要求我们把所有的文件加入到git控制里，但是我们知道很多IDEA的自带配置文件是不用也没有必要加入git（之前在说git add . 的时候也说过），所以可以利用IDEA的.gitignore插件来帮助我们忽略这些没有必要的插件，这里也放一个.gitignore教程。 参考 廖雪峰的git教程 详解git fetch与git pull的区别 版本控制之IDEA使用Git 如何在IntelliJ IDEA中使用.ignore插件忽略不必要提交的文件]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你不知道的Java 网络IO]]></title>
    <url>%2F2018%2F05%2F21%2FJava%E5%9F%BA%E7%A1%80%2F%E4%BD%A0%E4%B8%8D%E7%9F%A5%E9%81%93%E7%9A%84Java-%E7%BD%91%E7%BB%9CIO%2F</url>
    <content type="text"><![CDATA[引：可能很多同学一看Java Java 网络IO，心里肯定会觉得这个有什么好讲的，不就是Socket吗，说对也对，因为他讲到了BIO(同步阻塞IO)，但是却不知还有NIO(同步非阻塞IO)，AIO(异步非阻塞IO)！ 项目源码关于BIO、NIO以及AIO的代码都放在github上了，注释应该很详细了，大家有需要的可以看一下：你不知道的那些Java网络IO（BIO、NIO、AIO） 同步or异步 阻塞or非阻塞在谈到IO的时候，避免不了听到同步、异步、阻塞、非阻塞这几个名词或者是他们的组合词，我们经常会感到迷惑不解。 同步or异步同步和异步是相对于IO事件(读写操作)而言的 同步：在进行IO操作时，程序不能干别的事情，等着IO事件完成之后才能去做别的事情 异步：不关心IO处理操作(因为把IO操作交给操作系统干了)，在处理IO的时候，可以去做别的事情，然后等待IO事件处理完成的通知 阻塞or非阻塞阻塞和非阻塞是相对于数据而言的 阻塞：如果数据没有准备好，程序就一直等待，直到数据准备好了才往下执行 非阻塞：不管数据有没有准备好，程序都往下进行 这里是自己看到的一个例子，可以结合起来理解： 如果你想吃一份宫保鸡丁盖饭： 同步阻塞：你到饭馆点餐，然后在那等着，还要一边喊：好了没啊！（IO操作[拿饭]没有干好，预想之外的事都不能干，数据[饭]没有好，就一直等着） 同步非阻塞：在饭馆点完餐，就去遛狗了。不过溜一会儿，就回饭馆喊一声：好了没啊！（IO操作[拿饭]没有干好，预想之外的事都不能干，数据[饭]没有好，但是不用一直等着，可以继续干预先安排的事[遛狗]，但是需要时不时去问一下饭有没有好） 异步阻塞：遛狗的时候，接到饭馆电话，说饭做好了，让您亲自去拿。（IO操作[拿饭]没有干好，但是我想干啥就干啥，等着通知就好，数据[饭]没有好，就一直等着去拿饭） 异步非阻塞：饭馆打电话说，我们知道您的位置，一会给你送过来，安心遛狗就可以了。（IO操作[拿饭]没有干好，但是我想干啥就干啥，等着通知就好，数据[饭]没有好，但是不用一直等着，可以继续干预先安排的事） I/O模型Unix定义了五种I/O模型，如下： 阻塞I/O 非阻塞I/O I/O复用（select、poll、linux 2.6种改进的epoll） 信号驱动IO（SIGIO） 异步I/O（POSIX的aio_系列函数） 下图是五种I/O模型的比较： POSIX把I/O操作划分成两类： 同步I/O: 同步I/O操作导致请求阻塞，直至操作完成 异步I/O: 异步I/O操作不导致请求阻塞 从上面的图中可以看出Unix的前四种I/O模型都是同步I/O, 只有最后一种才是异步I/O。 我们在看看Java中的IO分类： 传统的Java BIO (blocking I/O)是Unix I/O模型中的第一种。 Java NIO中如果不使用select模式，而只把channel配置成nonblocking则是第二种模型。 Java NIO select实现的是一种多路复用I/O。底层使用epoll或者相应的poll系统调用。 第四种模型JDK应该是没有实现。 Java NIO2增加了对第五种模型的支持，也就是AIO。 BIO网络编程传统的同步阻塞模型(BIO)开发中，ServerSocket负责绑定IP地址，启动监听端口；Socket负责发起连接操作。连接成功后，双方通过输入和输出流进行同步阻塞式通信。 简单的描述一下BIO的服务端通信模型：采用BIO通信模型的服务端，通常由一个独立的Acceptor线程负责监听客户端的连接，它接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理没处理完成后，通过输出流返回应答给客户端，线程销毁。即典型的一请求一应答通信模型。如下图： 该模型最大的问题就是缺乏弹性伸缩能力，当客户端并发访问量增加后，服务端的线程个数和客户端并发访问数呈1:1的正比关系，Java中的线程也是比较宝贵的系统资源，线程数量快速膨胀后，系统的性能将急剧下降，随着访问量的继续增大，系统最终就死掉了。 为了改进这种一连接一线程的模型，我们可以使用线程池来管理这些线程（需要了解更多请参考前面提供的文章），实现1个或多个线程处理N个客户端的模型（但是底层还是使用的同步阻塞I/O），通常被称为“伪异步I/O模型“。伪异步I/O模型图如下： 我们知道，如果使用CachedThreadPool线程池，其实除了能自动帮我们管理线程（复用），看起来也就像是1:1的客户端：线程数模型，而使用FixedThreadPool我们就有效的控制了线程的最大数量，保证了系统有限的资源的控制，实现了N:M的伪异步I/O模型。但是，正因为限制了线程数量，如果发生大量并发请求，超过最大数量的线程就只能等待，直到线程池中的有空闲的线程可以被复用。而对Socket的输入流就行读取时，会一直阻塞。 所以在读取数据较慢时（比如数据量大、网络传输慢等），大量并发的情况下，其他接入的消息，只能一直等待，这就是最大的弊端。 PS： 源码都在github上。 NIO网络编程NIO(同步非阻塞IO)提供了与传统BIO模型中的Socket和ServerSocket相对应的SocketChannel和ServerSocketChannel两种不同的套接字通道实现。新增的着两种通道都支持阻塞和非阻塞两种模式。阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用NIO的非阻塞模式来开发。 在用NIO进行开发时，我们需要先了解一下NIO的几个核心概念： 缓冲区 BufferBuffer是一个对象，包含一些要写入或者读出的数据。在NIO库中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的；在写入数据时，也是写入到缓冲区中。任何时候访问NIO中的数据，都是通过缓冲区进行操作。 缓冲区实际上是一个数组，并提供了对数据结构化访问以及维护读写位置等信息。具体的缓存区有这些：ByteBuffe、CharBuffer、 ShortBuffer、IntBuffer、LongBuffer、FloatBuffer、DoubleBuffer。他们实现了相同的接口：Buffer。 通道 Channel我们对数据的读取和写入要通过Channel，它就像水管一样，是一个通道。通道不同于流的地方就是通道是双向的，可以用于读、写和同时读写操作。底层的操作系统的通道一般都是全双工的，所以全双工的Channel比流能更好的映射底层操作系统的API。 Channel主要分两大类： SelectableChannel：用户网络读写 FileChannel：用于文件操作 网络编程中涉及的ServerSocketChannel和SocketChannel都是SelectableChannel的子类。 多路复用器 SelectorSelector提供选择已经就绪的任务的能力：Selector会不断轮询注册在其上的Channel，如果某个Channel上面发生读或者写事件，这个Channel就处于就绪状态，会被Selector轮询出来，然后通过SelectionKey可以获取就绪Channel的集合，进行后续的I/O操作。 一个Selector可以同时轮询多个Channel(所以是非阻塞的)，因为JDK使用了epoll()代替传统的select实现，所以没有最大连接句柄1024/2048的限制。所以，只需要一个线程负责Selector的轮询，就可以接入成千上万的客户端。 创建NIO服务端的通信流程我们可以看下面这种通信序列图： PS： 源码都在github上。 AIO网络编程异步的套接字通道是真正的异步非阻塞I/O，对应于UNIX网络编程中的事件驱动I/O（AIO）。他不需要过多的Selector对注册的通道进行轮询即可实现异步读写，从而简化了NIO的编程模型。 AIO(异步非阻塞IO)提供了与传统BIO模型中的Socket和ServerSocket相对应的AsynchronousSocketChannel和AsynchronousServerSocketChannel两种不同的套接字通道实现。 异步的处理异步无非是通知系统做一件事情。然后忘掉它，自己做其他事情去了。很多时候系统做完某一件事情后需要一些后续的操作。怎么办？这时候就是告诉异步调用如何做后续处理。通常有两种方式： 将来式: 当你希望主线程发起异步调用，并轮询等待结果的时候使用将来式; 回调式: 常说的异步回调就是它。 PS： AIO的代码主要基于回调式，源码都在github上。 BIO、NIO、AIO适用场景分析: BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。 NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。 AIO方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。 参考 Java中BIO,NIO,AIO的理解 Linux select和poll系统调用 java aio 编程 Java 网络IO编程总结（BIO、NIO、AIO均含完整实例代码） Java之IO,BIO,NIO,AIO知多少？ ServerSocketChannel的用法详解 (001)java中的AIO]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>BIO</tag>
        <tag>NIO</tag>
        <tag>AIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP协议]]></title>
    <url>%2F2018%2F05%2F20%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2FHTTP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[引：作为Web开发人员，可能你最需要深入学习的就是HTTP协议了吧！ HTTP认识HTTP协议是Hyper Text TransferProtocol（超文本传输协议）的缩写,它是一个基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）的应用层协议。它工作于客户端-服务端架构之上。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。Web服务器根据接收到的请求后，向客户端发送响应信息。 HTTP特点 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。 灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 HTTP 0.9和1.0使用非持续连接：限制每次连接只处理一个请求，服务器处理完客户的请求，并收到客户的应答后，即断开连接。HTTP 1.1使用持续连接：不必为每个web对象创建一个新的连接，一个连接可以传送多个对象，采用这种方式可以节省传输时间。 无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 PS： HTTP协议是无状态的和Connection: keep-alive的区别： 无状态是指协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。从另一方面讲，打开一个服务器上的网页和你之前打开这个服务器上的网页之间没有任何联系。HTTP是一个无状态的面向连接的协议，无状态不代表HTTP不能保持TCP连接，更不能代表HTTP使用的是UDP协议（无连接）。 从HTTP/1.1起，默认都开启了Keep-Alive，保持连接特性，简单地说，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。 HTTP工作原理HTTP协议定义Web客户端如何从Web服务器请求Web页面，以及服务器如何把Web页面传送给客户端。HTTP协议采用了请求/响应模型。客户端向服务器发送一个请求报文，服务器将返回一个响应报文。 以下是 HTTP 请求步骤： 客户端连接到Web服务器：一个HTTP客户端，通常是浏览器，与Web服务器的HTTP端口（默认为80）建立一个TCP套接字连接。例如：http://www.todorex.com。 发送HTTP请求：通过TCP套接字，客户端向Web服务器发送一个文本的请求报文。 服务器接受请求并返回HTTP响应Web服务器解析请求，定位请求资源。服务器将资源复本写到TCP套接字，由客户端读取。 释放连接TCP连接：若请求报文首部的connection 模式为close，则服务器主动关闭TCP连接，客户端被动关闭连接，释放TCP连接;若connection 模式为keepalive，则该连接会保持一段时间，在该时间内可以继续接收请求。 客户端浏览器解析HTML内容客户端浏览器首先解析响应报文，然后客户端浏览器读取响应数据HTML，根据HTML的语法对其进行格式化，并在浏览器窗口中显示。 HTTP报文之请求报文请求报文由请求行(请求方法、URL、协议版本)、请求头部、空行(回车+换行)和请求数据(主体)四个部分组成。如下图： 它的例子如下： 请求报文之URLHTTP使用统一资源标识符（Uniform Resource Identifiers, URI）来传输数据和建立连接。URI包含了用于查找某个资源的足够的信息。 统一资源定位符（Uniform Resource Locator, URL）是互联网上用来标识某一处资源的地点，所以可见URL是URI的子集。以下面这个URL为例，介绍下普通URL的各部分组成： http://www.aspxfans.com:8080/news/index.asp?boardID=5&amp;ID=24618&amp;page=1#name 从上面的URL可以看出，一个完整的URL包括以下几部分： 协议部分：该URL的协议部分为“http:”，这代表网页使用的是HTTP协议。在Internet中可以使用多种协议，如HTTP，FTP等等本例中使用的是HTTP协议。在”HTTP”后面的“//”为分隔符。 域名部分：该URL的域名部分为“www.aspxfans.com”。一个URL中，也可以使用IP地址作为域名使用。在建立TCP连接的时候用的就是IP地址，我们可以用域名是因为有了DNS域名解析。 端口部分：跟在域名后面的是端口，域名和端口之间使用“:”作为分隔符。端口不是一个URL必须的部分，如果省略端口部分，将采用默认端口，HTTP默认的端口号为80，HTTPS的端口号为443。 虚拟目录部分：从域名后的第一个“/”开始到最后一个“/”为止，是虚拟目录部分。虚拟目录也不是一个URL必须的部分。本例中的虚拟目录是“/news/”。 文件名部分：从域名后的最后一个“/”开始到“?”为止，是文件名部分，如果没有“?”,则是从域名后的最后一个“/”开始到“#”为止，是文件部分，如果没有“？”和“#”，那么从域名后的最后一个“/”开始到结束，都是文件名部分。本例中的文件名是“index.asp”。文件名部分也不是一个URL必须的部分，如果省略该部分，则使用默认的文件名，一般为index.html。 锚部分：从“#”开始到最后，都是锚部分(HTML的节点)。本例中的锚部分是“name”。锚部分也不是一个URL必须的部分。 参数部分：从“？”开始到“#”为止之间的部分为参数部分，又称搜索部分、查询部分。本例中的参数部分为“boardID=5&amp;ID=24618&amp;page=1”。参数可以允许有多个参数，参数与参数之间用“&amp;”作为分隔符。 请求报文之请求方法根据HTTP标准，HTTP请求可以使用多种请求方法。HTTP1.0定义了三种请求方法： GET, POST 和 HEAD方法。HTTP1.1新增了六种请求方法：OPTIONS, PUT, DELETE, TRACE，CONNECT和PATCH 方法。 这八种方法(动作)表明了请求的URL指定的资源的操作方式，分别如下： 方法 操作方式 GET 请求指定的页面信息，并返回实体主体 HEAD 类似于get请求，只不过返回的响应中没有具体的内容，用于获取报头 POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改 PUT 从客户端向服务器传送的数据取代指定的文档的内容 DELETE 请求服务器删除指定的页面 CONNECT HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器 OPTIONS 允许客户端查看服务器的性能 TRACE 回显服务器收到的请求，主要用于测试或诊断 PATCH 用来将局部修改应用于某一资源 PS： GET和POST的区别： GET提交的数据会放在URL之后，以?分割URL和传输数据，参数之间以&amp;相连，如EditPosts.aspx?name=test1&amp;id=123456. POST方法是把提交的数据放在HTTP包的Body中。 GET提交的数据大小有限制，最多只能有1024字节（因为浏览器对URL的长度有限制），而POST方法提交的数据没有限制。 GET方式提交数据，会带来安全问题，比如一个登录页面，通过GET方式提交数据时，用户名和密码将出现在URL上，如果页面可以被缓存或者其他人可以访问这台机器，就可以从历史记录获得该用户的账号和密码。 请求报文之通用首部常见的通用首部如下： Pragma：指定“no-cache”值表示服务器必须返回一个刷新后的文档，即使它是代理服务器而且已经有了页面的本地拷贝；在HTTP/1.1版本中，它和Cache-Control:no-cache作用一模一样。Pargma只有一个用法， 例如： Pragma: no-cache注意: 在HTTP/1.0版本中，只实现了Pragema:no-cache, 没有实现Cache-Control Cache-Control：指定请求和响应遵循的缓存机制。缓存指令是单向的（响应中出现的缓存指令在请求中未必会出现），且是独立的（在请求消息或响应消息中设置Cache-Control并不会修改另一个消息处理过程中的缓存处理过程）。请求时的缓存指令包括no-cache、no-store、max-age、max-stale、min-fresh、only-if-cached，响应消息中的指令包括public(可以被任何缓存所缓存)、private(内容只缓存到私有缓存中)、no-cache(所有内容都不会被缓存)、no-store、no-transform、must-revalidate、proxy-revalidate、max-age、s-maxage。 Connection：之前已经说过，主要是控制TCP连接是否在请求完马上端开。 Date：表示消息发送的时间。 请求报文之请求首部常见的请求首部如下： If-Modified-Since：把浏览器端缓存页面的最后修改时间发送到服务器去，服务器会把这个时间与服务器上实际文件的最后修改时间进行对比。如果时间一致，那么返回304，客户端就直接使用本地缓存文件。如果时间不一致，就会返回200和新的文件内容。客户端接到之后，会丢弃旧文件，把新文件缓存起来，并显示在浏览器中。 If-None-Match：If-None-Match和ETag一起工作，工作原理是在HTTP Response中添加ETag信息。 当用户再次请求该资源时，将在HTTP Request 中加入If-None-Match信息(ETag的值)。如果服务器验证资源的ETag没有改变（该资源没有更新），将返回一个304状态告诉客户端使用本地缓存文件。否则将返回200状态和新的资源和Etag。 Accept：浏览器端可以接受的MIME类型。例如：Accept: text/html 代表浏览器可以接受服务器回发的类型为 text/html 也就是我们常说的html文档，如果服务器无法返回text/html类型的数据，服务器应该返回一个406错误(non acceptable)。通配符 * 代表任意类型，例如 Accept: */* 代表浏览器可以处理所有类型，(一般浏览器发给服务器都是发这个)。 Accept-Encoding：浏览器申明自己可接收的编码方法，通常指定压缩方法，是否支持压缩，支持什么压缩方法（gzip，deflate）;Servlet能够向支持gzip的浏览器返回经gzip编码的HTML页面。许多情形下这可以减少5到10倍的下载时间。例如： Accept-Encoding: gzip, deflate。如果请求消息中没有设置这个域，服务器假定客户端对各种内容编码都可以接受。 Accept-Language：浏览器申明自己接收的语言。语言跟字符集的区别：中文是语言，中文有多种字符集，比如big5，gb2312，gbk等等；例如：Accept-Language: en-us。如果请求消息中没有设置这个报头域，服务器假定客户端对各种语言都可以接受。 Accept-Charset：浏览器可接受的字符集。如果在请求消息中没有设置这个域，缺省表示任何字符集都可以接受。 User-Agent：告诉HTTP服务器，客户端使用的操作系统和浏览器的名称和版本 Referer：包含一个URL，用户从该URL代表的页面出发访问当前请求的页面。提供了Request的上下文信息的服务器，告诉服务器我是从哪个链接过来的，比如从我主页上链接到一个朋友那里，他的服务器就能够从HTTP Referer中统计出每天有多少用户点击我主页上的链接访问他的网站。 Host：（发送请求时，该头域是必需的）主要用于指定被请求资源的Internet主机和端口号，它通常从HTTP URL中提取出来的。HTTP/1.1请求必须包含主机头域，否则系统会以400状态码返回。 Authorization：授权信息，通常出现在对服务器发送的WWW-Authenticate头的应答中。主要用于证明客户端有权查看某个资源。当浏览器访问一个页面时，如果收到服务器的响应代码为401（未授权），可以发送一个包含Authorization请求报头域的请求，要求服务器对其进行验证。 Range：可以请求实体的一个或者多个子范围。 Cookie：最重要的请求头之一, 将cookie的值发送给HTTP服务器。 请求报文之实体首部常见的实体首部如下： Content-Type：说明了实体主体内对象的媒体类型。 Content-Length：表示请求消息正文的长度。 Content-Range：用于指定整个实体中的一部分的插入位置，他也指示了整个实体的长度。在服务器向客户返回一个部分响应，它必须描述响应覆盖的范围和整个实体长度。一般格式：Content-Range:bytes-unitSPfirst-byte-pos-last-byte-pos/entity-length。 Content-Encoding：WEB服务器表明自己使用了什么压缩方法（gzip，deflate）压缩响应中的对象。只有在解码之后才可以得到Content-Type头指定的内容类型。 Content-Language：WEB服务器告诉浏览器自己响应的对象所用的自然语言。 请求报文之其他首部 P3P：用于跨域设置Cookie, 这样可以解决iframe跨域访问cookie的问题。 HTTP报文之响应报文响应报文由状态行(协议版本、状态码、消息状态)、响应头部、空行(回车+换行)和响应数据(主体)四个部分组成。如下图： 它的例子如下： 响应报文的通用首部和实体首部以及其他首部都和请求报文差不多，我们主要讲解响应首部。 响应报文之响应首部 Allow：服务器支持哪些请求方法 Expires：指明应该在什么时候认为文档已经过期，从而不再缓存它，重新从服务器获取，会更新缓存。过期之前使用本地缓存。HTTP1.1的客户端和缓存会将非法的日期格式（包括0）看作已经过期。eg：为了让浏览器不要缓存页面，我们也可以将Expires实体报头域，设置为0。 Set-Cookie：非常重要的header, 用于把cookie发送到客户端浏览器，每一个写入cookie都会生成一个Set-Cookie。 Last-Modified：用于指示资源的最后修改日期和时间。Last-Modified也可用setDateHeader方法来设置。 Server：指明HTTP服务器用来处理请求的软件信息。 Location：用于重定向一个新的位置，包含新的URL地址。表示客户应当到哪里去提取文档。Location通常不是直接设置的，而是通过HttpServletResponse的sendRedirect方法，该方法同时设置状态代码为302。Location响应报头域常用在更换域名的时候。 WWW-Authenticate：该响应报头域必须被包含在401（未授权的）响应消息中，客户端收到401响应消息时候，并发送Authorization报头域请求服务器对其进行验证时，服务端响应报头就包含该报头域。 HTTP之状态码状态代码有三位数字组成，第一个数字定义了响应的类别，共分五种类别: 状态码 说明 1xx 指示信息–表示请求已接收，继续处理 2xx 成功–表示请求已被成功接收、理解、接受 3xx 重定向–要完成请求必须进行更进一步的操作 4xx 客户端错误–请求有语法错误或请求无法实现 5xx 服务器端错误–服务器未能实现合法的请求 常用的状态码如下： 状态码 说明 200 OK 客户端请求成功 400 Bad Request 客户端请求有语法错误，不能被服务器所理解 401 Unauthorized 请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 403 Forbidden 服务器收到请求，但是拒绝提供服务 404 Not Found 请求资源不存在，eg：输入了错误的URL 500 Internal Server Error 服务器发生不可预期的错误 503 Server Unavailable 服务器当前不能处理客户端的请求，一段时间后可能恢复正常 参考 《图解HTTP》 关于HTTP协议，一篇就够了 HTTP协议详解]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP协议]]></title>
    <url>%2F2018%2F05%2F18%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2FTCP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[引：TCP作为传输层的一大协议，虽然没有UDP简单，但是胜在可靠。 TCP认识TCP(传输控制协议) 是一种面向连接、可靠的、基于字节流的传输层协议。TCP在传送数据之前会先相互发送一些预备报文段协商一些参数，比如序号等等，TCP将用户数据打包成报文段，发送数据后启动一个定时器，另一端对收到的数据进行确认，对失序的数据重新排序，丢弃重复数据，TCP提供端到端的流量控制，并计算和验证一个强制性的端到端校验和。 TCP特点 TCP是面向连接的，通信前需要建立连接，通信结束需要释放连接。 TCP提供可靠交付服务，可靠指的是：TCP发送的数据无重复、无丢失、无错误、与发送端顺序一致。 TCP是面向字节流的，面向字节流指的是：TCP以字节为单位。虽然传输的过程中数据被划分成一个个数据报，但这只是为了方便传输，接收端最终接受到的数据将与发送端的数据一模一样。 TCP提供全双工通信，全双工通信指的是：TCP的两端既可以作为发送端，也可以作为接收端。 一条TCP连接的两端只能有两个端点，TCP只能提供点到点的通信，而UDP可以任意方式的通信。 TCP首部 16位端口号:包含源端口和目的端口，客户端通常使用系统自动选择的临时端口号，而服务器则使用自主定义端口号. 32位序号:一次TCP通信过程中一个传输方向上的字节流的每个字节的编号，例如:A发送给B的第一个TCP报文段中，序号值被系统初始化为某个随机值ISN，那么在该传输方向上，后续的TCP报文段中序号值将被系统设置为ISN加上该报文段所携带数据的第一个字节在整个字节流中的偏移。 32位的确认号: 用作对另外一方发送来的TCP报文段的响应，其值是收到的TCP报文段的序号值加1。 4位头部长度: 标识TCP头部有多少个32bit(4字节)，最大60字节. 6位标志位: URG:表示紧急指针是否有效. ACK:表示确认号是否有效，我们称携带ACK标志的TCP报文段为确认报文段. PSH:提示接收端应用程序应该立即从TCP接收缓冲区中读走数据,为接收数据腾出空间. RST:表示要求对方重新建立连接(复位报文段) SYN:表示请求建立一个连接(同步报文段); FIN:表示通知对方本端要关闭连接了(结束报文段); 16位窗口大小:TCP流量的一个控制手段,,它告知是对方本端的TCP接收缓冲区还能容纳多少字节的数据，这样对方就可以控制发送数据的速度. 16位校验和:由发送端填充，接收端对TCP报文段执行CRC算法（循环冗余码检验，与UDP一样），检验TCP头部在传输过程中是否损坏，不仅包括TCP头部，也包括数据部分。 16位紧急指针:是一个正的偏移量.它和序号字段的值相加表示最后一个紧急数据的下一个字节的序号. 选项字段，上述字段都是每个TCP头部必须要有的，而选项字段是可选的，且长度可变，最长40字节。 最常用的选项字段为MMS：最大报文长度。 TCP连接建立(三次握手) TCP协议中，主动发起请求的一端称为客户端，被动连接的一端称为服务端。不管是客户端还是服务端，TCP连接建立完后都能发送和接收数据。 握手前：服务器和客户端都为CLOSED状态，在通信开始前，双方都得创建各自的传输控制块（TCB）。服务器创建完TCB后遍进入LISTEN状态，此时准备接收客户端发来的连接请求。 第一次握手：客户端向服务端发送连接请求报文段。该报文段的头部中SYN=1，ACK=0，(表示该报文段为连接请求报文) seq=x(x为本次TCP通信的字节流的初始序号)。请求发送后，客户端便进入SYN-SENT状态。 第二次握手 ：服务端收到连接请求报文段后，如果同意连接，则会发送一个应答：SYN=1，ACK=1，(表示该报文段为连接同意的应答报文) seq=y，(表示服务端作为发送者时，发送字节流的初始序号) ack=x+1(表示服务端希望下一个数据报发送序号从x+1开始的字节)。该应答发送完成后便进入SYN-RCVD状态。 第三次握手 ：当客户端收到连接同意的应答后，还要向服务端发送一个确认报文段，表示：服务端发来的连接同意应答已经成功收到。该报文段的头部为：ACK=1，seq=x+1，ack=y+1。客户端发完这个报文段后便进入ESTABLISHED状态，服务端收到这个应答后也进入ESTABLISHED状态，此时连接的建立完成！ PS：为什么连接建立需要三次握手，而不是两次握手？ 防止失效的连接请求报文段被服务端接收，从而产生错误，失效的连接请求指的是：若客户端向服务端发送的连接请求丢失，客户端等待应答超时后就会再次发送连接请求，此时，上一个连接请求就是失效的。 若建立连接只需两次握手，服务端在收到连接请求后就进入ESTABLISHED状态。此时如果网络拥塞，客户端发送的连接请求迟迟到不了服务端，客户端便超时重发请求，此时，如果那个失效的连接请求抵达了服务端，但此时的客户端早已进入CLOSED状态，服务端将会一直等待下去，这样浪费服务端连接资源。 TCP连接释放(四次握手)TCP连接发送数据是双向的，因此在四次挥手中，前两次挥手用于断开一个方向的连接，后两次挥手用于断开另一方向的连接。 第一次握手 ：若A认为数据发送完成，则它需要向B发送连接释放请求。该请求只有报文头，头中携带的主要参数为：FIN=1，(表示该报文段是一个连接释放请求) seq=u(u-1是A向B发送的最后一个字节的序号)。此时，A将进入FIN-WAIT-1状态。 第二次握手 ：B收到连接释放请求后，会通知相应的应用程序，告诉它A向B这个方向的连接已经释放。此时B进入CLOSE-WAIT状态，并向A发送连接释放的应答，其报文头包含： ACK=1，(表示应答) seq=v (v-1是B向A发送的最后一个字节的序号)，ack=u+1(表示希望收到从第u+1个字节开始的报文段，并且已经成功接收了前u个字节)。A收到该应答，进入FIN-WAIT-2状态，等待B发送连接释放请求。第二次挥手完成后，A到B方向的连接已经释放，B不会再接收数据，A也不会再发送数据。但B到A方向的连接仍然存在，B可以继续向A发送数据。 第三次握手 ：当B向A发完所有数据后，向A发送连接释放请求，请求头：FIN=1，ACK=1，seq=w，ack=u+1。B便进入LAST-ACK状态。 第四次握手 ：A收到释放请求后，向B发送确认应答，此时A进入TIME-WAIT状态。该状态会持续2MSL(报文最大生存时间)时间，若该时间段内没有B的重发请求的话，就进入CLOSED状态，撤销TCB。当B收到确认应答后，也便进入CLOSED状态，撤销TCB。 TCP的可靠传输TCP采用了校验和、连接管理、序列号、确认应答，重发控制、滑动窗口协议（连续ARQ协议、流控制、拥塞控制）等机制来保证它的可靠性。 校验和TCP和UDP校验和的方式一致，可以参照另一篇博客——UDP协议 连接管理其实就是利用建立连接时的三次握手来提高可靠性。 通过序列号与确认应答在TCP中，当发送端的数据到达接收主机时，接收端主机会返回一个收到消息的通知，这个消息叫做确认应答(ACK)，比如客户端发送[数据(1-1000)]，那么服务端将会回应[确认应答(下一个数1001)]。在一定时间内没有等到确认应答，发送端会认为数据已经丢失，并进行重发。 滑动窗口协议(连续ARQ协议)概念先简单说说ARQ(Automatic Repeat reQuest)协议(自动重传请求协议)： 当请求失败时它会自动重传，直到请求被正确接收为止。这种机制保证了每个分组都能被正确接收。 再看连续ARQ协议：在ARQ协议发送者每次只能发送一个分组，在应答到来前必须等待。而连续ARQ协议的发送者拥有一个发送窗口，发送者可以在没有得到应答的情况下连续发送窗口中的分组。 发送窗口 发送窗口的大小由接收窗口的剩余大小决定。接收者会把当前接收窗口的剩余大小写入应答TCP报文段的头部，发送者收到应答后根据该值和当前网络拥塞情况设置发送窗口的大小。发送窗口的大小是不断变化的。 发送窗口(p1-p3)由三个指针构成： p1：p1指向发送窗口的后沿，它后面的字节表示已经发送且已收到应答。 p2：p2指向尚未发送的第一个字节。p1-p2间的字节表示已经发送，但还没收到确认应答。这部分的字节仍需保留，因为可能还要超时重发。p2-p3间的字节表示可以发送，但还没有发送的字节。 p3：p3指向发送窗口的前沿，它前面的字节尚未发送，且不允许发送。 发送者每收到一个应答，后沿就可以向前移动指定的字节。此时若窗口大小仍然没变，前沿也可以向前移动指定字节。当p2和前沿重合时，发送者必须等待确认应答。 接收窗口 接收者收到的字节会存入接收窗口，接收者会对已经正确接收的有序字节进行累计确认，发送完确认应答后，接收窗口就可以向前移动指定字节。如果某些字节并未按序收到，接收者只会确认最后一个有序的字节，从而乱序的字节就会被重新发送。 流控制概念让发送端根据接收端的实际接收能力控制发送的数据量。 目的防止接收端在高负荷的情况下接收数据，因为这个时候如果接收端会将本应该接收的数据丢弃，就又会触发重发机制，从而导致网络流量的无端浪费。 具体实现接收端主动向发送端主机通知自己可以接受数据的大小，于是发送端会发送不超过这个限度的数据。这个大小限度就是接收窗口大小，所以流控制就是利用滑动窗口协议实现的。 死锁问题当发送者收到了一个窗口为0的应答，发送者便停止发送，等待接收者的下一个应答。但是如果这个窗口不为0的应答在传输过程丢失，发送者一直等待下去，而接收者以为发送者已经收到该应答，等待接收新数据，这样双方就相互等待，从而产生死锁。为了避免此类问题的发生，发送端主机会时不时发送一个叫做窗口探测的数据段，此数据段仅含一个以获取最新窗口的大小信息。 拥塞控制拥塞控制和流控制的区别？ 拥塞控制：拥塞控制是作用于网络的，它是防止过多的数据注入到网络中，避免出现网络负载过大的情况 流控制：流控制是作用于接收者的，它是控制发送者的发送速度从而使接收者来得及接收 拥塞情况观察拥塞的方式有两种：一是超时，二是连续接收到3个重复ACK。 PS：为什么是3个连续的ACK：由于我们不知道一个重复的ACK是由一个丢失的报文引起的，还是由于仅仅出现了几个报文段的重新排序引起的，因此我们等待少量的重复的ACK到来。因为若只是一些报文段的重新排序引起的，一般在重新排序报文段完成并产生一个新的ACK之前只可能产生1-2个重复的ACK。 拥塞的不同处理方式对于由于超时重传认为的拥塞，我们一般是重传报文段，然后进入慢启动算法(下方)；对于由于接收到3个重复的ACK认为的拥塞，我们一般是立即重传报文段，然后进入拥塞避免算法(下方)。这样处理的原因是因为当因为定时器超时，此时网络中可能已经很拥塞，数据确认的ACK已经无法发送回来，因此我们立即减少注入网络中的数据，使用慢启动拥塞窗口减小为1；而对于收到,3个重复的ACK说明还有其他的报文段到达了目的地(因为接收方只有在收到失序的报文段时才会产生重复的ACK而且还有重复的ACK发送回来)，也即收发两端还有数据的流动，因此我们不必使用慢启动突然减少注入网络的数据。 慢启动算法 和 拥塞避免算法发送方维护一个发送窗口，发送窗口的大小取决于网络的拥塞情况(拥塞窗口)，发送窗口是动态变化的。发送方还维护一个慢启动阈值。 发送窗口 &lt; 慢启动阈值：使用慢启动算法(指数级) 发送窗口 &gt; 慢启动阈值：使用拥塞避免算法(线性加一) 发送窗口 = 慢启动阈值：使用慢开始算法或拥塞避免算法 算法的具体过程： 通信开始时，使用慢启动算法，发送方的发送窗口设为1，并发送第一个分组M1； 接收方收到M1后，返回确认应答，此时发送方发送窗口扩大两倍，并发送M2、M3；（即，发送方每次收到确认应答后，都将发送窗口设为当前值的两倍） 若发送窗口&gt;慢启动阈值，则使用拥塞避免算法，每次收到确认应答后都将发送窗口+1； 若发送方出现了超时重传，则表明网络出现拥塞，此时： 慢启动阈值设为当前发送窗口的一半； 发送窗口设为1； 启用拥塞避免算法； PS：发送超时重传时，发送窗口有可能已经超过了慢开始门限，也有可能还没超过；此时不管何种情况，都一律启用拥塞避免算法，并执行上述三步操作！ 慢开始算法的作用：慢开始算法将发送窗口从小扩大，而且按指数级扩大，从而避免一开始就往网络中注入过多的分组从而导致拥塞；它将窗口慢慢扩大的过程其实也在探测网络拥塞情况的过程，当发现出现拥塞时，及时降低发送速度，从而减缓网络拥塞。 拥塞避免算法的作用：拥塞避免算法使发送窗口以线性方式增长，而非指数级增长，从而使网络更加不容易发生拥塞。 快重传和快恢复当因收到三个及三个以上的重复ACK时，使用如下拥塞控制方法： 收到3个重复的ACK，将慢启动阈值设为当前拥塞窗口大小的一半 此时立即重传丢失的报文不用等到定时器超时(超时重传)，此为快重传。 此后开始执行拥塞避免而不是慢启动，此为快恢复。 TCP的应用当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用。常见的使用UDP协议的应用如下： HTTP(超文本传输协议) FTP(文件传输协议) POP、SMTP(邮件传输协议) Telnet、Telnet(远程连接协议) QQ文件传输 参考 计算机网络传输层知识点全覆盖 TCP协议详解—学习笔记 TCP协议]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UDP协议]]></title>
    <url>%2F2018%2F05%2F17%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2FUDP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[引：UDP作为传输层的一大协议，虽然没有TCP可靠，但是却胜在简单。 UDP认识UDP(用户数据报协议) 是一种简单的面向数据报、无连接、传输层协议，并且保留了信息边界。UDP不提供错误校正，不保证有序，无法去重复，没有流量控制和拥塞控制，不能保证数据一定到达目的地，但是可以通过校验和提供错误侦测。UDP提供的的是不可靠传输，因此要有应用层来提供这些功能。 UDP特点 UDP只在IP数据报服务的基础上增加了少量的功能：利用端口号是实现分用、对整个报文的差错检测。 UDP是无连接的，通信前不需要建立连接，通信结束也无需释放连接。 UDP是不可靠的 它是尽力而为交付，不能确保每一个数据报都送达。 UDP是面向报文的，面向报文就是指：UDP数据传输的单位是报文，且不会对数据作任何拆分和拼接 操作。在发送端，应用程序给传输层的UDP什么样的数据，UDP不会对数据进行切分，只增加一个UDP头并交给网络层。在接收端，UDP收到网络层的数据报后，去除IP数据报头部后遍交给应用层，不会作任何拼接操作。 相比于TCP，UDP没有拥塞控制，UDP始终以恒定的速率发送数据，并不会根据网络拥塞情况对发送速率作调整。这种方式有利有弊。弊端：网络拥塞时有些报文可能会丢失，因此UDP不可靠。优点：有些使用场景允许报文丢失，如：直播、语音通话，但对实时性要求很高，此时UDP还是很有用武之地的。 UDP支持一对一、一对多、多对多、多对一通信；而TCP只支持一对一通信。 UDP首部开销小，只有8字节。而TCP头部至少由20字节，相比于TCP要高效很多。 UDP数据包首部 UDP数据包首部解析 16位源端口号：发送端应用程序使用的端口号，用于区分数据报来自哪个进程，多路复用一个传输层（复用：在发送端，多个应用进程公用一个传输层）。 16位目的端口号：数据送往接收端哪个应用程序，利用端口号实现多路分用（分用：在接收端，传输层会根据端口号将数据分派给不同的应用进程）。 16位UDP长度：UDP数据报首部和UDP数据报数据部分总字节数，最小值为8字节(仅有首部)，最大值为65535字节。 16位UDP检验和：UDP的校验和是可选的，TCP是必需的。UDP的校验和覆盖首部及数据部分。在下一节。 数据：要发送的数据，可以为空(0字节)。 UDP检验和UDP校验和的内容超出了UDP数据报文本身的范围，实际上，它的值是通过计算UDP数据报及一个伪包头而得到的。校验和的计算方法与通用的一样，都是累加求和。它的校验和的检验范围如下图： 伪首部并非UDP数据报中实际的有效成分。伪首部是一个虚拟的数据结构，其中的信息是从数据报所在IP分组头的分组头中提取的，既不向下传送也不向上递交，而仅仅是为计算校验和。这样的校验和，既校验了UDP用户数据的源端口号和目的端口号以及UDP用户数据报的数据部分，又检验了IP数据报的源IP地址和目的IP地址。伪报头保证UDP数据单元到达正确的目的地址。 校验方式： 《TCP/IP 详解》卷一 第一版中如下计算检验和字段的值： 发送方计算UDP检验和：首先把检验和字段置为0，把上图中,各部分数据(包括UDP伪首部及填充字段)按每16bit进行二进制反码求和(若最高位产生进位就加到最低位上去)，所求结果就是16bitUDP检验和字段的值。 接收方计算UDP检验和：对收到的UDP数据报(加上了UDP首部和填充字节)按每16bit进行二进制反码求和(若最高位产生进位就加到最低位上去)，若结果为全1，则UDP数据报在传输过程中没有出现差错，否则数据报有差错。 《TCP/IP 详解》卷一 第二版中如下计算检验和字段的值： 发送方计算UDP检验和：首先把检验和字段置为0，把上图中,各部分数据(包括UDP伪首部及填充字段)按每16bit进行二进制反码求和(若最高位产生进位就加到最低位上去)，最后结果再按位取反，所得结果就是16bitUDP检验和字段的值。 接收方计算UDP检验和：对收到的UDP数据报(加上了UDP首部和填充字节)按每16bit进行二进制反码求和(若最高位产生进位就加到最低位上去)，再按位取反，若结果为全0，则UDP数据报在传输过程中没有出现差错，否则数据报有差错。因为检验和的值从不为0xFFFF UDP服务器三类地址绑定 本地地址 远端地址 描述 LocalIP:Lport ForeignIP:Fport 只限于一个客户 LocalIP:Lport *:* 只限于一个本地IP和端口的数据包 *:port *:* 接收发送到Lport的所有数据包 第一行中服务器限定了只从本地Local这个IP地址的Lport端口接收数据报，而且只接收来自IP为Foreign且端口为Fport发来的数据。 第二行中服务器限定了只从本地LocalIP这个IP地址的Lport端口接收数据报，但可以接收任何主机发送的数据。 第三行中服务器只限定了接收数据的端口号，因此任何一个本地接口IP都可以接收它，而且数据可以来自任何主机发送的数据。 UDP的应用当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。常见的使用UDP协议的应用如下： QQ语言和视频 DNS(域名服务器) NFS(网络文件系统) TFTP(普通文件传输协议) 参考 UDP协议 UDP协议的应用]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>UDP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库事务]]></title>
    <url>%2F2018%2F05%2F11%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[引：数据库事务在数据库操作中是十分重要的，因为它要么全部执行，要么全部执行，这样才能保证数据库的数据的完整性与一致性。 什么是事务构成单一逻辑工作单元的操作集合。 事务是访问并可能更新各种数据项的一个程序执行单元，事务通常用形如begin transaction 和 end transaction来界定，事务由它们之间执行的全体操作组成。 举个例子：将钱从一个账户转到另一个账户就是一个事务，该事务包括分别对两个账户的更新。 ACID特性 原子性（Atomicity）：事务是一个不可分割的操作，要么全都正确执行，要么全都不执行。 一致性（Consistency）：事务开始前和事务结束后，数据库的完整性约束没有被破坏。比如上面转账例子中，两个账户的总金额就是完整性约束，因为他们的总金额是不变的。但是在并发事务中，一致性很容易被破坏，需要我们特别注意。 隔离性（Isolation）：事务的执行是相互独立的，它们不会相互干扰，一个事务不会看到另一个正在运行过程中的事务的数据。 持久性（Durability）：事务结束后，事务的结果必须是永久保存的。即使数据库发生崩溃，在数据库恢复后事务提交的结果仍然不会丢失。 确保隔离性有可能对系统性能造成较大的不利影响，由于这个原因，一些应用在隔离性上采取一些妥协。 事务的分类 扁平事务(Flat Transactions)：它是实际生产环境中最常用、最简单的事务类型。在扁平事务中，所有操作都处于同一层次，其由begin transaction开始，commit或rollback结束，其间的操作是原子的，要么都执行，要么都回滚，因此扁平事务是应用程序称为原子操作的的基本组成模块。但是发生错误时都需要回滚到事务的起始位置，无法回滚部分操作，所以回滚开销太大。 带有保存点的扁平事务(Flat Transactions with Savepoints)： 除了支持扁平事务支持的操作外，允许在事务执行过程中回滚同一事务中较早的一个状态。这是因为某些事务可能在执行过程中出现的错误并不会导致所有的操作都无效，放弃整个事务不合乎要求，开销太大，保存点用来通知事务系统应该记住事务当前的状态，以便当之后发生错误时，事务能回到保存点当时的状态。 链事务(Chained Transactions)：在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务，提交事务操作和开始下一个事务操作 将合并为一个原子操作，这意味着下一个事务将看到上一个事务的结果，就好像一个事务中进行的一样。和带有保存点的扁平事务不同的是，带有保存点的扁平事务能回滚到任意正确的保存点，而链事务中的回滚仅限当前事务，即只能恢复到最近的一个保存点。 嵌套事务(Nested Transactions)：由一个顶层事务(top-level transaction)控制着各个层次的事务，顶层事务之下嵌套的事务被称为子事务。嵌套事务是由若干事务组成的一棵树，子树既可以是嵌套事务也可以是扁平事务，处在叶节点的事务是扁平事务，但是每个事务从根到叶节点的距离可以说是不同的。子事务既可以提交也可以回滚。但是它的提交操作并不马上生效。除非其父事务已经提交。树中的任意事务回滚会引起它的所有子事务一同回滚，故子事务仅保留ACI特性而不具有D特性。 分布式事务(Distributed Transactions)：通常是一个分布式环境下运行的扁平事务，因此需要根据数据所在位置访问网络中的不同节点。 数据库并发访问会出现的问题读问题 脏读：A事务读取B事务尚未提交的更改数据，并在这个数据的基础上进行操作，这时候如果事务B回滚，那么A事务读到的数据是不被承认的。 虚度（不可重复读）：A事务读取了B事务已经提交的更改数据。假如A在取款事务的过程中，B往该账户转账100，A两次读取的余额发生不一致。防止读到更改数据，需要对操作的数据添加行级锁。 幻读：A事务读取B事务提交的新增数据。例如银行系统在同一个事务中两次统计存款账户的总金额，在两次统计中，刚好新增了一个存款账户，存入了100，这时候两次统计的总金额不一致。 防止读到新增数据，需要对操作的数据添加表级锁。 更新问题 第一类丢失更新：A事务撤销时，把已经提交的B事务的更新数据覆盖了。 第二类丢失更新：A事务覆盖B事务已经提交的数据，造成B事务所做的操作丢失。 事务隔离级别为了解决上述问题，数据库通过多种并发控制机制（常用的有两阶段封锁和快照隔离）解决并发访问的问题。但是直接使用并发控制机制是很复杂的，数据库给用户提供了不同的事务隔离级别，只要设置了事务隔离级别，数据库就会分析事务中的sql语句然后自动选择合适的并发控制机制。 四种隔离级别如下： 可串行化(SERIALIZABLE)：保证可串行化调度，不允许出现任何问题。 可重复读(REPEATABLE READ) ：只允许读取已提交的数据，而且在一个事务两次读取一个数据项期间，其他事务不能更新该数，单不要求该事务与其他事务可串行化。 已提交读(READ COMMITTED)：只允许读取已提交的数据，但不要求可重复读。 未提交读(READ UNCOMMITTED)：允许读取未提交的数据，这是SQL允许的最低一致性级别。 不同的隔离级别对并发问题的解决情况如下图： 隔离级别 脏读 虚读 幻读 第一列丢值更新 第二类丢失更新 可串行化(SERIALIZABLE) 不允许 不允许 不允许 不允许 不允许 可重复读(REPEATABLE READ) 不允许 不允许 允许 不允许 不允许 已提交读(READ COMMITTED) 不允许 允许 允许 不允许 允许 未提交读(READ UNCOMMITTED) 允许 允许 允许 不允许 允许 参考 《数据库系统概念》 数据库事务详解 数据库并发事务存在的问题（脏读、不可重复读、幻读等） 数据库的事务与并发控制 MySQL中事务的分类 数据库隔离级别及其实现原理]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库范式]]></title>
    <url>%2F2018%2F05%2F10%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E8%8C%83%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：设计好数据库的表的前提就是要满足更高级别数据库的范式，当然级别不是越高越好，但是至少不差！ 数据库范式的优缺点优点 减少数据冗余 消除异常（插入异常，更新异常，删除异常） 缺点 查询时要联结多个表，增加了查询的复杂度 查询时需要联结多个表，降低了数据库查询性能 什么是范式(NF Normal Form)范式是一张数据表的表结构所符合的某种设计标准，满足高等级的范式的先决条件是满足低等级范式。 五大范式以下范式的基本概念可以参照我的另一篇博文：关系型数据库的基础概念；具体案例可以参照这篇博文：数据库范式那些事 第一范式（1NF） 如果一个关系模式R的所有属性都是不可分的基本数据项，则R∈1NF 第一范式就是每一个属性都不可再分。不符合第一范式则“不能”称为关系数据库，因为你可以一张表搞定所有，而不用产生关系。 第二范式（2NF） 若关系模式R∈1NF，并且每一个非主属性都完全函数依赖于R的码，则R∈2NF 表中的属性必须完全依赖于全部主键，而不是部分主键。所以只有一个主键的表如果符合第一范式，那一定是第二范式 减少数据容冗余和减少更新异常 第三范式（3NF） 若关系模式R∈2NF，并且每一个非主属性对于码都不存在传递函数依赖，则R∈3NF 消除了非主属性对于码的传递函数依赖 减少数据容冗余和减少常插入异常，更新异常，删除异常 巴斯-科德范式（BCNF） 若关系模式R∈3NF，并且每一个主属性对于码都不存在部分与传递函数依赖，则R∈BCNF 消除主属性对于码的部分与传递函数依赖，BCNF是在第三范式的基础上的一种特殊情况，既每个表中只有一个候选键。 减少插入异常，更新异常与删除异常 第四范式（4NF） 若关系模式R∈1NF，并且只允许的非平凡多值依赖是函数依赖，不允许存在其他非平凡且非函数依赖的多值依赖，则R∈4NF。 平凡的多值依赖属于第四范式 减少数据容冗余和减少常插入异常，更新异常，删除异常 总结数据库设计应用的范式不是越高越好，要看实际情况而定。第三范式已经很大程度上减少了数据冗余，并且减少了造成插入异常，更新异常，和删除异常了。大多数情况应用到第三范式已经足够，在一定情况下第二范式也是可以的。 参考 解释一下关系数据库的第一第二第三范式 数据库范式那些事 数据库中的范式和多值依赖]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关系型数据库的基础概念]]></title>
    <url>%2F2018%2F05%2F10%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[引：在学习或者设计关系型数据库之前，我们都需要先学习关系型数据库的基础概念。 数据库关系模型数据库结构 关系数据库由表的集合构成，每个表有唯一的名字。 在关系模型的术语中，关系用来指代表，元组用来指代行 ，属性用来指代表中的列，关系实例用来指代一个关系的特定实例。 对于关系的每个属性，都存在一个允许取值的集合，称为该属性的域。 如果域中的元素被看做是不可再分的单元，则域是原子的。 数据库模式 数据库模式是数据库的逻辑设计，数据库实例是给定时刻数据库数据的一个快照。 关系对应于程序设计语言中变量的定义，关系模式对应于程序设计语言中类型的定义，关系实例对应于程序设计语言中变量的值。 关系模式由属性序列及各属性对应的域组成。 码 超码是一个或多个属性的集合，这些属性的集合可以使我们在一个关系中唯一地表示一个元组。 如果K是一个超码，那么K的任意超集也是超码，他们的任意真子集都不能称为超码，这样最小的超码称为候选码(码),候选码中任何一个属性称为主属性，其它为非主属性。 主码代表被数据库设计者用来在一个关系汇总区分不同元组的候选码，主码应该选择那些值从不或极少变化的属性。 一个关系模式(r1)可能在它的属性中包含另一个关系模式(r2)的主码，那么这个属性在r1上称做参照r2的外码。关系r1被称为外码依赖的参照关系，r2被称为外码的被参照关系。 函数依赖若在一张表中，在属性（或属性组）X的值确定的情况下，必定能确定属性Y的值，那么就可以说Y函数依赖于X，写作 X → Y。 完全函数依赖 在一张表中，若 X → Y，且对于 X 的任何一个真子集（假如属性组 X 包含超过一个属性的话），X → Y 不成立，那么我们称 Y 对于 X 完全函数依赖，记作 X F→ Y。（那个F应该写在箭头的正上方） 部分函数依赖 假如 Y 函数依赖于 X，但同时 Y 并不完全函数依赖于 X，那么我们就称 Y 部分函数依赖于 X，记作 X P→ Y。（那个P应该写在箭头的正上方） 传递函数依赖 在 Y 不包含于 X，且 X 不函数依赖于 Y这个前提下，假如 Z 函数依赖于 Y，且 Y 函数依赖于 X ，那么我们就称 Z 传递函数依赖于 X ，记作 X T→ Z。（那个T应该写在箭头的正上方） 多值依赖若在一张表中，在属性集X, Y, 和Z是U的子集，并且Z=U-X-Y，当且仅当表中的记录上当X，Z确定时，属性Y有一组值，这组值仅仅决定于属性X值而与属性Z值无关，多值依赖X-&gt;-&gt;Y成立。如果把上面的一组改为一个，那么多值依赖就变成了函数依赖。当然一个值组成的组也是组，所以说，函数依赖是多值依赖的特殊情况。 平凡的多值依赖 若X-&gt;-&gt;Y，而Z等于空集，则称X-&gt;-&gt;Y为平凡的多值依赖，属性集合中分为两个真子集，每一个X对应一组Y的取值 非平凡的多值依赖 若X-&gt;-&gt;Y，而Z不等于空集，则称X-&gt;-&gt;Y为非平凡的多值依赖 参考 《数据库系统概念》]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL必知必会]]></title>
    <url>%2F2018%2F05%2F07%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FMySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A%2F</url>
    <content type="text"><![CDATA[引:虽然用了这么久的数据库，但是有时候使用起来难免会去查怎么使用，这样下去也不是办法，所以自己就在这里以Mysql为例总结一下经常用到的地方。 基本注意点 SQL关键字使用大写，所有列和表名使用小写 SQL语句由子句构成，一个子句通常由一个关键字和一个数据组成，子句的顺序一般为: SELECT 数据 FROM 数据 WHERE 数据 GROUP BY 数据 HAVING 数据 ORDER BY 数据 LIMIT 数据 通配符搜索的处理一般要比其他搜索所花时间长，不要过度使用通配符，如果要，就应该将通配符放在搜索集合小的搜索上 多数DBMS使 +或||来实现拼接，MYSQL则使 Concat函数来实现 数据库列般称为列，计算字段一般称为字段 MySQL使用的日期格式必须是yyyy-mm-dd WHERE在数据分组前进行过滤，HAVING在数据分组后进行过滤 子查询最常见的使用是在WHERE子句的IN操作符后 在删除或更新表之前先SELECT出来，防止删错 利用外键约束，防止删除与其他表相关联的行 MySQL基本使用 MySQL帮助 相关命令 -h/–help MySQL服务启动和关闭 mysql.server start/stop MySQL连接 mysql -u 用户名 -p 密码 -h 主机名 -P 端口 （默认用户名为使用者名，主机名默认为localhost，端口默认为3306） 退出命令行 quit/exit 显示所有数据库 SHOW DATABASES 使用数据库 USE 数据库名 显示某库下所有的表 SHOW TABLES 显示某表下面的列 SHOW COLUMNS FROM 表名 / DISCRIBE 表名 显示服务器的状态信息 SHOW STATUS 显示创建特定数据库或表的MySQL语句 SHOW CREATE DATABASE 数据库名 / TABLE 表名 安全管理 用户管理 USE mysql SELECT user FROM user CREATE USER rex IDENTIFIED BY ‘密码’ //创建用户账号 RENAME USER rex TO rex1 // 修改用户名 DROP USER rex // 删除用户账号 SHOW GRANTS FOR rex // 显示rex的权限，USAGE ON .表示没有权限 GRANT SELECT ON 数据库/表.* TO rex // 给rex对数据库/表的读权限 REVOKE SELECT ON 数据库/表.* TO rex // 撤销rex对数据库/表的读权限 更改密码 SET PASSWORD FOR rex = Password ‘新密码’ SET PASSWORD = Password ‘新密码’ // 修改当前用户的密码 数据库维护 数据库备份 使用mysqldump 使用mysqlhotcopy 使用BACKUP TABLE或SELECT INTO OUTFILE 维护数据库 ANALYZE/CHECK TABLE 表名 // 检查表键是否正确 OPTIMIZE TABLE 表名 // 回收所用空间 查看日志文件 错误日志：通常为/data/hostname.err，可通过–log-error修改文件 查询日志：通常为/data/hostname.log，可通过–log修改文件 二进制文件：通常为/data/hostname-bin 缓慢查询日志：通常为/data/hostname-slow.log，可通过hostname-slow- queries修改文件 创建和操纵表 创建表 CREATE IF NOT EXISTS TABLE 表名(id int NOT NULL AUTO_INCREMENT ,…, PRIMARY KEY(id)) ENGINE=InnoDB 更新表 ALTER TABLE 表名 ADD 类型 // 增加列 ALTER TABLE 表1 ADD CONSTRAINT fk表1表2 FOREIGN KEY(表2id) REFERENCES 表2(表2id) 删除表 DROP TABLE 表名 重命名表 RENAME TABLE 表名1 TO 表名2 查询数据基本查询数据 检索单个列 SELECT prod_name FROM product 检索多个列 SELECT prod_id, prod_name FROM product 检索所有列 SELECT * FROM product 检索不同的行 SELECT DISTINCT vend_id FROM product 限制结果的行数为前5条/第二个5条 SELECT * FROM product LIMIT 5 / LIMIT 5(开始位置，第一行其实第0 行),5(要检索的行数) SELECT * FROM product LIMIT 5 (偏移量) OFFSET 5 (开始位置) 排序检索数据 按一个列排序 SELECT prod_name FROM product ORDER BY prod_name 按多个列排序(先按prod_price排序，如果相同，则比较prod_name) SELECT prod_id, prod_price, prod_name FROM product ORDER BY prod_price, prod_name 指定排序方向(默认升序ASC，降序DESC) SELECT prod_id, prod_price, prod_name FROM product ORDER BY prod_price DESC 过滤数据 WHERE子句过滤 SELECT prod_name, prod_price FROM product WHERE prod_price = 2.50 WHERE子句操作符 操作符 | 说明—|—= | 等于&lt;&gt; | 不等于!= | 不等于&lt; | 小于&lt;= | 小于等于> | 大于>= | 大于等于BETWEEN… AND | 在指定的两个值之间(mysql包括两端)NOT BETWEEN… AND | 不在指定的两个值之间(mysql不包括两端) 空值检查(需要注意null和没有值得区别) SELECT prod_name FROM products WHERE prod_price IS NULL 数据过滤操作符 操作符 | 说明 —|— AND | 且（优先级比OR高） OR | 或 IN | 在指定范围内，如WHERE id IN (1002 1003) NOT IN | 不在指定范围内 数据过滤通配符(利用LIKE操作符) 操作符 | 说明 —|— % | 表示任意字符出现的任意次数 _ | 表示单个字符 用正则表达式进行搜索(正则表达式的使用自行搜索) SELECT * FROM product WHERE prod_name REGEXP ‘.000’ OR prod_name REGEXP ‘1000|2000’ OR prod_name REGEXP ‘[123] Ton’ 创建计算字段计算字符是运行时在SELECT语句内创建的。 拼接字段(Concat函数) SELECT Concat(vend_name,’(‘,vend_country,’)’) FROM vendors 使用别名(列名，表名都可以使用，使用关键字AS，也可省略) SELECT Concat(RTrim(vend_name),’(‘, RTrim(vend_country),’)’) AS vend_title FROM vendors 执行算术计算(加减乘除) SELECT quantity*item_price AS expanded_price FROM orderitems 使用数据处理函数 文本处理函数函数 | 说明—|—Left() | 返回串左边的字符Right() | 返回串右边的字符Length() | 返回串的长度Locate() | 找出一个串的子串Lower() | 将串转化为小写Upper() | 将串转化为大写LRrim() | 去掉串左边的空格RTrim() | 去掉串右边的空格Trim() | 去掉串两边的空格SubString() | 返回子串的字符 日期和时间处理函数 函数 | 说明 —|— AddDate() | 增加一个日期(天、周等) AddTime() | 增加一个时间(时、分等) CurDate() | 返回当前的日期 CurTime() | 返回当前的时间 Date() | 返回日期时间的日期部分 DateDiff() | 计算两个日期之差 Date_Format() | 返回一个格式化的日期或时间串 Day() | 返回一个日期的天数部分，类推年月日，时分秒 Now() | 返回当前日期和时间 数值处理函数 函数 | 说明 —|— Abs() | 返回一个数的绝对值 Cos() | 返回一个角度的余弦，类推正弦 Exp() | 返回一个数的指数值 Mod() | 返回除数操作的余数 Rand() | 返回一个随机数 Sqrt() | 返回一个数的平方根 汇总数据 聚集函数 函数 | 说明 —|— AVG() | 返回某列的平均值 COUNT() | 返回某列的行数 MAX() | 返回某列的最大值 MIN() | 返回某列的最小值 SUM() | 返回某列的总和 分组数据 创建分组(先分组后聚集) SELECT vend_id COUNT(*) AS num_prods FROM product GROUP BY vend_id 过滤分组 SELECT cust_id COUNT() AS orders FROM order GROUP BY cust_id HAVING COUNT()&gt;=2 使用子查询 利用子查询进行过滤(找出买TNT2的顾客信息) SELECT cust_name, cust_contact FROM customers WHERE cust_id IN (SELECT cust_id FROM order WHERE order_num IN (SELECT order_num FROM orderitem WHERE prod_id=’TNT2’)) 使用计算字段使用子查询(显示顾客的信息和订单量) SELECT cust_name, cust_state, (SELECT COUNT (*) FROM order WHERE order.cust_id = customer.cust_id) AS orders FROM customer 联结表查询 联结查询(没有WHERE子句会产生笛卡尔积) SELECT vend_name, prod_name FROM vendor, product, WHERE vendor.vend_id = product.vend_id 内部联结(等值联结，首选) SELECT vend_name, prod_name FROM vendor INNER JOIN product ON vendor.vend_id = product.vend_id 多表联结 SELECT vend_name, prod_name, quantity FROM vendor, product, orderitem WHERE product.vend_id = vendor.vend_id AND orderitem.prod_id = product.prod_id 自联结(一般联结查询要比子查询快) ELECT p1.prod_id, p1.prod_name FROM product p1, product p2 WHERE p1.vend_id = p2.vend_id AND p2.prod_id = ‘DTNTR’ 自然联结(排除一个列多次出现，使每个列只返回一次; 大部分内部联结都是自然联结) 外部联结(联结包括了那些在相关表没有关联行的行，左外联结(左边的所有行必出现)，右外联结(右边的所有行必出现)) SELECT vend_name, prod_name FROM vendor LEFT OUTER JOIN product ON vendor.vend_id = product.vend_id 组合查询 创建组合查询(大部分使用WHERE子句更快，但是对于多个表使用UNION可能更简单，重复行会被自动取消，如果不取消，使用UNION ALL) SELECT vend_id, prod_id, prod_price FROM product WHERE prod_price &lt;=5 UNION SELECT vend_id, prod_id, prod_price FROM product WHERE vend_id IN (1001, 1002) 插入数据 插入一行数据(如果是完整的行，可以不写列名，但是要注意值的顺序) INSERT INTO customer(列名) VALUES(类名对应的值) 插入多个行 INSERT INTO customer(列名) VALUES(类名对应的值),VALUES(类名对应的值) 插入检索出的数据 INSERT INTO customer(列名) SELECT (列名) FROM 表名 更新数据 更新表中特定的列(一定不要忘了WHERE子句) UPDATE customer SET 列名 = 值 WHERE 子句 更新多列 UPDATE customer SET 列名 = 值,列名 = 值 WHERE 子句 删除数据 删除特定的行 DELETE FROM 表 WHERE 子句 使用视图 创建视图 CREATE VIEW 视图名 AS SELECT 语句 查看创建视图的语句 SHOW CREATE VIEW 视图名 删除视图 DROP VIEW 视图名 更新视图（先删除原视图，再创建新视图） 参考 《MySQL必知必会》]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HelloWorld_Shiro Activity]]></title>
    <url>%2F2018%2F05%2F03%2FHelloWorld%2FHelloWorld-Shiro-Activity%2F</url>
    <content type="text"><![CDATA[引：记得去年暑假要弄工作流Activity没有弄出来，这次刚好看到了一个基于Shiro和Activity的考勤项目，就想写一下了！ 技术点 前端模板引擎：Velocity（不做重点讲解，它的页面主要使用的BootStrap的Admin开源框架） 后台：SSM框架 任务调度框架：Quartz 工作流引擎：Activity 权限控制框架：Shiro 项目功能 利用Shiro实现登录模块并实现权限控制 实现查看出勤记录 利用Quartz实现定时任务，每天凌晨扫描没有打卡记录的员工并记录 利用Activity实现补签流程 项目源码HelloWorld_Shiro Activity 之 WorkAttendance考勤项目 重点源码说明利用Shiro实现登录与权限控制我们这里主要利用了Shiro来进行登录验证，我们可以先看看Shiro架构，如下图： Subject主要是存储了访问信息 SecurityManager是Shiro的核心，他主要用于协调Shiro内部各种安全组件 Realm用于连接Shiro和客户系统的用户数据的桥梁。一旦Shiro真正需要访问各种安全相关的数据（比如使用用户账户来做用户身份验证以及权限验证）时，他总是通过调用系统配置的各种Realm来读取数据，可以对比为SpringSecurity的Provider。 Shrio配置文件主要是WorkAttendance/src/main/resources/spring-shiro.xml，在配置文件中，我们除了配置Realm和SecurityManager，还要配置一个ShiroFilter过滤链，这个过滤链主要配置要拦截或者忽略的路径，可以对比为SpringSecurity的配置类WebSecurityConfigurerAdapter。当然我们也可以使用注解来实现路径权限控制，如: @RequiresPermissions(“attend:attendList”) 我们看看登录源代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879// LoginController的验证登录的方法public String checkLogin(HttpServletRequest request) throws UnsupportedEncodingException, NoSuchAlgorithmException &#123; String username = request.getParameter("username"); String pwd = request.getParameter("password"); // 组装成Token给Realm使用 UsernamePasswordToken token = new UsernamePasswordToken(username,pwd); // 等到登录访问信息 Subject subject = SecurityUtils.getSubject(); try &#123; // 进入Realm进行认证 subject.login(token); // 设置session过期时间 SecurityUtils.getSubject().getSession().setTimeout(1800000); &#125; catch (Exception e) &#123; return "login_fail"; &#125; return "login_succ";&#125;// 自定义的Realmpublic class MyRealm extends AuthorizingRealm &#123; @Autowired private UserService userService;// 授权 @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) &#123; // PrincipalCollection,可以理解身份上下文 String username = (String) principalCollection.getPrimaryPrincipal(); User user = userService.findUserByUserName(username); SimpleAuthorizationInfo authorizationInfo = new SimpleAuthorizationInfo(); for(Role role :user.getRoleList())&#123; authorizationInfo.addRole(role.getRole()); for(Permission permission :role.getPermissionList())&#123; authorizationInfo.addStringPermission(permission.getPermission()); &#125; &#125; return authorizationInfo; &#125;// 登入验证 @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authenticationToken) throws AuthenticationException &#123; // UsernamePasswordToken封装了用户名和密码 UsernamePasswordToken usernamePasswordToke = (UsernamePasswordToken)authenticationToken; String username = usernamePasswordToke.getUsername(); User user = userService.findUserByUserName(username); if(user==null)&#123; return null; &#125;else &#123; // 会使用自定义的账号密码校验器进行验证，并返回AuthenticationInfo AuthenticationInfo info = new SimpleAuthenticationInfo(user.getUsername(), user.getPassword(), getName()); SecurityUtils.getSubject().getSession().setAttribute("userInfo",user); return info; &#125; &#125;&#125;// 自定义的密码验证器，配置文件中配置public class CustomCredentialsMatcher extends SimpleCredentialsMatcher &#123; @Override public boolean doCredentialsMatch(AuthenticationToken authenticationToken, AuthenticationInfo authenticationInfo) &#123; // 对比用户登入的数据与数据库查询出来的信息 try &#123; UsernamePasswordToken usernamePasswordToken = (UsernamePasswordToken) authenticationToken; // 用户登录的密码 String password = String.valueOf(usernamePasswordToken.getPassword()); Object tokenCredentials = MD5Utils.encryptPassword(password); // getCredentials()和equals都是SimpleCredentialsMatcher自带的方法 Object acountCredentials = getCredentials(authenticationInfo); return equals(tokenCredentials,acountCredentials); &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; return false; &#125;&#125; 利用Quartz实现定时任务它的核心元素关系图如下： 它的配置文件在WorkAttendance/src/main/resources/spring-job.xml，我们也主要就是配置SchedulerFactory，Trigger和Job。里面关于cronExpression可以使用在线Cron表达式生成器来确定或者书写。 我们看看定时任务的源代码：12345678910// 其实很简单，因为我们在配置文件中以及配置好要触发的类和方法了public class AttendCheckTask &#123; @Autowired private AttendService attendService; // JobMethod public void checkAttend() &#123; attendService.checkAttend(); &#125;&#125; 利用Activity实现补签流程它的配置文件主要在WorkAttendance/src/main/resources/spring-activity.xml，我们主要就是配置processEngineFactory，processEngineConfiguration（会设置自动建表23张以及要部署的流程资源）以及各个服务类。 关于流程资源我们可以利用IDEA的actiBPM插件去画这个流程图，需要注意的是设置好各个ID，因为我们后面需要用到它。 接下来我们看看它的核心代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// 1. 开始流程并提交任务public void startReAttendFlow(ReAttend reAttend) &#123; // 从公司组织架构中，查询到此人上级领导人用户名 // 这里手动设置 reAttend.setCurrentHandler("rex666"); reAttend.setStatus(RE_ATTEND_STATUS_ONGOING); // 插入数据库补签表(ID自增) reAttendMapper.insertSelective(reAttend); // 将一些需要的参数放入流程中传递，即Variables Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); map.put(RE_ATTEND_SIGN, reAttend); // 后面需要根据流程中的变量名来获取 map.put(NEXT_HANDLER, reAttend.getCurrentHandler()); // 获得流程实例 ProcessInstance instance = runtimeService.startProcessInstanceByKey(RE_ATTEND_FLOW_ID, map); // 获得任务 Task task = taskService.createTaskQuery().processInstanceId(instance.getId()).singleResult(); // 提交用户补签任务 taskService.complete(task.getId(), map);&#125;// 2. 当前处理人获得需要处理的任务public List&lt;ReAttend&gt; listTasks(String userName) &#123; //转换成页面实体 需要返回的对象 List&lt;ReAttend&gt; reAttendList = new ArrayList&lt;ReAttend&gt;(); List&lt;Task&gt; taskList = taskService.createTaskQuery().processVariableValueEquals(userName).list(); if (CollectionUtils.isNotEmpty(taskList)) &#123; for (Task task : taskList) &#123; Map&lt;String, Object&gt; variable = taskService.getVariables(task.getId()); ReAttend reAttend = (ReAttend) variable.get(RE_ATTEND_SIGN); reAttend.setTaskId(task.getId()); reAttendList.add(reAttend); &#125; &#125; return reAttendList;&#125;// 3.当前处理人处理任务@Transactionalpublic void approve(ReAttend reAttend) &#123; // 需要处理的任务 Task task = taskService.createTaskQuery().taskId(reAttend.getTaskId()).singleResult(); // 如果同意 if (("" + RE_ATTEND_STATUS_PSSS).equals(reAttend.getApproveFlag())) &#123; Attend attend = new Attend(); attend.setId(reAttend.getAttendId()); attend.setAttendStatus(ATTEND_STATUS_NORMAL); // 将出勤数据的状态从异常变为正常 attendMapper.updateByPrimaryKeySelective(attend); // 审批通过，修改补签数据状态 reAttend.setStatus(RE_ATTEND_STATUS_PSSS); reAttendMapper.updateByPrimaryKeySelective(reAttend); &#125; else if (("" + RE_ATTEND_STATUS_REFUSE.toString()).equals(reAttend.getApproveFlag())) &#123; reAttend.setStatus(RE_ATTEND_STATUS_REFUSE); reAttendMapper.updateByPrimaryKeySelective(reAttend); &#125; // 完成任务 taskService.complete(task.getId());&#125; 其他这个项目关于前端页面前端模板引擎Velocity，SSM架构，Mybatis自动生成插件以及分页方法，这里都不再多说，项目的注释应该算是很全了，认真看就行。 参考与致谢 SSM实战-码码员工考勤系统]]></content>
      <categories>
        <category>HelloWorld</category>
      </categories>
      <tags>
        <tag>SSM</tag>
        <tag>Shiro</tag>
        <tag>Activity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HelloWorld_SpringBoot Angular]]></title>
    <url>%2F2018%2F04%2F25%2FHelloWorld%2FHelloWorld-SpringBoot-Angular%2F</url>
    <content type="text"><![CDATA[引：前段时间写了个前后台不分离的SSMLogin，大家可能会觉得前后台不分离太low，所以这次我们使用SpringBoot+Angular搭建了一个利用Token来进行身份验证的前后台分离登录Demo项目。 项目源码SpringBoot+Angular Angular前端本文前端基于Angular官方样例Tour of Heroes，请先到官网下载，也可以拷贝自己的项目源码（不过最好还是一步步来，先去官网下载源码），这次前端不是主要讲解的地方，所以官网源码部分就不说了，自己去看。我只说增加的核心部分。 login组件下面是登录的ts代码：1234567891011121314151617181920212223242526272829export class LoginComponent implements OnInit &#123; // 用来接收后台的数据 model: any = &#123;&#125;; //注入依赖对象 constructor( private router: Router, private authenticationService: AuthenticationService, ) &#123; &#125; ngOnInit() &#123; // 重置登录状态 this.authenticationService.logout(); &#125; login() &#123; // 利用authenticationService获取对象 this.authenticationService.login(this.model.username, this.model.password).subscribe( result =&gt; &#123; if (result) &#123; // 登录成功，调制路由 this.router.navigate(['dashboard']); &#125; else &#123; this.log('Username or Password is incorrect'); &#125; &#125; ) &#125;&#125; AuthenticationService服务看看它的代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// http头，使用json传递数据const httpOptions = &#123; headers: new HttpHeaders(&#123;'Content-Type': 'application/json'&#125;)&#125;;@Injectable()export class AuthenticationService &#123; // 认证的url private url: string = `$&#123;environment.apiURL&#125;/auth`; constructor(private http: HttpClient) &#123; &#125; login(username: string, password: string): Observable&lt;boolean&gt; &#123; return this.http.post&lt;any&gt;(this.url,JSON.stringify(&#123;username: username, password: password&#125;),httpOptions).pipe( tap(response =&gt; &#123; // 获得token认证 let token = response.token; if (token) &#123; // 存储token到浏览器localStorage中，以后每次都带着它去请求数据 localStorage.setItem('currentUser',token); &#125; &#125;), catchError(err =&gt; &#123; console.error(err); return of (false); &#125; ) ) &#125; // 从localStorage获得token getToken(): String &#123; return localStorage.getItem('currentUser'); &#125; logout(): void &#123; // 清空token，那么没有Token也就不能刷新页面了 localStorage.removeItem('currentUser'); &#125; isLoggedIn(): boolean &#123; var token: String = this.getToken(); return token &amp;&amp; token.length &gt; 0; &#125;&#125; AuthenticationInterceptor拦截器有了这个拦截器，以后所有的请求都过经过这里，看看它的代码：12345678910111213141516171819@Injectable()export class AuthenticationInterceptor implements HttpInterceptor &#123; // next 相当于Java Filter 的chain intercept(req: HttpRequest&lt;any&gt;, next: HttpHandler): Observable&lt;HttpEvent&lt;any&gt;&gt; &#123; const idToken = localStorage.getItem('currentUser'); if (idToken) &#123; // 将原来的请求加上token包装成新的请求发送 const cloned = req.clone(&#123; headers: req.headers.set('Authorization', 'Bearer ' + idToken) &#125;); return next.handle(cloned); &#125; else &#123; return next.handle(req); &#125; &#125;&#125; CanActivateAuthGuard保卫有了CanActivateAuthGuard就能够防止未登录用户访问其他页面，看看它的代码：12345678910111213141516171819@Injectable()export class CanActivateAuthGuard implements CanActivate &#123; constructor( public router: Router, private authService: AuthenticationService ) &#123;&#125; canActivate(route: ActivatedRouteSnapshot, state: RouterStateSnapshot) &#123; if (this.authService.isLoggedIn()) &#123; // 可以通过 return true; &#125; // 不能通过，跳转到登录页面 this.router.navigate(['/login']); return false; &#125;&#125; Springboot后台我们首先要对SpringBoot的项目结构有个熟悉的认识，如果不知道的可以先稍微了解一下他，他太棒了。这次开发也是上帝模式。 SpringSecurity权限控制首先我们要对前台的请求进行认证，利用配置文件设置一些值：12345678910111213# 控制跨域访问cors: allowedOrigins: &quot;*&quot; allowedMethods: GET,POST,DELETE,PUT,OPTIONS allowedHeaders: Origin,X-Requested-With,Content-Type,Accept,Accept-Encoding,Accept-Language,Host,Referer,Connection,User-Agent,Authorization# token配置jwt: header: Authorization secret: mySecret expiration: 7200 issuer: IATA authenticationPath: /auth SpringSecurity配置类在com.todorex.config.WebSecurityConfig类中，在这个类中，我们主要是配置认证路径、跨域访问以及过滤器等设置。 SpringSecurity自定义过滤器在com.todorex.config.AuthenticationTokenFilter类中，主要是验证token，但不重新计算token。 token生成方法在com.todorex.util.JwtTokenUtil类中，主要有生成token以及验证token的方法。 Contoller主要是控制处理URL，其中比较重要的就是com.todorex.controller.AuthenticationController类，它是用来进行权限认证的，我们看看它的代码：123456789101112131415161718192021222324252627282930@RestController@RequestMapping(produces = MediaType.APPLICATION_JSON_VALUE)public class AuthenticationController &#123; @Autowired private AuthenticationManager authenticationManager; @Autowired private JwtTokenUtil jwtTokenUtil; @Autowired private UserDetailsService userDetailsService; // 请求路径(/auth) @PostMapping(value = "$&#123;jwt.authenticationPath&#125;") public AuthenticationResponse login(@RequestBody AuthenticationRequest request) throws AuthenticationException &#123; // 对包装过后的UsernamePasswordAuthenticationToken精心再包装成Authentication final Authentication authentication = authenticationManager.authenticate(new UsernamePasswordAuthenticationToken(request.getUsername(), request.getPassword())); // 将该认证添加到上下文中（避免多次验证） // SecurityContextHolder用于存储安全上下文（security context）的信息 SecurityContextHolder.getContext().setAuthentication(authentication); final UserDetails userDetails = userDetailsService.loadUserByUsername(request.getUsername()); // 实际应用中，生成token时可能会用到更多的参数 final String token = jwtTokenUtil.generate(userDetails.getUsername()); // 返回Token return new AuthenticationResponse(token); &#125;&#125; 其他都是普通的Controller，但是对于URL的设计我们需要注意，我们主要是用Restful风格的URL，这种风格是怎么样的呢？我们可以参考下面的博文：【Restful】三分钟彻底了解Restful最佳实践。 Service主要是处理业务的，这里我们需要注意的这个类：com.todorex.service.UserDetailsServiceImpl，我们需要实现UserDetailsService接口，因为SpringSecurity方法会用到，看看下面的代码：123456789101112131415161718192021222324252627282930313233343536373839@Servicepublic class UserDetailsServiceImpl implements UserDetailsService&#123; @Autowired private UserRepository userRepository; @Override public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException &#123; User user = userRepository.findByUsername(s); if (user == null) &#123; throw new UsernameNotFoundException(String.format("No user found with username '%s'.", s)); &#125; else &#123; return create(user); &#125; &#125; /** * 包装成SpringSecurity需要的User * @param user * @return */ private static org.springframework.security.core.userdetails.User create(User user) &#123; return new org.springframework.security.core.userdetails.User(user.getUsername(), user.getPassword(), mapToGrantedAuthorities(user.getAuthorities())); &#125; /** * 包装权限 * @param authorities * @return */ private static List&lt;GrantedAuthority&gt; mapToGrantedAuthorities(List&lt;Authority&gt; authorities) &#123; // Java8语法 return authorities.stream() .map(authority -&gt; new SimpleGrantedAuthority(authority.getName().name())) .collect(Collectors.toList()); &#125;&#125; Dao这里我们使用的JPA，它内部实现是Hibernate，我们只要先定义Entity再定义Dao类就可以了。 EntityEntity定义之后可以根据实体自动建表（可在配置文件中配置），如下：1234567# jpa配置 jpa: database: MYSQL show-sql: true hibernate: # 表不存在就自动建表 ddl-auto: create DaoDao接口只要继承JpaRepository就会有很多内置方法，如果要自己写SQL也可以参照com.todorex.HeroRepository的写法。 单元测试我们可以先定义总的接口：1234@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringBootTestAbstract &#123;&#125; 然后每个要测试的类继承他就可以了，避免了重复配置，IDEA还有很多技巧，自己可以去baidu、google，这里也举个例子：12345678910111213141516public class DataSourceTest extends SpringBootTestAbstract&#123; @Autowired ApplicationContext applicationContext; @Autowired DataSourceProperties dataSourceProperties; @Test public void testDataSource() throws Exception &#123; // 获取配置的数据源 DataSource dataSource = applicationContext.getBean(DataSource.class); // 查看配置数据源信息 System.out.println(dataSource); System.out.println(dataSource.getClass().getName()); System.out.println(dataSourceProperties); &#125;&#125; 日志SpringBoot默认使用logback作为日志框架，我们可以做如下配置：123456789# 日志配置logging: level: # 配置包以及输出等级 com.todorex: debug pattern: console: &quot;%d - %msg%n&quot; path: /var/localLog/ file: /var/localLog/springbootdemo.log 参考 Angular 5集成Spring Boot,Spring Security,JWT和CORS Angular_Heroes教程 揭秘SpringSecurity(一)_请求认证过程 揭秘SpringBoot(一)_SpringBoot运行原理 【Restful】三分钟彻底了解Restful最佳实践 什么是 JWT – JSON WEB TOKEN ajax 跨域 CROS Spring Boot 日志配置(超详细)]]></content>
      <categories>
        <category>HelloWorld</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>SpringSecurity</tag>
        <tag>JWT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[揭秘SpringSecurity(一)_请求认证过程]]></title>
    <url>%2F2018%2F04%2F25%2F%E6%B7%B1%E5%85%A5SSM%2F%E6%8F%AD%E7%A7%98SpringSecurity-%E4%B8%80-%E8%AF%B7%E6%B1%82%E8%AE%A4%E8%AF%81%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[引：有了Spring作为基础，Spring家族的很多框架都显得那么棒，尤其是Springboot的出现，简化了配置，家族框架就显得更棒了，我们这次分析一下其中的SpringSecurity，我们会由请求认证过程，来分析其中的各个组件！ 一次认证过程 大家可以找到一个工程，这里也可以看看我的SpringBoot+Angular工程debug验证我画的流程图。 核心组件Filter在最开始debug的过程中我们会发现pring Security使用了springSecurityFillterChian作为了安全过滤的入口，我只介绍几个比较常用的过滤器。 SecurityContextPersistenceFilter两个主要职责： 请求来临时，创建SecurityContext安全上下文信息 请求结束时清空SecurityContextHolder（可获得当前操作的用户是谁，该用户是否已经被认证，他拥有哪些角色权限等信息）。 我们看看它的源码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class SecurityContextPersistenceFilter extends GenericFilterBean &#123; static final String FILTER_APPLIED = "__spring_security_scpf_applied"; // 安全上下文存储的仓库 private SecurityContextRepository repo; public SecurityContextPersistenceFilter() &#123; // HttpSessionSecurityContextRepository是SecurityContextRepository接口的一个实现类 // 使用HttpSession来存储SecurityContext this(new HttpSessionSecurityContextRepository()); &#125; public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest)req; HttpServletResponse response = (HttpServletResponse)res; if(request.getAttribute("__spring_security_scpf_applied") != null) &#123; chain.doFilter(request, response); &#125; else &#123; boolean debug = this.logger.isDebugEnabled(); request.setAttribute("__spring_security_scpf_applied", Boolean.TRUE); if(this.forceEagerSessionCreation) &#123; HttpSession session = request.getSession(); if(debug &amp;&amp; session.isNew()) &#123; this.logger.debug("Eagerly created session: " + session.getId()); &#125; &#125; // 包装request，response HttpRequestResponseHolder holder = new HttpRequestResponseHolder(request, response); // 从Session中获取安全上下文信息 SecurityContext contextBeforeChainExecution = this.repo.loadContext(holder); boolean var13 = false; try &#123; var13 = true; // 请求开始时，设置安全上下文信息，这样就避免了用户直接从Session中获取安全上下文信息 SecurityContextHolder.setContext(contextBeforeChainExecution); chain.doFilter(holder.getRequest(), holder.getResponse()); var13 = false; &#125; finally &#123; if(var13) &#123; SecurityContext contextAfterChainExecution = SecurityContextHolder.getContext();\ //请求结束后，清空安全上下文信息 SecurityContextHolder.clearContext(); this.repo.saveContext(contextAfterChainExecution, holder.getRequest(), holder.getResponse()); request.removeAttribute("__spring_security_scpf_applied"); &#125; &#125; ... &#125; &#125;&#125; UsernamePasswordAuthenticationFilter这个可能是我们遇见最多的过滤器了，一个最直观的业务场景便是允许用户在表单中输入用户名和密码进行登录，而这背后用到的就是UsernamePasswordAuthenticationFilter。这个过滤器也可以见证我们之前画的时序图，我们看看它的源码：123456789101112131415161718192021public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException &#123; if(this.postOnly &amp;&amp; !request.getMethod().equals("POST")) &#123; throw new AuthenticationServiceException("Authentication method not supported: " + request.getMethod()); &#125; else &#123; // 获取用户名，密码 String username = this.obtainUsername(request); String password = this.obtainPassword(request); if(username == null) &#123; username = ""; &#125; if(password == null) &#123; password = ""; &#125; username = username.trim(); // 生成Authentication，下面会介绍 UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken(username, password); this.setDetails(request, authRequest); // 讲Authentication交给AuthenticationManager认证 return this.getAuthenticationManager().authenticate(authRequest); &#125; &#125; 自定义Filter当自带的Filter不能满足你的要求时（例如我们要先对token进行认证），我们可以自定义过滤器，只要继承各种Filter接口，并实现其中方法即可。 Authentication先看他的源码：12345678910111213public interface Authentication extends Principal, Serializable &#123; // 权限信息列表 Collection&lt;? extends GrantedAuthority&gt; getAuthorities(); // 密码信息，用户输入的密码字符串，在认证过后通常会被移除，用于保障安全 Object getCredentials(); // 细节信息，它记录了访问者的ip地址和sessionId的值。 Object getDetails(); // 最重要的身份信息，大部分情况下返回的是UserDetails接口的实现类 Object getPrincipal(); // 是否已认证 boolean isAuthenticated(); void setAuthenticated(boolean var1) throws IllegalArgumentException;&#125; 从它的源码可以知道它拥有的权限信息列表，密码，用户细节信息，用户身份信息，认证信息。 它有很多实现类，比如流程图中的UsernamePasswordAuthenticationToken，以及AnonymousAuthenticationToken等。 AuthenticationManager先看看它的源码：1234public interface AuthenticationManager &#123; // 主要是认证传进来的Authentication Authentication authenticate(Authentication var1) throws AuthenticationException;&#125; 它最有用的实现类就是流程图中的ProviderManager，我们可以看看它的源码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class ProviderManager implements AuthenticationManager, MessageSourceAware, InitializingBean &#123; // 维护一个AuthenticationProvider列表 private List&lt;AuthenticationProvider&gt; providers; private boolean eraseCredentialsAfterAuthentication; public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; Class&lt;? extends Authentication&gt; toTest = authentication.getClass(); AuthenticationException lastException = null; // 要从新返回的Authentication Authentication result = null; // 遍历AuthenticationProvider列表 Iterator var6 = this.getProviders().iterator(); while(var6.hasNext()) &#123; AuthenticationProvider provider = (AuthenticationProvider)var6.next(); if(provider.supports(toTest)) &#123; try &#123; // 对传进来的authentication进行认证 result = provider.authenticate(authentication); if(result != null) &#123; // 将属性复制给result this.copyDetails(authentication, result); break; &#125; &#125; catch (AccountStatusException var11) &#123; ... &#125; &#125; &#125; if(result == null &amp;&amp; this.parent != null) &#123; try &#123; // 如果列表里的Provider都不支持该authentication，则到父类查找 result = this.parent.authenticate(authentication); &#125; catch (ProviderNotFoundException var9) &#123; ; &#125; catch (AuthenticationException var10) &#123; lastException = var10; &#125; &#125; if(result != null) &#123; if(this.eraseCredentialsAfterAuthentication &amp;&amp; result instanceof CredentialsContainer) &#123; // 擦除密码信息 ((CredentialsContainer)result).eraseCredentials(); &#125; this.eventPublisher.publishAuthenticationSuccess(result); return result; &#125; else &#123; ... &#125; &#125; AuthenticationProvider看看它的源码先：123456public interface AuthenticationProvider &#123; // 认证 Authentication authenticate(Authentication var1) throws AuthenticationException; // 判断是否支持传进来的Authentication boolean supports(Class&lt;?&gt; var1);&#125; 我们接着看看它最常用的一个实现DaoAuthenticationProvider。也看看它的源码：1234567891011121314151617181920212223242526272829303132333435public class DaoAuthenticationProvider extends AbstractUserDetailsAuthenticationProvider &#123; // 密码加密器 private PasswordEncoder passwordEncoder; // 加载用户的UserDetailsService private UserDetailsService userDetailsService; protected void additionalAuthenticationChecks(UserDetails userDetails, UsernamePasswordAuthenticationToken authentication) throws AuthenticationException &#123; if(authentication.getCredentials() == null) &#123; ... &#125; else &#123; // 验证密码 String presentedPassword = authentication.getCredentials().toString(); if(!this.passwordEncoder.matches(presentedPassword, userDetails.getPassword())) &#123; ... &#125; &#125; &#125; // 最核心的方法 protected final UserDetails retrieveUser(String username, UsernamePasswordAuthenticationToken authentication) throws AuthenticationException &#123; this.prepareTimingAttackProtection(); try &#123; // 获得UserDetails UserDetails loadedUser = this.getUserDetailsService().loadUserByUsername(username); if(loadedUser == null) &#123; ... &#125; else &#123; return loadedUser; &#125; &#125; catch (UsernameNotFoundException var4) &#123; ... &#125; &#125;&#125; UserDetailsService先看看它的源码：123public interface UserDetailsService &#123; UserDetails loadUserByUsername(String var1) throws UsernameNotFoundException;&#125; 这个接口的实现类有JdbcDaoImpl（负责从数据库加载用户）等，当然我们也可以自己实现这个接口。只要实现loadUserByUsername方法即可。 再看看UserDetails是个什么东西？ 看看它源码：12345678910111213141516public interface UserDetails extends Serializable &#123; // 权限属性 Collection&lt;? extends GrantedAuthority&gt; getAuthorities(); // 密码属性 String getPassword(); // 用户名属性 String getUsername(); // 账户是否过期 boolean isAccountNonExpired(); // 账户是否被锁 boolean isAccountNonLocked(); // 密码是否过期 boolean isCredentialsNonExpired(); // 是否启用 boolean isEnabled();&#125; 它代表了最详细的用户信息，这个接口涵盖了一些必要的用户信息字段，具体的实现类对它进行了扩展。这里我们普通的User类也可以实现这个接口。 核心配置通过我们上面对核心组件的解读再结合流程流就应该可以理解SpringSecurity的请求认证过程。但是不可能我们对所有的路径都需要认证，或者说它总要提供一个东西让我们配置它的细节，那就是WebSecurityConfigurerAdapter接口，它主要使用了适配器模式。我们主要看看我们需要覆盖它的方法：12345678910111213public abstract class WebSecurityConfigurerAdapter implements WebSecurityConfigurer&lt;WebSecurity&gt; &#123; // 配置AuthenticationManagerBuilder protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; this.disableLocalConfigureAuthenticationBldr = true; &#125; // 配置WebSecurity public void configure(WebSecurity web) throws Exception &#123; &#125; // 配置HttpSecurity protected void configure(HttpSecurity http) throws Exception &#123; ((HttpSecurity)((HttpSecurity)((AuthorizedUrl)http.authorizeRequests().anyRequest()).authenticated().and()).formLogin().and()).httpBasic(); &#125;&#125; 配置AuthenticationManagerBuilder我们可以看看它的使用案例：123456789public class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth .inMemoryAuthentication() .withUser("admin").password("admin").roles("USER"); &#125;&#125; 想要在WebSecurityConfigurerAdapter中进行认证相关的配置，可以使用configure(AuthenticationManagerBuilder auth)暴露一个AuthenticationManager的建造器：AuthenticationManagerBuilder 。如上所示，我们便完成了内存中用户的配置，也可以在这里讲自己定义的UserDetailService注入。 配置WebSecurity我们可以看看它的使用案例：12345678910111213141516171819202122232425262728293031public class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http // 配置路径拦截，表明路径访问所对应的权限，角色，认证信息。 .authorizeRequests() .antMatchers("/resources/**", "/signup", "/about").permitAll() .antMatchers("/admin/**").hasRole("ADMIN") .antMatchers("/db/**").access("hasRole('ADMIN') and hasRole('DBA')") .anyRequest().authenticated() .and() // 配置表单认证 .formLogin() .usernameParameter("username") .passwordParameter("password") .failureForwardUrl("/login?error") .loginPage("/login") .permitAll() .and() // 配置注销 .logout() .logoutUrl("/logout") .logoutSuccessUrl("/index") .permitAll() .and() // 配置basic登录 .httpBasic() .disable(); &#125;&#125; 方法里的各项配置分别代表了http请求相关的安全配置，这些配置项无一例外的返回了Configurer类，而所有的http相关配置可以通过查看HttpSecurity的主要方法得知。 WebSecurityBuilder我们可以看看它的使用案例：12345678public class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override public void configure(WebSecurity web) throws Exception &#123; web .ignoring() .antMatchers("/resources/**"); &#125;&#125; 这个配置中并不会出现太多的配置信息。 架构 将这个架构图结合流程图我们会可以大致总结出核心组件之间的关系，有利于我们我们更好的理解SpringSecurity的架构以及请求认证过程。 参考 Spring Security(一)–Architecture Overview Spring Security源码分析一：Spring Security认证过程]]></content>
      <categories>
        <category>深入SSM</category>
      </categories>
      <tags>
        <tag>SpringSecurity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[揭秘SpringBoot(一)_SpringBoot运行原理]]></title>
    <url>%2F2018%2F04%2F21%2F%E6%B7%B1%E5%85%A5SSM%2F%E6%8F%AD%E7%A7%98SpringBoot-%E4%B8%80-SpringBoot%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[引：可能你早已开始使用SpringBoot，但是你却不知道SpringBoot是个什么东西，他又是怎么运行的，这里给你答案！ SpringBoot是什么用过Spring的人都知道，你肯定需要些很多很多的XML来用配置复杂的依赖关系，你肯定厌倦了。这个时候SpringBoot出现了，SpringBoot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置（想想肯定会很开心）。 核心理念习惯优于配置 SpringBoot与Spring Framework的区别做个下面的比喻： SpringFramework 就像一个大型电子器件生产公司，它生产的电子器件（比如zookeeper，redis等整合包）都很优秀，当其他小公司（开发者）生产机器人（项目）需要使用到它的电子器件时，就发现需要大量的焊接工作（配置XML）来连接自己的电子器件（zookeeper，redis），这样真的太耗时了，而SpringBoot 就像这个电子器件生产公司在原来电子器件的基础上包装出来的许多统一的插口（各种starter），这些插头可以与小公司的电子器件可以直接连接，不需要焊接工作就可以直接使用。 通过上面的比喻我们可以了解到他们两者的区别，也发现其实SpringBoot并不是什么新东西，它只是原来Spring的基础上重新包装过，从而简化了Spring的相关配置。 SpringBoot的核心功能 SpringBoot可以以jar包的形式独立运行，因为SpringBoot内嵌Servlet容器，如Tomcat、Jetty。 Spring会根据类路径中的jar包、类，为jar包里的类自动配置Bean，极大减少了我们要使用的配置。 提供starter(起动机)简化了Maven配置(依赖加载)，一个starter依赖抵了好几个依赖。 SpringBoot运行原理 对于SpringBoot工程我们总是先看到它的启动类，如下： 1234567@SpringBootApplicationpublic class SpringbootLoginApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootLoginApplication.class, args); &#125;&#125; 对于SpringBoot的运作原理，我们应该先从启动类的@SpringBootApplication注解来分析，这个注解是一个组合注解，我们进入它的源码看看： 1234567891011121314151617181920212223242526272829303132333435363738@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan( excludeFilters = &#123;@Filter( type = FilterType.CUSTOM, classes = &#123;TypeExcludeFilter.class&#125;), @Filter( type = FilterType.CUSTOM, classes = &#123;AutoConfigurationExcludeFilter.class&#125;)&#125;)public @interface SpringBootApplication &#123; @AliasFor( annotation = EnableAutoConfiguration.class ) Class&lt;?&gt;[] exclude() default &#123;&#125;; @AliasFor( annotation = EnableAutoConfiguration.class ) String[] excludeName() default &#123;&#125;; @AliasFor( annotation = ComponentScan.class, attribute = "basePackages" ) String[] scanBasePackages() default &#123;&#125;; @AliasFor( annotation = ComponentScan.class, attribute = "basePackageClasses" ) Class&lt;?&gt;[] scanBasePackageClasses() default &#123;&#125;;&#125; 总得来说最重要的就是@SpringBootConfiguration，@EnableAutoConfiguration，@ComponentScan这三个注解，我们一个个分析： @SpringBootConfiguration 我们进入该注解，我发现它的代码如下： 123456@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Configurationpublic @interface SpringBootConfiguration &#123;&#125; 你会发现其核心注解就是@Configuration，它对于我们来说应该不陌生，因为它就是Java配置形式的Spring Ioc容器的配置类使用的那个@Configuration（相当于XML配置文件的一个Bean），SpringBoot社区推荐使用基于JavaConfig的配置形式，所以，这里的启动类标注了@Configuration之后，本身其实也是一个IoC容器的配置类。 @ComponentScan 这个注解很简单，很常见，但是也很重要。它主要的作用就是自动扫描并加载符合条件的组件（比如@Controller和@Service等）或者bean定义，最终将这些bean定义加载到IoC容器中。我们看看它的源码： 123456789101112131415161718192021222324252627282930313233343536373839@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE&#125;)@Documented@Repeatable(ComponentScans.class)public @interface ComponentScan &#123;// 设置默认路径@AliasFor("basePackages")String[] value() default &#123;&#125;;// 如果不指定，则默认Spring框架实现会从声明@ComponentScan所在类的package进行扫描。// 所以SpringBoot的启动类最好是放在root package下，因为默认不指定basePackages。@AliasFor("value")String[] basePackages() default &#123;&#125;;Class&lt;?&gt;[] basePackageClasses() default &#123;&#125;;Class&lt;? extends BeanNameGenerator&gt; nameGenerator() default BeanNameGenerator.class;Class&lt;? extends ScopeMetadataResolver&gt; scopeResolver() default AnnotationScopeMetadataResolver.class;ScopedProxyMode scopedProxy() default ScopedProxyMode.DEFAULT;// 扫描类型String resourcePattern() default "**/*.class";// 可设置过滤器boolean useDefaultFilters() default true;ComponentScan.Filter[] includeFilters() default &#123;&#125;;ComponentScan.Filter[] excludeFilters() default &#123;&#125;;// 配置懒加载，如果没被使用，就先不生成Beanboolean lazyInit() default false;@Retention(RetentionPolicy.RUNTIME)@Target(&#123;&#125;)public @interface Filter &#123; FilterType type() default FilterType.ANNOTATION; @AliasFor("classes") Class&lt;?&gt;[] value() default &#123;&#125;; @AliasFor("value") Class&lt;?&gt;[] classes() default &#123;&#125;; String[] pattern() default &#123;&#125;;&#125;&#125; @EnableAutoConfiguration 这个注解可以说是SpringBoot自动配置的核心了，灰常重要。我们进去看一下它的源码： 1234567891011121314@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage// 借助@Import的帮助，将所有符合自动配置条件的bean定义加载到IoC容器@Import(&#123;AutoConfigurationImportSelector.class&#125;)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = "spring.boot.enableautoconfiguration"; Class&lt;?&gt;[] exclude() default &#123;&#125;; String[] excludeName() default &#123;&#125;;&#125; 我们需要好好看看AutoConfigurationImportSelector，它利用SpringFactoriesLoader.loadFactoryNames方法来扫描具有META-INF/spring.factories 文件的jar包，代码如下： 1234protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123;List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(this.getSpringFactoriesLoaderFactoryClass(), this.getBeanClassLoader());return configurations;&#125; 配合@EnableAutoConfiguration使用的话，它更多是提供一种配置查找的功能支持，即根据@EnableAutoConfiguration的完整类名如org.springframework.boot.autoconfigure.EnableAutoConfiguration作为查找的Key,获取对应的一组@Configuration类，并将其中org.springframework.boot.autoconfigure.EnableAutoConfiguration对应的配置项实例化为对应的标注了@Configuration的JavaConfig形式的IoC容器配置类，然后汇总为一个（相当于一个XML文件）并加载到IoC容器（和Spring一样）。 我们可以看看spring-boot-autoconfigure.jar 里就有一个spring.factories 文件，此文件中声明了有哪些自动配置。我们看一点点： 12345# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\# 配置AOP对象org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\ 看完@SpringBootApplication注解，我们再看看SpringApplication的run方法。 我们通过debug发现将进入这个方法： 1234public static ConfigurableApplicationContext run(Class&lt;?&gt;[] primarySources, String[] args) &#123; // 会先创建SpringApplication对象实例，然后调用它的实例run方法 return (new SpringApplication(primarySources)).run(args);&#125; 我们看看在实例初始化的过程中他做了什么： 123456789101112131415161718192021222324public SpringApplication(ResourceLoader resourceLoader, Class... primarySources) &#123; this.sources = new LinkedHashSet(); // banner的打印模式，此时是控制台模式 this.bannerMode = Mode.CONSOLE; // 开启日志 this.logStartupInfo = true; // 启用CommandLineProperties this.addCommandLineProperties = true; // 开启headless模式支持，Headless模式是在缺少显示屏、键盘或者鼠标时的系统配置（自行了解） this.headless = true // 启用注册ShutdownHook，用于在非Web应用中关闭IoC容器和资源 this.registerShutdownHook = true; this.additionalProfiles = new HashSet(); this.resourceLoader = resourceLoader; this.primarySources = new LinkedHashSet(Arrays.asList(primarySources)); // 判断是否是web运行环境(Servlet) this.webApplicationType = this.deduceWebApplicationType(); // 设置初始化器(在META-INF/spring.factories 文件里，可扩展) this.setInitializers(this.getSpringFactoriesInstances(ApplicationContextInitializer.class)); // 设置监听器(在META-INF/spring.factories 文件里，可扩展) this.setListeners(this.getSpringFactoriesInstances(ApplicationListener.class)); // 推断并设置main方法的定义类 this.mainApplicationClass = this.deduceMainApplicationClass();&#125; SpringApplication实例初始化完成并且完成设置后，就开始执行run方法的逻辑，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public ConfigurableApplicationContext run(String... args) &#123; // 开启任务执行时间监听器 StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList(); // 设置系统属性 this.configureHeadlessProperty(); //开启广播，宣告SpringBoot要开始执行了 SpringApplicationRunListeners listeners = this.getRunListeners(args); listeners.starting(); Collection exceptionReporters; try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 创建并配置当前Spring Boot应用将要使用的Environment（包括配置要使用的PropertySource以及Profile）。 ConfigurableEnvironment environment = this.prepareEnvironment(listeners, applicationArguments); // 宣告SpringBoot应用使用的Environment准备好了。 this.configureIgnoreBeanInfo(environment); // 决定是否打印Banner Banner printedBanner = this.printBanner(environment); // 根据用户是否明确设置了applicationContextClass类型，决定该为当前SpringBoot应用创建什么类型的ApplicationContext // 然后根据条件决定是否添加ShutdownHook，决定是否使用自定义的BeanNameGenerator，决定是否使用自定义的ResourceLoader， // 最重要的是将之前准备好的Environment设置给创建好的ApplicationContext使用。 context = this.createApplicationContext(); // 得到异常报告者 exceptionReporters = this.getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[]&#123;ConfigurableApplicationContext.class&#125;, new Object[]&#123;context&#125;); // ApplicationContext创建好之后，遍历调用ApplicationContextInitializer的initialize（applicationContext）方法来对已经创建好的ApplicationContext进行进一步的处理。 // 遍历调用所有SpringApplicationRunListener的contextPrepared()方法。 // 将之前通过@EnableAutoConfiguration获取的所有配置以及其他形式的IoC容器配置加载到已经准备完毕的ApplicationContext // (很重要，可以进入看看) this.prepareContext(context, environment, listeners, applicationArguments, printedBanner); // 初始化所有自动配置类，调用ApplicationContext的refresh()方法 this.refreshContext(context); // 调用所有的SpringApplicationRunListener的finished()方法，宣告SpringBoot已经完成了ApplicationContext初始化的全部过程。 this.afterRefresh(context, applicationArguments); //关闭任务执行时间监听器 stopWatch.stop(); if(this.logStartupInfo) &#123; // //如果开启日志，则打印执行的时间 (new StartupInfoLogger(this.mainApplicationClass)).logStarted(this.getApplicationLog(), stopWatch); &#125; listeners.started(context); this.callRunners(context, applicationArguments); &#125; catch (Throwable var10) &#123; // //调用异常分析器打印报告，调用所有的SpringApplicationRunListener的finished()方法将异常信息发布出去 this.handleRunFailure(context, var10, exceptionReporters, listeners); throw new IllegalStateException(var10); &#125; try &#123; listeners.running(context); return context; &#125; catch (Throwable var9) &#123; this.handleRunFailure(context, var9, exceptionReporters, (SpringApplicationRunListeners)null); throw new IllegalStateException(var9); &#125;&#125; 参考 Spring Boot干货系列：（三）启动原理解析 Spring Boot学习笔记03–深入了解SpringBoot的启动过程 spring boot应用启动原理分析]]></content>
      <categories>
        <category>深入SSM</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HelloWorld_SSMLogin]]></title>
    <url>%2F2018%2F04%2F17%2FHelloWorld%2FHelloWorld-SSMLogin%2F</url>
    <content type="text"><![CDATA[引：想着怎么教一个人快速入门SSM，讲原理是真的太费时间，还是以搭建具体流程加上源码比较好吧，先模仿，后创新嘛！ 项目架构项目仓库地址 我们先把文件夹创建好，当然也可以先直接从我仓库地址把它克隆下来，删除其中部分的代码文件。 配置文件解析配置文件里面都有注释，大家可以对照着看： pom.xml文件pom文件作为Maven工程的核心，主要是用来引入jar包的，在我的pom文件中也详细列出了我们需要哪些包，以及哪些包是用来干什么的。 web.xml文件web.xml作为Web功能的核心，主要是设置了如何接受请求，这里会结合SpringMVC的前端控制器类DispatcherServlet作为请求分发的核心Servlet，以及在第一次加载过程中，后台服务需要加载哪些配置文件。 ssm配置文件（依靠Spring整合）我们看到spring文件夹下有三个文件，分别对应了dao，service，web三层的Bean配置。 spring-dao-config.xml文件这里主要是配置数据库连接池（数据源），以及注入SqlSessionFactory和所有在com.todorex.dao下得所有Dao接口。 spring-service-config.xml文件这里主要配置扫描并注入com.todorex.service包下所有Service注解类，以及配置事务管理器。 spring-web-config.xml文件这里主要配置扫描并注入com.todorex.controller包下所有Controller注解类，以及配置视图解析器。这里还有一个超级重要的就是配置处理静态资源的方式。 mybatis-config.xml文件这里主要是设置mybatis的全局属性。 jdbc.properties文件这里主要配置数据库连接的相关信息。 log4j.properties文件这里主要配置日志记录的相关信息。 配置文件都配置完了，我们终于可以开始写代码了! SSM代码需求实现用户的登录与注销。 上帝视角开发（我需要什么就造什么）我需要一个能处理我的请求（URL）的Controller知道要controller，我们就造一个，我们在com.todorex.controller包下新建一个LoginController类。 Controller的作用主要是根据你请求的URL来做不同的事（对应的方法），结果是返回一个ModelAndView（当然View和Model也可以分开），如果方法的逻辑只是页面间的跳转和简单数据处理，我们就用不到Service了，如过我们需要进行业务处理以及操作数据库，那么我们就需要用到Service了。 PS：这里需要注意请求转发和请求重定向的区别（注释中有） 我需要一个能处理业务的Service在service层设计一个好的接口是至关重要的（我们还是HelloWorld，以后有经验了自然能设计得好一些），如果实现类有多个的话 ，可以用@Service(“userService1”)来注入，@Resource(name=”userService1”) 来对应获取。在处理业务逻辑的时候，一般都会涉及到数据库操作，这个时候我们就需要用到Dao了。 我需要一个能处理数据的Dao这里我们要明确一点：一个Dao接口对应一个Mapper文件，Dao定义接口方法，Mapper文件实现该方法的sql语句。 日志这里我们举一个例子，就是记录登录用户的名字和时间，看下面的代码：1234567891011121314151617public class LoginController &#123; // 获得日志对象 Logger logger = Logger.getLogger(LoginController.class); @RequestMapping(value = "/checkLogin",method = RequestMethod.POST) public String checkLogin(User user, Model model) &#123; user = userService.checkLogin(user.getUsername(),user.getPassword()); if (user != null) &#123; // 日志记录用户登录 logger.info(user.getUsername()+"在"+new Date() + "登录过!"); model.addAttribute("user",user); return "redirect:/success"; &#125; else &#123; return "redirect:/fail"; &#125; &#125;&#125; 单元测试 配置一个基类（用于加载配置文件） 123456@RunWith(SpringJUnit4ClassRunner.class) //使用junit4进行测试// 导入多个配置文件@ContextConfiguration(locations=&#123;"classpath:spring/spring-*.xml","classpath:mybatis-config.xml"&#125;) //加载配置文件//所有继承该类的测试类都会遵循该配置public class BaseJunit4Test &#123;&#125; 在各个对应的包下建立单元测试，如; 12345678910public class UserDaoTest extends BaseJunit4Test &#123; @Autowired private UserDao userDao; @Test public void TestFindByUsername() &#123; User user = userDao.findByUsername("rex"); System.out.println(user); &#125;&#125; 页面编写这里只举一个例子（其实主要就是jsp的用法）,success.jsp:123456789101112131415161718192021222324252627&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;%--引入jstl标签库，很重要--%&gt;&lt;%@ taglib prefix=&quot;c&quot; uri=&quot;http://java.sun.com/jsp/jstl/core&quot;%&gt; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt; &lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;!--添加背景图片--&gt;&lt;body background=&quot;image/success.jpg&quot;&gt;&lt;div style=&quot;margin: auto&quot;&gt;&lt;div&gt; &lt;%--利用jstl标签获取session中的user的值--%&gt; &lt;strong style=&quot;font-size: 100px;color: red&quot;&gt; $&#123;sessionScope.user.username&#125;!&lt;/strong&gt; &lt;strong style=&quot;font-size: 100px;color: blue&quot;&gt; ，你他妈登录成功了&lt;/strong&gt;&lt;/div&gt;&lt;form action=&quot;/LoginDemo/outLogin&quot; &gt; &lt;button type=&quot;submit&quot; class=&quot;btn btn-success col-lg-12&quot; style=&quot;font-size: 100px;text-align: center&quot;&gt;退出登录&lt;/button&gt;&lt;/form&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 终于大功告成！！！ 参考SSM搭建(整合)+用户模块(登录和注销)实现]]></content>
      <categories>
        <category>HelloWorld</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>SpringMVC</tag>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[揭秘Mybatis(二)_Mybatis工作原理]]></title>
    <url>%2F2018%2F04%2F16%2F%E6%B7%B1%E5%85%A5SSM%2F%E6%8F%AD%E7%A7%98Mybatis-%E4%BA%8C-Mybatis%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[引：了解完Mybatis的架构，那么它的执行流程又是怎么样的呢？ Mybatis主要组件及工作流程主要组件 Configuration：MyBatis所有的配置信息都维持在Configuration对象之中 SqlSession：作为MyBatis接口层的AOP，表示和数据库交互的会话，完成必要数据库增删改查功能 Executor：MyBatis执行器，是MyBatis 调度的核心，负责SQL语句的生成和查询缓存的维护 StatementHandler：封装了JDBC Statement操作，负责对JDBC statement 的操作，如设置参数、将Statement结果集转换成List集合 ParameterHandler：负责对用户传递的参数转换成JDBC Statement 所需要的参数 resultSetHandler：负责将JDBC返回的ResultSet结果集对象转换成List类型的集合 TypeHandler：负责java数据类型和jdbc数据类型之间的映射和转换 MappedStatement：MappedStatement维护了一条节点的封装 SqlSource：负责根据用户传递的parameterObject，动态地生成SQL语句，将信息封装到BoundSql对象中，并返回 BoundSql：表示动态生成的SQL语句以及相应的参数信息 工作流程图 这张图也超级棒（Nice 兄Dei），在下面参考也将看到出处。我们下面的源码分析也会参考这张图。 Mybatis初始化源码分析 获取配置文件创建SqlSessionFactory 123String resource = &quot;mybatis-config.xml&quot;;InputStream inputStream = Resources.getResourceAsStream(resource);SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); 进入到SqlSessionFactory的build方法 123456789101112131415161718public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) &#123; SqlSessionFactory var5; try &#123; // 解析刚刚创建的配置文件文件流 XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties); var5 = this.build(parser.parse()); &#125; catch (Exception var14) &#123; throw ExceptionFactory.wrapException("Error building SqlSession.", var14); &#125; finally &#123; ErrorContext.instance().reset(); try &#123; inputStream.close(); &#125; catch (IOException var13) &#123; ; &#125; &#125; return var5;&#125; 会进入到XMLConfigBuilder的parse方法去解析配置文件的具体内容生成Configuration对象 1234567891011121314151617181920212223242526272829303132333435public Configuration parse() &#123; if(this.parsed) &#123; throw new BuilderException("Each XMLConfigBuilder can only be used once."); &#125; else &#123; this.parsed = true; // 解析配置文件 this.parseConfiguration(this.parser.evalNode("/configuration")); return this.configuration; &#125;&#125;private void parseConfiguration(XNode root) &#123; try &#123; // 解析&lt;properties&gt;节点，数据源配置文件 this.propertiesElement(root.evalNode("properties")); // 解析&lt;typeAliases&gt;节点，别名节点 this.typeAliasesElement(root.evalNode("typeAliases")); // 解析&lt;plugins&gt;节点，插件节点 this.pluginElement(root.evalNode("plugins")); // 解析&lt;objectFactory&gt;节点 this.objectFactoryElement(root.evalNode("objectFactory")); // 解析&lt;reflectorFactory&gt;节点 this.objectWrapperFactoryElement(root.evalNode("objectWrapperFactory")); // 解析&lt;settings&gt;节点 this.settingsElement(root.evalNode("settings")); // 解析&lt;environments&gt;节点 this.environmentsElement(root.evalNode("environments")); this.databaseIdProviderElement(root.evalNode("databaseIdProvider")); this.typeHandlerElement(root.evalNode("typeHandlers")); // 解析&lt;mappers&gt;节点，很重要 this.mapperElement(root.evalNode("mappers")); &#125; catch (Exception var3) &#123; throw new BuilderException("Error parsing SQL Mapper Configuration. Cause: " + var3, var3); &#125;&#125; 我们最关心的可能就是mapper的解析了，所以我们进入mapperElement方法看看： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869private void mapperElement(XNode parent) throws Exception &#123; if(parent != null) &#123; Iterator i$ = parent.getChildren().iterator(); while(true) &#123; // 遍历&lt;mappers&gt;下所有子节点 while(i$.hasNext()) &#123; XNode child = (XNode)i$.next(); String resource; // 如果当前节点为&lt;package&gt; if("package".equals(child.getName())) &#123; // 获取&lt;package&gt;的name属性（该属性值为mapper class所在的包名） resource = child.getStringAttribute("name"); // 将该包下的所有Mapper Class注册到configuration的mapperRegistry容器中 this.configuration.addMappers(resource); &#125; else &#123; // 依次获取resource、url、class属性 resource = child.getStringAttribute("resource"); String url = child.getStringAttribute("url"); String mapperClass = child.getStringAttribute("class"); XMLMapperBuilder mapperParser; InputStream inputStream; // 解析resource属性（Mapper.xml文件的路径） if(resource != null &amp;&amp; url == null &amp;&amp; mapperClass == null) &#123; ErrorContext.instance().resource(resource); // 将Mapper.xml文件解析成输入流 inputStream = Resources.getResourceAsStream(resource); // 使用XMLMapperBuilder解析Mapper.xml，并将Mapper Class注册进configuration对象的mapperRegistry容器中 mapperParser = new XMLMapperBuilder(inputStream, this.configuration, resource, this.configuration.getSqlFragments()); // 这个很重要，看看具体怎么解析 mapperParser.parse(); &#125; else if(resource == null &amp;&amp; url != null &amp;&amp; mapperClass == null) &#123; // 解析url属性（Mapper.xml文件的路径） ErrorContext.instance().resource(url); inputStream = Resources.getUrlAsStream(url); mapperParser = new XMLMapperBuilder(inputStream, this.configuration, url, this.configuration.getSqlFragments()); mapperParser.parse(); &#125; else &#123; // 解析class属性（Mapper Class的全限定名） if(resource != null || url != null || mapperClass == null) &#123; throw new BuilderException("A mapper element may only specify a url, resource or class, but not more than one."); &#125; // 将Mapper Class的权限定名转化成Class对象 Class&lt;?&gt; mapperInterface = Resources.classForName(mapperClass); this.configuration.addMapper(mapperInterface); &#125; &#125; &#125; return; &#125; &#125; &#125;public void parse() &#123; if(!this.configuration.isResourceLoaded(this.resource)) &#123; // 解析&lt;mapper&gt;节点 this.configurationElement(this.parser.evalNode("/mapper")); // 将该Mapper.xml添加至configuration的LoadedResource容器中，下回无需再解析 this.configuration.addLoadedResource(this.resource); // 将该Mapper.xml对应的Mapper Class注册进configuration的mapperRegistry容器中，很重要，下马需要仔细看看 this.bindMapperForNamespace(); &#125; this.parsePendingResultMaps(); this.parsePendingChacheRefs(); this.parsePendingStatements();&#125; bindMapperForNamespace极其重要，因为这里会给Mapper接口创建动态代理对象，我们看看源码： 12345678910111213141516171819private void bindMapperForNamespace() &#123; // 获取当前映射文件对应的DAO接口的全限定名 String namespace = this.builderAssistant.getCurrentNamespace(); if(namespace != null) &#123; // 将全限定名解析成Class对象 Class boundType = null; try &#123; boundType = Resources.classForName(namespace); &#125; catch (ClassNotFoundException var4) &#123; ; &#125; if(boundType != null &amp;&amp; !this.configuration.hasMapper(boundType)) &#123; // 将当前Mapper.xml标注为已加载下回就不用再加载了 this.configuration.addLoadedResource("namespace:" + namespace); // 将Mapper接口的Class对象注册进configuration中（其实是在configuration的MapperRegistry里面） this.configuration.addMapper(boundType); &#125; &#125;&#125; 我们再进入到this.configuration.addMapper方法中看看会做些什么： 12345678910111213141516171819202122232425public &lt;T&gt; void addMapper(Class&lt;T&gt; type) &#123; this.mapperRegistry.addMapper(type);&#125;public &lt;T&gt; void addMapper(Class&lt;T&gt; type) &#123; if(type.isInterface()) &#123; if(this.hasMapper(type)) &#123; throw new BindingException("Type " + type + " is already known to the MapperRegistry."); &#125; boolean loadCompleted = false; try &#123; // 创建MapperProxyFactory对象（用于创建DAO接口的代理对象），并put进knownMappers中 // 为后面的创建Mapper代理对象做准备 this.knownMappers.put(type, new MapperProxyFactory(type)); MapperAnnotationBuilder parser = new MapperAnnotationBuilder(this.config, type); parser.parse(); loadCompleted = true; &#125; finally &#123; if(!loadCompleted) &#123; this.knownMappers.remove(type); &#125; &#125; &#125;&#125; 等Mapper全都解析好之后，初始化工作基本就完成了。 Mybatis工作流程源码分析 创建SqlSession对象 123456789101112131415161718192021222324252627282930SqlSession sqlSession = sqlSessionFactory.openSession();public SqlSession openSession() &#123; // 从数据源创建SqlSession会话对象 return this.openSessionFromDataSource(this.configuration.getDefaultExecutorType(), (TransactionIsolationLevel)null, false);&#125;private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; DefaultSqlSession var8; try &#123; // 初始化读取了Environment里面的数据源以及事务配置 Environment environment = this.configuration.getEnvironment(); // 获取事务工厂 TransactionFactory transactionFactory = this.getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); // 生成MyBatis执行器 Executor executor = this.configuration.newExecutor(tx, execType); // 创建DefaultSqlSession对象 var8 = new DefaultSqlSession(this.configuration, executor, autoCommit); &#125; catch (Exception var12) &#123; this.closeTransaction(tx); throw ExceptionFactory.wrapException("Error opening session. Cause: " + var12, var12); &#125; finally &#123; ErrorContext.instance().reset(); &#125; return var8;&#125; 从SqlSession对象获得Mapper（后面会看到这是个代理对象），看看执行流程： 1234567891011121314151617181920212223242526272829303132UserMapper userMapper = sqlSession.getMapper(UserMapper.class);public &lt;T&gt; T getMapper(Class&lt;T&gt; type) &#123; // 进入configuration return this.configuration.getMapper(type, this);&#125;public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; // 调用configuration对象的apperRegistry的getMapper方法 return this.mapperRegistry.getMapper(type, sqlSession);&#125;public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; // 这个是在初始化过程中解析mapper时生成的，现有看到了Mapper对象的工厂 MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory)this.knownMappers.get(type); if(mapperProxyFactory == null) &#123; throw new BindingException("Type " + type + " is not known to the MapperRegistry."); &#125; else &#123; try &#123; // 生成Mapper实例，进入看看 return mapperProxyFactory.newInstance(sqlSession); &#125; catch (Exception var5) &#123; throw new BindingException("Error getting mapper instance. Cause: " + var5, var5); &#125; &#125;&#125;public T newInstance(SqlSession sqlSession) &#123; // 原来这个还是个代理对象 MapperProxy&lt;T&gt; mapperProxy = new MapperProxy(sqlSession, this.mapperInterface, this.methodCache); return this.newInstance(mapperProxy);&#125; 获得Mapper代理对象我看看他是怎么执行Mapper接口的方法的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354List&lt;User&gt; userList = userMapper.selectList();// 一进去就发现直接到了invoke方法，相当于把方法的执行都交给了代理对象去执行public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; if(Object.class.equals(method.getDeclaringClass())) &#123; try &#123; return method.invoke(this, args); &#125; catch (Throwable var5) &#123; throw ExceptionUtil.unwrapThrowable(var5); &#125; &#125; else &#123; // 从当前代理对象处理类MapperProxy的methodCache属性中获取MapperMethod对象,如果methodCache中没有就创建并加进去。 MapperMethod mapperMethod = this.cachedMapperMethod(method); // 该方法就会调用JDBC执行相应的SQL语句 return mapperMethod.execute(this.sqlSession, args); &#125;&#125;public Object execute(SqlSession sqlSession, Object[] args) &#123; Object param; Object result; // 比对mapper标签 if(SqlCommandType.INSERT == this.command.getType()) &#123; param = this.method.convertArgsToSqlCommandParam(args); result = this.rowCountResult(sqlSession.insert(this.command.getName(), param)); &#125; else if(SqlCommandType.UPDATE == this.command.getType()) &#123; param = this.method.convertArgsToSqlCommandParam(args); result = this.rowCountResult(sqlSession.update(this.command.getName(), param)); &#125; else if(SqlCommandType.DELETE == this.command.getType()) &#123; param = this.method.convertArgsToSqlCommandParam(args); result = this.rowCountResult(sqlSession.delete(this.command.getName(), param)); &#125; else &#123; if(SqlCommandType.SELECT != this.command.getType()) &#123; throw new BindingException("Unknown execution method for: " + this.command.getName()); &#125; if(this.method.returnsVoid() &amp;&amp; this.method.hasResultHandler()) &#123; this.executeWithResultHandler(sqlSession, args); result = null; &#125; else if(this.method.returnsMany()) &#123; // 最终会进入这里 result = this.executeForMany(sqlSession, args); &#125; else if(this.method.returnsMap()) &#123; result = this.executeForMap(sqlSession, args); &#125; else &#123; param = this.method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(this.command.getName(), param); &#125; &#125; if(result == null &amp;&amp; this.method.getReturnType().isPrimitive() &amp;&amp; !this.method.returnsVoid()) &#123; throw new BindingException("Mapper method '" + this.command.getName() + " attempted to return null from a method with a primitive return type (" + this.method.getReturnType() + ")."); &#125; else &#123; return result; &#125;&#125; MapperMethod到底如何去执行executeForMap(sqlSession, args)的呢？我们可以继续进入： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145private &lt;E&gt; Object executeForMany(SqlSession sqlSession, Object[] args) &#123; // 将参数拼接到SQL Object param = this.method.convertArgsToSqlCommandParam(args); List result; if(this.method.hasRowBounds()) &#123; RowBounds rowBounds = this.method.extractRowBounds(args); result = sqlSession.selectList(this.command.getName(), param, rowBounds); &#125; else &#123; // 进入到这里，让sqlSession来处理 result = sqlSession.selectList(this.command.getName(), param); &#125; return !this.method.getReturnType().isAssignableFrom(result.getClass())?(this.method.getReturnType().isArray()?this.convertToArray(result):this.convertToDeclaredCollection(sqlSession.getConfiguration(), result)):result;&#125;public &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter) &#123; return this.selectList(statement, parameter, RowBounds.DEFAULT);&#125;public &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter, RowBounds rowBounds) &#123; List var6; try &#123; // 根据StatementId(com.todorex.UserMapper.selectList)， // 在配置对象Configuration中查找相对应的MappedStatement MappedStatement ms = this.configuration.getMappedStatement(statement); // 将查询任务委托给MyBatis 的执行器 Executor List&lt;E&gt; result = this.executor.query(ms, this.wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); var6 = result; &#125; catch (Exception var10) &#123; throw ExceptionFactory.wrapException("Error querying database. Cause: " + var10, var10); &#125; finally &#123; ErrorContext.instance().reset(); &#125; return var6;&#125;public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; // 根据具体传入的参数，动态地生成需要执行的SQL语句，用BoundSql对象表示 BoundSql boundSql = ms.getBoundSql(parameterObject); // 为当前的查询创建一个缓存Key CacheKey key = this.createCacheKey(ms, parameterObject, rowBounds, boundSql); // 再进去 return this.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);&#125;public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; // 获得缓存对象 Cache cache = ms.getCache(); if(cache != null) &#123; this.flushCacheIfRequired(ms); if(ms.isUseCache() &amp;&amp; resultHandler == null) &#123; this.ensureNoOutParams(ms, parameterObject, boundSql); // 如果缓存中有查询结果，则返回查询结果 List&lt;E&gt; list = (List)this.tcm.getObject(cache, key); if(list == null) &#123; // 如果缓存中没有查询结果则查询数据库 list = this.delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); // 将查询结果放入缓存中 this.tcm.putObject(cache, key, list); &#125; return list; &#125; &#125; // 如果没有缓存对象则查询数据库（进入这里） return this.delegate.query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);&#125;public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; ErrorContext.instance().resource(ms.getResource()).activity("executing a query").object(ms.getId()); if(this.closed) &#123; throw new ExecutorException("Executor was closed."); &#125; else &#123; if(this.queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) &#123; this.clearLocalCache(); &#125; List list; try &#123; ++this.queryStack; list = resultHandler == null?(List)this.localCache.getObject(key):null; if(list != null) &#123; this.handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); &#125; else &#123; // 缓存中没有值，直接从数据库中读取数据（进入这里） list = this.queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; &#125; finally &#123; --this.queryStack; &#125; return list; &#125;&#125;private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; this.localCache.putObject(key, ExecutionPlaceholder.EXECUTION_PLACEHOLDER); List list; try &#123; // 执行查询返回List 结果（进入这里） list = this.doQuery(ms, parameter, rowBounds, resultHandler, boundSql); &#125; finally &#123; // 清楚之前的缓存 this.localCache.removeObject(key); &#125; // 将查询的结果放入缓存之中 this.localCache.putObject(key, list); if(ms.getStatementType() == StatementType.CALLABLE) &#123; this.localOutputParameterCache.putObject(key, parameter); &#125; return list;&#125; public &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; List var9; try &#123; Configuration configuration = ms.getConfiguration(); // 创建StatementHandler对象来执行查询操作 StatementHandler handler = configuration.newStatementHandler(this.wrapper, ms, parameter, rowBounds, resultHandler, boundSql); // 利用StatementHandler对象创建java.Sql.Statement对象（进入这里） stmt = this.prepareStatement(handler, ms.getStatementLog()); // 调用StatementHandler.query()方法，返回List结果集 （进入这里） var9 = handler.query(stmt, resultHandler); &#125; finally &#123; this.closeStatement(stmt); &#125; return var9;&#125;private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException &#123; // 创建连接 Connection connection = this.getConnection(statementLog); // 创建java.Sql.Statement对象，传递给StatementHandler对象 Statement stmt = handler.prepare(connection); // 对创建的Statement对象设置参数，即设置SQL语句中占位符设置为指定的参数 handler.parameterize(stmt); return stmt;&#125;public &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler) throws SQLException &#123; // 调用preparedStatemnt的execute()方法，然后将resultSet交给ResultSetHandler处理 PreparedStatement ps = (PreparedStatement)statement; ps.execute(); // 使用ResultHandler来处理ResultSet（进入这里） return this.resultSetHandler.handleResultSets(ps);&#125; 终于查询完了，现在可以处理结果了，我们看看handleResultSets(Statement stmt)方法： 1234567891011121314151617181920212223242526272829303132333435363738public List&lt;Object&gt; handleResultSets(Statement stmt) throws SQLException &#123; ErrorContext.instance().activity("handling results").object(this.mappedStatement.getId()); // 最后的结果集 List&lt;Object&gt; multipleResults = new ArrayList(); int resultSetCount = 0; ResultSetWrapper rsw = this.getFirstResultSet(stmt); List&lt;ResultMap&gt; resultMaps = this.mappedStatement.getResultMaps(); int resultMapCount = resultMaps.size(); this.validateResultMapsCount(rsw, resultMapCount); while(rsw != null &amp;&amp; resultMapCount &gt; resultSetCount) &#123; // 获得resultMap ResultMap resultMap = (ResultMap)resultMaps.get(resultSetCount); // 这里才开始处理（这里自己去看吧，反正会先处理行值，然后映射成对象，和JDBC一样） this.handleResultSet(rsw, resultMap, multipleResults, (ResultMapping)null); rsw = this.getNextResultSet(stmt); this.cleanUpAfterHandlingResultSet(); ++resultSetCount; &#125; String[] resultSets = this.mappedStatement.getResulSets(); if(resultSets != null) &#123; while(rsw != null &amp;&amp; resultSetCount &lt; resultSets.length) &#123; ResultMapping parentMapping = (ResultMapping)this.nextResultMaps.get(resultSets[resultSetCount]); if(parentMapping != null) &#123; String nestedResultMapId = parentMapping.getNestedResultMapId(); ResultMap resultMap = this.configuration.getResultMap(nestedResultMapId); this.handleResultSet(rsw, resultMap, (List)null, parentMapping); &#125; rsw = this.getNextResultSet(stmt); this.cleanUpAfterHandlingResultSet(); ++resultSetCount; &#125; &#125; return this.collapseSingleResultList(multipleResults);&#125; 参考 终结篇：MyBatis原理深入解析（一） MyBatis源码解析(二)——动态代理实现函数调用]]></content>
      <categories>
        <category>深入SSM</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[揭秘Mybatis(一)_Mybatis架构]]></title>
    <url>%2F2018%2F04%2F16%2F%E6%B7%B1%E5%85%A5SSM%2F%E6%8F%AD%E7%A7%98Mybatis-%E4%B8%80-Mybatis%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[引：从JDBC到Hibernate再到Mybatis，你可能会使用很多框架，但是你却不知道框架为你解决什么了或是不知道它的整个架构，我们这里就是帮你解决这些问题！ 为什么要使用MybatisJDBC的使用每一个人学Java的数据库操作应该都是从JDBC开始，它基本有以下7个步骤： 加载JDBC驱动 建立并获取数据库连接 创建 JDBC Statements 对象 设置SQL语句的传入参数 执行SQL语句并获得查询结果 对查询结果进行转换处理并将处理结果返回； 释放相关资源（关闭Connection，关闭Statement，关闭ResultSet）； JDBC相应的问题 数据库连接频繁的开启和关闭本身就造成了资源的浪费，影响系统的性能 SQL语句基本都散落在各个JAVA类中可读性很差，不利于维护以及做性能调优。 在后台代码中自己需要根据请求的传入参数（参数个数和顺序都不确定）去拼凑相应的SQL语句。 执行SQL语句后，返回的是一个ResultSet结果集，这个时候我们就需要将ResultSet对象的数据取出来，不然等到释放资源时就取不到这些结果信息了。 SQL重复的问题，不利于维护和复用。 Mybatis相应的解决 数据库连接的获取和关闭我们可以使用数据库连接池来解决资源浪费的问题。通过连接池就可以反复利用已经建立的连接去访问数据库了。减少连接的开启和关闭的时间。（数据库连接池以及数据源的配置） 将这些SQL语句统一集中放到配置文件或者数据库里面（以key-value的格式存放）。然后通过SQL语句的key值去获取对应的SQL语句。（Mapper文件） 使用一种有别于SQL的语法来嵌入变量（比如使用＃变量名）。这样，SQL语句经过解析后就可以动态的生成符合上下文的SQL语句。（Mapper文件里面的SQL语句） 将结果不做任何处理就直接返回，也有可能将结果转换成一个JavaBean对象返回、一个Map返回、一个List返回等，而且可以将SQL语句和传入参数两部分合起来可以作为数据缓存的key值。（语句标签返回结果的配置） 将重复的代码抽离出来成为独立的一个类，然后在各个需要使用的地方进行引用（SQL代码块） Mybatis架构 这张图超级棒，可以在后面的参考找到出处。我们就按照这个4层进行分析： 接口层接口调用方式主要有以下两种： 基于StatementId(命名空间+语句id)，范例如下： 1List&lt;?&gt;|int|void sqlSession select|update|delete|insert(statementId,params) 基于Mapper接口 MyBatis 将配置文件中的每一个 节点抽象为一个 Mapper 接口,这个接口中声明的方法和 节点中的 节点项对应，即 节点的id值为Mapper 接口中的方法名称，parameterType 值表示Mapper 对应方法的入参类型，而resultMap 值则对应了Mapper 接口表示的返回值类型或者返回结果集的元素类型。范例如下： 1234567891011&lt;mapper namespace="com.todorex.UserMapper"&gt; &lt;select id="selectList" resultType="com.todorex.User"&gt; select * from user &lt;/select&gt;&lt;/mapper&gt;public interface UserMapper &#123; List&lt;User&gt; selectList();&#125; 根据MyBatis 的配置规范配置好后，通过SqlSession.getMapper(UserMapper.class)方法，MyBatis会根据相应的接口声明的方法信息，通过动态代理机 制 生成一个Mapper 实例，我们调用Mapper接口的某一个方法时，MyBatis会根据这个方法的方法名和参数类型，确定StatementId，底层还是通过StatementId来实现对数据库的操作，MyBatis引用Mapper接口这种调用方式是为了满足面向接口编程的需 要。（其实还有一个原因是在于，面向接口的编程，使得用户在接口上可以使用注解来配置SQL语句，这样就可以脱离XML配置文件）。 数据处理层数据处理层可以说是MyBatis的核心，它要完成两个功能： 通过传入参数构建动态SQL语句 MyBatis 通过传入的参数值，使用 OGNL表达式 来动态地构造SQL语句，使得MyBatis有很强的灵活性和扩展性。参数映射指的是对于java 数据类型和jdbc数据类型之间的转换：这里有包括两个过程： 查询阶段，我们要将java类型的数据，转换成jdbc类型的数据，通过 preparedStatement.setXXX() 来设值 返回阶段，我们要对resultset查询结果集的jdbcType 数据转换成java 数据类型 SQL语句的执行以及封装查询结果集成List 动态SQL语句生成之后，MyBatis 将执行SQL语句，并将可能返回的结果集转换成List 列表。MyBatis 在对结果集的处理中，支持结果集关系一对多和多对一的转换，并且有两种支持方式，一种为嵌套查询语句的查询，还有一种是嵌套结果集的查询。 框架支持层 事务管理机制 事务管理机制对于ORM框架而言是不可缺少的一部分，事务管理机制的质量也是考量一个ORM框架是否优秀的一个标准。 连接池管理机制 由于创建一个数据库连接所占用的资源比较大，对于数据吞吐量大和访问量非常大的应用而言，连接池的设计就显得非常重要。 缓存机制 为了提高数据利用率和减小服务器和数据库的压力，MyBatis 会对于一些查询提供会话级别的数据缓存，会将对某一次查询，放置到SqlSession 中，在允许的时间间隔内，对于完全相同的查询，MyBatis会直接将缓存结果返回给用户，而不用再到数据库中查找。 SQL语句的配置方式 传统的MyBatis 配置SQL语句方式就是使用XML文件进行配置的，但是这种方式不能很好地支持面向接口编程的理念，为了支持面向接口的编程，MyBatis 引入了Mapper接口的概念，面向接口的引入，对使用注解来配置SQL语句成为可能，用户只需要在接口上添加必要的注解即可，不用再去配置XML文件了，但是，目前的MyBatis 只是对注解配置SQL语句提供了有限的支持，某些高级功能还是要依赖XML配置文件配置SQL 语句。 引导层引导层是配置和启动MyBatis配置信息的方式。MyBatis 提供两种方式来引导MyBatis： 基于XML配置文件的方式 基于Java API 的方式 范例可以查看官方使用手册：Mybatis官方使用手册 参考 终结篇：MyBatis原理深入解析（一）]]></content>
      <categories>
        <category>深入SSM</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[揭秘SpringMVC(一)_.SpringMVC大全解]]></title>
    <url>%2F2018%2F04%2F15%2F%E6%B7%B1%E5%85%A5SSM%2F%E6%8F%AD%E7%A7%98SpringMVC-%E4%B8%80-SpringMVC%E5%A4%A7%E5%85%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[引：现在基于所有的Web应用都离不开Spring，用了Spring，你自然会去用他家的MVC框架——SpringMVC！所以掌握SpringMVC也是非常重要的。 SpringMVC请求处理流程总览我们可以用下面一张图来介绍SpringMVC的核心组件和请求处理流程： 流程中出现的核心组件如下： DispatcherServlet是springmvc中的前端控制器，负责接收request并将request转发给对应的处理组件. HanlerMapping是springmvc中完成url到controller映射的组件.DispatcherServlet接收request,然后从HandlerMapping查找处理request的controller. Controller（HandlerAdapter）处理request,并返回ModelAndView对象,Controller是springmvc中负责处理request的组件(类似于struts2中的Action) ModelAndView是封装Model对象和View对象的组件 ViewResolver是视图解析器，负责解析ModelAndView对象生成对应的View对象 View视图组件，复制渲染页面 整个流程的大致流程如下： 当request到来时，DispatcherServlet对request进行捕获，并执行doService方法，继而执行doDispatch方法。 HandlerMapping解析请求，并且返回HandlerExecutionChain（其中包含对应的controller和interceptors） 通过HandlerExecutionChain得到Handler相关类，Handler先执行拦截器的pre相关方法，接着执行handler方法，最后调用拦截器的post相关方法 解析handler方法返回的ModelAndView 根据ViewResolver（可以在配置文件中配置，也就是视图解析器）生成View对象 View对象渲染页面并response给客户端 SpringMVC请求处理初始化源码分析 首先，Tomcat每次启动时都会加载并解析/WEB-INF/web.xml文件，所以可以先从web.xml找突破口（DispatcherServlet的配置），主要代码如下（我们每次都会这样配置）： 123456789101112131415161718&lt;servlet &gt; &lt;servlet-name &gt;spring-mvc&lt;/servlet-name&gt; &lt;!-- DispatcherServlet类，这个类在spring-mvc的包下面 --&gt; &lt;servlet-class &gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 初始化参数，这里主要是读取SpringMVC的一些配置信息，比如： 配置注解驱动，静态资源映射，视图解析器，自动扫描装配等相关信息。 --&gt; &lt;init-param &gt; &lt;param-name &gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value &gt;classpath:/spring-mvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 启动时加载 --&gt; &lt;load-on-startup &gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping &gt; &lt;servlet-name &gt;spring-mvc&lt;/servlet-name&gt; &lt;url-pattern &gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 进入DispatchServlet的分析，先看它的类图： 它是一个Servlet的子类，那么我们就要专注于它的init、service（后续分析）、doGet、doPost等相关方法，在它的父类HttpServeltBean，我们找到了init方法，如下： 1234567891011121314151617public final void init() throws ServletException &#123; try &#123; // 获取Servlet中的init参数，并创建了一个BeanWapper对象，由子类真正执行BeanWrapper的初始化工作 // 但是HttpServeltBean的子类并没有覆盖其initBeanWrapper方法，所以创建的BeanWrapper没有用 PropertyValues pvs = new HttpServletBean.ServletConfigPropertyValues(this.getServletConfig(), this.requiredProperties); BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this); ResourceLoader resourceLoader = new ServletContextResourceLoader(this.getServletContext()); bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, this.getEnvironment())); this.initBeanWrapper(bw); bw.setPropertyValues(pvs, true); &#125; catch (BeansException var4) &#123; this.logger.error("Failed to set bean properties on servlet '" + this.getServletName() + "'", var4); throw var4; &#125; // 这里进要进入到Framework的initServletBean方法了 this.initServletBean();&#125; 从上面的init方法中，我们由它的initServletBean方法进入到FrameworkServlet的initServletBean方法，如下： 123456789101112131415protected final void initServletBean() throws ServletException &#123; long startTime = System.currentTimeMillis(); try &#123; // 创建Spring容器，并调用onRefresh方法来完成配置文件的加载 this.webApplicationContext = this.initWebApplicationContext(); this.initFrameworkServlet(); &#125; catch (ServletException var5) &#123; this.logger.error("Context initialization failed", var5); throw var5; &#125; catch (RuntimeException var6) &#123; this.logger.error("Context initialization failed", var6); throw var6; &#125;&#125; 在容器加载的过程中会调用DispatchServlet的initStrategies方法来完成Dispatchservlet中定义的初始化工作，看DispatchServlet的源码： 12345678910111213141516171819202122232425262728protected void onRefresh(ApplicationContext context) &#123; this.initStrategies(context);&#125;// 初始化SpringMVC框架需要的8个组件，这8个组件对应8个bean对象保存在DispatchServlet类中protected void initStrategies(ApplicationContext context) &#123; // 用于处理文件上传服务，将Request包装成DefaultMultipartHttpServletRequest this.initMultipartResolver(context); // 用于处理应用的国际化问题，控制应用中的字符编码问题 this.initLocaleResolver(context); // 用于定义一个主题 this.initThemeResolver(context); // 用于定义用户设置的请求映射关系，将用户请求的URL映射后才能一个个Handler实例 // 如果没有定义HandlerMapping，将获取默认的BeanNameURLHandlerMapping和DefaultAnnotaionHandlerMapping this.initHandlerMappings(context); // 用于根据Handler的类型定义不同的处理规则（调用Controller实例），默认的为： // HttpRequestHandlerAdapter、SimpleControllerHandlerAdapter、ThrowawayControllerAdapter、AnnotationMethodHandlerAdapter this.initHandlerAdapters(context); // 当Handle处理出错时，会通过这个Handler来统一处理，默认为SimpleMappingExceptionResolver， // 将错误日志记录在日志文件中，并且跳转到默认的错误页面 this.initHandlerExceptionResolvers(context); // 将指定的ViewName按照定义的requestToViewNameTranslator替换成想要的格式，如加上前缀或者后缀。 this.initRequestToViewNameTranslator(context); // 用于将View解析成页面，在ViewResolvers中可以设置多个解析策略，默认的解析策略为InternalResourceViewResolver，按照JSP页面来解析 this.initViewResolvers(context); // 为一个请求存储意图为另外一个请求所使用的属性提供了一条途径(通常存储在session) this.initFlashMapManager(context);&#125; SpringMVC请求处理流程源码分析关注完初始化init方法，我们要进入正式的流程分析了，其实就是在sevice方法里面(在其父类FrameworkServlet里)，我们看看下面的源码：1234567protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; if(HttpMethod.PATCH.matches(request.getMethod())) &#123; this.processRequest(request, response); &#125; else &#123; super.service(request, response); &#125;&#125; 根据service方法，我们一步步调试进入service –&gt; processRequest –&gt; doService（将ApplicationContext、localeResolver、themeResolver等对象添加到request中以便后面使用） –&gt; doDispatch，我们最终将目光定位在doDispatch，因为从它的方法体就可以看出它是整个SpringMVC的核心方法。我们看看DispatchServlet里面的doDispatch方法源码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; // //处理文件上传请求 processedRequest = this.checkMultipart(request); multipartRequestParsed = processedRequest != request; // 解析请求（匹配URL），获取HandlerExecutionChain对象 mappedHandler = this.getHandler(processedRequest); if(mappedHandler == null || mappedHandler.getHandler() == null) &#123; this.noHandlerFound(processedRequest, response); return; &#125; // 从HandlerExecutionChain对象获取HandlerAdapter对象，实际上是从HandlerMapping对象中获取 HandlerAdapter ha = this.getHandlerAdapter(mappedHandler.getHandler()); String method = request.getMethod(); boolean isGet = "GET".equals(method); if(isGet || "HEAD".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if(this.logger.isDebugEnabled()) &#123; this.logger.debug("Last-Modified value for [" + getRequestUri(request) + "] is: " + lastModified); &#125; if((new ServletWebRequest(request, response)).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; // 在controller方法执行前，执行拦截器的相关方法（pre） if(!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // 执行HandlerAdapter对象的handle方法，返回ModelAndView mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if(asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; this.applyDefaultViewName(processedRequest, mv); // 在controller方法执行后，执行拦截器的相关方法（post） mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception var19) &#123; dispatchException = var19; &#125; // 进行视图解析 this.processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception var20) &#123; this.triggerAfterCompletion(processedRequest, response, mappedHandler, var20); &#125; catch (Error var21) &#123; this.triggerAfterCompletionWithError(processedRequest, response, mappedHandler, var21); &#125; &#125; finally &#123; if(asyncManager.isConcurrentHandlingStarted()) &#123; if(mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else if(multipartRequestParsed) &#123; this.cleanupMultipart(processedRequest); &#125; &#125; &#125; 上面是整体的流程，下面我们具体到对MVC架构的三个模块的分析： Control（C）Spring MVC的Control主要由HandlerMapping和HandlerAdapters两个组件提供。 HandlerMapping并没有规定这个URL与应用的处理类如何映射，在这个接口中只定义了根据URL必须返回一个由HandlerExecutionChain代理的处理链，我们可以在这里处理链中添加任意的HandlerAdapters实例来处理这个URL对应的请求。这个和Servlet规范中的filter处理是类似的。 HandlerMapping的初始化（可以参照HandlerMapping的子类SimpleUrlHandlerMapping里面的initApplicationContext方法代码） HandlerMapping的初始化工作完成的两个最重要的工作就是将URL与Handler的对应关系保存在handlerMap集合中，并将所有的interceptors对象保存在adaptedInterceptors数组中，等到请求到来时执行所有的adaptedInterceptors数组中的Interceptor对象，所有的Interceptor对象必须实现HandlerInterceptor接口。 HandlerAdapter(可以看成Controller)的初始化（可以参照HandlerAdapter的子类SimpleControllerHandlerAdapter里面的代码） HandlerAdapter的初始化工作主要是创建一个HandlerAdapter对象，将这个HandlerAdapter对象保存在DispatcherServlet的HandlerAdapters集合中。当SpringMVC将某个URL对应到某个Handler时，在HandlerAdapters集合中查询那个HandlerAdapters对象supports这个Handler，那么HandlerAdapters就会被返回（设计模式），并调用这个HandlerAdapters接口对应的方法。如果这个HandlerAdapters对象是SimpleControllerHandlerAdapter，则将调用其ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler)方法。如果用户没有定义HandlerAdapter的实现类，默认的为：HttpRequestHandlerAdapter、SimpleControllerHandlerAdapter、ThrowawayControllerAdapter、AnnotationMethodHandlerAdapter。 Control的调用逻辑根据DispatcherServlet的doDispath方法我们可以看到通过getHandler方法匹配到某个Handler并返回这个Handler的处理链HandlerExecutionChain对象，而这个HandlerExecutionChain对象将会包含一个匹配上的HandlerAdapter以及用户自定义的多个HandlerInterceptor对象。我们先看HandlerInterceptor接口，在HandlerInterceptor接口中有三个方法如下：123456789public interface HandlerInterceptor &#123; // 在Handler执行前 boolean preHandle(HttpServletRequest var1, HttpServletResponse var2, Object var3) throws Exception; // 在Handler执行后 void postHandle(HttpServletRequest var1, HttpServletResponse var2, Object var3, ModelAndView var4) throws Exception; // 在View渲染完成后，DispatchServlet返回之前执行。 // PS：当preHandler返回false时，当前的请求将在执行完该方法后直接返回，Handler不再执行 void afterCompletion(HttpServletRequest var1, HttpServletResponse var2, Object var3, Exception var4) throws Exception;&#125; 我们然后看看HandlerExecutionChain类的getHandler方法，你会发现返回的是Object对象，所以在这里Handler对象是没有类型的，Handler的类型是由HandlerAdapter（匹配到的）决定的。接下里执行Handler对象的具体方法，如果Handler对象的相应方法返回一个ModelAndView对象，接下去就去执行View渲染。 Model（M）Model实例既在业务逻辑层被使用，也在渲染页面中被使用，我们这里主要讲一下在页面模板渲染中的使用。 如果Handler返回了ModelAndView对象，那么说明Handler需要传一个Model实例给View去渲染模板。可以说ModelAndView对象就是连接业务逻辑层与View视图层的桥梁，对SpringMVC来说它也是连接Handler与View的桥梁。 ModelAndView对象会持有一个ModelMap对象和一个View对象（可以查看ModelAndView的源码），ModelMap对象就是执行模板渲染时所需要的变量对应的实例（对应到Struts2的值栈），如JSP通过request.getAttribute(String)获得JSTL标签名对应的对象。ModelMap其实也是个Map，在Handler中将模板需要的对象存在这个Map中，然后传递到View对应的ViewResolvers中。 View（V）Spring MVC的View主要由RequestToViewNameTranslator和ViewResolver两个组件提供。 RequestToViewNameTranslator支持用户自定义对ViewName的解析，如加上前缀或者后缀等。 ViewResolver会根据用户的请求的ViewName创建合适的模板引擎（解析器）来渲染最终的页面。ViewResolver会根据ViewName创建一个View对象，调用View对象的render方法渲染页面。 我们重点关注这个ViewResolver，先看他的类图： 我们从UrlBaseViewResolver对象的loadView方法-&gt;buildView方法可以看到如下代码： 12345678910protected AbstractUrlBasedView buildView(String viewName) throws Exception &#123; AbstractUrlBasedView view = (AbstractUrlBasedView)BeanUtils.instantiateClass(this.getViewClass()); view.setUrl(this.getPrefix() + viewName + this.getSuffix()); String contentType = this.getContentType(); if(contentType != null) &#123; view.setContentType(contentType); &#125; ... 省略 return view;&#125; 结合类图可以发现不同的解析器生成的View对象是不一样的。 获得View对象之后就可以调用View对象的render方法渲染页面。 参考 《深入分析Java Web技术内幕》 一步步分析SpringMVC源码]]></content>
      <categories>
        <category>深入SSM</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[揭秘Spring(四)_Spring设计模式]]></title>
    <url>%2F2018%2F04%2F12%2F%E6%B7%B1%E5%85%A5SSM%2F%E6%8F%AD%E7%A7%98Spring-%E5%9B%9B-Spring%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：说完了IOC和AOP（虽然可能还是不够深入，不够全面，但是对于自己还是有一定的收获，日后有新的领悟再来调整），再来说说Spring这么优秀的框架所使用的的设计模式，可谓遍地都是，我就自己看到写一下。 单例模式单例模式的的原理可以参照设计模式之禅——单例模式。 Spring应用到的单例模式可以在org.springframework.beans.factory.config.AbstractFactoryBean类中看到这个逻辑。看看它的getObject方法：1234public final T getObject() throws Exception &#123; // 如果是单例且已经初始化，就直接返回 return this.isSingleton()?(this.initialized?this.singletonInstance:this.getEarlySingletonInstance()):this.createInstance();&#125; 工厂方法模式工厂方法模式的的原理可以参照设计模式之禅——工厂方法模式。 Spring应用到的工厂方法模式可以在org.springframework.beans.factory.BeanFactory类中看到这个逻辑。我们看到下面的代码：1234public interface BeanFactory &#123; // 根据唯一标识来获得Bean对象 Object getBean(String var1) throws BeansException;&#125; 抽象工厂模式抽象工厂模式的的原理可以参照设计模式之禅——抽象工厂模式。 Spring应用到的抽象工厂模式可以在org.springframework.beans.factory.BeanFactory类中看到这个逻辑。通过它的实现，我们可以从Spring的容器访问bean。根据采用的策略，getBean方法可以返回已创建的对象（共享实例，单例作用域）或初始化新的对象（原型作用域）。在BeanFactory的实现中，我们可以区分：ClassPathXmlApplicationContext，XmlWebApplicationContext，StaticWebApplicationContext，StaticPortletApplicationContext，GenericApplicationContext，StaticApplicationContext，相当于不同的Creator。 建造者模式建造者模式的的原理可以参照设计模式之禅——建造者模式。 Spring应用到的建造者模式可以在org.springframework.beans.factory.support.BeanDefinitionBuilder类中检索这个逻辑。这是一个允许我们以编程方式定义bean的类。BeanDefinitionBuilder包含几个方法，它们为AbstractBeanDefinition抽象类的相关实现设置值，比如作用域，工厂方法，属性等。想看看它是如何工作的，请查看以下这些方法：1234567891011121314151617181920212223242526272829303132333435363738394041public class BeanDefinitionBuilder &#123; private AbstractBeanDefinition beanDefinition; // 设置Bean的父类名 public BeanDefinitionBuilder setParentName(String parentName) &#123; this.beanDefinition.setParentName(parentName); return this; &#125; // 设置Bean的工厂方法 public BeanDefinitionBuilder setFactoryMethod(String factoryMethod) &#123; this.beanDefinition.setFactoryMethodName(factoryMethod); return this; &#125; // 设置Bean的构造函数参数 public BeanDefinitionBuilder addConstructorArgValue(Object value) &#123; this.beanDefinition.getConstructorArgumentValues().addIndexedArgumentValue( this.constructorArgIndex++, value); return this; &#125; // 添加Bean的属性值 public BeanDefinitionBuilder addPropertyValue(String name, Object value) &#123; this.beanDefinition.getPropertyValues().add(name, value); return this; &#125; // 设置Bean的初始化方法 public BeanDefinitionBuilder setInitMethodName(String methodName) &#123; this.beanDefinition.setInitMethodName(methodName); return this; &#125; // 返回建造好的对象 public AbstractBeanDefinition getBeanDefinition() &#123; this.beanDefinition.validate(); return this.beanDefinition; &#125;&#125; 原型模式原型模式的的原理可以参照设计模式之禅——原型模式。 Spring应用到的原型模式可以在org.springframework.beans.factory.support.AbstractBeanFactory类中看到这个逻辑。它使用一种特定的原型设计模式，它先初始化bean原型作用域(克隆)。新对象基于配置文件中的bean定义。 模板模式模板模式的的原理可以参照设计模式之禅——模板模式。 Spring应用到的模板模式可以在org.springframework.context.support.AbstractApplicationContext类以及它的实现类中看到这个逻辑。它的模板方法是refresh方法，而refreshBeanFactory以及getBeanFactory等方法都由子类具体实现。 访问者模式访问者模式模式的的原理可以参照设计模式之禅——访问者模式。 Spring应用到的访问者模式可以在org.springframework.beans.factory.config.BeanDefinitionVisitor类中看到这个逻辑。该对象用于解析bean元数据并将其解析为String（例如：具有作用域或工厂方法名称的XML属性）或Object（例如：构造函数定义中的参数）。已解析的值在与分析的bean关联的BeanDefinition实例中进行判断设置。具体的源码请看BeanDefinitionVisitor的代码片段：12345678910111213141516171819202122232425262728public class BeanDefinitionVisitor &#123; public void visitBeanDefinition(BeanDefinition beanDefinition) &#123; visitParentName(beanDefinition); visitBeanClassName(beanDefinition); visitFactoryBeanName(beanDefinition); visitFactoryMethodName(beanDefinition); visitScope(beanDefinition); visitPropertyValues(beanDefinition.getPropertyValues()); ConstructorArgumentValues cas = beanDefinition. getConstructorArgumentValues(); visitIndexedArgumentValues(cas. getIndexedArgumentValues()); visitGenericArgumentValues(cas. getGenericArgumentValues()); &#125; protected void visitParentName(BeanDefinition beanDefinition) &#123; String parentName = beanDefinition.getParentName(); if (parentName != null) &#123; String resolvedName = resolveStringValue(parentName); if (!parentName.equals(resolvedName)) &#123; beanDefinition.setParentName(resolvedName); &#125; &#125;&#125;&#125; 代理模式代理模式的的原理可以参照设计模式之禅——代理模式。 Spring应用到的代理模式可以在org.springframework.aop.framework.ProxyFactoryBean类中看到这个逻辑。详细说明可以参照上一篇文章。 策略模式策略模式的的原理可以参照设计模式之禅——策略模式。 Spring应用到的策略模式可以在org.springframework.aop.framework.DefaultAopProxyFactory类中看到这个逻辑。看一下这个类的源码：1234567891011121314151617public class DefaultAopProxyFactory implements AopProxyFactory, Serializable &#123; public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; if(!config.isOptimize() &amp;&amp; !config.isProxyTargetClass() &amp;&amp; !this.hasNoUserSuppliedProxyInterfaces(config)) &#123; return new JdkDynamicAopProxy(config); &#125; else &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if(targetClass == null) &#123; throw new AopConfigException("TargetSource cannot determine target class: Either an interface or a target is required for proxy creation."); &#125; else &#123; // 根据目标类是否有接口而采取不同的策略 return (AopProxy)(!targetClass.isInterface() &amp;&amp; !Proxy.isProxyClass(targetClass)?new ObjenesisCglibAopProxy(config):new JdkDynamicAopProxy(config)); &#125; &#125; &#125;&#125; 适配器模式适配器模式的的原理可以参照设计模式之禅——适配器模式。 Spring应用到的适配器模式可以在org.springframework.aop.framework.adapter.DefaultAdvisorAdapterRegistry类中看到这个逻辑，Spring需要将每个Advice（通知）都封装成对应的拦截器类型，返回给容器，所以需要使用适配器模式对Advice进行转换。下面我们看看具体的代码：12345678910111213141516171819202122232425// Adapteepublic interface MethodBeforeAdvice extends BeforeAdvice &#123; void before(Method method, Object[] args, Object target) throws Throwable; &#125;// Targetpublic interface AdvisorAdapter &#123; boolean supportsAdvice(Advice advice); MethodInterceptor getInterceptor(Advisor advisor); &#125;// Adapterclass MethodBeforeAdviceAdapter implements AdvisorAdapter, Serializable &#123; public boolean supportsAdvice(Advice advice) &#123; return (advice instanceof MethodBeforeAdvice); &#125; public MethodInterceptor getInterceptor(Advisor advisor) &#123; MethodBeforeAdvice advice = (MethodBeforeAdvice) advisor.getAdvice(); return new MethodBeforeAdviceInterceptor(advice); &#125; &#125; 观察者模式观察者模式的的原理可以参照设计模式之禅——观察者模式。 Spring应用到的观察者模式可以应用程序上下文相关的事件传输看到这个逻辑，具体一点在AbstractApplicationContext与org.springframework.context.ApplicationListener以及org.springframework.context.event.ApplicationEventMulticaster中看到，我们可以看到下面的相关代码：123456789101112131415161718192021222324public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext, DisposableBean &#123; // 定义传播者，用来传播消息 private ApplicationEventMulticaster applicationEventMulticaster; // 注册监听者 protected void registerListeners() &#123; ... &#125;&#125;public interface ApplicationEventMulticaster &#123; void addApplicationListener(ApplicationListener&lt;?&gt; var1); void addApplicationListenerBean(String var1); void removeApplicationListener(ApplicationListener&lt;?&gt; var1); void removeApplicationListenerBean(String var1); void removeAllListeners(); void multicastEvent(ApplicationEvent var1); void multicastEvent(ApplicationEvent var1, ResolvableType var2);&#125; 解释器模式解释器模式的的原理可以参照设计模式之禅——解释器模式。 Spring应用到的解释器模式主要以Spring Expression Language（SpEL）为例。SpEL是一种由Spring的org.springframework.expression.ExpressionParser实现分析和执行的语言。这些实现使用作为字符串给出的Spel表达式，并将它们转换为org.springframework.expression.Expression的实例。上下文组件由org.springframework.expression.EvaluationContext实现表示，例如：StandardEvaluationContext。 参考参考了超级多，都快忘了，各位大佬不要介意！]]></content>
      <categories>
        <category>深入SSM</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7利用Nginx配置HTTPS]]></title>
    <url>%2F2018%2F04%2F12%2F%E5%B7%A5%E5%85%B7%2FCentos7%E5%88%A9%E7%94%A8Nginx%E9%85%8D%E7%BD%AEHTTPS%2F</url>
    <content type="text"><![CDATA[引：最近在做一个微信小程序项目，坑爹的小程序不仅需要https协议，而且还要是80端口才能访问后台，这里总结一下Nginx的安装过程与HTTPS的配置。 Ngnix的安装由于后面Nginx需要添加模块，所以我们采用源码安装，具体安装方法可以参考 走进Linux_软件安装 中的源码安装一节。 这里需要注意的我们在 产生makefile文件的时候 需要加一些configure arguments，以便安装相关模块。如下：1./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module --with-file-aio --with-http_realip_module 安装完之后可以利用下面的命令查看Ngnix版本及其编译参数：12345678/usr/local/nginx/sbin/nginx -V// 输出如下结果就是对的nginx version: nginx/1.11.6built by gcc 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC)built with OpenSSL 1.0.2k-fips 26 Jan 2017TLS SNI support enabledconfigure arguments: --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module --with-file-aio --with-http_realip_module 然后我们测试新的nginx程序是否正确：12345/usr/local/nginx/sbin/nginx -t// 输出如下结果J就表面安装成功nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful 配置HTTPSSSL证书申请SSL证书遵守 SSL（Secure Sockets Layer 安全套接层）协议，由受信任的数字证书颁发机构CA，在验证服务器身份后颁发，具有服务器身份验证和数据传输加密功能，也就是说你想要使用https就需要拥有SSL证书。 这里我们使用openssl证书来举例，微信小程序官网也是使用openssl来进行HTTPS服务器配置。 生成私钥 1234567891011// 进入nginx的安装目录cd /usr/local/nginx// 创建一个存放私钥的文件夹（自定义）mkdir key// 进入key文件夹cd key// 生成私钥openssl genrsa -out server.key 2048 生成csr文件 12345678910111213141516// CSR 是Certificate Signing Request的缩写，即证书签名请求，// 这不是证书，可以简单理解成公钥，生成证书时要把这个提交给权威的证书颁发机构。// 生成csr文件openssl req -new -key server.key -out certreq.csr// 输入上面的命令后会要求你输入一些信息：Country Name： CN //您所在国家的ISO标准代号，中国为CNState or Province Name：guandong //您单位所在地省/自治区/直辖市Locality Name：shenzhen //您单位所在地的市/县/区Organization Name： Tencent Technology (Shenzhen) Company Limited //您单位/机构/企业合法的名称Organizational Unit Name： R&amp;D //部门名称Common Name： www.example.com //通用名，网站域名。此项必须与您访问提供SSL服务的服务器时所应用的域名完全匹配。Email Address： //您的邮件地址，不必输入，直接回车跳过&quot;extra&quot;attributes // 以下信息不必输入，回车跳过直到命令执行完毕。 生成crt证书 12// CRT 即 certificate的缩写，即证书。openssl x509 -req -days 365 -in certreq.csr -signkey server.key -out certreq.crt Nginx配置SSL加密想要https就要监听443端口，nginx.conf已经预留出了server，只要我们把注释去掉开启即可。 12345678910111213141516171819202122232425// 编辑Ngnix配置文件vim /usr/local/nginx/conf/nginx.conf// 修改监听443端口的Server，使其如下：server &#123; listen 443 ssl; server_name www.example.com; ssl on; # ssl_certificate证书其实是个公钥，它会被发送到连接服务器的每个客户端 ssl_certificate /usr/local/nginx/key/certreq.crt; # ssl_certificate_key私钥是用来解密的，所以它的权限要得到保护但nginx的主进程能够读取 ssl_certificate_key /usr/local/nginx/key/server.key; ssl_session_timeout 5m; # 指定SSL服务器端支持的协议版本 ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # 选择加密算法 ssl_ciphers HIGH:!aNULL:!MD5; # ssl_ciphers ALL：!ADH：!EXPORT56：RC4+RSA：+HIGH：+MEDIUM：+LOW：+SSLv2：+EXP; # 在使用SSLv3和TLS协议时指定服务器的加密算法要优先于客户端的加密算法 ssl_prefer_server_ciphers on; # 虽然我们要使用HTTPS，但是服务器的程序接收的还是HTTP，所以要做个反向代理 location /&#123; proxy_pass http://localhost:8080; &#125;&#125; 这样虽然可以利用https来访问我们的ip，但是对于浏览器还是不受信任的。 导入证书如果你是找一个知名的SSL证书颁发机构如VeriSign、Wosign、StartSSL签发的证书，并且浏览器已经内置并信任了这些根证书，如果你是自建证书（向我们刚才那样）或获得二级证书授权，那么就需要将证书添加到浏览器，这样在访问站点时才不会显示不安全连接。不够买证书微信小程序会不支持。 证书生成的方法有很多，这里说两种： 购买阿里云的免费证书 购买GETSSL官网证书 购买好证书并下载后（可以将证书和私钥放到之前的key目录）需要从新配置nginx.conf文件，如下：123456789101112131415server &#123; listen 443 ssl; server_name www.example.com; ssl on; # pem是crt的一种，内容是BASE64编码，Apache和*NIX服务器偏向于使用这种编码格式 ssl_certificate /usr/local/nginx/key/*.pem; ssl_certificate_key /usr/local/nginx/key/*.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location /&#123; proxy_pass http://localhost:8080; &#125;&#125; 参考 linux nginx配置https openssl、x509、crt、cer、key、csr、ssl、tls 这些都是什么鬼?]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>HTTPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[揭秘Spring(三)_Spring之AOP]]></title>
    <url>%2F2018%2F04%2F11%2F%E6%B7%B1%E5%85%A5SSM%2F%E6%8F%AD%E7%A7%98Spring-%E4%B8%89-Spring%E4%B9%8BAOP%2F</url>
    <content type="text"><![CDATA[引：前一节讲到Spring的核心概念IOC，那么就不能不提到Spring的另一个核心概念AOP，我们先是先讲一下它的概念与原理实现，然后在讲Spring中AOP的实现。 AOPAOP思想AOP（Aspect Oriented Programming的缩写，意为：面向切面编程）是对OOP的一种补充。 面向对象(OOP)引入了继承、多态、封装，将系统的业务功能按照模块划分，每个模块用一个或多个类来表示。而对于一些系统功能，无法使用OOP的思想来实现它们。这些系统功能往往穿插在业务功能的各处，和业务代码耦合在一起；而且系统功能往往会被重复使用，这就导致了模块不利于复用，这就是使用OOP实现系统功能的弊端。 AOP即为面向切面编程，它把系统需求按照功能分门归类，把它们封装在一个个切面中，然后再指定这些系统功能往业务功能，主要应用于权限认证、日志，事务等。 它的主要是好处如下： 降低模块之间的耦合度 使系统容易扩展 更好的代码复用。 AOP实现原理实现AOP的技术，主要分为两大类：一是采用动态代理技术，利用截取消息的方式，对该消息进行装饰，以取代原有对象行为的执行；二是采用静态织入的方式，引入特定的语法创建“方面”，从而使得编译器可以在编译期间织入有关“方面”的代码。而Spring采用的是动态代理技术，关于动态代理的实现可以参照自己之前的博客 设计模式之禅——代理模式一文中的动态代理这一节去了解。 SpringAOP实现Spring的AOP实现遵守AOP联盟的约定。同时Spring又扩展了它，增加了Pointcut、Advisor等一些接口使得其更加灵活。 Spring AOP的基本概念 切面（Aspect）：类似于OOP中的Class，一个Aspect存放一个系统功能的所有逻辑。切面用Spring的 Advisor或拦截器实现。 连接点（Joinpoint）：程序执行过程中的某一事件，如方法被调用时、抛出异常时。 切入点（Pointcut）：指定一个通知将被引发的一系列连接点的集合。AOP框架必须允许开发者指定切入点：例如，使用正则表达式。 Spring定义了Pointcut接口，用来组合MethodMatcher和ClassFilter，可以通过名字很清楚的理解， MethodMatcher是用来检查目标类的方法是否可以被应用此通知，而ClassFilter是用来检查Pointcut是否应该应用到目标类上。 引入（Introduction）: 添加方法或字段到被通知的类。 Spring允许引入新的接口到任何被通知的对象。例如，你可以使用一个引入使任何对象实现 IsModified接口，来简化缓存。Spring中要使用Introduction, 可有通过DelegatingIntroductionInterceptor来实现通知，通过DefaultIntroductionAdvisor来配置Advice和代理类要实现的接口。 目标对象（Target Object）: 包含连接点的对象。也被称作被通知或被代理对象（POJO）。 AOP代理（AOP Proxy）: AOP框架创建的对象，包含通知。 在Spring中，AOP代理可以是JDK动态代理或者CGLIB代理。 织入（Weaving）: 组装方面来创建一个被通知对象。这可以在编译时完成（例如使用AspectJ编译器），也可以在运行时完成。Spring和其他纯Java AOP框架一样，在运行时完成织入。 通知（Advice）：具体的横切逻辑；Spring中有五种Advice： 前置通知（Before Advice） 后置通知（After Advice） 返回通知（After Return Advice） 环绕通知（Around Advice） 抛出异常后通知（After Throwing Advice） SpringAOP动态代理Spring AOP中使用了两种动态代理，一种是JDK的动态代理，一种CGLIB的动态代理。JDK的动态代理必须指定接口，这些接口都是已经被代理对象实现了的；而CGLIB代理则不需要指定接口。 JDK动态代理如果被代理对象实现了需要被代理的接口，则使用JDK的动态代理。我们一步步来看这个过程： 首先明确我们使要生成一个代理，而Spring的内部机制是由FactoryBean的getObject方法来产生的，所以我们会一步步debug到这个方法行（在FactoryBeanRegistrySupport类的doGetObjectFromFactoryBean中），我们看看这个方法的源代码： 123456789101112131415public Object getObject() throws BeansException &#123; // 初始化通知器链，为代理对象配置通知器链。 this.initializeAdvisorChain(); //区分SingleTon和ProtoType，生成对应的Proxy if(this.isSingleton()) &#123; // 只有SingleTon的Bean才会一开始就初始化，ProtoType的只有在请求的时候才会初始化，代理也一样 return this.getSingletonInstance(); &#125; else &#123; if(this.targetName == null) &#123; this.logger.warn("Using non-singleton proxies with singleton targets is often undesirable. Enable prototype proxies by setting the 'targetName' property."); &#125; return this.newPrototypeInstance(); &#125;&#125; 到达getObject方法后，我们需要去看看它是怎么初始化通知链的就是initializeAdvisorChain的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243 private synchronized void initializeAdvisorChain() throws AopConfigException, BeansException &#123; // 初始化过程的标志位advisorChainInitialized，这个标志用来表示通知器链是否已经初始化。 if(!this.advisorChainInitialized) &#123; if(!ObjectUtils.isEmpty(this.interceptorNames)) &#123; if(this.beanFactory == null) &#123; throw new IllegalStateException("No BeanFactory available anymore (probably due to serialization) - cannot resolve interceptor names " + Arrays.asList(this.interceptorNames)); &#125; if(this.interceptorNames[this.interceptorNames.length - 1].endsWith("*") &amp;&amp; this.targetName == null &amp;&amp; this.targetSource == EMPTY_TARGET_SOURCE) &#123; throw new AopConfigException("Target required after globals"); &#125; String[] var1 = this.interceptorNames; int var2 = var1.length; for(int var3 = 0; var3 &lt; var2; ++var3) &#123; String name = var1[var3]; if(this.logger.isTraceEnabled()) &#123; this.logger.trace("Configuring advisor or advice '" + name + "'"); &#125; if(name.endsWith("*")) &#123; if(!(this.beanFactory instanceof ListableBeanFactory)) &#123; throw new AopConfigException("Can only use global advisors or interceptors with a ListableBeanFactory"); &#125; this.addGlobalAdvisor((ListableBeanFactory)this.beanFactory, name.substring(0, name.length() - "*".length())); &#125; else &#123; Object advice; if(!this.singleton &amp;&amp; !this.beanFactory.isSingleton(name)) &#123; advice = new ProxyFactoryBean.PrototypePlaceholderAdvisor(name); &#125; else &#123; advice = this.beanFactory.getBean(name); &#125; this.addAdvisorOnChainCreation(advice, name); &#125; &#125; &#125; this.advisorChainInitialized = true; &#125;&#125; 初始化只是在应用第一次通过ProxyFactoryBean获取代理对象的时候。完成这个初始化之后，接着会读取配置中出现的所有通知器（把通知器的名字交给容器的getBean，IOC容器的回调获取通知器），把通知器加入拦截器链（addAdvisoronChainCreation实现）。 生成代理对象，利用ProxyFactoryBean的getSingletonInstance方法，源码如下： 123456789101112131415161718192021 private synchronized Object getSingletonInstance() &#123; if(this.singletonInstance == null) &#123; //这里会调用getBean，获取被代理对象 this.targetSource = this.freshTargetSource(); if(this.autodetectInterfaces &amp;&amp; this.getProxiedInterfaces().length == 0 &amp;&amp; !this.isProxyTargetClass()) &#123; // 根据 AOP 框架判断需要代理的接口 Class&lt;?&gt; targetClass = this.getTargetClass(); if(targetClass == null) &#123; throw new FactoryBeanNotInitializedException("Cannot determine target class for proxy"); &#125; //这里是设置代理对象的接口 this.setInterfaces(ClassUtils.getAllInterfacesForClass(targetClass, this.proxyClassLoader)); &#125; super.setFrozen(this.freezeProxy); //这里方法会使用ProxyFactory生成需要的Proxy this.singletonInstance = this.getProxy(this.createAopProxy()); &#125; return this.singletonInstance;&#125; 进入ProxyCreatorSupport的createAopProxy，源码如下： 1234567 protected final synchronized AopProxy createAopProxy() &#123;if (!this.active) &#123; activate();&#125;//通过AopProxyFactory取得AopProxy，AopProxyFactory是在初始化函数中定义的，使用的是DefaultAopProxyFactoryreturn getAopProxyFactory().createAopProxy(this);&#125; 那么DefaultAopProxyFactory如何生成AopProxy了，这里有两种方式，JdkDynamicAopProxy和CglibProxyFactory,DefaultAopProxyFactory的createAopProxy的源码如下： 1234567891011121314151617181920212223 public class DefaultAopProxyFactory implements AopProxyFactory, Serializable &#123; @Override public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &#123; //获取配置的目标对象 Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; //如果没有目标对象，抛出异常，提醒AOP应用提供正确的目标配置 throw new AopConfigException("TargetSource cannot determine target class: " + "Either an interface or a target is required for proxy creation."); &#125; // 这个判断很重要，通过目标类是否是接口来决定采用什么代理方式 if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &#123; return new JdkDynamicAopProxy(config); &#125; //由于CGLIB是一个第三方类库，所以需要在CLASSPATH中配置 return new ObjenesisCglibAopProxy(config); &#125; else &#123; return new JdkDynamicAopProxy(config); &#125; &#125;&#125; 由于我们这里目标类是接口，所以采用JdkDynamicAopProxy 生成AopProxy代理对象，我们可以看一下JdkDynamicAopProxy的invoke方法源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource; Class&lt;?&gt; targetClass = null; Object target = null; Object var13; try &#123; if(!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) &#123; Boolean var20 = Boolean.valueOf(this.equals(args[0])); return var20; &#125; if(!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) &#123; Integer var18 = Integer.valueOf(this.hashCode()); return var18; &#125; if(method.getDeclaringClass() == DecoratingProxy.class) &#123; Class var17 = AopProxyUtils.ultimateTargetClass(this.advised); return var17; &#125; Object retVal; // Advised接口或者其父接口中定义的方法,直接反射调用,不应用通知 if(!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp; method.getDeclaringClass().isAssignableFrom(Advised.class)) &#123; retVal = AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); return retVal; &#125; if(this.advised.exposeProxy) &#123; oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; //获得目标对象的类 target = targetSource.getTarget(); if(target != null) &#123; targetClass = target.getClass(); &#125; // 获得拦截链 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); // 如果没有可以应用到此方法的通知(Interceptor)，此直接反射调用 method.invoke(target, args) if(chain.isEmpty()) &#123; Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &#125; else &#123; //创建MethodInvocation MethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); // 处理通知 retVal = invocation.proceed(); &#125; Class&lt;?&gt; returnType = method.getReturnType(); if(retVal != null &amp;&amp; retVal == target &amp;&amp; returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp; !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &#123; retVal = proxy; &#125; else if(retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) &#123; throw new AopInvocationException("Null return value from advice does not match primitive return type for: " + method); &#125; var13 = retVal; &#125; finally &#123; if(target != null &amp;&amp; !targetSource.isStatic()) &#123; targetSource.releaseTarget(target); &#125; if(setProxyContext) &#123; AopContext.setCurrentProxy(oldProxy); &#125; &#125; return var13; &#125; CGLIB动态代理如果被代理对象没有实现需要被代理的接口，则使用CGLIB动态代理，CGLIB动态代理按照前面的分析基本与JDK动态代理一样，由于在Spring AOP中对应的包装类为CglibAopProxy，CglibAopProxy的intercept回调方法的实现和JdkDynamicAopProxy的回调实现是非常类似的，只是在CglibAopProxy中构造的是CglibMethodInvocation对象来完成拦截器链的调用，这里看一下与invoke类似的getCallbacks源码：1234567891011121314151617181920212223242526272829303132333435363738private Callback[] getCallbacks(Class&lt;?&gt; rootClass) throws Exception &#123; boolean exposeProxy = this.advised.isExposeProxy(); boolean isFrozen = this.advised.isFrozen(); boolean isStatic = this.advised.getTargetSource().isStatic(); Callback aopInterceptor = new CglibAopProxy.DynamicAdvisedInterceptor(this.advised); Object targetInterceptor; if(exposeProxy) &#123; targetInterceptor = isStatic?new CglibAopProxy.StaticUnadvisedExposedInterceptor(this.advised.getTargetSource().getTarget()):new CglibAopProxy.DynamicUnadvisedExposedInterceptor(this.advised.getTargetSource()); &#125; else &#123; targetInterceptor = isStatic?new CglibAopProxy.StaticUnadvisedInterceptor(this.advised.getTargetSource().getTarget()):new CglibAopProxy.DynamicUnadvisedInterceptor(this.advised.getTargetSource()); &#125; Callback targetDispatcher = (Callback)(isStatic?new CglibAopProxy.StaticDispatcher(this.advised.getTargetSource().getTarget()):new CglibAopProxy.SerializableNoOp()); Callback[] mainCallbacks = new Callback[]&#123;aopInterceptor, (Callback)targetInterceptor, new CglibAopProxy.SerializableNoOp(), targetDispatcher, this.advisedDispatcher, new CglibAopProxy.EqualsInterceptor(this.advised), new CglibAopProxy.HashCodeInterceptor(this.advised)&#125;; Callback[] callbacks; if(isStatic &amp;&amp; isFrozen) &#123; Method[] methods = rootClass.getMethods(); Callback[] fixedCallbacks = new Callback[methods.length]; this.fixedInterceptorMap = new HashMap(methods.length); for(int x = 0; x &lt; methods.length; ++x) &#123; // 获得拦截链 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(methods[x], rootClass); // 准备处理通知 fixedCallbacks[x] = new CglibAopProxy.FixedChainStaticTargetInterceptor(chain, this.advised.getTargetSource().getTarget(), this.advised.getTargetClass()); this.fixedInterceptorMap.put(methods[x].toString(), Integer.valueOf(x)); &#125; callbacks = new Callback[mainCallbacks.length + fixedCallbacks.length]; System.arraycopy(mainCallbacks, 0, callbacks, 0, mainCallbacks.length); System.arraycopy(fixedCallbacks, 0, callbacks, mainCallbacks.length, fixedCallbacks.length); this.fixedInterceptorOffset = mainCallbacks.length; &#125; else &#123; callbacks = mainCallbacks; &#125; return callbacks;&#125; 参考 深入剖析Spring(四)——AOP Spring AOP源码分析（生成代理对象） Spring AOP四种实现方式Demo详解与相关知识探究]]></content>
      <categories>
        <category>深入SSM</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[揭秘Spring(二)_Spring之IOC]]></title>
    <url>%2F2018%2F04%2F11%2F%E6%B7%B1%E5%85%A5SSM%2F%E6%8F%AD%E7%A7%98Spring(%E4%BA%8C)_Spring%E4%B9%8BIOC%2F</url>
    <content type="text"><![CDATA[引：前一篇文章我们介绍了Spring的整体架构以及核心组件，接下来我们将讲解Spring的核心概念之一IOC，我们将先简单介绍IOC与DI，然后再深入SpringIOC容器的工作流程。 IOC与DIIoC和DI是Spring的两个核心概念，很多人都把它们视为相同的东西（之前自己也一直这样认为），但事实并非如此。 IoC(Inversion of Control)：控制反转。 DI(Dependency Injection)：依赖注入 开始画重点了： 控制反转是目的，依赖注入是实现控制反转的手段。 控制反转是一种设计模式思想，它是一种宽泛的概念，只要一个类将对它内部状态的控制权交由其他机制去完成即为控制反转。控制反转是为了降低类与类之间的耦合度。而Spring采用依赖注入这一具体的手段来达到控制反转的目的。 关于依赖注入可以看我之前的文章先吹响口号_6大设计原则中的依赖倒置原则 DIP一节，这里就不做过多的介绍了。 IOC容器工作流程IOC容器实际上就是 Context 组件结合其他Bean和Core组件共同构建了一个 Bean 关系网，如何构建这个关系网？构建的入口就在 AbstractApplicationContext 类的 refresh 方法中。这个方法的代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243public void refresh() throws BeansException, IllegalStateException &#123; Object var1 = this.startupShutdownMonitor; synchronized(this.startupShutdownMonitor) &#123; // 为刷新准备新的context this.prepareRefresh(); // **创建BeanFactory** ConfigurableListableBeanFactory beanFactory = this.obtainFreshBeanFactory(); // 刷新所有BeanFactory子容器 this.prepareBeanFactory(beanFactory); try &#123; // 注册实现了BeanPostProcessor接口的bean（AOP使用） this.postProcessBeanFactory(beanFactory); // 初始化和执行BeanFactoryPostProcessor beans this.invokeBeanFactoryPostProcessors(beanFactory); // 初始化和执行BeanPostProcessors beans this.registerBeanPostProcessors(beanFactory); // 初始化MessageSource this.initMessageSource(); // 初始化 event multicaster （多路广播） this.initApplicationEventMulticaster(); // 刷新由子类实现的方法 this.onRefresh(); // 注册事件 this.registerListeners(); // 初始化单例Bean this.finishBeanFactoryInitialization(beanFactory); // 发布相应的事件 this.finishRefresh(); &#125; catch (BeansException var9) &#123; if(this.logger.isWarnEnabled()) &#123; this.logger.warn("Exception encountered during context initialization - cancelling refresh attempt: " + var9); &#125; // 销毁beans this.destroyBeans(); this.cancelRefresh(var9); throw var9; &#125; finally &#123; this.resetCommonCaches(); &#125; &#125; &#125; 这个方法就是构建整个IOC容器过程的完整的代码，了解了里面的每一行代码基本上就了解大部分 Spring 的原理和功能了。 这段代码主要包含这样几个步骤： 构建 BeanFactory 注册可能感兴趣的事件 创建 Bean 实例对象 触发被监听的事件 其中我们我们最关心的就是BeanFactory和创建Bean实例对象了，我们下面可以好好看看： 创建BeanFactory工厂我们利用debug可以进入到refresh()方法里面的obtainFreshBeanFactory()方法里面的refreshBeanFactory() （有点绕，但是自己就不画时序图了） 去看看他的创建代码：123456789101112131415161718192021protected final void refreshBeanFactory() throws BeansException &#123; if(this.hasBeanFactory()) &#123; this.destroyBeans(); this.closeBeanFactory(); &#125; try &#123; // 创建一个DefaultListableBeanFactory（上一节说过的很重要的类） DefaultListableBeanFactory beanFactory = this.createBeanFactory(); beanFactory.setSerializationId(this.getId()); this.customizeBeanFactory(beanFactory); // **这个方法会加载、解析Bean的定义** this.loadBeanDefinitions(beanFactory); Object var2 = this.beanFactoryMonitor; synchronized(this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException var5) &#123; throw new ApplicationContextException("I/O error parsing bean definition source for " + this.getDisplayName(), var5); &#125; &#125; 创建Bean实例并构建Bean的关系网我们利用debug可以进入到refresh()方法里面的finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory)方法里面的preInstantiateSingletons() （有点绕，但是自己就不画时序图了） 去看看它的创建Bean的代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public void preInstantiateSingletons() throws BeansException &#123; if(this.logger.isDebugEnabled()) &#123; this.logger.debug("Pre-instantiating singletons in " + this); &#125; List&lt;String&gt; beanNames = new ArrayList(this.beanDefinitionNames); Iterator var2 = beanNames.iterator(); while(true) &#123; while(true) &#123; String beanName; RootBeanDefinition bd; do &#123; do &#123; do &#123; if(!var2.hasNext()) &#123; var2 = beanNames.iterator(); while(var2.hasNext()) &#123; beanName = (String)var2.next(); Object singletonInstance = this.getSingleton(beanName); if(singletonInstance instanceof SmartInitializingSingleton) &#123; final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton)singletonInstance; if(System.getSecurityManager() != null) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; public Object run() &#123; smartSingleton.afterSingletonsInstantiated(); return null; &#125; &#125;, this.getAccessControlContext()); &#125; else &#123; smartSingleton.afterSingletonsInstantiated(); &#125; &#125; &#125; return; &#125; beanName = (String)var2.next(); bd = this.getMergedLocalBeanDefinition(beanName); &#125; while(bd.isAbstract()); &#125; while(!bd.isSingleton()); &#125; while(bd.isLazyInit()); if(this.isFactoryBean(beanName)) &#123; // 这个Bean很重要，Spring有一大半扩展功能都与这个Bean有关系， // 它是个工厂Bean，可以产生Bean实例的Bean， // Spring获取FactoryBean本身的对象是通过在前面加上&amp;来完成的 final FactoryBean&lt;?&gt; factory = (FactoryBean)this.getBean("&amp;" + beanName); boolean isEagerInit; if(System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123; isEagerInit = ((Boolean)AccessController.doPrivileged(new PrivilegedAction&lt;Boolean&gt;() &#123; public Boolean run() &#123; return Boolean.valueOf(((SmartFactoryBean)factory).isEagerInit()); &#125; &#125;, this.getAccessControlContext())).booleanValue(); &#125; else &#123; isEagerInit = factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean)factory).isEagerInit(); &#125; if(isEagerInit) &#123; // 普通的Bean只要通过getBean方法直接创建它的实例 // getBean方法里面包含了他们关系的创建 this.getBean(beanName); &#125; &#125; else &#123; this.getBean(beanName); &#125; &#125; &#125; &#125; IOC容器的扩展点如何让这些 Bean 对象有一定的扩展性（就是可以加入用户的一些操作）也是我们需要思考的！那么有哪些扩展点呢？ Spring 又是如何调用到这些扩展点的？ 对 Spring 的 IOC 容器来说，主要有这么几个扩展点： BeanFactoryPostProcessor， BeanPostProcessor：他们分别是在构建 BeanFactory 和构建 Bean 对象时调用。 InitializingBean 和 DisposableBean ：他们分别是在 Bean 实例创建和销毁时被调用。用户可以实现这些接口中定义的方法，Spring 就会在适当的时候调用他们。 FactoryBean ：他是个特殊的 Bean，这个 Bean 可以被用户更多的控制。 这些扩展点通常也是我们使用 Spring 来完成我们特定任务的地方，是否精通 Spring 就看你有没有掌握好Spring有哪些扩展点，并且如何使用他们。 要知道如何使用他们就必须了解他们内在的机理。可以用下面一个比喻（优秀）来解释： 我们把 IOC 容器比作一个箱子，这个箱子里有若干个球的模子，可以用这些模子来造很多种不同的球，还有一个造这些球模的机器，这个机器可以产生球模。那么他们的对应关系就是 BeanFactory 就是那个造球模的机器，球模就是 Bean，而球模造出来的球就是 Bean 的实例。 那前面所说的几个扩展点又在什么地方呢？ BeanFactoryPostProcessor 对应到当造球模被造出来时，你将有机会可以对其做出设当的修正，也就是他可以帮你修改球模。而 InitializingBean 和 DisposableBean 是在球模造球的开始和结束阶段，你可以完成一些预备和扫尾工作。BeanPostProcessor 就可以让你对球模造出来的球做出适当的修正。最后还有一个 FactoryBean，它可是一个神奇的球模。这个球模不是预先就定型了，而是由你来给他确定它的形状，既然你可以确定这个球模型的形状，当然他造出来的球肯定就是你想要的球了，这样在这个箱子里你可以发现所有你想要的球。 IOC容器的使用我们使用 Spring 必须要首先构建 IOC 容器，没有它 Spring 无法工作，ApplicatonContext.xml 就是 IOC 容器的默认配置文件，Spring 的所有特性功能都是基于这个 IOC 容器工作的，比如后面要介绍的 AOP。 参考 《深入分析Java Web技术内幕》 深入剖析Spring(一)——IoC的基本概念(从面向对象角度介绍)]]></content>
      <categories>
        <category>深入SSM</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[揭秘Spring(一)_Spring架构]]></title>
    <url>%2F2018%2F04%2F10%2F%E6%B7%B1%E5%85%A5SSM%2F%E6%8F%AD%E7%A7%98Spring-%E4%B8%80-Spring%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[引：Spring作为现在最优秀的框架之一，被广泛得使用在Web场景中。很多人只会使用，但是却不知道Spring整个体系架构。 Spring的骨骼架构Spring总共有十几个组件，但是真正核心的组件只有几个，如下图为Spring框架开始以来拥有的总体架构图： 从上图可以看出，在Spring框架中的 核心组件 只有三个：core、context、bean。他们构建起整个Spring的骨骼架构，没有他们就不可能有AOP、Web等上层的 特性功能 。 Spring的设计理念上面说了三个核心组件，但是最重要就是Bean组件了，用过Spring的人都知道，我们所有的类基本上都会交给Spring托管，也就是说Spring就是面向Bean的编程。Bean在Spring中的作用就像Object对OOP的意义一样，没有对象的概念就没有面向对象的概念，在Spring中没有Bean也就没有Spring存在的意义。 使用Spring最大的原因： 是他解决了一个非常关键的问题，它可以让你把对象之间的依赖关系解耦，其中的关系交由IOC容器（Bean关系的集合）来管理，核心就是依赖注入机制。Spring也正是通过把对象包装在Bean中达到管理这些对象及做一些列额外操作的目的。 一般框架设计理念： 先构建一个数据结构，然后根据这个数据结构设计它的生存环境，并让它在这个环境中按照一定的规律不停的运动，在他不停运动的过程中设计它们与环境或者与其他个体完成信息交换。 核心组件如何协同工作参考《深入分析Java Web技术内幕》一书中有个形象的比喻：Spring框架就像一场演出，Bean相当于演员，Context相当于演出的舞台背景、Core相当于演出的道具（把演员联系起来）。如果想演出足够新颖，就需要Spring提供的其他特色功能了。 回到Spring：Bean包装的是Object，而Object必然有数据，如何给这些数据提供生成环境就是Context要解决的事情，对于Context来说就是要发现每个Bean之间的关系，为他们建立这种关系并且维护好这种关系，而发现、建立和维护每个Bean之间的关系维护这种关系就需要Core组件了，Core组件其实就是发现、建立和维护每个Bean之间的关系所需要的一些列工具。最后我们发现Context就是一个Bean关系的集合，这个关系集合就叫IOC容器，当建立起IOC容器，Spring就可以工作了。他们的关系可以用下图来描述： 核心组件解析Bean组件Bean 组件在 Spring 的 org.springframework.beans 包下。这个包下的所有类主要解决了三件事：Bean 的定义、 Bean 的解析以及对Bean 的创建。对 Spring 的使用者来说唯一需要关心的就是 Bean 的创建，其他两个由 Spring 在内部帮你完成了，对你来说是透明的。 Bean的定义Bean 的定义主要有 BeanDefinition 描述，如下图（RootBeanDefinition类图）说明了这些类的层次关系： Bean 的定义就是完整的描述了在 Spring 的配置的Bean中所有的信息。当 Spring 成功解析你定义的一个Bean后，在 Spring 的内部他就被转化成 BeanDefinition 对象，它可以定义为SINGLETON还是PROTOTYPE。以后所有的操作都是对这个对象完成的。 Bean的解析Bean 的解析过程非常复杂，功能被分的很细，因为这里需要被扩展的地方很多，必须保证有足够的灵活性，以应对可能的变化。Bean 的解析方式有很多种，这也就导致配置方式有很多种（之后会介绍各种Bean的配置方法，如xml，扫描，注解、java配置）。这里就介绍一下最早的解析XML配置，它的过程主要通过下图中的类(XmlBeanDefinitionReader)完成： Bean的创建Spring Bean 的创建是典型的工厂模式，我们可以通过DefaultListableBeanFactory这个类来了解Spring的工厂模式，工厂模式的顶级接口是 BeanFactory，下图是这个工厂的继承层次关系： BeanFactory 有三个子类：ListableBeanFactory、HierarchicalBeanFactory 和 AutowireCapableBeanFactory。但是从上图中我们可以发现最终的默认实现类是 DefaultListableBeanFactory，他实现了所有的接口。 框架核心：那为何要定义这么多层次的接口呢？ 查阅这些接口的源码和说明发现，每个接口都有他使用的场合，它主要是为了区分在 Spring 内部在操作过程中对象的传递和转化过程中，对对象的数据访问所做的限制，具体如下： ListableBeanFactory 接口表示这些 Bean 是可列表的 HierarchicalBeanFactory 表示的是这些 Bean是有继承关系的，也就是每个 Bean有可能有父 Bean。 AutowireCapableBeanFactory 接口定义Bean的自动装配规则。 这四个接口共同定义了 Bean 的集合、Bean 之间的关系、以及 Bean 行为。 Context组件Context 在 Spring 的 org.springframework.context 包下，Context 组件在 Spring 中的作用实际上就是给Spring提供一个运行时的环境，用以保存各个对象的状态 。下面看一下这个环境是如何构建的。 ApplicationContext 是 Context 的顶级父类，他除了能标识一个应用环境的基本信息外，他还继承了六个接口，这六个接口主要是扩展了 Context 的功能。下面是 Context 相关的类结构图： 从上图中可以看出 ApplicationContext 继承了BeanFactory，这也说明了 Spring 容器中运行的主体对象是 Bean，另外 ApplicationContext 继承了 ResourceLoader 接口，使得 ApplicationContext 可以访问到任何外部资源（就是Core里面的工具了，这将在 Core 中详细说明）。 ApplicationContext 的子类主要包含两个方面： ConfigurableApplicationContext：表示该Context是可修改的，也就是在构建 Context 中用户可以动态添加或修改已有的配置信息，它下面又有多个子类，其中最经常使用的是可更新的 Context，即 AbstractRefreshableApplicationContext 类。 WebApplicationContext ：看到web就知道这为 web 准备的 Context 他可以直接访问到 ServletContext，通常情况下，这个接口使用的少。再往下分就是按照构建 Context 的文件类型（没列出，感兴趣的可以自己去看），接着就是访问 Context 的方式。这样一级一级构成了完整的 Context 等级层次。 总体来说 ApplicationContext 必须要完成以下几件事： 标识一个应用环境 利用 BeanFactory 创建 Bean 对象 保存对象关系表 能够捕获各种事件 Context 作为 Spring 的 IOC 容器，基本上整合了 Spring 的大部分功能，或者说是大部分功能的基础。 Core组件Core 组件在Spring 的org.springframework.core包下，它作为 Spring的核心组件，他其中包含了很多的关键类，其中一个重要组成部分就是定义了资源（Resource）的访问方式。这种把所有资源都抽象成一个接口的方式很值得在以后的设计中拿来学习。下面就重要看一下这个部分在 Spring 的作用。我们通过下图（ Resource 相关的类结构图）来理解： 从上图可以看出 Resource 接口封装了各种可能的资源类型，也就是对使用者来说屏蔽了文件类型的不同。对资源的提供者来说，如何把资源包装起来交给其他人用这也是一个问题(所以产生了很多方式)，我们看到 Resource 接口继承了 InputStreamSource 接口，这个接口中有个 getInputStream 方法，返回的是 InputStream 类。这样所有的资源都被可以通过 InputStream 这个类来获取，所以也屏蔽了资源的提供者。另外还有一个问题就是加载资源的问题，也就是资源的加载者要统一，从上图中可以看出这个任务是由 ResourceLoader 接口完成，他屏蔽了所有的资源加载者的差异，只需要实现这个接口就可以加载所有的资源，他的默认实现是 DefaultResourceLoader。 那Context 和 Resource 是如何建立关系的？下面是他们的类关系图： 从上图可以看出，Context 是把资源的加载、解析和描述工作委托给了 ResourcePatternResolver 类来完成，他相当于一个接头人，他把资源的加载、解析和资源的定义整合在一起便于其他组件使用。Core 组件中还有很多类似的方式。 参考 《深入分析Java Web技术内幕》 Spring多种加载Bean方式解析]]></content>
      <categories>
        <category>深入SSM</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_防火墙配置]]></title>
    <url>%2F2018%2F04%2F09%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux-%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[引：保障数据的安全性是继保障数据的可用性之后最为重要的一项工作。防火墙作为公网与内网之间的保护屏障，在保障数据的安全性方面起着至关重要的作用。 防火墙管理工具在公网与企业内网之间充当保护屏障的防火墙虽然有软件或硬件之分，但主要功能都是 依据策略对穿越防火墙自身的流量进行过滤。 防火墙策略可以基于流量的源目地址、端口号、协议、应用等信息来定制，然后防火墙使用预先定制的策略规则监控出入的流量，若流量与某一条策略规则相匹配，则执行相应的处理，反之则丢弃。这样一来，就可以保证仅有合法的流量在企业内网和外部公网之间流动了。 在Centos 7系统中，firewalld防火墙取代了iptables防火墙。但是 iptables与firewalld都不是真正的防火墙 ，它们都只是用来定义防火墙策略的 防火墙管理工具 而已，或者说，它们只是一种 服务 。iptables服务会把配置好的防火墙策略交由内核层面的netfilter网络过滤器来处理，而firewalld服务则是把配置好的防火墙策略交由内核层面的nftables包过滤框架来处理。换句话说，当前在Linux系统中其实存在多个防火墙管理工具，旨在方便运维人员管理Linux系统中的防火墙策略，我们只需要配置妥当其中的一个就足够了。虽然这些工具各有优劣，但它们在防火墙策略的配置思路上是保持一致的。 Iptables在早期的Linux系统中，默认使用的是iptables防火墙管理服务来配置防火墙。尽管新型的firewalld防火墙管理服务已经被投入使用多年，但是大量的企业在生产环境中依然出于各种原因而继续使用iptables。 策略与规则链防火墙会从上至下的顺序来读取配置的策略规则，在找到匹配项后就立即结束匹配工作并去执行匹配项中定义的行为（即放行或阻止）。如果在读取完所有的策略规则之后没有匹配项，就去执行默认的策略。一般而言，防火墙策略规则的设置有两种：一种是“通”（即放行），一种是“堵”（即阻止）。当防火墙的默认策略为拒绝时（堵），就要设置允许规则（通），否则谁都进不来；如果防火墙的默认策略为允许时，就要设置拒绝规则，否则谁都能进来， 防火墙也就失去了防范的作用。 iptables服务把用于处理或过滤流量的策略条目称之为规则，多条规则可以组成一个规则链，而规则链则依据数据包处理位置的不同进行分类，具体如下： 在进行路由选择前处理数据包（PREROUTING） 处理流入的数据包（INPUT） 处理流出的数据包（OUTPUT） 处理转发的数据包（FORWARD） 在进行路由选择后处理数据包（POSTROUTING） 一般来说，从内网向外网发送的流量一般都是可控且良性的，因此我们使用最多的就是INPUT规则链， 该规则链可以增大黑客人员从外网入侵内网的难度。 iptables还可以选择采用什么样的动作来处理这些匹配的流量，比如“允许”、“拒绝”、“登记”、“不理它”。这些动作对应到iptables服务的术语中分别是 ACCEPT（允许流量通过） REJECT（拒绝流量通过）： LOG（记录日志信息） DROP（拒绝流量通过）。 “允许流量通过”和“记录日志信息”都比较好理解，这里需要着重讲解的是REJECT和DROP的不同点。就DROP来说，它是直接将流量丢弃而且不响应；REJECT则会在拒绝流量后再回复一条“您的信息已经收到，但是被扔掉了”信息，从而让流量发送方清晰地看到数据被拒绝的响应信息。 基本使用iptables是一款基于命令行的防火墙策略管理工具，对于日常的防火墙策略配置来讲，只需要掌握常用的参数并做到灵活搭配即可，这就足以应对日常工作了。 iptables命令可以根据流量的源地址、目的地址、传输协议、服务类型等信息进行匹配，一旦匹配成功，iptables就会根据策略规则所预设的动作来处理这些流量。另外，再次提醒一下，防火墙策略规则的匹配顺序是从上至下的，因此要把较为严格、优先级较高的策略规则放到前面，以免发生错误。下表总结归纳了常用的iptables命令参数： 参数 作用 -P 设置默认策略 -F 清空规则链 -L 查看规则链 -A 在规则链的末尾加入新规则 -I num 在规则链的头部加入新规则 -D num 删除某一条规则 -s 匹配来源地址IP/MASK，加叹号“!”表示除这个IP外 -d 匹配目标地址 -i 网卡名称 匹配从这块网卡流入的数据 -o 网卡名称 匹配从这块网卡流出的数据 -p 匹配协议，如TCP、UDP、ICMP –dport num 匹配目标端口号 –sport num 匹配来源端口号 范例如下：1234567891011121314151617181920212223242526272829303132333435363738// 1. 查看已有的防火墙规则链iptables -L// 2. 清空已有的防火墙规则链iptables -F// 3. 把INPUT规则链的默认策略设置为拒绝(规则链的默认策略拒绝动作只能是DROP，而不能是REJECT)// 特别注意，如果你是在云服务上做实验，千万不要这样做，因为它会由于防火墙断开你的ssh连接，只能到控制台登录修改。iptables -P INPUT DROP// 4. 向INPUT链中添加拒绝ICMP流量进入的策略规则iptables -I INPUT -p icmp -j DROP// 5. 删除INPUT规则链中刚刚加入的那条策略（允许ICMP流量）iptables -D INPUT 1// 6. 将INPUT规则链设置为只允许指定网段的主机访问本机的22端口，拒绝来自其他所有主机的流量iptables -I INPUT -s 192.168.10.0/24 -p tcp --dport 22 -j ACCEPT// 7. 向INPUT规则链中添加拒绝所有人访问本机12345端口的策略规则iptables -I INPUT -p tcp --dport 12345 -j REJECT// 8. 向INPUT规则链中添加拒绝192.168.10.5主机访问本机80端口（Web服务）的策略规则iptables -I INPUT -p tcp -s 192.168.10.5 --dport 80 -j REJECT// 9. 向INPUT规则链中添加拒绝所有主机访问本机1000～1024端口的策略规则iptables -A INPUT -p tcp --dport 1000:1024 -j REJECT// 10. 使用iptables命令配置的防火墙规则默认会在系统下一次重启时失效，如果想让配置的防火墙策略永久生效，还要执行// 保存命令：service iptables save// 如果出现The service command supports only basic LSB actions (start, stop, restart, try-restart, reload, force-reload, status). For other actions, please try to use systemctl.需要如下操作：yum install iptables-services // 安装服务systemctl enable iptables // 设置开机启动iptablessystemctl start iptables //打开iptables然后执行就可以了 FirewalldCentos7系统中集成了多款防火墙管理工具，其中firewalld（Dynamic Firewall Manager of Linux systems，Linux系统的动态防火墙管理器）服务是默认的防火墙配置管理工具，它拥有基于CLI（命令行界面）和基于GUI（图形用户界面）的两种管理方式。但是我们只介绍命令行界面。 区域Zone相较于传统的防火墙管理配置工具，firewalld支持动态更新技术并加入了区域（zone）的概念。简单来说，区域就是firewalld预先准备了几套防火墙策略集合（策略模板），用户可以根据生产场景的不同而选择合适的策略集合，从而实现防火墙策略之间的快速切换。从而极大地提升了防火墙策略的应用效率。firewalld中常见的区域名称（默认为public）以及相应的策略规则如下表所示： 区域 默认规则策略 trusted 允许所有的数据包 home 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh、mdns、ipp-client、amba-client与dhcpv6-client服务相关，则允许流量 internal 等同于home区域 work 拒绝流入的流量，除非与流出的流量数相关；而如果流量与ssh、ipp-client与dhcpv6-client服务相关，则允许流量 public 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh、dhcpv6-client服务相关，则允许流量 external 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh服务相关，则允许流量 dmz 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh服务相关，则允许流量 block 拒绝流入的流量，除非与流出的流量相关 drop 拒绝流入的流量，除非与流出的流量相关 基本使用：firewall-cmdfirewall-cmd是firewalld防火墙配置管理工具的CLI（命令行界面）版本。它的参数一般都是以“长格式”来提供的，但是Centos7支持部分命令的参数补齐，其中就包含这条命令，美滋滋。也就是说，现在除了能用Tab键自动补齐命令或文件名等内容之外，还可以用Tab键来补齐下表中所示的长格式参数了： 参数 作用 –get-default-zone 查询默认的区域名称 –set-default-zone=&lt;区域名称&gt; 设置默认的区域，使其永久生效 –get-zones 显示可用的区域 –get-services 显示预先定义的服务 –get-active-zones 显示当前正在使用的区域与网卡名称 –remove-source= 将源自此IP或子网的流量导向指定的区域 –remove-source= 不再将源自此IP或子网的流量导向某个指定区域 –add-interface=&lt;网卡名称&gt; 将源自该网卡的所有流量都导向某个指定区域 –change-interface=&lt;网卡名称&gt; 将某个网卡与区域进行关联 –list-all 显示当前区域的网卡配置参数、资源、端口以及服务等信息 –list-all-zones 显示所有区域的网卡配置参数、资源、端口以及服务等信息 –add-service=&lt;服务名&gt; 设置默认区域允许该服务的流量 –add-port=&lt;端口号/协议&gt; 设置默认区域允许该端口的流量 –remove-service=&lt;服务名&gt; 设置默认区域不再允许该服务的流量 –remove-port=&lt;端口号/协议&gt; 设置默认区域不再允许该端口的流量 –reload 让“永久生效”的配置规则立即生效，并覆盖当前的配置规则 –panic-on 开启应急状况模式 –panic-off 关闭应急状况模式 与Linux系统中其他的防火墙策略配置工具一样，使用firewalld配置的防火墙策略默认为运行时（Runtime）模式，又称为当前生效模式，而且随着系统的重启会失效。如果想让配置策略一直存在，就需要使用永久（Permanent）模式了，方法就是在用firewall-cmd命令正常设置防火墙策略时添加–permanent参数，这样配置的防火墙策略就可以永久生效了。但是使用永久生效模式设置的策略只有在系统重启之后才能自动生效。如果想让配置的策略立即生效，需要手动执行firewall-cmd –reload命令。 使用范例如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344// 1. 查看firewalld服务当前所使用的区域firewall-cmd --get-default-zone// 2. 查询eth0网卡在firewalld服务中的区域firewall-cmd --get-zone-of-interface=eth0// 3. 把firewalld服务中eth0网卡的默认区域修改为external，并在系统重启后生效。// 分别查看当前与永久模式下的区域名称：firewall-cmd --permanent --zone=external --change-interface=eth0firewall-cmd --get-zone-of-interface=eth0firewall-cmd --permanent --get-zone-of-interface=eth0// 4. 把firewalld服务的当前默认区域设置为publicfirewall-cmd --set-default-zone=public// 5. 启动/关闭firewalld防火墙服务的应急状况模式，阻断一切网络连接（当远程控制服务器时请慎用）firewall-cmd --panic-onfirewall-cmd --panic-off// 6. 查询public区域是否允许请求SSH和HTTPS协议的流量firewall-cmd --zone=public --query-service=sshfirewall-cmd --zone=public --query-service=https// 7. 把firewalld服务中请求HTTPS协议的流量设置为永久允许，并立即生效firewall-cmd --zone=public --add-service=httpsfirewall-cmd --permanent --zone=public --add-service=httpsfirewall-cmd --reload// 8. 把firewalld服务中请求HTTP协议的流量设置为永久拒绝，并立即生效firewall-cmd --permanent --zone=public --remove-service=httpfirewall-cmd --reload// 9. 把在firewalld服务中访问8080和8081端口的流量策略设置为允许，但仅限当前生效firewall-cmd --zone=public --add-port=8080-8081/tcp// 10. 把原本访问本机888端口的流量转发到22端口，要且求当前和长期均有效firewall-cmd --permanent --zone=public --add-forward-port=port=888:proto=tcp:toport=22:toaddr=192.168.10.10(目标地址)firewall-cmd --reload// 11. firewalld中的富规则表示更细致、更详细的防火墙策略配置，// 它可以针对系统服务、端口号、源地址和目标地址等诸多信息进行更有针对性的策略配置。// 它的优先级在所有的防火墙策略中也是最高的。比如，我们可以在firewalld服务中配置一条富规则，使其拒绝192.168.10.0/24网段的所有用户访问本机的ssh服务（22端口）：firewall-cmd --permanent --zone=public --add-rich-rule=&quot;rule family=&quot;ipv4&quot; \source address=&quot;192.168.10.0/24&quot; service name=&quot;ssh&quot; reject&quot; 参考 iptables与firewalld防火墙]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_Linux中常用的网络命令]]></title>
    <url>%2F2018%2F04%2F08%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux_Linux%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E7%BD%91%E7%BB%9C%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[引：Linux的网络功能是相当强大的。所以我们必须要好好了解它，这里我们只是介绍一下常用的命令。 设置网络参数的命令ipconfigifconfig主要是可以都手动启动、查看与修改网络接口的相关参数，范例如下：12345678910111213141516171819202122232425// 1. 查看所有网络接口ifconfig// 2. 查看eth0网卡ifconfig eth0输出：eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.16.0.9 netmask 255.255.240.0 broadcast 172.16.15.255 ether 52:54:00:1c:91:2a txqueuelen 1000 (Ethernet) RX packets 15979545 bytes 1741444280 (1.6 GiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 15811187 bytes 2149680103 (2.0 GiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0* eth0：就是网络卡的代号，也有 lo 这个 loopback* mtu：网络接口的最大传输单元* inet：IPv4 的 IP 地址，后续是子网掩码和广播地址* RX：那一行代表的是网络由启动到目前为止的封包接收情况， packets 代表封包数、errors 代表封包发生错误的数量、 dropped 代表封包由于有问题而遭丢弃的数量等等* TX：与 RX 相反，为网络由启动到目前为止的传送情况；collisions：代表封包碰撞的情况，如果发生太多次， 表示您的网络状况不太好// 3. 暂时修改网络接口，给予eth0一个192.168.100.100/24的参数ifconfig eth0 192.168.100.100// 4. 将手动的处理全部取消，使用原有的设置值重置网络参数/etc/init.d/network restart 网络排错与查看命令ping这个 ping 是很重要的指令，ping 主要透过 ICMP（Internet控制报文协议） 封包来进行整个网络的状况报告。范例如下：12345678910111213141516// 1. 检测一下168.95.1.1这部DNS主机是否存在(存在于网络环境中)ping -c 3 168.95.1.1输出：PING 168.95.1.1 (168.95.1.1) 56(84) bytes of data.64 bytes from 168.95.1.1: icmp_seq=1 ttl=239 time=69.9 ms64 bytes from 168.95.1.1: icmp_seq=2 ttl=239 time=70.4 ms64 bytes from 168.95.1.1: icmp_seq=3 ttl=239 time=69.9 ms--- 168.95.1.1 ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 2002msrtt min/avg/max/mdev = 69.920/70.119/70.467/0.328 ms// 2. 找出最大的MTU数值(如果有响应，那就是可以接受这个数据包，如果无响应，就表示这个MTU太大了)ping -c 2 -s 1000 -M do 192.168.1.254 netstat如果你觉得你的某个网络服务明明就启动了，但是就是无法造成联机的话，要查询一下自己的网络接口所监听的端口 (port) 来看看是否真的有启动。范例如下：1234567891011// 1. 列出当前路由表状态，且以IP及port number进行系那是netstat -rn// 2. 列出当前的所有网络连接状态，使用IP与port numbernetstat -an// 3. 显示目前已经启动的网络服务netstat -tulnp// 4. 查看本机上所有的网络连接状态netstat -atunp host这个命令可以用来查出某个主机名的IP，范例如下：12// 1. 列出www.yahoo.com的IP(向/etc/resolv.conf里面记录的DNS服务器查询IP)host www.yohoo.com nslookup功能和host一样，范例如下： 12345// 1. 查询www.google.com的IPnslookup www.google.com// 2. 找出168.95.1.1的主机名 (建议使用dig)nslookup 168.95.1.1 远程连接命令与即时通信软件telnettelnet本身数据的在传输过程中使用的是明文，所以数据在Internet上面传输的时候，会比较危险。使用范例如下：123456// 1. 连接到当前热门的PTT BBS站点ptt.ccyum install telnet // 默认没有安装（自己未成功）// 2. 检测本地主机的110这个port是否正确启动,// 如果出现telnet: connect to address 127.0.0.1: Connection refused，代表这个port没有启动或者这个连接有问题telnet localhost 22 ftp用于处理ftp服务器的下载数据，范例如下：12// 1. 连接到一个ftp服务器ftp ip //之后可以利用help来帮助操作 文字接口网页浏览links最大的功能就是查阅Linux本机上面以html语法写成的文件数据。具体效果自己看吧，范例如下：12// 1. 浏览Linux kernel网站links http://www.kernel.org wget主要的功能是取得网页数据。范例如下：123// 1. 下载 2.6.17 版的linux内核wget \http://www.kernel.org/pub/linux/kernel/v2.6/linux-2.6.17.tar.gz 参考 《鸟哥的Linux私房菜》]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_软件安装]]></title>
    <url>%2F2018%2F04%2F08%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux_%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85-%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[引：当你拿到一台新电脑的第一反应是什么，当然是装软件，然后好好玩呀！服务器也是如此，所以你必须掌握软件的安装。 源码安装开放源码的软件安装相关概念Linux上几乎所有的软件都经过了GPL授权，因此几乎所有的软件都会提供源码。而一个软件要在Linux上执行，必须是二进制文件，因此当我们拿到软件源码后，需要将它编译成二进制文件才能在Linux上运行。 开放源码、编译程序、可执行文件 开放源码：就是程序代码，写给人类看的语言，但机器并不认识，所以无法执行。 编译程序：将程序代码转译称为机器看得懂的语言。 可执行文件：经过编译程序变成二进制程序后，机器看得懂所以可执行的文件。 函式库类似子程序的角色，可以被呼叫来执行的一段功能函数。 make与configure configure:侦测用户操作环境，是否支持软件的运行，侦测完毕生成makefile文件 是否有适合的编译程序可以编译本软件的程序代码 是否已经存在本软件所需要的函数库，或其他需要的相依软件 操作系统平台是否适合本软件，包括 Linux 的核心版本 核心的头文件定义档 (header include) 是否存在 (驱动程序必须要的侦测)。 make:make是一个程序，会去找makefile文件，然后执行编译。 tarball软件tarball文件其实就是将软件的源码先以tar打包，然后再压缩。其实就是一个软件包。通常解压缩之后会存在源代码文件、侦测程序文件（configure）、本软件的简易说明与安装说明（README）。 Tarball的安装的基本步骤 取得源文件：将tarball文件在/usr/local/src目录解压缩 取得步骤流程：进入新建立的目录下面，去查阅INSTALL与README等相关文件内容（很重要） 相关属性软件安装：根据INSTALL/README的内容查看并安装好一些相关的软件 建立makefile文件：以自动检测程序（configure）检测操作环境，并建立Makefile文件 编译：以make这个程序并使用该目录下得Makefile作为它的参数配置文件，来进行make的操作 安装：以make这个程序，并以Makefile这个参数配置文件，依据install这个目标（在Makefile文件中会有多个操作目标，如clean）的指定来安装到正确地路径。 Tarball软件安装的建议事项在默认情况下，原本的Linux distribution发布安装的软件大多是在/usr里面的，而自行安装的软件则建议放置在/usr/local里面。 linux distribution默认的安装软件的路径如下，以httpd为例： /etc/httpd（配置文件） /usr/lib（函数库） /usr/bin（可执行文件） /usr/share/man（在线帮助文档） tarball安装，默认放在/usr/local，如下目录：（升级，删除不方便） /usr/local/etc /usr/local/bin /usr/local/lib /usr/local/man tarball安装，但是单一软件都在同一个目录下，以apache为例：（利于删除，升级） /usr/local/apache/etc /usr/local/apache/bin /usr/local/apache/lib /usr/local/apache/man 当然，实际安装的时候还是得视该软件的Makefile里头的install目标信息才能知道安装路径情况。 为了方便Tarball的管理，这样建议： 最好将tarball的原始数据解压缩到/usr/local/src当中 安装时，最好安装到/usr/local这个默认路径下 考虑将来的删除，最好可以将每个软件单独安装在/usr/local下面 为安装到单独目录的软件的man page加入到man path搜索，即在/etc/man.config增加一行。 简单安装范例（ntp时间服务器）假设这个软件在/opt下，解压到/usr/local/src，并安装到/usr/local/ntp目录下。12345678910111213141516171819cd /usr/local/src //切换目录tar -zxvf /opt/ntp-4.2.4p7.tar.gz //解压缩到此目录cd ntp-4.2.4p7/vi INSTALL // 查阅安装信息// 检查configure支持参数，并实际生成makefile规则文件(很重要)./configure --help | more./configure --prefix=/usr/local/ntp \--enable-all-clocks --enable-parse-clocks //开始建立makefile（设置了安装目录等）// 开始编译并安装make clean; makemake checkmake install 利用patch更新源码12345678910// 基本语法1. patch -p 数字 &lt; patch_file 更新2. patch -R &lt; patch_file 还原更新假如patch_file第一行是***/home/guest/example/expatch.old，如果执行patch -p0 &lt; patch_file，则更新的文件是/home/guest/example/expatch.old，如果执行patch -p4 &lt; patch_file，则更新的文件是expatch.old，基本语法中数字是指拿掉第几个下划线之前的东西（包括下划线）。在更新之后，还是需要重新编辑，这才是最终的正确的软件。 RPM安装RPM和DPKG当前Linux上有两款主流的软件管理程序，分别是：RPM和DPKG。这两款软件均提供在线升级机制。 RPM RPM全称为Red Hat Package Manager，是Red Hat公司研发的Linux软件管理程序。目前CentOS、SuSE、Fedora等操作系统使用它。 RPM使用YUM进行在线升级。 DPKG dpkg由Debian Linux开发，目前使用该软件的操作系统有Ubuntu、B2D等。 dpkg使用apt-get进行在线升级。 PS：什么是“在线升级机制”？一个软件往往会依赖其他软件的一些功能，那么在安装过程中，只有确保一个软件所依赖的所有软件都被安装后，该软件才能被正确安装。而在线升级机制能够在软件安装过程中，若发现该软件的依赖软件尚未安装，则会自动从互联网中下载所依赖的软件。这就是在线升级机制 RPM默认安装的路径 /etc 一些设置文件放置的目录，例如/etc/crontab /usr/bin 一些可执行文件 /usr/lib 一些程序使用的动态函数库 /usr/share/doc 一些基本的软件使用手册与帮助文档 /usr/share/man 一些man page文件 RPM安装因为安装软件是root的工作，所以你必须是root用户才能使用rpm命令，使用范例如下(例子为安装rp-pppoe-3.5-32.1.i386.rpm)：12// 安装软件是，显示安装信息与进度rpm -ivh rp-pppoe-3.5-32.1.i386.rpm RPM的升级与更新范例如下：1234567rpm -Uvh 需要升级的软件名-Uvh:若待升级的软件尚未安装，则直接安装rpm -Fvh 需要升级的软件名-Fvh:若待升级的软件尚未安装，则该软件不会被安装 RPM查询查询的信息分为两类，一类是查询已被安装的软件的信息(由/var/lib/rpm提供)，另一类是查询尚未被安装的软件安装包的信息。 第一类信息通过rpm -q查询，第二类信息通过rpm -qp查询。范例如下：123456789101112131415161718// 1. 找出你的Linux是否安装logrotate这个软件rpm -q logrorate// 2. 列出logrotate这个软件所提供的所有目录与文件rpm -ql logrorate// 3. 列出logrotate这个软件的相关文件说明rpm -qi logrorate// 4. 列出logrotate这个软件的设置文件与帮助文件rpm -qc logroraterpm -qd logrorate// 5. 列出logrotate这个软件所依赖软件的文件rpm -qR logrorate// 6. 列出该文件属于哪一个软件rpm -qf /bin/sh 卸载RPM与重建数据库卸载一个软件非常方便，通过-e即可删除。但一个软件所提供的动态函数库被其他软件引用，那么该软件将无法卸载，除非将引用该函数库的所有软件都卸载后才能卸载。范例如下：1234561. 找出与pam有关的软件名称，并尝试删除pam这个软件rpm -qa | grep pamrpm -e pam（出错，因为你需要先删除依赖它的软件）2. 删除pam-devel软件rpm -e pam-devel (成功) 当/var/lib/rpm内的文件发生损坏时，可以通过如下命令重建数据库修复：1rpm --rebuilddb YUM安装RPM虽然省去了编译过程，并且提供数据库存储软件的信息，但仍然需要我们手动下载RPM安装包，而YUM的出现解决了这一问题。较多软件的RPM安装包都存放在了YUM Server上，只要我们的计算机能连互联网，就能使用yum自动下载RPM安装包并安装软件。 yum功能yum的使用非常简单，就是通过yum这个命令，用法范例如下： 查询功能 1234567891011121314// 1. 搜索磁盘阵列相关的软件yum search raid// 2. 找出mdadm这个软件的功能如何yum info mdadm// 3. 列出yum服务器上面提供的所有软件名称yum list// 4. 列出目前服务器上可供本机升级的软件有哪些yum list updates// 5. 列出提供passwd这个文件的软件有哪些yum provides passwd 安装/升级功能 12// 1. 安装/升级pam-develyum install/update pam-devel 删除功能 12// 1. 删除pam-develyum remove pam-devel 管理的选择：RPM or Tarball建议如下： 优先选择原厂的RPM功能 选择软件官方网站发布的RPM或者是提供的容器网址（yum server） 利用Tabball安装特殊软件（没有RPM） 用Tarball测试新版软件 RPM与Tarball各有优点，但是如果有RPM的话，优先选择RPM。如果无法解决依赖性问题，那就选tarball。 参考 《鸟哥的Linux私房菜》]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_daemon为服务(service)保驾护航]]></title>
    <url>%2F2018%2F04%2F03%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux_daemon%E4%B8%BA%E6%9C%8D%E5%8A%A1(service)%E4%BF%9D%E9%A9%BE%E6%8A%A4%E8%88%AA%2F</url>
    <content type="text"><![CDATA[引：我们进程会听到daemon，但是却不知道其义，其实就是一个守护进程，作用是支持其他服务(service)的运行。我们下面可以好好看看linux中的daemon与service！ 什么是daemon与服务系统为了某些功能必须要提供一些服务，这个服务就称为service。但是service的提供总是需要进程的运行，所以实现这个service的程序我们就称它为daemon。 daemon的分类分类方式一：按照“是否可以独立启动”分类 stand alone类型的daemon：这种类型的daemon可以自行启动，启动之后可以常驻内存，直到手动关闭该daemon才释放资源。如www。 由super daemon管理的daemon：这种类型的daemon由super daemon统一管理，当请求到来时，由super daemon启动请求的服务，请求完成后便释放内存资源。如telnet。 分类方式二：按照“请求到来时是否能够立即运行”分类 signal-control类型的daemon这种类型的daemon当有请求到来时便能立即执行。如打印机服务。 interval-control类型的daemon这种类型的daemon会周期性地执行某项工作，因此它没有请求一说，它会周期性地读取配置文件，并执行配置文件中要求的功能。如crond、atd都属于interval-control类型的daemon。 通常在服务的名称的之后都会加一个d。 网络服务与端口的对应当系统提供了网络服务，就会涉及到端口的问题，这些服务与端口的定义文件在/etc/services。大家可以自己查看一下。如下：12tcpmux 1/tcp # TCP port service multiplexertcpmux 1/udp # TCP port service multiplexer 第一列为daemon的名称，第二列为该daemon所使用的端口号与网络数据包协议。 daemon的启动脚本与启动方式stand-alone类型的daemon和super daemon类型的daemon有各自的启动方式 stand alone型Daemon的启动方式 通过/etc/init.d/xxx启动。启动一个服务是一个繁琐的过程，你需要进行一系列启动前的操作，为了避免这些麻烦，服务提供商把这些繁琐的过程封装在一个shell srcipt中，我们只需执行一个shell script即可启动一个daemon。几乎所有的stand alone型daemon的启动脚本都放在/etc/init.d/下，所以我们只需执行 /etc/init.d/xxx start 即可启动xxx服务。 通过service命令启动。若每次启动一个命令都要写/etc/init.d/略微有些麻烦，service命令将其进行了封装，我们只要执行 “service xxx start/status/restart/stop” 即可开启/查看/重启/关闭xxx服务。 super daemon型Daemon的启动方式 设置daemon的配置文件，每一个被super daemon管理的daemon都有一个配置文件，在/etc/xinetd.d/目录下。每个daemon的开启或关闭均在该daemon对应的配置文件中设置。 启动super daemon，super daemon是一个stand alone型daemon，因此在daemon的配置文件设置好后可通过service xinetd start启动所有由super daemon管理的daemon。 解析super daemon的配置文件默认值配置文件：xinetd.conf高版本的contos可能没有该文件，是因为没有安装，所以要先用“yum install xinetd”安装之后，就可以看见了。 super daemon的默认配置文件为:/etc/xinetd.conf，它为它所管理的所有daemon做了一些默认的配置。从最后一行的includedir /etc/xinetd.d可以看出，它加载了它所管理的所有daemon的配置。 下面来看一下具体的某个daemon的配置：12345678910service rsync #service后为daemon的名字&#123; disable = yes # yes表示关闭此daemon，no表示开启此daemon socket_type = stream #stream表示使用TCP、dgram表示使用UDP、raw表示直接与IP交互 wait = no user = root #以什么用户的身份启动这个daemon server = /usr/bin/rsync #这个daemon的启动程序 server_args = --daemon #启动时所需的参数 log_on_failure += USERID # 登录失败时需要记录用户&#125; =：表示将某个参数设为等号右侧的值，若先前设置中已设置过该参数，则直接覆盖 +=：表示保留先前设置的这个参数，再给这个参数增加个值。 -和-=的含义同上。 super deamon的防火墙管理由于受super daemon管理的daemon的请求都首先需要经过super daemon，因此super daemon可以充当防火墙的角色，拒绝一些不安全的请求。super daemon提供了两种防火墙机制，第一种方式提供较多详细的安全设置，而第二种方式只能阻挡或允许指定的IP，具体见下： 使用受super daemon管理的daemon的配置文件实现防火墙机制 在某个具体的daemon配置文件中添加如下参数，即可为daemon配置防火墙： instance=数字/UNLIMITED：设置该daemon能够承受的最大连接数。` per_source=数字/UNLIMITED：每个IP的最大连接数。 Cps=数字1 数字2：该daemon在一秒内的连接数超过数字1，则暂时关闭该da* emon数字2的秒数。 log_on_success/failure=PID/HOST/USERID/EXIT/DURATION：当登录成功/* 失败时记录的信息。HOST：连接者的IP、EXIT：离开时间、DURATION：为该用户服务的时间。 redirect=IP：将用户的请求转至指定服务器。 bind=IP：允许用户用哪个IP访问本服务。only_from=[0.0.0.0,192.168.1.0:24]：只允许指定IP的用户访问。0.0.0.0表示允许所有用户，192.168.1.0:24表示只允许192.168.1.1－192.168.1.255之间的用户访问。access_time=00:00-12:00：只允许该时间段内访问。 使用xinetd提供的/etc/hosts.allow和/etc/hosts.deny实现防火墙机制 /etc/hosts.allow ：我们可以在该文件中设置允许访问的IP /etc/hosts.deny ：我们可以在该文件中设置不允许访问的IP 系统开启的服务查看系统启动的服务一般情况下，我们会比较关心网络监听的服务，所以都会使用netstat命令(之前也提到过)，这里再次说明几个范例：12345678// 1. 找出目前系统开启的网络服务netstat -tulp// 2. 找出所有有监听网络的服务netstat -lnp// 3. 查看所有的服务状态 service --status-all 设置Daemon开启启动在设置Daemon开机启动之前，最好先了解一下Linux主机是怎么开机的？ 打开计算机电源，开始读取BIOS并进行主机的自我测试 通过BIOS取得第一个可开机设备，读取主要开机区(MBR)取得启动装载程序 通过启动装载程序的设置，取得kernel并加载内存且检测系统硬件 内核主动调用init进程 init进程开始执行系统初始化(/etc/rc.d/rec.sysinit) 依据init的设置进行daemonstart(/etc/rc.d/rc[0-6].d/*) 加载本机设置 在启动Linux系统时，可以进入不同的模式，这模式我们称为执行等级(run level)，不同执行等级有不同的功能与服务。图型界面为run level5，纯文本界面为run level3。当我们想要知道哪些服务默认可以启动，这就需要下面的命令来查询: chkconfig：管理系统服务默认开机启动与否，范例如下： 12345678910111213// 1. 列出目前系统上面所有被chkconfig管理的服务chkconfig --list | more // 分为两个块，分别为两种启动方式的daemon// 2. 显示目前在run level 3 启动的服务chkconfig --list | grep &apos;2:on&apos;// 3. 让atd这个服务在run level 3，4，5时启动chkconfig --level 345 atd on// 4. 查看httpd，再查看默认有无启动，之后以chkconfig设置为默认启动/etc/init.d/httpd status // 查看本身chkconfig --list httpd // 查看是否默认启动chconfig httpd on; //设置为开机启动 chkconfig：设置自己的系统服务1chkconfig [--add|--del] [服务名称] // 该服务必须在/etc/init.d/内 RHEL7的sytemctl（代替service和chkconfig）centos7版本中使用了systemd，systemd同时兼容service,对应的命令就是systemctl 。systemctl是RHEL 7 的服务管理工具中主要的工具，它融合之前service和chkconfig的功能于一体。可以使用它永久性或只在当前会话中启用/禁用服务。 systemd把不同的资源称为Unit每一个 Unit 都有一个配置文件，告诉 Systemd 怎么启动这个 Unit存放目录：/etc/systemd/system和/usr/lib/systemd/system。 使用范例如下：1234567891011121314151617181920212223242526272829303132333435// 1. 以树形列出正在运行的进程，它可以递归显示控制组内容systemd-cgls// 2. 启动一个服务systemctl start firewalld.service// 3. 关闭一个服务systemctl stop firewalld.service// 4. 重启一个服务systemctl restart firewalld.service// 5. 显示一个服务的状态systemctl status firewalld.service// 6. 在开机时启动一个服务systemctl enable firewalld.service// 7. 在开机时禁用一个服务systemctl disable firewalld.service// 8. 查看服务是否开机启动systemctl is-enabled firewalld.service// 9. 查看已启动的服务列表systemctl list-unit-files | grep enabled// 10. 查看启动失败的服务列表systemctl --failedPS：1. 使用命令 systemctl is-enabled firewalld.service 得到的值可以是enable、disable或static， 这里的 static 它是指对应的 Unit 文件中没有定义[Install]区域，因此无法配置为开机启动服务。2. 启用服务就是在当前“runlevel”的配置文件目录/etc/systemd/system/multi-user.target.wants/里，建立/usr/lib/systemd/system里面对应服务配置文件的软链接； 禁用服务就是删除此软链接，添加服务就是添加软连接。 参考 《鸟哥的Linux私房菜》 RHEL7的sytemctl（代替service和chkconfig）]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_认识你的进程]]></title>
    <url>%2F2018%2F04%2F02%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux_%E8%AE%A4%E8%AF%86%E4%BD%A0%E7%9A%84%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[引：linux服务器上可以跑很多很多的程序，当然也会遇到很多的问题，所以我们需要学会去管理好它。尤其像ps，top这些命令，你一定会很想去了解它吧！ 理解进程什么是进程进程： 一个程序被加载到内存当中运行，那么在内存中的那个数据就被称为进程。 系统也会给予这个进程一个ID，称为PID。同时触发这个进程的用户与相关属性关系，给予这个PID一组有效的权限设置。 进程与程序程序和进程概念 程序：通常为二进制程序，放置在存储媒介中，以物理文件的形式存在。 进程：程序在触发后，执行者的权限与属性、程序的程序代码与所需数据等都会被加载到内存中，操作系统给予这个内存中的单元一个标识符（PID），可以说，进程就是一个正在运行的程序。 子进程与父进程举个栗子：当我们登录系统后，会取得一个bash的shell，然后，我们用这个bash提供的接口去执行另一个命令，那些另外执行的命令也会被触发称为PID，那个后来执行命令才产生的PID就是“子进程”，而在我们原本在bash环境下，就称为“父进程”。子进程会具有PPID(父PID)。 fork and exec：过程调用的流程在Linux的过程调用中通常被称为fork and exec的流程，进程都会父进程以复制(fork)的方式产生一个一模一样的子进程（PID不一样），然后被复制出来的子进程再以exec的方式来执行实际要进行的进程，最终称为一个子进程的存在。 工作管理什么是工作管理工作管理： 当我们登录系统取得bash shell之后，在单一终端机下同时进行多个工作的行为管理。 下面是前台和后台定义: 前台: 你可以控制与执行命令的环境 后台： 可以自行运行的工作，你无法用ctrl + c终止它，但是可以用bg/fg调用该工作的环境 要进行bash的工作管理必须要注意的限制是： 这些工作所触发的进程必须要来自你的shell子进程（只管理自己的bash） 后台中“执行”的进程不能等待terminal/shell的输入。 job管理实际中使用的job控制主要有下面的命令：1234567891011121314151617181920212223242526272829// 1. 直接将命令丢到后台中“执行”的 &amp;tar -zpcf /tmp/tec/tar.gz /etc &amp;/*会出现[1]（工作好） 13456（进程号）完成后会输出： [1] 完成 tar -zpcf /tmp/etc.tar.gz /etc *//*但是需要注意的是，运行的信息还是会出现在屏幕上，会影响我们正常继续使用，所以我们需要利用数据流重定向输入到文件中。*/// 2. 将目前的工作丢到后台中“暂停”：ctrl + zvim ~/.bashrc 按ctrl+z/*会输出 [2]+ 已停止 vim ~/.bashrc */// 3. 查看目前的后台工作状态：jobs// 4. 将后台工作拿到前台来处理：fgfg %2 //拿出刚刚vim的工作// 5. 让工作在后台下得状态变成运行中：bgbg %2// 6. 管理后台当中的工作：killkill -signal %jobnumber/PID/命令/* signal-1：重新读取一次参数的配置文件-2：与ctrl + c一样-9：立刻强制删除一个工作，不会删除过程文件-15(默认值)：以正常的程序方式终止一项工作，会删除过程文件 */ 脱机管理如果你是使用&amp;来放置后台工作，当你断开与终端机的连接（脱机），那么后台工作就会被中断掉。如果我们不想这样就可以使用at或者nohup命令，我们主要讲一下nohup的这个命令，这个命令可以让你在脱机或注销系统后，还能够让工作继续进行。范例如下：12345// 1. 在终端机前台中工作nohup 命令// 1. 在终端机后台工作nohup 命令 &amp; 当你使用这个命令之后，你会发现会出现一个nohup.out文件，这个文件其实就是将原本前台显示的东西重定向到这个文件中。 进程管理进程的查看静态的psPS：如果man page不好查阅，最好是直接被几个常用的参数。 这个命令是将某个时间点的进程运行情况选取下来，主要的范例如下： 仅查看自己的bash的相关进程 123456789101112131415161718192021222324ps -l/* 输出列子如下：F S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD4 S 0 10573 10567 0 80 0 - 29064 wait pts/0 00:00:00 bash含义如下：F：程序标识（process flags），说明程序的权限，4代表root，1代表子程序仅能fork不能execS：程序状态（state），主要有R(running)、S(sleep)、D(不可唤醒)、T(stop)、Z（僵尸，命令位会跟&lt;defunct&gt;）UID/PID/PPID ：PPID指父程序的PIDC：代表CPU使用率，单位为百分比PRI/NI：此程序被CPU执行优先级，数值越小程序优先级越高ADDR/SZ/WCHAN：ADDR代表在内存哪个部分，SZ代表用掉多少内存，WCHAN表示程序是否正在运作TTY：登陆者的终端机位置，远程登录时为 pts/nTIME：使用掉的CPU时间，程序实际花费CPU运作时间CMD：触发程序的指令 */ 查看系统所有进程：ps aux 12345678910111213141516171819202122232425262728ps aux/* 输出列子如下：USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.1 43156 3136 ? Ss 3月10 1:27 /usr/lib/systemd/systemd --swi含义如下：USER：该进程属于哪个用户账号PID ：进程ID%CPU：该进程使用掉的CPU资源内存百分比%MEM：该进程所占用的物理内存百分比VSZ：该进程使用掉的虚拟内存量（KB）RSS：该进程占用的固定的内存量（KB）TTY：登陆者的终端机位置，远程登录时为 pts/nSTAT：与ps -l的S表示相同START：该进程被触发启动的时间TIME：程序实际花费CPU运作时间CMD：该进程的实际命令 */ 动态的top这个命令可以持续的检测进程运行的状态，主要范例如下：12345678910111213141516171819202122232425// 1. 每两秒更新一次top，查看整体信息，默认5秒top -d 2/* 输出例子：top - 10:54:10 up 22 days, 19:25, 1 user, load average: 0.13, 0.07, 0.06Tasks: 69 total, 2 running, 66 sleeping, 1 stopped, 0 zombie%Cpu(s): 0.5 us, 0.0 sy, 0.0 ni, 99.5 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 1883844 total, 77012 free, 356884 used, 1449948 buff/cacheKiB Swap: 0 total, 0 free, 0 used. 1328820 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1861 root 20 0 608356 12236 1788 S 0.5 0.6 60:48.59 barad_agent top见界面主要分为两个界面： 上面为整个系统的资源使用状态，基本上总共有六行，显示的内容依次是： 1. 目前的时间，开机到目前为止所经过的时间，已经登录系统的的用户数,系统在1，5，15分钟的平均工作负载 2. 目前进程的总量与各个累呗进程的总量，注意zombie僵尸进程的数量 3. CPU的整体负载，注意wa（I/Owait） 4. 物理内存的使用情况 5. 虚拟内存的使用情况，swap的是用来一定要小 6. 这个是当在top进程中输入命令时显示状态的地方，输入r可修改nice值 下面为每个进程使用资源情况，各个参数含义可参照ps。 */ 进程树pstree如果想找到进程之间的相关性，这个pstree就能够很好的帮助我们，它会使用线段将相关性进程连接起来，范例如下：1234567891011// 1.列出目前系统上面所有的进程数的相关性pstree -A输入如下：systemd-+-acpid |-2*[agetty] |-atd |-auditd---&#123;auditd&#125; ...// 2. 在1的基础上，同时显示出PID与userspstree -Aup 进程的执行顺序CPU优先处理哪个进程，这就需要考虑到程序的优先执行序(priority)与CPU的调度。具体到值来说就是要考虑到PRI和nice值（之前用top和ps显示过）。PRI值越低代表越优先，不过这个PRI值是由内核动态调整的，具有无法调整，但是Nice值我们可以改变。下面的PRI值改变的公式： PRI(new) = PRI(old) + nice 下面是关于nice值的使用范例：12345// 1. 在使用命令的时候设置nice值，给nice值为-5去执行vinice -n vi &amp;// 2. 已存在进程的nice重新分配，将PID为18625的进程nice值调整到10renice 10 18625 系统资源的查看 查看内存的使用情况，范例如下： 12// 1. 查看目前系统的内存容量free -m 查看系统与内核相关信息，范例如下： 12// 1. 输出系统的基本信息uname -a 查看系统启动时间与内存负载，范例如下： 1uptime 跟踪网络(很重要)，范例如下： 12345// 1. 列出目前系统以及新建的网络连接与unix socket状态netstat// 2. 找出目前系统上已在监听的网络连接机及其PID(很重要)netstat -tlnp 分析内核产生的信息，范例如下： 12345// 1. 输出所有的内核开机时的信息dmesg | more// 2. 查找开机的时候硬盘的相关信息dmesg | grep i hd 检测系统资源变化，范例如下： 1234567// 1. 统计目前主机CPU状态，每秒一次，共计三次vmstat 1 3// 2. 系统上面所有磁盘的读写状态vmstat -dPS：详细的各个字段的含义，大家就自己查询man vmstat好了，习惯就好。 参考 《鸟哥的Linux私房菜》]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_例行性工作(crontab)]]></title>
    <url>%2F2018%2F03%2F31%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux_%E4%BE%8B%E8%A1%8C%E6%80%A7%E5%B7%A5%E4%BD%9C(crontab)%2F</url>
    <content type="text"><![CDATA[引：系统常常会主动进行一些任务，这依靠的就是设置了例行性工作。 什么是例行性工作（定时任务crontab）根据单词crontab（定时任务）就可以知道 例行性工作 其实就是每天都会干的事。 Linux工作调度的种类 例行性的，就是每隔一定的周期要来办的事，利用crontab实现，这个命令所设置的工作将会循环一直进行下去，可循环的时间为分钟，小时，每周，每月或每年等，crontab除了可以使用命令执行外，也可编辑/etc/crontab来支持。至于让crontab可以生效的后台服务是crond这个服务。 突发性的，就是这次做完以后就没有的事，利用at实现，但是这个必须要有atd后台服务支持才行。 Linux上常见的例行性工作 进行日志文件的轮替，让旧的数据和新的数据分开存放 日志文件分析logwatch的任务 新建locate的数据库，系统会主动进行updatedb whatis数据库的建立 删除临时文件 仅执行一次的工作调度：atat的运行方式我们使用at这个命令来生成所要进行的工作，并将这个工作以文本文件的方式写入/var/spool/at目录中，该工作便能等待atd这个服务的取用与执行了。但是并不是所有的人都可以进行at工作调度工作的，因为安全。我们可以利用/etc/at.allow与/etc/at.deny这两个文件进行at的使用限制，加上这两个文件后，at的工作情况其实是这样的： 先寻找/etc/at.allow这个文件，写在这个文件中的用户才能使用at，没有在这个文件中的用户则不能使用at(即时没有写在at.deny当中) 如果/etc/at.allow不存在，就寻找/etc/at.deny这个文件，若卸载这个at.deny的用户则不能使用at，而没有在这个文件中的用户就可以使用at了 如果这两个文件都不存在，那么就只有root可以使用at这个命令 实际运行单一工作调度单一工作调度的进行就使用at这个命令，这个命令的运行十分简单！将at加上一个时间即可！范例入下：12345// 1. at [-mldv] TIMEat noe + 5 minutes // 再过五分钟执行，接下来输入执行的命令，使用ctrl + d 结束。// 2. at -c 工作号码 // 将第几号工作调出来查看at -c 1 // 将第一号工作调出来 事实上，当我们使用at时会进入一个at shell的环境来让用户执行工作命令，此时，建议你最好使用绝对路径来执行你的命令，比较不会有问题。 at还有一个很棒的优点就是后台执行的功能，和nohup类似。 at的工作管理 主要是利用下面的命令：12345# 查询目前主机上面有多少的at工作调度atq# 将第3个工作删除atrm 3 循环执行的例行性工作调度相对于at是仅执行一次的工作，循环执行的例行性工作调度室友crond这个系统服务来控制的，由于Linux系统上原本就有很多的例行性工作，所以这个系统服务是默认开启的。另外，由于用户自己也可以进行例行性工作调度，所以，Linux可提供用户控制例行性工作调度的命令（crontab）。 用户的设置与使用为了安全性的问题，与at类似，我们可以限制使用crontab的用户账号。使用的限制数据有： /etc/cron.allow：将可以使用crontab的账号写入其中，若不在这个文件内的用户则不可使用crontab。 /etc/cron.deny：将不可以使用crontab的账号写入其中，若为记录到这个文件中的用户，就可以使用crontab。 以优先级来说，/etc/cron.allow比/etc/cron.deny要优先，而判断上面，两个文件只选择一个来限制而已，因此，建议你只要保留一个即可。 当用户使用crontab这个命令来新建工作调度之后，该项工作就会被记录/var/spool/cron/里面，而且是以账号来区分的。另外，cron执行的每一项工作都会被记录到/var/log/cron这个日志文件中，所以，如果你的Linux不知道是否被植入密码，也可以查询一下这个日志文件。 下面是它的使用范例：12345678910111213// 1. 用root的身份在每天的12:00和14:00查看主文件夹目录ß# 编辑crontab的工作内容crontab -e# 进入vi界面，每项工作都是一行0 12,14 * * * ls / // 解释各列含义：// 1. 分；2. 小时；3. 日期；4. 月份; 5. 周； 6. 命令// 其中“,”表示分割时段，“-”表示一段时间范围，/n 表示每隔n单位间隔// 2. 查询crontab任务crontab -l// 3. 若要删除一项工作，必须要用crontab -e去编辑，如果想要删除全部工作，如下：crontab -r 系统的配置文件：/etc/crontabcrontab -e是针对用户的例行性工作来设计的，如果我们要修改系统的例行性任务，就需要编辑/etc/crontab了。 基本上，cron这个服务的最低检测限制是“分钟”，所以cron会每分钟去读取一次/etc/crontab与/var/spool/cron里面的数据内容。 可唤醒停机期间的工作任务如果例行性工作是在凌晨4点运行的，但是刚好关机了， 你7点开机了，你总不能不管它吧，这就需要用到anacron。 什么是anacronanacron存在的目的 是处理非24小时一直启动的linux系统的crontab的执行。 anacron也是通过crontab来运行的，因此anacron的运行的时间通常有两个，一是系统开机期间运行，一个是写入crontab的调度中。 anacron使用anacron的语法如下：1anacron [-sfn] [job] 参考 《鸟哥的Linux私房菜》]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_账号管理]]></title>
    <url>%2F2018%2F03%2F31%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux_%E8%B4%A6%E5%8F%B7%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[引：管理员的工作中，相对重要的一环就是“账号管理”。因为整个系统都是你在管理，并且所有的一般用户的账号申请必须要通过你的协助才行。所以我们必须要知道如果管理好一个服务器主机的账号！ 账号与用户组在管理Linux账号时，我们必须要先了解一下Linux到底是如何辨别每一个用户的。 用户表示符：UID与GID虽然我们登录Linux主机的时候，输入的是我们的账号，但是其实Linux主机并不会直接认识你的账号，它仅认识ID，而你的ID域账号的对应关系就在/etc/passwd当中。 每一个文件都具有所有者与所属用户组的属性，所以每个登录的用户至少会取得两个ID，一个是用户ID(UID)，一个是用户组ID(GID)。 用户账号Linyx系统上面的用户如果需要登录主机以取得shell的工作环境，它必须要在计算机前面利用tty1~tty7的终端机提供的login接口，并输入账号与密码后才能登录。当我们输入账号密码后，系统主要做了如下工作： 先寻找/etc/passwd里面是否有你输入的帐号？如果没有则跳出，如果有的话则将该帐号对应的UID与GID（在/etc/group中）读出来，另外，该帐号的主文件夹与shell设定也一并读出。 再来则是核对密码表啦！这是Linux会进入/etc/shadow里面找出对应的帐号与UID，然后核对一下你刚刚输入的密码与里面的密码是否相符。 如果一切都OK的话，就进入Shell控管的阶段咯！ /etc/passwd文件结构如下： 这个文件的构造是这样的：每一行代表一个帐号，有几行就代表有几个帐号在你的系统中！不过需要特别留意的是，里头很多帐号本身就是系统正常运作所必须要的，我们可以简称为系统帐号，如bin，daemon，adm，nobody等。 我们先来看一下每个Linux系统都会有的第一行，就是root这个系统管理员那一行好了，你可以明显的看出来，每一行使用：分隔，共有七个字段，分别是 字段号 字段含义 1 账号名称 2 密码，被该放到/etc/shadow文件中，以x代替 3 UID，0为系统管理员，可以多个账号的UID为0，但不建议。1~99为发现版自建系统账号，100~499为用户使用的系统账号，500~*为一般用户可登录账号 4 密码，GID，与/etc/group有关 5 用户信息说明 6 主文件夹 7 shell /etc/shadow文件结构如下： 文件构造基本与/etc/passwd一样，但是它有9个字段，分别是： 字段号 字段含义 1 账号名称，需要与/etc/passwd对应 2 密码，但是被加密过的 3 最近更改密码的日期，以1970年1月1号作为1而累加的日期 4 密码不可被更动的日期 5 密码需要重新更改的天数 6 密码需要更改期限前的警告天数 7 密码过期后的账号宽限时间（密码失效日） 8 账号失效日期 9 保留，用于以后扩展 有效与初始用户组：groups，newgrp /etc/group文件结构如下： 文件构造基本与/etc/passwd一样，但是它有4个字段，分别是： 字段号 字段含义 1 用户组名称 2 用户组密码，以x代替 3 GID，/etc/passwd第四个字段使用的GID对应的用户组名就是由这里来的 4 用户组支持的账号名称，多用户以”,”分割 我们知道用户可以同时加入多个用户组，那么我们在执行工作时，到底是以哪个用户组为准呢？，这就需要引入有效用户组的概念。 /etc/gshadow文件结构如下： 文件构造基本与/etc/group一样，它有4个字段，分别是： 字段号 字段含义 1 用户组名称 2 用户组密码,开头为!表示无合法密码，所以无用户组管理员 3 用户组管理员的账号，用户组管理员能够将账号添加到自己管理的用户组中 4 该用户组的所属账号（与/etc/group内容相同） 有效用户组与初始用户组 初始用户组：就是/etc/passwd里面的第四列的GID，当用户登录系统，立刻就拥有这个用户组的相关权限。 有效用户组：就是利用groups命令看到的第一个用户组，可以利用newgrp命令更改有效用户组，newgrp命令更改目前用户的有效用户组是以另一个shell来提供这个功能的，如果要回到原来的用户组只要输入exit即可。 账号管理管理账号主要是新增、删除与更改用户的相关信息。 新增与删除用户账号可以使用useradd命令来新建用户，密码的给予则是使用passwd命令。下面是范例：（里面有很多参数，自己可以去了解）12345678910111213141516171819202122# 新增useradd leonardll -d /home/leonard/# 默认会创建用户主文件夹，且权限为700，这是重点# drwx------ 2 leonard leonard 4096 3月 31 09:36 /home/leonard/grep leonard /etc/passwd /etc/shadow /etc/group# /etc/passwd:leonard:x:1001:1001::/home/leonard:/bin/bash# /etc/shadow:leonard:!!:17621:0:99999:7:::# /etc/group:leonard:x:1001:# 不加账号，默认修改自己的密码passwd leonard# 显示账号的相关信息chage leonard# 修改账号的相关信息usermod leonard# 删除账号，-r：连主文件夹一起删除userdel leonard 其实系统已经帮我们设置好了非常多的默认值，所以我们可以简单的使用“useradd 账号”来创建用户，Centos这些默认值主要会帮我们处理下面几个项目： 在/etc/passwd 里面创建一行与账号相关的数据，包括创建UID/GID/主文件夹等； 在/etc/shadow里面将此账号的密码相关参数填入，但是尚未有密码； 在/etc/group里面加入一个与账号名称一模一样的组名； 在/home下面创建一个与账号同名的目录作为用户的主文件夹，且权限为700 用户功能不论是useradd、usermod还是userdel，那都是系统管理员能够使用的命令，下面我们就介绍一些一般身份用户常用的账号数据更改与查询命令 finger，可以查阅很多用户相关的信息，大部分都是/etc/passwd这个文件的信息。范例如下： 12345// 我的linux默认没有装finger，可以利用下面的命令安装yum install finger// 查阅用户信息，若不跟没有用户，则查询当前用户finger rex chfn(change finger)，用于修改一些相关信息,范例如下： 123456chfn rexChanging finger information for rex.名称 []: rex办公 []: 123456办公电话 []: 123456住宅电话 []: 123456 chsh(change shell)，用于修改shell。 id，用于查询自己或某人的相关UID/GID等信息。 新增与删除用户组基本上，用户组的内容都与这两个文件有关：/etc/group,/etc/gshadow。下面是一些相关命令使用的范例：12345678910111213141516# 新建一个用户组，名称为hdgroupadd hd# 修改用户组的相关参数 -g：修改既有GID，-n：修改既有组名groupmod -g 201 -n myhd hd# 删除用户组名groupdel myhd# 用户组管理员相关命令# 给用户组设置一个密码gpasswd hd# 加入用户组管理员为rexgpasswd -A rex hd# 让rex登录系统，增加leonard为hd成员gpasswd -a leonard hd 主机的具体权限规划：ACL的使用什么是ACLACL是Access Control List的缩写，主要的目的是提供传统的owner、group、others的read、write、execute权限之外的具体权限设置。ACL可以针对单一用户、单一文件或目录进行r、w、x的权限设置，对于需要特殊权限的使用状况非常有帮助。 ACL主要可以针对下面几方面来设置控制权限： 用户：可以针对用户来设置权限 用户组：可以针对用户组来设置权限 默认属性（mask）：还可以在该目录下新建文件目录设置新数据的权限、 ACL的设置技巧 getfacl：取得某个文件/目录的ACL设置项目 setfacl：设置某个文件/目录的ACL规定 下面是范例：12345678910111213// 取得某个文件/目录的ACL设置项目getfacl rootfile// 输出# file: rootfile# owner: root# group: rootuser::rw-group::r--other::r--// 设置某个文件/目录的ACL规定setfacl -m u:rex:rwx rootfile 用户身份切换在Linux系统中是需要做身份的变换的，主要有以下几个原因： 使用一般账号：系统平日操作的好习惯（不然你就有机会从删库到跑路了） 用较低的权限启动系统服务 软件本身的限制 根据上面的考虑，我们都是使用一般账号登录系统的，等有需要进行系统维护或软件更新时才转为root身份来操作。从一般用户转变为root主要有下面两种方式： “su -”：需要root用户密码 “sudo命令”：sudo需要输入用户自己的密码 susu是最简单的身份切换命令了，它可以进行任何身份的切换。但是下面有几点比较重要： 若要完整切换到新用户的环境，必须要使用“su -username” 或 “su -|username”，才会连同PATH/USER/MAIL等变量都转成新用户的环境。如果只是使用“su”切换到root用户，PATH/USER/MAIL等变量都没有变，会导致很多命令执行不了。 如果仅想执行一次root命令，可以利用“su - -c “命令串””d的方式来处理。 使用root切换成为任何用户时，并不需要输入新用户的密码。 虽然使用su很方便，但是会导致root密码外流。所以很多情况下我们通过sudo来处理。 sudosudo的执行仅需要自己的密码即可！甚至可以设置不需要密码即可执行sudo，由于sudo可以让你以其他用户身份执行命令（通常是使用root的身份来执行命令），因此不是所有人都能够执行sudo，而是仅有/etc/sudoers内的用户才能够执行sudo这个命令。 sudo的命令用法 1234sudo [-u 新用户账号]// 范例，以sshd的身份在/tmp下面新建一个名为mysshd的文件sudo -u sshd touch /tmp/mysshd sudo的执行流程 当用户执行sudo时，系统在/etc/sudoers文件中查找该用户是否有执行sudo的权限； 若用户具有可执行sudo的权限后，便让用户输入用户自己的密码来确认； 若密码输入成功，便开始进行sudo后面接的命令（root执行sudo不需要输入密码） 若欲切换的身份与执行者的身份相同，也不需要输入密码 visudo与/etc/sudoers 我们一般不直接去修改/etc/sudoers文件，而是利用visudo命令去修改，因为这个命令会在结束离开的时候去检验/etc/sudoers的语法，下面是他的用法案例： 1234567891011121314151617181920// 1. 单一用户可以执行root的所有命令与sudoers文件语法// 四个参数含义为(1).用户账号，(2).登陆者的来源主机，(3).(可切换的身份)，(4).可执行的命令root ALL=(ALL) ALL //文件中原有rex ALL=(ALL) ALL //新增// 2. 利用用户组以及免密码的功能处理visudo# %wheel ALL=(ALL) NOPASSWD: ALL //文件中原有，需要将#去掉，文件中的%表示后面接一个用户组usermod -a -G wheel rex //将rex加入wheel组中// 3. 有限制的命令操作，通过更改可执行的命令一栏的数据，就可以控制具体操作的安全性rex ALL=(ALL) !/usr/bin/passed //不让rex可以修改密码// 4. 通过别名设置visudoUser_Alias ADMPW(大写) = rex1,rex2Cmnd_Alias ADMPWCOM(大写) = !/usr/bin/passwd, /usr/bin/passed [A-Za-z]ADMPW ALL=(root) ADMPWCOM// 5. sudo搭配su的使用方式,让用户用自己的密码变成rootUser_Alias ADMPW(大写) = rex1,rex2ADMPW ALL=(root) /bin/su - 参考 《鸟哥的Linux私房菜》]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_shell script 入门]]></title>
    <url>%2F2018%2F03%2F30%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux_shell%20script%20%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[引：要想管理好自己的主机，自动化管理系统的好工具——shell script，这个家伙是真的需要好好学习学习的！ 什么是shell scriptshell script 是利用shell的功能所写的一个“程序”，这个程序是使用纯文本文件，将一些shell的语法与命令（含外部命令）写在里面，搭配正则表达式，管道命令与数据重定向等功能，以达到我们所想要的处理目的。 为什么要学习shell script 自动化管理的重要依据 追踪与管理系统的重要工作 简单入侵检测功能 连续命令单一化 简易的数据处理 跨平台与学习历程较短 shell script编写的注意事项 命令的执行是从上而下，从左往右地分析与执行； 命令、参数间的多个空白都会被忽视掉； 空白行也将被忽略掉，并且tab按键所得的空白同样视为空格键； 如果读到一个enter符号（CR），就尝试开始结束该行（或该串）命令 至于如果一行的内容太多，则可以使用“\enter”来扩展至下一行； “#”可作为批注，任何加在#后面的数据将全部被视为批注文件而被忽略。 shell script的执行假设你的程序文件名是/home/rex/shell.sh 直接执行命令：shell.sh文件必须具备可读可执行(rx)的权限，然后： 绝对路径：使用/home/rex/shell.sh 相对路径：假设工作目录在/home/rex/,则使用./shell.sh来执行 变量“PATH”功能：将shell.sh放在PATH指定的目录内，例如：~/bin/。 以bash进程来执行：通过“bash shell.sh”或“sh shell.sh”来执行 利用source来执行：这样这个脚本将在父进程中执行，各项操作都会在原本的bash内生效。如果直接执行，script是在子进程中的bash内执行的，当子进程完成后，子进程的各项变量或操作将会结束而不会传回到父进程中。 良好的 script 撰写习惯在每个 script 的档头处记录好： script 的功能； script 的版本资讯； script 的作者与联络方式； script 的版权宣告方式； script 的 History (历史纪录)；6。script 内较特殊的命令，使用绝对路径的方式来下达； script 运行时需要的环境变量预先宣告与配置。 Hello Word程序123456789#!/bin/bash // 声明这个script使用的shell名称# Program:# This program shows &quot;Hello World!&quot; in your screen.# History:# 2015/11/03 Jiange First releasePATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/binexport PATHecho -e &quot;Hello World! \a \n&quot;exit 0 善用判断式利用test命令的测试功能如下面的例子，用于检测文件夹是否存在：1test -e /dmtsai &amp;&amp; echo &quot;exist&quot; || echo &quot;Not exist&quot; 利用判断符号[]如果我想要知道 $HOME 这个变量是否为空的，可以这样做：1[ -z &quot;$HOME&quot; ] ; echo $? 对于判断符号我们一定要注意： 在中括号 [] 内的每个组件都需要有空白键来分隔； 在中括号内的变量，最好都以双引号括号起来； 在中括号内的常数，最好都以单或双引号括号起来。 shell script 的默认变量($0, $1…)运行的脚本档名为 $0 变量，第一个接的参数就是 $1，依次类推。其他特殊变量： $# ：代表后接的参数个数； $@ ：代表”$1” “$2” “$3” “$4” …之意，每个变量是独立的(用双引号括起来)； $* ：代表『”$1c$2c$3c$4…” ，其中 c 为分隔字节，默认为空白键。 条件判断式利用 if …. then如下面的代码：1234567if [ &quot;$1&quot; == &quot;hello&quot; ]; then echo &quot;Hello, how are you ?&quot;elif [ &quot;$1&quot; == &quot;&quot; ]; then echo &quot;You MUST input parameters, ex&gt; &#123;$0 someword&#125;&quot;else echo &quot;The only parameter is &apos;hello&apos;, ex&gt; &#123;$0 hello&#125;&quot;fi 利用 case ….. esac 判断如下面的代码：1234567891011121314case $1 in &quot;one&quot;) echo &quot;Your choice is ONE&quot; ;;&quot;two&quot;) echo &quot;Your choice is TWO&quot; ;;&quot;three&quot;) echo &quot;Your choice is THREE&quot; ;;*) echo &quot;Usage $0 &#123;one|two|three&#125;&quot; ;;esac 利用 function 功能如下面的代码：12345678910111213141516171819function printit()&#123; echo &quot;Your choice is $1&quot; # 这个 $1 必须要参考底下命令的下达&#125;echo &quot;This program will print your selection !&quot;case $1 in &quot;one&quot;) printit 1 # 请注意， printit 命令后面还有接参数！ ;;&quot;two&quot;) printit 2 ;;&quot;three&quot;) printit 3 ;; *) echo &quot;Usage $0 &#123;one|two|three&#125;&quot; ;;esac 循环（loop）while do done, until do done (不定次数循环)如下面的代码：123456789while [ condition ] &lt;==中括号内的状态就是判断式do &lt;==do 是循环的开始！ 程序段落done &lt;==done 是循环的结束until [ condition ]do 程序段落done for…do…done (固定次数循环)如下面的代码：1234for var in con1 con2 con3 ...do 程序段done for…do…done 的数值处理如下面的代码：12345678read -p &quot;Please input a number, I will count for 1+2+...+your_input: &quot; nus=0for (( i=1; i&lt;=$nu; i=i+1 ))do s=$(($s+$i))doneecho &quot;The result of &apos;1+2+3+...+$nu&apos; is ==&gt; $s&quot; shell script 的追踪与调试可以使用下面的命令：123456sh [-nvx] scripts.sh选项与参数：-n ：不要运行 script，仅查询语法的问题；-v ：在运行 sccript 前，先将 scripts 的内容输出到屏幕上；-x ：将使用到的 script 内容显示到萤幕上，这是很有用的参数！ 参考 《鸟哥的Linux私房菜》]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_深入bash数据操作]]></title>
    <url>%2F2018%2F03%2F30%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux_%E6%B7%B1%E5%85%A5bash%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[引：在这里有一切你想要的bash数据操作知识，比如数据流重定向，管道命令，正则表达式的使用，大家可以快快进来！ 数据流的重定向什么是数据流重定向一般来说，如果你要执行一个命令，通常它会是这样的： 文件 -&gt; 标准输入 -&gt;命令 如果执行正确，命令 -&gt; 标准输出 -&gt; 文件/设备；如果执行错误，命令 -&gt; 标准错误输出 -&gt; 文件或设备 标准输出，标准错误输出，标准输入 标准输出：指的是命令执行所回传的正确信息，代码为1，使用&gt; 或 &gt;&gt;; 标准错误输出：指的是命令执行错误失败后，所回传的错误信息，代码为12，使用2&gt; 或 2&gt;&gt;; 标准输入：将原本需要键盘输入的数据改由文件内容来替代，代码为0，使用&lt; 或 &lt;&lt;; 如下面的命令：1ll / &gt; ~/rootfile // 显示文件名信息到rootfile文件中 关于重定向输出文件的创建方式如下： 该文件如果不存在，系统会自动将它创建起来 当这个文件存在，那么系统就会将这个文件内容清空，然后再将数据写入 若以&gt;输入到一个以存在的文件中，那个文件就会被覆盖，如果不想被覆盖，可以使用 &gt;&gt; /dev/null 垃圾桶黑洞设备与特殊写法 /dev/null 垃圾桶黑洞设备，如果我们知道错误信息会发生，所以要讲错误信息忽略掉而不显示或存储，我们就需要使用/dev/null这个黑洞设备了。写法如下： 1ll / 2&gt; /dev/null 如果我们要将正确地与错误数据都写入同一个文件中去，这个时候就需要使用特殊写法了，如下： 12ll / &gt; ~/rootfile 2&gt;&amp;1 ll / &amp;&gt; ~/rootfile 为什么要使用命令输出重定向 屏幕输出的信息很重要，而且我们需要将它存下来的时候 后台执行中的程序，不希望它干扰屏幕正常的输出结果时 一些系统的例行命令的执行结果，希望它可以存下来时 一些执行命令的可能已知信息时，想以“2&gt;/dev/null”将它丢掉时 错误信息与正确信息需要分别输出时 命令执行的判断依据：；， &amp;&amp;，||在某些情况下，很多命令我们需要一次输入去执行，而不像分开执行，基本有两个选择，一个是通过shell script编写脚本去执行，一种是听过下面的介绍来一直输入多重命令。 cmd ; cmd (不考虑命令相关性的连续命令执行，第一个命令执行结束后便会执行第二个命令) cmd &amp;&amp; cmd (若第一个命令执行成功才会执行第二个命令；若第一个命令执行失败，则不会执行第二个命令。) cmd || cmd (若第一个命令执行成功，则不执行第二个命令；若第一个命令执行失败，才会执行第二个命令。) 管道命令(pipe)什么是管道命令管道命令 能够将一个命令的执行结果经过筛选，只保留我们需要的信息。 它的符号是 “ | ”。 管道命令有下面两个比较需要注意的地方： 管道命令仅会处理标准输出，对于标准错误输出会予以忽略 管道命令必须要能够接收来自前一个命令的数据成为标准输人继续处理才行。 管道命令选取指定列：cutcut为剪切的意思，它能将一行行的数据按照指定的分隔符切成一列列，然后只显示特定列的数据。 cut有两种使用方式： 按照指定字符分隔，这个命令会按照特定的分隔符将数据切分，并只显示第n列的数据。如下： 1cut -d &apos;分隔符&apos; -f n(第几列) 选择特定范围内的数据，如下： 1cut -c 起始字符的下标-结束字符的下标 关键词搜索指定行：grepgrep用于进行关键词查找，它会将文件中含有关键词的那一整行输出来。grep的两种使用方式如下： 从指定文件中将符合关键词的行搜索出来，如下： 1grep [-参数] ‘关键词’ 文件 采用管道，将前一个命令的执行结果输出给grep，并通过grep的关键词搜索将符合条件的行搜索出来，如下： 1命令 | grep [-参数] ‘关键词’ 排序：sortsort命令能够将指定文件 或 前一个命令的结果数据 按照指定字段进行排序。sort两种使用方式与grep基本一样，一种是将文件中的数据按照指定字段排序。另一种是使用管道，将前一个命令执行的结果按照指定字段进行排序。。 去除重复行：uniq该命令只能用于管道，如统计当前系统所有用户的登录次数：如下：1last | cut -d &apos; &apos; -f 1 | uniq -c 统计字数、行数、字符数：wcwc只能通过管道使用，如下：1命令 | wc [-参数] 双向重定向：teetee只能和管道结合使用，如将last中的信息输出指文件并显示在屏幕上,指令如下：1last | tee -a lastfile | cut -d &apos; &apos; f 1 切割文件：split该命令能将一个大文件切分成若干个小文件。用法如下：1split [-bl] 大文件 小文件名字前缀 正则表达式什么是正则表达式正则表达式 就是处理字符串的方法，它是行为单位来进行字符串的处理行为正则表达式通过一些特殊符号的辅助，可以让用户轻易达到查找、删除、替换某特定字符串的处理程序。 正则表达式基本上就是一种“表示法”，只要工具支持这种表示法，那么工具程序就可以用来作为正则表达式的字符串处理之用。比如vi、grep、awk、sed等工具。 正则表达式的字符串表达方式依照不同的严谨度可以分为基本正则表达式与扩展正则表达式。 基础正则表达式基础正则表达式字符 RE字符 意义 ^word 待查找的字符串(word)在行首 word$ 待查找的字符串(word)在行尾 . 代表一定有一个任意字符的字符 \/ 转义字符,将特殊符号的特殊意义去除 * 重复0个或多个的前一个字符 [list] 从字符集合的RE字符里面找出想要选取的字符 [n1-n2] 从字符集合的RE字符里面找出想要选取的字符范围 [^list] 从字符集合的RE字符里面找出不要的字符串或范围 /{n,m/} 连续n到m个的前一个RE字符,/{n/}表示连续n个,/{n,/}表示连续n个及以上 PS：正则表达式的特殊字符与一般在命令行输入的“通配符”并不相同，通配符的*代表的是零到无限多个字符的意思，但是在正则表达式中*是表示重复0到无穷多个前一个RE字符的意思。 基础正则表达式练习(以grep工具为例) 查找特定字符串 123grep -n ‘the’ regular_express.txtgrep -vn &apos;the&apos; regular_express.txt (-v反向选择) 利用中括号[]来查找集合字符 12345grep -n &apos;t[ae]st&apos; regular_express.txt (可匹配test或tast)grep -n &apos;[^g]oo&apos; regular_express.txt (oo前不能有g的字符)grep -n &apos;[^[:lower:]]oo&apos; regular_express.txt ([:lower:]代表a-z的意思) 行首和行尾字符 123grep -n &apos;^test&apos; regular_express.txt (注:^在[]内表示“反向选择”,在[]外表示定位在行首)grep -n &apos;/.$&apos; regular_express.txt (找出行尾结束为小数点的那一行) 任意一个字符.与重复字符* 12345grep -n ‘g..d’ regular_express.txt (可匹配good,glad等字符)grep -n &apos;ooo*&apos; regular_express.txt (匹配至少两个o以上的字符)grep -n &apos;g.*g&apos; regular_express.txt (找出g开头与g结尾的字符串,.*表示o个或多个任意字符的意思) 限定连续RE(Regular Expression)字符范围{} 12345grep -n &apos;o/&#123;2/&#125;&apos; regular_express.txt (找出两个o的字符串)grep -n ‘go/&#123;2,5/&#125;g’ regular_express.txt (g后有两个到5个o,然后接一个g的字符串)grep -n ‘go/&#123;2,/&#125;g’ regular_express.txt (g后有两个及以上的o,然后接一个g的字符串) sed工具sed本身是一个管道命令，它可以将数据进行替换、删除、新增、选取特定行等功能。使用方式如下：1sed [-nefr] [动作] 扩展正则表达式一般情况下只需要基础正则表达式即可，但是有时候还需要一些扩展功能，比如整合两条管道命令，这就需要用到扩展正则表达式，如果是grep，它基本使用命令是egrep，基本的符号如下： 字符 意义与范例 + 重复一个或多个的前一个RE字符，如：egrep -n ‘go+d’ regular_express.txt ? 0个或一个的前一个RE字符，如：egrep -n ‘go?d’ regular_express.txt \ 用或的方式找出字符串，如：egrep -n ‘gd\ good’ regular_express.txt () 找出“组”的字符串 (如:egrep -n ‘g(la \ oo)d’ regular_express.txt 表示找出glad或good字符串) ()+ 多个重复组的判别 (如echo ‘AxyzxyzxyzxyzC’ \ egrep ‘A(xyz)+C’ 找出开头是A结尾是C,中间有一个以上的“xyz”字符串) 文件的格式化处理文件格式化：printf如果我们需要将自己的数据给它格式化输出，我们就需要一个好的样式，输出的方式其实和C语言的格式化输出差不多，如下：1printf &apos;打印格式&apos; 实际内容 好用的数据处理工具：awkawk相当适合处理小型的数据，它的基本用法如下：1234awk ‘条件类型1&#123;动作1&#125; 条件类型2&#123;动作2&#125; ...’ filename// 例子last -n 5 | awk &apos;&#123;print $1 &quot;\t&quot; $3&#125;&apos; // 取出登录者账号和ip 这个awk的处理流程如下： 读入第一行，并将第一行的填入$0,$1等变量中 依据条件类型的限制，判断是否需要进行后面的动作 做完所有的动作与条件类型 若还有后续行，就重复上面1~3的步骤，直到所有数据都读完为止。 文件比较工具：diffdiff用于比较两个文件之间的区别,并且是以行为单位的,diff也可以比较两个目录。用法如下：1diff [-bBi] from-file to-file patch这个命令与diff有密不可分的联系，将旧的文件升级成为新的文件的方法是先比较新旧版本的区别，将将区别文件制作成为补丁文件，再有补丁问价更新旧文件即可。例子如下：1234567891011// 范例:以/tmp/test内的passwd.old 与passwd.new 制作补丁文件,并更新旧版数据diff -Naur passwd.old passwd.new &gt;passwd.patch// 更新旧文件,变成和新文件一样patch -p0 &lt; passwd.patch// 恢复旧文件的内容patch -R -p0 &lt; passwd.patch 参考 《鸟哥的Linux私房菜》]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_初探shell步入bash]]></title>
    <url>%2F2018%2F03%2F28%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux_%E5%88%9D%E6%8E%A2shell%E6%AD%A5%E5%85%A5bash%2F</url>
    <content type="text"><![CDATA[引：在Linux的环境下，如果你不懂bash是什么，那么其他的东西就不用学了！ 认识bash这个shell管理整个计算机硬件的其实是操作系统的内核，这个内核是需要保护的，所以我们一般用户就只能通过shell来跟内核通信，以让内核达到我们所想要达到的工作，那么系统。 硬件、内核与shell下面是硬件、内核与shell的关系： 我们必须要通过“shell”将我们输入的命令与内核通信，好让内核可以控制硬件来正确无误地工作。 其实shell的功能只是提供用户操作系统的一个接口，因此这个shell需要可以调用其他软件才好。只要能够操作应用程序的接口都能够称为shell。 狭义的shell指的是命令行方面的软件，包括bash等。广义的shell包括图形界面的软件，因为图形界面也能够操作各种应用程序来调用内核工作。 为什么要学命令行界面的shell 命令行界面的shell：大家（几乎所有发行版）都一样 远程管理：命令行界面就是比较快，而且较不容易出现断线或者信息外流的问题。 Linux的任督二脉：shell是也。因为要想将自己的主机管理好，良好的shell程序编写是必须的。 系统合法与/etc/shells功能目前我们的Linux有下面几个可以用的shell，我们可以通过查看/etc/shells这个文件，可以看到如下：12345678/bin/sh (已经被/bin/bash所替代)/bin/bash (Linux默认的shell)/sbin/nologin/usr/bin/sh/usr/bin/bash/usr/sbin/nologin/bin/tcsh (整合C shell，提供了更多的功能)/bin/csh (已经被/bin/tcsh所替代) Linux默认的就是bash。系统上合法的shell都要写入/etc/shells这个文件中，因为系统某些服务在运行过程中，会去检查用户能够使用的shells，而这些shell的查询就是借助/etc/shells这个文件。 用户默认取得的shell可以通过查看/etc/passwd文件，如下：123root:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologin bash shell的功能bash的优点如下： 命令记忆能力，~/.bash_history里面会记录前一次登录所执行过的命令，而这一次登录都被暂存在临时内存中，成功注销后，本次执行的命令会记录到文件中。最大的好处就是可以查询曾经做过的操作，利于排错。 命令与文件补全功能（Tab键的好处） 命令别名设置功能（alias）执行如下得命令： alias 简化命令=’实际命令’ （设置别名）; unalias 简化命令（解除别名） 作业控制、前台、后台控制 程序脚本 通配符（*） shell的变量功能变量是bash环境中非常重要的一个玩意儿。 什么是变量变量： 就是以一组文字或符号等，来替代一些设置或者一串保留的数据。 变量的方便性在于： 变量的可变性与方便性 简化bash环境操作 脚本程序设计的好帮手 变量的分类在Linux中，变量分为环境变量(全局变量) 和 局部变量。环境变量能被子进程继承，而局部变量只能在当前进程中使用。 不论是环境变量还是局部变量。他们又都可以分为系统变量 和 自定义变量。系统变量是系统启动时自动创建的变量，往往为系统运行提供支持；而自定义变量是用户自己定义的。一般而言，系统变量全为大写，自定义变量全为小写。 变量的显示与设置：echo，unset 变量的显示：echo 读变量，只需要在变量名称前面加上$，或者是以${变量}的方式来显示就可以。 变量的修改：“=” 只需要用等号连接变量与它的内容就好了。它具有如下设置规则： 等号两边不能直接接空格符 变量名称只能是英文字母与数字，但是开头字符不能是数字 变量内容若有空格可使用双引号或单引号将变量的内容结合起来 可以用转义字符”\”将特殊符号（如enter、$、\、空格符、！等）变成一般字符。 在一串命令中，还需要其他的命令提供的信息，可以使用反单引号“`命令`”或“$(命令)” 若该变量为了增加变量内容时，则可用“$变量名称”或${变量}累加内容，后用冒号连接。 若该变量需要在其他自进程执行，则需要以export来使变量变成环境变量。 通常大写字符为系统默认变量，自行设置变量可以使用小写字符，方便判断。 取消变量的方法为使用“unset 变量名称” 什么是子进程： 在一个bash中开启一个新的bash，那么原本的bash称为父进程，新的bash称为子进程。 子进程会继承父进程的所有环境变量，而父进程的局部变量只能在父进程中使用。 环境变量的功能环境变量可以帮我们达到很多功能，包括主文件夹的变换、提示符的显示、执行文件查找的路径等。在shell环境下，可以通过env与export查看环境变量。下面主要介绍一下主要的环境变量： HOME：用户主目录，当我们使用cd 或cd ~时就会调用这个环境变量找到用户主目录 SHELL：当前使用的SHELL，默认使用/bin/bash HISTSIZE：历史命令的最大条数 PATH：可执行文件的查找路径。这是一个非常重要的环境变量，当我们直接写一个命令时，系统就会在PATH路径中寻找这个命令，这样我们在执行命令的时候就不用输命令完整的路径了。多个路径之间用:分隔 LANG：当前系统的语言 RANDOM：随机数生成器的路径。该路径默认指向/dev/random这个文件，这个文件是一个随机数生成器，当我们使用$RANDOM时就能获得一个0-32767之间的随机整数 当然我们还可以通过set来查看所有变量（含环境变量和自定义变量）：这里也解释几个比较重要的变量： PS1：命令提示符，在命令输入光标前有一串用中括号括起来的信息，这就是命令提示符。命令提示符究竟需要显示哪些信息，这就是由PS1这个局部变量决定的。由于它是局部变量，因此子进程中无法继承这个变量，子进程拥有自己的PS1。 $：当前shell的PID，可以通过如下命令查看当前shell的PID： echo $$ ?：上个命令的执行结果,上个命令若执行成功，则echo $?就会返回0；若上个命令执行失败，则该值为一个非0整数。 变量内容的删除与替换 操作方式 说明 ${变量名#关键词} 从变量值的头部开始，依次向后删除到关键词第一次出现的位置为止 ${变量名##关键词} 从变量值的头部开始，依次向后删除到关键词最后一次出现的位置为止 ${变量名%关键词} 从变量值的尾部开始，依次向前删除到关键词第一次出现的位置为止 ${变量名%%关键词} 从变量值的尾部开始，依次向前删除到关键词最后一次出现的位置为止 ${变量名/旧字符串/新字符串} 从变量值的头部开始，依次向后找到第一个旧字符串，并将其替换 ${变量名//旧字符串/新字符串} 将变量值中所有的旧字符串替换成新字符串 Bash Shell的操作环境路径与命令的查找顺序基本上，命令运行的顺序可以这样看： 以相对/绝对路径执行命令，例如：“/bin/ls”或“./ls” 由alias找到该命令来执行 有bash内置的(builtin)命令来执行 通过$PATH这个变量的顺序找到的第一个命令来执行 bash的登录与欢迎环境：/etc/issue,/etc/motd /etc/issue：放置终端机接口登录成功的界面提示的字符。 /etc/issue.net：放置telnet远程登录成功的界面提示的字符。 /etc/motd：如果你想让用户登录后取得一些信息，可以将信息加入其中。比如告知登录者系统将在什么时候维护。 bash的环境配置文件由于系统有一些环境配置文件的存在，让bash在启动时直接读取这些配置文件，所有已进入bash就能够取得一堆有用的变量。而这些配置文件又可以分为全体系统的配置文件以及用户个人偏好配置文件。要注意的是，之前我们说的命令别名、自定义的变量在你注销bash后就会失效。所以你想要保留你的设置，就得要讲这些设置写入配置文件才行。，下面就看看这些东西： login shell与non-login shell login shell和non-login shell是两种shell登录的方式，它们登录后加载的环境配置文件有所不同。 login shell在获取bash前需要进行一套完整的登录过程，这个登录过程就称为login shell。所谓“完整的登录过程”指需要输入用户名和密码。login shell其实只会读取这两个配置文件：/etc/profile和(~/.bash_profile或 ~/.bash\_login或~/.profile) non-login shell获取bash不需要输入密码的登录过程称为non-login shell。如在bash中直接输入bash，从而打开一个子bash，这个过程不需要输入密码，因此称为non-login shell。比如在图形界面中。 /etc/profile：系统级的环境变量(login shell才会读) 。该文件存放系统级环境变量，所有的用户都会拥有，一般不建议修改这个文件。 ~/.bash_profile：用户个人的环境变量(login shell才会读)当/etc/profile中的环境变量加载完毕后就会加载本文件，本文件中定义了当前用户的环境变量。 ~/.bashrc：non-login shell会读取的环境配置文件当用户以non-login方式登录后，只会加载这个文件，该文件会对一些操作加上安全询问。这个文件不管哪种登录方式都会被加载，因此这里可以存放别名。 /etc/man.conf：设置man的存放路径如果使用源码安装软件的话(非rpm、yum)，一般软件会安装在自定义的目录中(一般为/usr/local/软件名)。那么软件中的man文件就无法被系统找到，从而无法通过“man+命令”找到这个软件的命令帮助文档。我们需要手动将该软件的man目录添加到/etc/man.conf中去，从而执行“man+命令”就能找到这个目录的帮助文档。 ~/.bash_history：存储用户历史命令 ~/.bash_logout：记录注销后系统执行的操作 通配符和特殊字符通配符在bash的操作环境中还有一个非常有用的功能，那就是通配符。下面是一些常用的通配符： 符号 意义 * 代表任意多个字符 ? 代表一个字符 [] [abcd]：代表该范围内的一个字符 [-] [a-z]：代表a-z之间的一个字符 [^] [^a-z]：代表除了a-z以外的所有字符 特殊字符下面是bash环境中的特殊符号： 符号 内容 # 注释 \ 转移字符，将特殊字符转为普通字符 ; 分隔多个目录，使得依次执行 ~ 用户主目录 $ 变量的起始符 &amp; 将目录置于后台执行 ! 非 / 目录分隔符 &gt;,&gt;&gt; 数据流重定向，输出导向 &lt;,&lt;&lt; 数据流重定向，输入导向 ‘’ 不含变量置换功能 “” 含有变量置换功能 `` 中间为待执行的命令，和$()一致 () 中间为子shell的起始和结束 {} 中间为命令块 参考 《鸟哥的Linux私房菜》]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_学会使用vim程序编辑器]]></title>
    <url>%2F2018%2F03%2F26%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux_%E5%AD%A6%E4%BC%9A%E4%BD%BF%E7%94%A8vim%E7%A8%8B%E5%BA%8F%E7%BC%96%E8%BE%91%E5%99%A8%2F</url>
    <content type="text"><![CDATA[引：系统管理员的重要工作就是修改与设置某些重要软件的配置文件，因此至少得到学会一种以上的命令行界面的文本编辑器。在所有的Linux发行版中都具有vi这款编辑器，我们这次学的它的高级版vim。 vi与vim虽然在Linux在命令行界面下的文本编辑器有很多，比如Emacs，pico，nano，joe与vim等。但是我们却一定要学会vi或者说vim，vim相当于vi的高级版。 为什么要学vim 所有的UNIX Like系统都会内置vi文本编辑器，其他文本编辑器不一定存在。 所有软件的编辑结构都会主动调用vi（例如crontab，visudo,edquota等）很重要 vim具有程序编辑能力，可以主动以字体颜色辨别语法的正确性，方便程序设计。 程序简单，编辑速度相当快速。 vi的使用vi分为3种模式，分别是一般模式、编辑模式与命令行模式。它们的作用如下： 一般模式：以vi打开一个文件就直接进入一般模式了。在这个模式中，你可以使用左右按键来移动光标，你可以删除字符或删除整行，也可以复制，粘贴你的文件数据。 编辑模式：在一般模式中是无法编辑文件内容的。要等到你按下“i,l,o,O,a,A,r,R”等任何一个字母之后才会进入编辑模式。通常在Linux中，按下这些按键时，在界面的左下方会出现INSERT或REPLACE的字样，此时才可以编辑，如果要回到一般模式，必须要按下ESC才可以退出编辑模式。 命令行模式：在一般模式中，输入“:、/、?”3个中的任何一个按钮，就可以将光标移动到最下面的那一行。在这个模式当中，可以提供你查找数据的操作，而读取、保存、大量替换字符、离开vi、显示行号等操作就是在此模式中完成的。 vi按键说明这个按键说明大部分人都会有总结，所以这里也就不再做无用功了，所以贴出下面的链接，遇到问题去查就好了，但是需要保证所有按键都亲自去试一遍！ Linux - vim按键说明 但是这里我还是想把常用的命令在这里再贴出来，希望能够记住： 一般模式可用的按钮说明，光标移动、复制粘贴、查找替换等 按键 按键说明 Ctrl + f 屏幕『向下』移动一页，相当于 [Page Down]按键 Ctrl + b 屏幕『向上』移动一页，相当于 [Page Up] 按键 0 或功能键Home 这是数字『 0 』：移动到这一行的最前面字符处 (常用) $ 或功能键End 移动到这一行的最后面字符处(常用) G 移动到这个档案的最后一行(常用) gg 移动到这个档案的第一行，相当于 1G 啊！ (常用) nEnter n为数字。光标向下移动 n 行(常用) /word 向光标之下寻找一个名称为 word 的字符串。例如要在档案内搜寻 server这个字符串，就输入 /vbird 即可！ (常用) :n1,n2s/word1/word2/g n1 与 n2 为数字。在第 n1 与 n2 行之间寻找 word1 这个字符串，并将该字符串取代为 word2 :1,$s/word1/word2/g 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 :1,$s/word1/word2/gc 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 ！且在取代前显示提示字符给用户确认 (confirm) 是否需要取代 x, X 在一行字当中，x 为向后删除一个字符 (相当于 [del] 按键)， X 为向前删除一个字符(相当于 [backspace] 亦即是退格键) dd 删除游标所在的那一整列 ndd n 为数字。删除光标所在的向下 n 列，例如 20dd 则是删除 20 列 yy 复制游标所在的那一行 nyy n 为数字。复制光标所在的向下 n 列，例如 20yy 则是复制 20 列 p, P p 为将已复制的数据在光标下一行贴上，P 则为贴在游标上一行！ 举例来说，我目前光标在第 20 行，且已经复制了 10 行数据。则按下 p 后， 那 10 行数据会贴在原本的 20 行之后，亦即由 21 行开始贴。但如果是按下 P 呢？ 那么原本的第 20 行会被推到变成 30 行。 u 复原前一个动作 Ctrl+r 重做上一个动作 . 不要怀疑！这就是小数点！意思是重复前一个动作的意思。 如果你想要重复删除、重复贴上等等动作，按下小数点“.”就好了！ 一般模式切换到编辑模式的可用的按钮说明 按键 按键说明 i, I 进入插入模式(Insert mode)：i 为从目前光标所在处插入， I 为在目前所在行的第一个非空格符处开始插入。 a, A 进入插入模式(Insert mode)：a为从目前光标所在的下一个字符处开始插入， A 为从光标所在行的最后一个字符处开始插入。 o, O 进入插入模式(Insert mode)：这是英文字母 o 的大小写。o 为在目前光标所在的下一行处插入新的一』； O 为在目前光标所在处的上一行插入新的一行！ r, R 进入取代模式(Replace mode)：r 只会取代光标所在的那一个字符一次；R会一直取代光标所在的文字，直到按下 ESC 为止。 Esc 退出编辑模式，回到一般模式中 一般模式切换到指令列模式的可用的按钮说明 按键 按键说明 :w 将编辑的数据写入硬盘档案中 :q 离开 vi :wq 储存后离开，若为 :wq! 则为强制储存后离开 vim的功能目前大部分的发行版都以vim替代vi的功能了，如果你使用vi后，却看到界面的右下角有显示目前光标的行列号码，那么你的vi已经被vim替代了，vim相比于vi有许多新的功能。 块操作vi的操作基本上都是以行为单位的操作，但是vim具有块操作的功能，具体的按键说明如下： 按键 按键说明 v 字符选择，将光标经过的地方反白选择 V 行选择，将光标经过的行反白选择 Ctrl + v 块选择，可以用长方形选择数据 y 将反白的地方复制 d 删除反白的地方 多文件编辑有事我们需要在一个vim内编辑多个文件，这个时候我们就需要多文件编辑功能，具体按键如下： 按键 按键说明 :n 编辑下一个文件 :N 编辑上一个文件 :files 列出目前这个vim打开的所有文件 多窗口功能很多时候我们需要对比文件，但是情况是在同一个vim窗口，这时候也就需要用到多窗口功能，具体按键如下： 按键 按键说明 ：sp filename 打开新窗口，如果有加filename,新窗口打开新文件，否则打开相同文件 Ctrl + w + j/↓ 按键的按法是：先按下Ctrl不放，再按下w后放开所有的按键，然后再按下j或箭头，则光标可移动到下方的窗口 Ctrl + w + k/↑ 同上，但是光标移动到上面的窗口 vim常用命令示意图 参考 《鸟哥的Linux私房菜》 Linux - vim按键说明]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_Linux磁盘与文件系统管理]]></title>
    <url>%2F2018%2F03%2F25%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux_Linux%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[引：系统管理员最重要的任务之一就是管理好自己的磁盘文件系统，所以本文的知识对于那些需要规划自己磁盘文件系统的人群特别重要，有些内容可能不太详细，所以日后自己亲身实践过后，希望能再开一篇详细的文章。 认识文件系统Linux最传统的磁盘文件系统使用的是EXT2（索引式文件系统）。所以要了解文件系统就得要又认识EXT2开始。 在Linux中，需要记录文件权限与文件属性，所以文件系统通常会将这两部分的数据分别存放在不同的块，权限和属性放置到inode中，至于实际数据则放置到data block块中，另外还有一个超级块（superblock）会记录整体文件系统的整体信息。每个inode，block都有编号，下面简略说明上面三个数据的意义： super block：记录此文件系统的整体信息，包括inode/block的总量、使用量、以及文件系统的格式与相关信息。 inode：记录文件的属性，一个文件占用一个inode，同时记录此文件的数据所在的block号码。 block：实际记录文件的内容，若文件太大时，会占用多个block。 Linux的Ext2文件系统 Ext2文件系统主要有boot sector，superblock，inode bitmap，block bitmap，inode table，data block六大部分。 data block是用来放置文件内容数据的地方，在Ext2文件系统中所支持的block大小有1KB、2KB及4KB三种。 inode记录文件的属性/权限等数据，每个inode大小均固定为128bytes；每个文件都仅占有一个inode而已；因此文件系统能够新建的文件数量，与inode数量有关。 文件的block记录文件的实际数据，目录的block则记录该目录下面文件名与其inode号码的对照表。 日志文件系统会多出一块记录区，随时记载文件系统的主要活动，可加快恢复时间。 Linux文件系统为增加其性能，会让主存储器作为大量的磁盘高速缓存。 文件系统的简单操作磁盘与目录的容量：df，du df：列出文件系统的整体磁盘使用量 在执行df命令之后，会出现如下信息： 1234567文件系统 1K-块 已用 可用 已用% 挂载点/dev/vda1 51474044 6759800 42092876 14% /devtmpfs 932632 0 932632 0% /devtmpfs 941920 24 941896 1% /dev/shmtmpfs 941920 316 941604 1% /runtmpfs 941920 0 941920 0% /sys/fs/cgrouptmpfs 188388 0 188388 0% /run/user/0 du：评估文件系统的磁盘使用量（常用于评估目录所占容量） 可以看看下面的案例： 123456// 1. 列出目前目录下的所有文件容量du// 2. 同范例一，但是将文件的容量也列出来du -a// 3. 检查根目录下面每个目录所占用的容量du -sm /* 连接文件 hard link (硬连接或实际连接) hard link只是在某个目录下新建一条文件名连接到某inode号码的管理记录。它的命令如下： ln hard link是有如下限制的： 不能跨文件系统 不能连接到目录 symbolic link (符号连接，也即是快捷方式) symbolic link就是在创建一个独立的文件，而这个文件会让数据的读取指向它连接的按个文件的文件名。它的命令如下： ls -s symbolic link与Windows的快捷方式可以画上等号，如果原文件被删除了，那symbolic link也就不能用了。 磁盘的分区、格式化、校验与挂载对于一个系统管理者(root)而言，磁盘的管理是相对重要的一环，如果我们想要在系统里面新增一块硬盘，应该有哪些动作需要做？ 对磁盘进行分区，以新建可用的分区 对该分区进行格式化，以创建系统可用的文件系统 若想要仔细一点，则可对刚才新建好的文件系统进行校验 在Linux系统上，需要创建挂载点（也即是目录），并将它挂载上来 磁盘分区：fdisk输入如下命令，进入磁盘分区操作： fdisk /dev/hdc(磁盘名) 接下来就是按照提示新增或者删除分区了。 磁盘格式化：mkfs分区完毕之后就要进行格式化，格式化非常简单，使用mkfs（make file system）即可。命令如下： mkfs [-t 文件系统格式] 磁盘设备的文件名 -t后的文件系统格式就是让你指定将文件系统格式化成哪种文件系统。如ext2、ext3、vfat等。 磁盘检验：fsck当系统运行出现问题导致文件系统发生错乱，此时就需要磁盘的检验。命令如下： fsck [-t 文件系统] [-ACay] 设备名称 通常只有root用户，而且在文件系统有问题的时候才能进行这个操作，因为在正常情况下使用这个命令会对系统伤害很大。 此外，fsck在扫描的时候，有问题的数据会被放在lost＋found这个文件夹中。所以正常情况下这个文件夹中是不应该有数据的。 磁盘挂载与卸载：mount，umount在挂载前需要确定下面几件事： 单一文件系统不应该被重复挂载在不同的挂载点（目录）中 单一目录不应该重复挂载多个文件系统 作为挂载带你的目录理论上应该都是空目录 具体命令如下 挂载： mount [-t 文件系统] [-L 文件系统的卷标名称] [-o 额外选项] [-n] 设备文件名 挂载点 卸载 umount [-fn] 设备文件名或挂载点 参考 《鸟哥的Linux私房菜》]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_Linux文件与目录管理大全解]]></title>
    <url>%2F2018%2F03%2F25%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux_Linux%E6%96%87%E4%BB%B6%E4%B8%8E%E7%9B%AE%E5%BD%95%E7%AE%A1%E7%90%86%E5%A4%A7%E5%85%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[引：在使用Linux的过程中，最多的命令莫过于在操作文件与目录，所以通过本文，能让你大概率熟悉所有关于文件与目录的命令与知识，但是参数方面就需要自己去查询了。 目录与路径绝对路径和相对路径 绝对路径：路径的写法一定由根目录/写起。 相对路径：路径的写法是相对于当前工作目录写的。 目录的相关操作 特殊目录列表 . ：当前目录 .. ：上层目录 - ：前一个工作目录 ~ ：登陆用户的主文件夹 ~account ：这个用户的主文件夹 （account是个账号名称） 常见目录处理的命令 cd：切换目录 pwd：显示当前目录 mkdir：新建一个新的目录 rmdir：删除一个空的目录，删除非空目录需要使用rm -r 好习惯：经常利用Tab键快速完整地输入目录或命令 环境变量PATH 当我们执行命令：ls －al的时候，系统会按照PATH设置的路径，去这些路径中寻找ls这个文件，并执行。如果PATH路径中有多个ls文件，那么先找到的那个ls文件被执行。 1234// 查看PATHecho $PATH// 在PATH中添加路径/demoPATH="$PATH":/demo 对于PATH我们有几点需要清楚： 不同身份用户默认的PATH不同，默认能够随意执行的命令也不同，差异较大的地方在于/sbin和/usr/sbin。 PATH是可以修改的，所以一般用户还是可以通过修改PATH来执行某些位于/sbin或/usr/sbin下的命令来查询。 使用绝对路径或相对路径直接指定某个命令的文件名来执行。 命令应该要放在正确的目录下，执行才会比较方便。 本目录（.）最好不要放到PATH当中，因为本目录会变化。 文件和目录管理在文件与目录的管理上，不外乎“显示属性”、“复制”、“删除文件”、“移动目录或文件”等。下面这这种管理动作的具体指令： 显示属性 ls 复制 cp 删除 rm 移动(重命名) mv 这些指令的具体参数，希望大家能够通过man info去熟悉。 我们可以通过下面的命令去取得路径的文件名与目录名称：1234// 取得文件名称basename /etc/sysconfig/network// 取得文件目录dirname /etc/sysconfig/network 文件内容查阅主要有下面一些命令： 命令 作用 cat 由第一行开始显示文件内容 tac 从最后一行开始显示，可以看出tac是cat的到写形式 nl 显示的时候，顺便输出符号 more 一页一页显示文件内容 less 与more类似，但是比more更好的是，它可以往前翻页 head 只看头几行 tail 只看尾几行 od 以二进制的方式读取文件内容 文件与目录的默认权限和隐藏权限除了基本的rwx权限之外，Linux的ext2/ext3文件系统下，我们还可以设置系统隐藏属性，它可以用chattr来设置，用lsattr来查看。最重要的属性就是可以设置文件/目录为不可修改，这可以让文件所有者都不能进行修改，这对于安全性方面是非常重要的。 文件的默认权限：umaskumask指定了目前用户在新建文件或目录时候的权限默认值。 指定了以下面的方式来指定：1234567[root@VM_0_9_centos ~]# umask0022 // 与一般权限有关的是后面是三个数字(表示不拥有该数值的权限，此例就表示group不拥有w，others不拥有w)[root@VM_0_9_centos ~]# umask -Su=rwx,g=rx,o=rx// 设置默认权限umask 002 在默认权限的属性上，目录与文件是不一样的，x权限对于目录是非常重要的，但是一般文件的创建则不应该拥有执行权限。所以默认情况下： 若用户创建“文件”则默认没有可执行权限，默认权限为666，即-rw-rw-rw- 若用户创建“目录”则默认拥有可执行权限，默认权限为777，即drwxrwxrwx 文件隐藏属性chattr，lsattr chattr 设置文件的隐藏属性 注意参数a（文件只能增加数据，不能删除也不能修改数据）和i(不能 删除，修改) lsattr 显示文件隐藏属性 文件的特殊权限SUID,SGID,SBIT SUID(u+s,如x为空，则出现大S)，限制与功能如下： SUID权限仅对二进制程序有效 执行者对于该程序需要x的可执行权限 本权限仅在执行该程序的过程中有效 执行者将具有该程序所有者的权限 SGID（g+s,如x为空，则出现大S），对于文件功能与SUID类似，但是对于目录有如下功能： 用户若对于此目录具有r与x的权限时，该用户能够进入此目录 用户在此目录下得有效用户组将变成该目录的用户组 若用户在此目录下具有w的权限（可以新建文件），则用户所创建的新文件的用户组与此目录的用户组相同 SBIT（o+t,如x为空，则出现大T），目前只针对目录有效，它的作用如下： 当用户对于此目录具有w，x权限，即具有写入的权限时，当用户在该目录下创建文件或目录时，仅有自己与root才有权利删除该文件。 查看文件类型：file如果想知道某个文件的基本数据，就可以使用file这个命令查看。 文件与命令的查询脚本文件名的查询如果你想知道类似ls这种命令的脚本放在哪里，就通过which或type来找寻。 which命令是根据PATH这个环境变量所规范的路径去查询“执行文件”的文件名。 文件名的查找通常find不很常用，因为速度慢，通常我们都是先使用whereis或者是locate来检查，如果真的找不到了，才以find来查找，因为whereis与loacate是利用数据库来查询数据的，而find是直接查找硬盘的。 whereis：寻找特定文件 locate：根据文件的部分名称查找，由于是查询数据库的，而数据库是当晚更新，所以你新建文件是查找不到的，可以利用updatedb手动更新，但是较慢。 find：参数很多，自己用的时候需要使用man page自行了解。 文件与文件系统的压缩与打包常见的压缩命令不同的压缩打包技术，对应着不同的解压缩拆包技术，所以在Linux中用后缀名来分辨压缩打包技术，如下表： 后缀 压缩打包技术 *.Z compress程序压缩 *.gz gzip程序压缩 *.bz2 bzip2程序压缩 *.tar tar程序打包，未压缩 *.tar.gz tar程序打包,gzip程序压缩 *.tar.bz2 tar程序打包,bzip2程序压缩 由于compress已经不再流行，所有我们主要讲解gzip和gzip2: gzip,zcat（用来替代compress） 目前gzip可以解开compress、zip与gzip等软件压缩的文件。可以看一下下面的案例： 123456// 1. 压缩文件gzip -v 文件名 // 参数v显示压缩比// 2. 查看压缩文件内容zcat 压缩文件// 3. 解压缩gzip -d 压缩文件名 // 参数d表示解压缩 bzip2,bzcat（用来替代gzip） 使用方法与gzip基本相同，不再赘述。 打包命令在压缩文件夹之前需要打包，然后我们就需要用到大名鼎鼎的tar，下面通过命令来具体介绍他的使用：123456// 1. 压缩，参数的含义自己去用man page查看tar -jcv -f filename.tar.bz2 // 要被压缩的文件或目录名称，tar并不会主动产生创建的文件名// 2. 查询tar -jtv -f filename.tar.bz2// 3. 解压缩tar -jxv -f filename.tar.bz2 -C 欲解压缩的目录（如：/tmp） 对于只是打包没有压缩的文件叫做tarfile 对于打包了并且压缩的文件叫做tarball 完整备份工具 dump 备份 restore 恢复 参考 《鸟哥的Linux私房菜》]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_Linux的文件权限与目录配置]]></title>
    <url>%2F2018%2F03%2F22%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux_Linux%E7%9A%84%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E4%B8%8E%E7%9B%AE%E5%BD%95%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[引：了解好文件权限和目录的具体含义才能更好的操作Linux，所以理解好文件权限与目录配置才至关重要。 用户与用户组用户（User） 用户可以随意改变自己所拥有的文件 root用户就是最大的大佬，可以干任何事。 用户组（Group） 同一个用户组的用户可以访问该用户组的文件 每个账号可以加入多个用户组 在同一个用户组的文件也可以设置不同的权限，可以不让本组用户查看 其他人（Others）除了文件用户、同组用户以外的人就是其他人。 Linux用户身份与用户组记录的文件 系统上的账号与一般身份用户以及root的相关信息都记录在/etc/passwd文件中 个人的密码都记录在/etc/shadow文件中 Linux所有的组名都记录在/etc/group文件中 文件权限概念Linux文件属性我们可以利用下面的命令来查看文件属性： ls -al // 列出所有文件详细的权限和属性（包含隐藏文件） 如下：123456总用量 92drwxr-xr-x. 22 root root 4096 3月 17 12:33 .dr-xr-xr-x. 20 root root 4096 3月 22 09:14 ..drwxr-xr-x. 2 root root 4096 11月 5 2016 admdrwxr-xr-x 2 root root 4096 3月 12 10:27 alldata... 省略 解释一下上面7列的意思： 第一列：文件的类型与权限 第一个字符代表这个文件是“目录、文件或链接文件等”。 d：目录文件 -：普通文件 l：链接文件 b：用于存储数据的设备文件 c：用于传输数据的设备文件：鼠标、键盘 接下来都是三个字符为一组，分别表示文件所有者的权限、同组用户的权限、其他用户的权限，而且r（读）、w（写）、x（执行）的顺序是固定不变的。 第二列：有多少文件名连接到此节点 第三列：这个文件（或目录）的所有者账号 第四列：这个文件所属的用户组 第五列：这个文件的大小，单位是B 第六列：这个文件的创建日期或修改日期 第七列：文件名 改变文件属性与权限的命令 chgrp：改变文件所属的用户组 （注意-R 参数，递归更改） chown：改变文件所有者 （注意-R 参数，递归更改） chmod：改变文件的权限 （注意-R 参数，递归更改） 改变文件的权限有两种办法，分别是：用数字进行权限的修改、用符号进行权限的修改。 用数字进行权限的修改：权限有9个字母组成，并且每三个为一组，分别表示：文件主的权限、同组用户的权限、其他人的权限。在这种方式中，r＝4、w＝2、x＝1，将每一组的三个值加起来，组成一个三位数即可。实例如下： 1chmod -R 754 文件或目录 用符号进行权限的修改：我们通过u(user)，g(group)，o(others)，a(all)来表示身份权限，通过r（读）,w（写）,x（执行）来表示读写的权限，通过+（加入），-（除去），=（设置）来表示修改操作，实例如下： 1chmod u/g/o/a +/-/= r/w/x 文件/目录 目录与文件的权限意义 权限对文件的重要性： r：可读取此文件的实际内容。 w：可以编辑、新增或者修改该文件的内容（单不含删除该文件） x：该文件具有可以被系统执行的权限。 权限对目录的重要性 r：表示具有读取目录结构的权限，即可以执行ls命令 w：表示具有更改该目录结构列表的权限，比如新建新的文件与目录、删除已经存在的文件与目录、将已存在或目录进行重命名、转移该目录内的文件和目录位置 x：表示用户能否进入该目录，即可以使用cd进入该目录 文件种类与扩展名 文件种类 普通文件 纯文本文件（ASCII），可以用cat命令读取 二进制文件（binary），Linux中的可执行文件 数据格式文件（data），就是程序运行时会被读取的具有特定格式的文件，如配置文件，需要用last命令去读取，用cat读取会乱码 目录 连接文件，类似Windows下的快捷方式 设备与设备文件 块设备文件，用于存储数据的设备文件，如：硬盘、软盘 字符设备文件，用于数据传输的设备文件，如：键盘、鼠标 套接字，这个设备文件在/var/run中 管道，用于解决多个程序同时访问一个文件所造成的错误问题 文件扩展名 Linux并没有扩展名，一个Linux的文件是否可以执行，取决于这个文件的属性中是否有x这个权限（也要真的可以执行）。 但是为了增强文件的可读性，我们还是给文件增加了“扩展名“。如下面几种（等）： ＊.sh表示脚本或批处理文件 ＊Z、＊.tar、＊.tar.gz、＊.zip、＊.tgz他们都是压缩文件 注意：从网上下载的文件的权限是有可能发生改变的，所以当我们下载的文件无法运行时查看一下它的权限是否有x。 Linux对文件的限制：Linxu默认采用Ext2/Ext3文件系统，对文件名的长度限制为，单个文件名或目录名最大长度255个字符；完整的文件或目录名最大长度为4096个字符。 Linux目录配置Linux目录配置标准FHS一句文件系统使用的频繁与否与是否允许用户随意改动，而将目录定义为四中交互的形态，如下： / 可分享的(shareable) 不可分享的(unshareable) 不变的(static) /usr (软件放置处) /etc (配置文件) 不变的(static) /opt (第三方软件) /boot(开机与内核文件) 可变动的(variable) /var/mail (用户邮箱信件) /var/run (程序相关) 可变动的(variable) /var/spool/news (新闻组) /var/lock (程序相关) 解释一下四个类型的意思： 可分享的：可以分享给网络上的其他主机挂载使用 不可分享的：只与自己的机器有关，所以自然就不能分享给其他主机 不变的：不管什么样的distributions，这些数据基本不发生变化。一般这些目录中存放函数库、系统配置文件等 可变的：经常改变的数据，如登录文件、新闻组等 根目录是整个系统最重要的目录，其他所有的子目录都是由根目录衍生而来的，同时根目录也与开机、还原、系统修复等操作有关。 FHS建议：根目录要足够的小，而且应用程序不要和根目录放在同一个分区中。同时，FHS建议根目录下应该要有这些目录： 目录 应放置文件内容 /bin 在bin目录下的命令可以被所有账号使用，一般的命令是：cat、chmod、chown、date、mv、mkdir、cp、bash /boot 主要放置开机会使用到的文件 /dev 任何设备都是以文件的形式存放在这个目录当中 /etc 统主要的配置文件都放在这个目录中。这个目录下的文件属性是可以给一般用户查阅的，但只有root才可以修改，FHS建议：这个目录下不要放置可执行文件 /home 系统默认的用户主文件夹,～表示当前登陆用户的主文件夹 ，～rex表示指定用户的主文件夹 /lib 存放开机时用到的库函数及/bin、/sbin目录下的命令会使用到的库函数 /media 放置可删除的设备文件。如：软盘、光盘 /mnt 如果要临时挂载一些额外的设备就放在这个文件夹下 /opt 放置第三方软件的目录 /root 系统管理员的主文件夹 /sbin 放置开机过程中需要的，包括开机、修复、还原系统所需要的命令 /srv 是service的缩写，存放网络服务所需的一些数据 /tmp 一般用户执行程序暂时存放数据的地方。任何人都可以访问，所以要定时清理一下。FHS建议distributions开机时要将这个目录清空 其他重要的目录： 目录 应放置文件内容 /lost+found 使用ext2/ext3文件系统才会产生的一个目录。当文件系统发生错误时，一些丢失的片段就会放在这个目录中 /proc 是一个虚拟文件系统，也就是它的数据都是存放在内存中的，不占用硬盘空间 /sys 也是一个虚拟文件系统，记录内核相关信息 开机的时候只有根目录被挂载了，其他的目录所在的分区都是在系统启动完成之后才被挂载的。因此与开机过程有关的目录就必须要和根目录放在同一个分区中。必须与根目录放在同一个分区中的目录有下面这些目录： /etc：配置文件 /bin：重要的执行文件 /dev：所需要的设备文件 /lib：执行文件所需要的库函数与内核所需要的模块 /sbin：重要的系统执行文件 /usr目录：＝UNIX Software Resource，是操作系统关键资源放置的目录。FHS建议：所有软件开发者都应将数据放置在这个目录的子目录下，而不要自行创建独立的目录。这个目录就相当于Windows下的c:\program files /var目录：/usr放置安装程序时所需要的较大容量的文件，而/var下存放系统运行后才会渐渐占用硬盘的目录。如：缓存、日志、Mysql数据库的文件等。 目录树在Linux里面，所有的文件与目录都是由根目录开始的，那是所有目录与文件的源头，然后在一个一个分支下来，我们称这种目录配置为目录树。 目录树主要有以下特征： 目录树的起始点为根目录（/，root） 每个目录不只能使用本地端的文件系统，也可以使用网络上的文件系统，例如可以利用NFS服务器挂载某特定目录等 米格文件在此目录树的文件名（包含完整路径）都是独一无二的。 参考 《鸟哥的Linux私房菜》]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_Linux命令使用与查询]]></title>
    <url>%2F2018%2F03%2F21%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux_Linux%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%E4%B8%8E%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[引：从浅入深，我们也从基础命令开始。学会基本命令的使用，学会怎么去查命令的使用，最后学会一丢丢维护（开关机）。 基础命令开始执行命令首先我们要了解命令的格式： command(命令或可执行文件) -options parameter1(参数1) parameter2(参数2) 如果命令太长，我们可以使用反斜杠(\)来转义[enter符号]，注意反斜杠必须立刻接特殊字符，才能转义。 在linux下面是区分大小写的。 基础命令的操作 显示日期与时间的命令：date 显示日历的命令：cal 简单好用的计算器：bc，使用quit停止 重要的热键 Tab按键：具有命令补全，文件补齐的功能 ctrl + c：可以让程序立刻停下来 ctrl + d：通常代码键盘输入结束，相当于exit 在线求助man page 与info pageman pageman其实是manual（操作说明）的简写，只要通过（man + 命令） 就会有详细的说明出现。 如 man date可以得到下面的文本：123456789101112131415161718192021222324252627282930313233DATE(1) User Commands DATE(1)NAME date - print or set the system date and timeSYNOPSIS date [OPTION]... [+FORMAT] date [-u|--utc|--universal] [MMDDhhmm[[CC]YY][.ss]]DESCRIPTION Display the current time in the given FORMAT, or set the system date. Mandatory arguments to long options are mandatory for short options too. -d, --date=STRING display time described by STRING, not &apos;now&apos; ...省略其他参数ENVIRONMENTEXAMPLESDATE STRINGAUTHOR Written by David MacKenzie.COPYRIGHTSEE ALSOGNU coreutils 8.22 November 2016 DATE(1) 我们首先看到的是“DATE(1)”，这个(1)是有特殊含义的，如下表： 代号 代表内容 1 用户在shell环境中可以操作的命令或可执行的文件 2 系统内核可调用的函数与工具等 3 一些常用的函数与函数库，大部分为C的函数库 4 设备文件的说明，通常在/dev的文件 5 配置文件或者某些文件的格式 6 游戏 7 惯例与协议等，例如Linux文件系统，网络协议、ASCII code等说明 8 系统管理员与可用的管理命令 9 跟kernel有关的文件 我们要特别注意1，5，8这三个号码，尽量背下来。 在上面的man page中，以NAME作为开始介绍，最后还有个SEE ALSO来作为结束。基本上，man page大致分为以下几个部分： 代号 内容说明 NAME 简短的命令、数据名称说明 SYNOPSIS 简短的命令执行语法（syntax）简介 DESCRIPTION 较为完整的说明，最好仔细看看 OPTIONS 针对SYNNPSIS部分中，有列举的所有可用的选项说明 COMMANDS 在这个程序在执行的时候，可以在此程序中执行的命令 FILES 这个程序或数据所使用或参考或连接到的某些文件 SEE ALSO 这个命令或数据有相关的其他说明 EXAMPLES 一些可以参考的范例 BUGS 是否有相关的错误 通常在查询某些数据是这样来查阅的： 先看NAME的项目，略微看一下数据的意思 再仔细看一下DESCRIPTION，这个部分会提到很多相关的资料和用法。 如果这个命令其实很熟悉了，那么主要就是查询OPTIONS的部分了。 最后会看一下和这个资料有关的还有哪些东西可以使用。 某些说明内容还会列举有关的文件（FILES）来提供我们参考。 man page 常用的按键： 按键 进行工作 空格键 向下翻一页 Page Down 向下翻一页 Page Up 向上翻一页 Home 去到第一页 End 在去到最后一页 /string 向下查询string字符串 ?string 向上查询string字符串 n,N 利用/或？来查询字符串时，可以用n来继续查询下一个查询，可以利用N来进行反向查询 q 结束这次man page 下面还有两个man的用途： man -f command （= whatis）：查询和command这个命令有关的说明文件 man -k data（= apropos）：查询包含data这个数据有关的文件 info pageinfo与man的用途差不多，都是用来查询命令的用法或者文件的格式，但是与man page一下子输出一堆信息不同的是，info page则是将文件数据拆成一个一个段落，每个段落用自己的页面来撰写，并且在各个页面中还有类似网页的“超链接”来调到各个页面，每个独立的页面也被称为一个节点（node）。 这里这里不多说，有兴趣者可以自己去看看使用。 其他有用的文件一般而言，命令或者软件开发者都会将自己的命令或者是软件的说明制作成“在线帮助文件”，但是毕竟不是什么都需要做成在线帮助文件的，在/usr/share/doc中我们会发现会有很多说明文件文档，这些会告诉我们怎么做，以及一些相关的原理。 开机与关机开机与登录一般服务器都不怎么重启，我们在登录服务器的时候，基本上都是使用ssh来登录，我们可以使用下面的命令： ssh ip 在这个命令之后会要求与你输入密码即可成功。 关机在Linux中，由于每个程序都是在后台运行的，因此你看不到屏幕后面其实可能有很多人同时在你的主机上面工作，所以我们不能随意关机。所以在正常情况下，要关机时要注意下面几件事： 查看系统的使用状态 如果要看目前有谁在线：执行“who”这个命令 如果要看网络的联机状态：执行“netstat -a”这个命令 如果要看后台执行的程序：执行“ps -aux”这个命令 通知在线用户关机的时刻 正确地关机命令使用：shutdown与reboot 将数据同步写入硬盘的命令：sync 惯用的关机命令：shutdown 重启、关机：reboot,halt,poweroff 总结这一章最为基础，灰常重要，就像地基，只有有了地基，我们才能好好造下面的房子。 参考 《鸟哥的Linux私房菜》]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_Linux磁盘分区]]></title>
    <url>%2F2018%2F03%2F21%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux_Linux%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[引：Linux在我印象中最大的特点就是它把所有的硬件都当做一个文件，然后还是以/为根节点的目录树，简洁明了，相信大家一定会爱上它的。因为涉及到文件的存储，所以我们要重视磁盘分区。 硬件设备在linux中的文件名Linux中每一个设备都被当成文件，所有的设备文件都在/dev这个目录下。下面列出几个常见设备与其在Linux当中的文件名，如下表： 设备 设备在Linux内的文件名 IDE硬盘 /dev/hd[a-d] SATA/USB/SCSI硬盘 /dev/sd[a-p] U盘 /dev/sd[a-p]（与SATA相同） 软驱 /dev/fd[0－1] 打印机 25针：/dev/lp[0－2] usb：/dev/usb/lp[0-15] 鼠标 usb:/dev/usb/mouse[0－15] ps2:/dev/psaux 当前CD/DVD ROM /dev/cdrom 当前鼠标 /dev/mouse 磁带机 IDE:/dev/ht0 SCSI:/dev/st0 硬盘分区磁盘的文件命名规则磁盘的接口有两种，分别是IDE接口、SATA接口。目前主流的接口是SATA接口。使用IDE接口的设备我们称为IDE设备。 IDE设备：一个IDE接口可以连接两个IDE设备，主机中一般用两个IDE接口，因此最多可以连接四个IDE设备。这两个IDE接口通常被称为IDE1、IDE2，而每个IDE接口连接的两个IDE设备又被分为主设备和从设备。这四个IDE设备的文件名如下表： IDE接口 主设备 从设备 IDE1 /dev/hda /dev/hdb IDE2 /dev/hdc /dev/hdd SATA设备：以SATA/USB/SCSI为接口的磁盘使用的都是SCSI模块来驱动的，因此他们的设备文件名都是/dev/sd[a-p]。但是与IDE设备不同的是，他们的文件名没有一定的顺序，谁先插上去，谁就是a，以此类推。 磁盘的组成整个磁盘的第一个扇区非常重要，因为他记录了下面的重要的信息： 主引导分区Master Boot Record,MBR：可以安装“引导加载程序”的地方。有446bytes。 分区表：记录整块硬盘的分区状况，有64bytes。 磁盘分区表对磁盘进行分区时，采用柱面作为基本单位。分区表有64bytes，被分成四个区域，每个区域记录当前磁盘的所有分区的起始和结束柱面号。例如：一块IDE硬盘被分成四个区域： P1：/dev/hda1 ，P2：/dev/hda2 ，P3：/dev/hda3 ，P4：/dev/hda4。每个磁盘的分区表只能被分成四个区域，这四个区域被称为主分区或扩展分区。当系统进行数据的读写时，一定要参考分区表才能进行。 分区的原因保证数据的安全性（分区不会影响）；提升系统的性能（只在自己的分区查找）。 扩展分区主分区和扩展分区都是分区表中的一条记录，主分区中存放通过直接索引就能到达的分区的开始和结束的柱面号；而扩展分区中存放的是逻辑分区表的开始和结束柱面号，这张逻辑分区表中才存放分区的开始和结束柱面号。 由于一张分区表只能存放四条记录，也就是四个分区，当我们想要多一些分区的时候就必须要通过扩展分区来实现。 分区表中的四条记录对应的设备文件名是不会变的。如上面的四个名字，所以逻辑分区的文件名一定是从5开始的。如：/dev/hda5。 提醒 扩展分区最多只能有1个。 Linux中，IDE硬盘最多有59个逻辑分区，5号－63号；SATA硬盘最多有11个逻辑分区，5号－15号。 在Windows中若D、E盘都是扩展分区中的逻辑分区，那么他们可以整合成一个分区；若两个盘一个是逻辑分区，一个是主分区，那他们是不能合并的。 一块硬盘的第一个扇区记录了MBR和分区表，非常的重要，如果第一个扇区坏了，那么整个硬盘就报废了。 开机流程整个开机流程到操作系统之前的动作应该是这样的： BIOS：开机主动执行的韧体，会认识第一个可开机的对象。 MBR：第一个可开机设备的第一个扇区的主引导分区块，内包含引导加载程序。 引导加载程序：一支可读取内核文件来执行的软件。（可多个不同系统的加载程序对应了不同的操作系统） 内核文件：开始操作系统的功能。 PS：为什么如果安装多重引导，最好先安装Windows在安装Linux？——因为Linux在安装的时候可以选择将引导加载程序安装在MBR或个别分区的启动扇区，而且在linnux的loader可以手动设置菜单，所以你可以在Linux的boot loader里面加入Windows开机的选项。Windows在安装的时候，它的安装程序会主动覆盖掉MBR以及自己所在分区的启动扇区，你没有选择的机会，而且没有让我们选择菜单的功能。 挂载目录树在Linux中，整个文件系统呈一棵以/为根目录的树。 文件系统与目录树的关系（挂载）挂载就是把一个目录当作磁盘中某一个分区的进入点，也就是说，进入了这个目录，就进入了这个磁盘的这个分区。这个进入的目录我们就称为挂载点。根目录一定要挂载到某个分区。 如何寻找挂载点（判断某个在文件在哪个分区下）？答：通过反向追踪即可，当我们想要知道/home/rex/test文件在那个分区时，只要逆向寻找第一个挂载点就是这个文件的挂载点。 可以使用下面的命令： df /home/rex/test 总结了解分区，了解开机流程，了解挂载，ok，就这些！ 参考 《鸟哥的Linux私房菜》]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_初识Linux]]></title>
    <url>%2F2018%2F03%2F20%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux_%E5%88%9D%E8%AF%86Linux%2F</url>
    <content type="text"><![CDATA[引：了解Linux，学习Linux，深入Linux。 Linux是什么Linux就是一套操作系统，它的内核是Linux Torvalds在1991年开发出来的。 Linux的内核版本看下面的例子：122.6.18-92.e15主版本.次版本.释出版本-修改版本 主、次版本为奇数：开发中版本，如2.5.xx，这种版本仅内核开发工程师使用。 主、次版本为偶数：稳定版本，如2.6.xx ，家庭、企业使用。 我们可以通过下面的命令查看自己的linux的版本号： uname -r Linux发行版Linux其实就是Linux Kernel（内核）＋内核工具。他是GNU GPL授权模式，任何人都可以获取源代码并进行修改。因此Linux的全名是：GNU/Linux。Linux ditribution是由各个商业公司开发，本质上是LinuxKernel＋内核工具＋软件，让普通用户都能使用的操作系统。 基本上Linux distributions并无太大区别，可以根据自己的喜好选择。他们的内核都是从www.kernel.org上下载的。 Linux的特色 自由与开放的使用与学习环境 配置需求低廉 内核功能强大而稳定 独立作业 Linux优点 稳定的系统 免费或少许费用 安全性、漏洞的快速修补 多任务、多用户 用户与用户组的规划 相对比较不耗资源的系统 整合度佳且多样的图形用户界面 Linux缺点 没有特定的支持产商 游戏的支持度不足 专业软件的支持度不足 Linux当前的角色企业环境的应用 网络服务器（当今最热门的运用） 关键任务的应用（金融数据库、大型企业） 学术机构的高性能运算任务 个人环境的使用 桌面计算机(在Linux系统上装一个X Window System软件之后，就能有桌面了) 手持设备（PAD、手机） 嵌入式系统 Linux的学习路线 学习计算机概论及硬件相关知识 从Linux的安装开始学起 学会使用Linux的基本技能 学会vi编辑器 shell与shell脚本的学习 一定要会软件管理员 了解网络基础 使用Linux架设网站 总结在使用Linux之前请学会Linux！ 参考 《鸟哥的Linux私房菜》]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进Linux_计算机基础]]></title>
    <url>%2F2018%2F03%2F20%2F%E8%B5%B0%E8%BF%9BLinux%2F%E8%B5%B0%E8%BF%9BLinux_%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[引：我也算是从通信专业转到计算机的，所以当然对计算机专业课知识不太了解，所以也想简单掌握以下计算机基础知识。 计算机其实是：接收用户输入指令和数据，经过中央处理器的数据欲逻辑单元运算处理后，以产生或存储成有用的信息。 计算机组成计算机硬件的五大单元 输入单元 输出单元 CPU内部的控制单元 CPU内部的算术逻辑单元 内存 CPU的种类CPU内部已经含有一些小指令集，我们所使用的软件都要经过CPU内部的微指令集来完成才行。这些指令集的设计主要被分为两种设计理念，如下： 精简指令集（RISC） 采用精简指令集的cpu的指令较为精简，每条指令的执行时间很短，完成的操作也很单纯，指令的执行性能较好；但是如果要做一些复杂的操作，则需要多个指令来协同完成。 常见的精简指令集CPU有： sun公司的SPARC系列，常应用于学术领域的大型工作站 IBM公司的Power Architecture（包括Power PC），如索尼的PS3 IBM公司的ARM系列，常用于手机、pda、导航系统、网络设备等 （使用最广泛） 复杂指令集（CISC） 每一条指令较为复杂，因为执行的时间比较长，但是每条指令处理的工作较为丰富。 常见的复杂指令集的CPU：AMD、Intel、VIA等x86架构的cpu。由于这些采用了复杂指令集的x86架构的cpu常常被用在个人计算机上，所以个人计算机常常就被称为x86计算机。x86架构的CPU最早由因特尔开发，并且它将CPU从8位提升为16位、32位。后来，AMD公司基于x86架构开发出了64位的CPU。所以64位CPUu的架构叫做x86_64，非64位cpu的架构仍然叫做x86。 接口设备 存储设备：包括硬盘，软盘等 显示设备：显卡等 网络设备：网卡等 计算机分类 超级计算机：运算速度最快的计算机，主要是用于需要有高速计算的项目中。 大型计算机：功能上不及超级计算机，但也可以用来处理大量数据与复杂计算。 迷你计算机：主机可以放在一般场所，无需像大型计算机一样需要特殊的空调场所。 工作站：工作站的价格比迷你计算机便宜许多，。是针对特殊用途而设计的计算机。 微电脑：个人计算机（PC）。 计算机上面的常用的计算单位（大小、速度等） 文件大小：1GB=1024*1024*1024Byte；1Byte=8bit CPU运算速度：MHz或者GHz，Hz为秒分之一 网络传输：Mbit/s或者MB/s，注意bit还是Byte 个人计算机架构与接口设备在计算机主板上的芯片组通常又分为两个桥接器来控制各组件的通信： 北桥负责连接速度较快的CPU、内存与显卡等组件。北桥的总线称为系统总线。因为是内存传输的主要通道，所以速度快。 南桥负责链接速度较慢的周边接口，包括硬盘、USB、网卡等。南桥的总线称为输入输出(I/O)总线。 AMD和Intel的芯片组架构最主要的区别是AMD的内存是直接与CPU通信而不通过北桥。 CPU外频与内屏 外频：CPU与外部组件进行数据传输/运算时的速度。 倍频：CPU内部用来加速工作性能的一个倍速，两者相乘才是cpu 的频率。 32位与64位 北桥所支持的频率称为前端总线速（FSB）度，而每次传送的位数则是总线宽度，所谓总线频宽则是“FSB*总线宽度”，业技术每秒钟可以传送的最大数据量。 CPU每次能处理的数据量称为字组大小(word size)，字组大小依据cpu的设计有32／64位。我们现在称计算机是32／64位是根据CPU解析的字组大小来的。 内存我们平时所说的内存的全名叫做动态随机访问存储器（DRAM）。DRAM是一种挥发性内存，只有它通电的时候才能被使用，断电数据就消失。DRAM分为： SDRAM DDR SDRAM，DDR=Double Data Rate 所以他的传输速度比SDRAM要快。 对服务器而言，内存的容量比CPU的速度更加重要。CPU与内存的外频应该相同才好。 双通道设计总线宽度一般是64位，也就是每次总线从内存中读写64位数据，若在主板上插两根内存条，那么总线宽度就达到128位，从而提升了内存的读写速度。在主板上插两根内存条的设计就叫做双通道设计。但是要启动双通道功能，安插的两根内存条必须型号一样，大小一样，这样才能整体上提升内存的读写速度。 DRAM与SRAMDRAM就是我们平时所说的内存，它的全称叫做动态随机访问存储器。而SRAM的全程叫做静态随机访问存储器。SRAM可以用在很多不同的地方，而CPU中的第二层高速缓存就是选择SRAM作为存储器。由于L2 Cache集成在CPU内部，CPU读取数据无需再经过北桥从内存中获取，直接从L2 Cache中获取，从而能提升性能。 显卡显卡又叫做VGA（Video Graphics Array）。图形影响的显示质量的好坏重点在于分辨率和色彩深度。由于显示的每一个像素都会占用内存，因此显卡上面也有个存储器，而这个存储器的大小直接影响显示的效果。早期时候3D的运算是交给CPU去处理的，为了减少CPU的负担，所以在显卡上设置一个处理器，这个处理器就是GPU。 PS: 如果你的主机是用来打3D游戏，那么显卡的选购非常重要，如果你的主机是用来作为网络服务器，那么简单的入门级显卡对你的主机来说就非常够用了。 硬盘与存储设备计算机系统上的存储设备包括硬盘、软盘、U盘等，我们主要介绍硬盘： 硬盘主要是由许多的盘片、机械手臂、磁头与主轴马达所组成。实际的数据都是写在具有磁性物质的盘片上，硬盘运行时，主轴马达让盘片转动，机械手臂可以伸缩，让读取头在盘片上面进行读写操作。 硬盘的最小存储单位是扇区，每个扇区的大小是512bytes，这个值是不可改变的。扇区组成的环叫做磁道。上下的所有磁道构成柱面。柱面是分割硬盘的最小单位。一般硬盘制造商杂显示硬盘容量时，大多是以十进制来编号，所有500GB的硬盘，理论上仅会有460GB左右的容量。 传输接口主要有以下几种： IDE接口：每秒传输可达133MB。 SATA接口：SATA－1每秒传输150MB，SATA－2每秒传输300MB，目前个人计算机都已使用SATA。 SCSI接口：这个接口含有一个处理器，硬盘的读写操作由这个处理器完成，从而提升计算机整体性能。 PS：硬盘很脆弱，千万别让它摔了还是怎样，血的教训。 主板主板可以说是整台主机相当重要的地方，因为重要的组件都是安插在主板上面的，而主板上面负责通信各个组件的就是芯片组。下面说说主板我们常用的东西： CMOS与BIOS：CMOS主要的功能是记录主板上面的重要参数，如系统时间等。BIOS为写入到主板上某一块闪存或EEPROM的程序，它可以在开机的时候执行，已加载CMOS当中的参数，并尝试调用存储设备中的开机程序，进一步进入操作系统当中。 连接接口设备：主板与各项输出/输入设备的链接主要都是在主机箱的后方，如USB接口RJ-45接口等。 计算机编码 常用的英文编码表是ASKII，每个字符占1B，因此总共有2的8次方种变化。 中文编码表常用gb2312，每个字符占2B，定义了一万三千多个字。但是，这个编码表对于数据库存储有问题，从数据库读出数据的时候有些字会被读错。 为了解决上面的问题，出现了Unicode编码表，就是UTF-8。 软件程序运行一般来说目前的计算机系统将软件分为两大类：一是系统软件（内核），一个是应用程序（日常所说的软件）。 机器程序与编译程序 机器程序：都是机器码，可以直接给机器识别。 编译程序：能够将高级语言编译成机器程序。 操作系统先看看操作系统的角色，从底层到高层：硬件-&gt;内核-&gt;系统调用-&gt;应用程序。其中内核以及系统调用被称为操作系统。 操作系统内核：操作系统其实也是一组程序，这组程序的重点在于管理计算机的所有活动以及驱动系统的所有硬件。 系统调用：操作系统提供的一组开发接口。 内核功能： 系统调用接口 程序管理 内存管理 文件系统管理 设备驱动 操作系统与驱动程序：操作系统通常会提供一个开发接口给硬件商，让他们可以根据这个接口色合计可以驱动他们硬件的驱动程序。 应用程序应用程序是参考操作系统提供的开发接口所开发出来的软件，这些软件可以让用户操作，以达到某些计算机的功能利用。 总结了解好计算机的基础知道，我们对计算机里面的硬件以及程序的实现有了一个大概的了解，有利于我们学习下面的知识。 参考 《鸟哥的Linux私房菜》]]></content>
      <categories>
        <category>走进Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——桥梁模式]]></title>
    <url>%2F2018%2F03%2F19%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E6%A1%A5%E6%A2%81%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：不变的部分用继承来实现，变得部分放在外部，并通过桥梁模式抽象耦合进来，这样就解决了继承的弊端。 定义桥梁模式也叫做桥接模式，其定义如下： 将抽象和实现解耦，使得两者可以独立变化。——结构类 下面是桥梁模式的通用类图： 我们看看桥梁模式类图中的4个角色： Abstraction抽象化角色：主要职责是定义出该角色的行为，同时保存一个对实现化角色的引用，该角色一般是抽象类。 Implementor实现化角色：定义角色必须的行为和属性。 RefinedAbstraction修正抽象化角色：它引用实现化角色对抽象化角色进行修正。 ConcreteImplementor具体实现化角色：实现接口或抽象类定义的方法和属性。 它的通用源码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public interface Implementor &#123; // 基本方法 public void doSomething(); public void doAnything();&#125;// 具体实现化角色public class ConcreteImplementor1 implements Implementor &#123; public void doSomething() &#123; // 业务逻辑处理 &#125; public void doAnything() &#123; // 业务逻辑处理 &#125;&#125;public class ConcreteImplementor2 implements Implementor &#123; public void doSomething() &#123; // 业务逻辑处理 &#125; public void doAnything() &#123; // 业务逻辑处理 &#125;&#125;// 抽象化角色public abstract class Abstraction &#123; // 定义对实现化角色的引用 private Implementor imp; // 约束子类必须实现该构造函数 public Abstraction(Implementor _imp) &#123; this.imp = _imp; &#125; // 自身的行为和属性 public void request() &#123; this.imp.doSomething(); &#125; // 获得实现化角色 public Implementor getImp() &#123; return imp; &#125;&#125;// 具体抽象化角色public class RefinedAbstraction extends Abstraction &#123; // 覆写构造函数 public RefinedAbstraction(Implementor _imp) &#123; super(_imp); &#125; // 修正父类的行为 @Override public void request() &#123; super.request(); super.getImp().doAnything(); &#125;&#125;// 场景类public class Client &#123; public static void main(String[] args) &#123; // 定义一个实现化角色 Implementor imp = new ConcreteImplementor1(); // 定义一个抽象化角色 Abstraction abs = new RefinedAbstraction(imp); // 执行 abs.request(); &#125;&#125; 应用优点 抽象和实现分离。 优秀的扩充能力。 实现细节对客户透明。 使用场景 不希望或不合适使用继承的场景。 接口或抽象类不稳定的场景。 重用性要求较高的场景。 注意事项使用桥梁模式主要考虑如何拆分抽象和实现。桥梁模式的意图还是对变化的封装，尽量把可能变化的因素封装到最细、最小的逻辑单元，避免风险扩散。 最佳实践继承非常好，但是有缺点。我们可以扬长避短，对于比较明确不发生变化的，则通过继承来完成；若不能确定是否会发生变化的，那就认为会发生变化，则通过桥梁模式来搭建一个桥梁将变化的的东西放在外部和本体进行连接。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——享元模式]]></title>
    <url>%2F2018%2F03%2F18%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：对象多了，而且还都是处于有用状态，那一定会出现内存溢出的问题，我们可以通过享元模式来实现对象的复用，以达到减少的目的，从而解决内存溢出的问题。 定义享元模式是池技术的重要实现方式，其定义如下： 使用”共享对象”可有效地支持大量的”细粒度的对象”。——结构类 享元模式的定义为我们提出了两个要求：细粒度对象和共享对象。我们知道分配太多的对象到应用程序中将有损程序的性能，同时还容易造成内存溢出，那怎么避免呢？就是享元模式提到的共享技术。我们先来了解一下对象的内部状态和外部状态： 内部状态：内部状态是对象可共享出来的信息，存储在享元对象并且不会随环境改变而改变，不必存储在具体某个对象中，属于可以共享的部分。 外部状态：外部状态是对象得以依赖的一个标记，是随环境改变而改变的，不可以共享的状态，他是一批对象的统一标识，是唯一的索引值。 下面是享元模式的通用类图： 简单介绍类图中的角色： Flyweight抽象享元角色：产品的抽象类，同时定义出对象的外部状态和内部状态的接口或实现。 ConcreteFlyWeight具体享元角色：具体的一个产品类，实现抽象角色定义的业务。该角色中需要注意的是内部状态处理应该与环境无关，不应该出现一个操作改变了内部状态，同时修改了外部状态，这是绝对不允许的。 UnsharedConcreteFlyWeight不可共享的享元角色：不存在外部状态或者安全要求（如线程安全）不能够使用共享技术的对象，该对象一般不会出现享元工厂中。（有点不太理解） FlyWeightFactory享元工厂：职责非常简单，就是构造一个池容器，同时提供从池中获取对象的方法。 享元模式的目的在于运用共享技术，使得一些细粒度的对象可以共享，多使用细粒度的对象，便于重构或重用，下面是它的通用代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// 抽象享元角色public abstract class Flyweight &#123; // 内部状态 private String intrinsic; // 外部状态 注意final protected final String extrinsic; // 要求享元角色必须接受外部状态 public Flyweight(String _extrinsic) &#123; this.extrinsic = _extrinsic; &#125; // 定义业务操作 public abstract vid operate(); // 内部状态的getter/setter public String getIntrinsic() &#123; return intrinsic; &#125; public void setIntrinsic(String intrinsic) &#123; this.intrinsic = intrinsic; &#125;&#125;// 具体享元角色public class ConcreteFlyweight1 extends Flyweight &#123; // 接受外部状态 public ConcreteFlyweight1(String _extrinsic) &#123; super(_extrinsic) &#125; // 根据外部状态进行逻辑处理 public void operate() &#123; // 业务逻辑 &#125;&#125;public class ConcreteFlyweight2 extends Flyweight &#123; // 接受外部状态 public ConcreteFlyweight2(String _extrinsic) &#123; super(_extrinsic) &#125; // 根据外部状态进行逻辑处理 public void operate() &#123; // 业务逻辑 &#125;&#125;// 享元工厂public class FlyweightFactory &#123; // 定义一个池容器 private static HashMap&lt;String,Flyweight&gt; pool = new HashMap&lt;String,Flyweight&gt;(); // 享元工厂 public static Flyweight getFlyweight(String extrinsic) &#123; // 需要返回的对象 Flyweight flyweight = null; // 在池中没有该对象 if(pool.containKey(extrinsic)) &#123; flyweight = pool.get(extrinsic); &#125; else &#123; // 根据外部状态创建享元对象 flyweight = new ConcreteFlyweight1(extrinsic); // 放置到池中 pool.put(extrinsic,flyweight); &#125; return flyweight; &#125;&#125; 应用优点可以大大减少应用程序创建的对象，降低程序内存的占用，增强程序对的性能。 缺点提高了系统的复杂性，需要分离出外部状态和内部状态，而且外部状态具有固化特性（加fianl关键字），不应该随内部改变而改变，否则导致系统的逻辑混乱。 使用场景 系统中存在大量的相似对象。 细粒度的对象都具有较接近的外部状态，而且内部状态与环境无关，也就是说对象没有特定身份。 需要缓冲池的场景。 注意事项当对象池的对象太少时，会出现线程不安全的现象。 最佳实践享元模式在Java API中也是随处可见的，比如String类的intern方法就是利用了String的对象池。当然对象池主要解决复用，而享元模式主要解决对象的共享问题，如果建立多个可共享的细粒度对象是其关注的重点。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——解释器模式]]></title>
    <url>%2F2018%2F03%2F18%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E8%A7%A3%E9%87%8A%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：无论是编译原理，还是解释型语言，都会涉及到解释，其思想也都和解释器模式类似。 定义给定一门语言，定义它的文法的一组表示，并定义一个解释器，该解释器使用该表示来解释语言中的句子。——行为类 解释器模式的通用类图如下： 这里解释一下类图中的角色: AbstractExpression抽象解释器：具体的即时任务又各个实现类完成，具体的解释器分别由TerminalExpression（值）和NotermianlExpression（符号）完成。 TerminalExpression终结符表达式：实现与文法中的元素相关联的解释操作，通常一个解释器模式中只有一个终结符表达式，但是有多个实例，对应不同的终结符。 NotermianlExpression非终结符表达式：文法中的每条规则对应于一个非终结表达式。 Context环境角色：存放数据 解释器是一个比较少用的模式，以下为其通用源码：1234567891011121314151617181920212223242526272829303132333435363738394041// 抽象表达式public abstract class Expression &#123; // 每个表达式必须有一个解释任务 public abstract Object interpreter(Context ctx);&#125;// 终结符表达式public class TerminalExpression extends Expression &#123; // 通常终结符表达式只有一个，但是有多个对象 public Object interpreter(Context ctx) &#123; // 主要处理场景元素和数据的转换 return null; &#125;&#125;// 非终结符表达式public class NotermianlExpression extends Expression &#123; // 每个非终结符表达式都会对其他表达式产生依赖 public NotermianlExpression(Expression... expression) &#123;&#125; public Object interpreter(Context ctx) &#123; // 进行文法处理 return null; &#125;&#125;// 场景类public class Client &#123; public static void main(String[] args) &#123; Context ctx = new Context(); // 通常定一个语法容器，容纳一个具体的表达式，通常为ListArray、LinkedList、Stack等容器 Stack&lt;Expression&gt; stack = null; for(;;) &#123; // 进行语法判断，并产生递归调用 &#125; // 产生一个完整的语法树，由各个具体的语法分析进行解析 Expression exp = stack.pop(); // 具体元素进入场景 exp.interpreter(ctx); &#125;&#125; 通常Client是一个封装类，封装的结果就是传递进来的规范语法文件，解释器分析后产生结果并返回，避免了调用者与语法解析器的耦合关系。 应用优点解释器是一个简单语法分析工具，它最显著的有点就是扩展性，修改语法规则只要修改相应的非终结符表达式就可以了，若扩展语法，则只要增加非终结符类就可以了。 缺点 解释器模式会引起类膨胀（显而易见） 解释器采用递归调用方法，调试复杂，且影响效率。 使用场景 重复发生的问题可以使用解释器模式，如对不同的日志文件进行不同的分析。 一个简单语法需要解释的场景。 注意事项尽量不要在重要的模块中使用解释器模式，否则维护回事一个很大的问题。 最佳实践解释器模式在实际的系统开发中使用得非常少，因为它会引起效率问题、性能以及维护等问题，一般在大中型的框架型项目能够找到它的身影，如一些数据分析工具、报表设计工具、科学计算工具等，若你确实遇到“一种特定类型的问题发生的频率足够高”的情况下，准备使用解释器模式时，可以考虑一下Expression4J、MESP、Jep等开元的解析工具包。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——状态模式]]></title>
    <url>%2F2018%2F03%2F18%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：状态（一个变量）变化了，然后就会出现不同的行为，这就是对状态模式最简单的理解，当然它还有很多约束。 定义当一个对象内在状态改变时允许其他改变行为，这个对象看起来像改变其类。——行为类 状态模式的核心是封装，状态的变更引起了行为的变更，从外部开起来就好像这个对象对应的类发生了改变一样，状态模式的通用类图如下： 简单介绍类图中的3个角色 State抽象状态角色：负责对象的状态的定义，并且封装环境角色以实现状态的切换。 ConcreteState具体对象状态定义：每个具体状态必须完成两个职责：本状态的行为管理以及趋向状态处理。 Context环境角色：定义客户端需要的接口，并且负责具体状态的切换。 下面是它的通用源码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182// 抽象状态角色public abstract class State &#123; // 定义一个环境角色，提供子类访问 protected Context context; // 设置环境角色 public void setContext(Context _context) &#123; this.context = _context; &#125; // 行为1 public abstract void handle1(); // 行为2 public abstract void handle2();&#125;// 具体状态角色public alass concreteState1 extends State &#123; @Override public void handle1() &#123; // 本状态下必须处理的逻辑 &#125; @Override public void handle2() &#123; // 设置当前状态为state2 super.context.setCurrentState(Context.STATE2); // 过度到state2状态，由Context实现 super.context.handle2(); &#125;&#125;public alass concreteState2 extends State &#123; @Override public void handle2() &#123; // 本状态下必须处理的逻辑 &#125; @Override public void handle1() &#123; // 设置当前状态为state1 super.context.setCurrentState(Context.STATE1); // 过度到state1状态，由Context实现 super.context.handle1(); &#125;&#125;// 环境角色，它具有以下两个不成文的约束：// 1. 把状态对象声明为静态变量，有几个状态对象就声明几个静态变量// 2. 环境角色具有状态抽象角色定义的所有行为，具体执行使用委托方式public class Context &#123; // 定义状态 public final static State STATE1 = new ConcreteState1(); public final static State STATE2 = new ConcreteState2(); // 当前状态 private State currentState; // 获得当前状态 public State getCurrentState() &#123; returncurrentState; &#125; // 设置当前状态 public void setCurrentState(State currentState) &#123; this.currentState = currentState; // 切换状态, 重要 this.currentState.setContext(this); // 行为委托, 重要 public void handle1() &#123; this.currentState.handle1(); &#125; public void handle2() &#123; this.currentState.handle2(); &#125; &#125;&#125;// 场景类public class Client &#123; public static void main(String[] args) &#123; // 定义环境角色 Context context = new Context(); // 初始化状态 context.setCurrentState(new ConcreteState1()); // 行为执行 context.handle1(); context.handle2(); &#125;&#125; 应用优点 结构清晰，提高系统的可维护性 遵循设计原则，很好体现了开闭原则和单一职责原则。 封装性非常好，将状态变化放置到类的内部来实现，外部的调用不用知道类内部如何实现状态和行为的变换。 缺点只有一个缺点，就是会随着状态的增多会出现类膨胀。 使用场景 行为随状态改变而改变的场景，如权限设计。 条件、分支判断语句的替代者。 注意事项状态模式适用于当某个对象在它的状态发生改变时，它的行为也随着发生比较大的变化，也就是说在行为受状态约束的情况下可以使用状态模式，而且使用时对象的状态最好不要超过5个。 最佳实践状态模式其实经常会遇到，因为基本上都会遇到状态的切换。对于状态顺序的不同组成不同的状态变化线，我们可以使用建造者模式。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——访问者模式]]></title>
    <url>%2F2018%2F03%2F15%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E8%AE%BF%E9%97%AE%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：一个对象结构包含很多类对象，他们又有不同的接口，而你想对这些对象实施一些依赖于其具体类的操作，接可以使用访问者模式。 定义封装一些作用于某种数据结构中的各元素的操作，它可以在不改变数据结构的前提下定义作用与这些元素的新操作。——行为类 它的通用类图如下： 我们看看类图中几个角色的职责： Visitor抽象访问者：声明访问者可以访问哪些元素，具体到程序找那个就是visit方法的参数定义哪些对象是可以被访问的。 ConcreteVisitor具体访问者：它影响访问者访问到一个类后该怎么干，要做什么事情。 Element抽象元素：声明接受哪一类访问者访问，程序上是通过accept方法中的参数来定义的。 ConcreteElement具体元素：实现accept方法，通常是visitor.visit(this)，基本都形成了一种模式了。 ObjectStruture结构对象：元素产生者，一般容纳在多个不同类，不同接口的容器，如List，Set，Map等，在项目中，一般很好抽象出这个角色。 接着看看具体的通用源码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273// 抽象元素public abstract class Element &#123; // 定义业务逻辑 public abstract void doSomething(); // 允许谁来访问 public abstract void accept(Ivisitor visitor);&#125;// 具体元素public class ConcreteElement1 extends Element &#123; // 完善业务逻辑 public void doSomething() &#123; // 业务处理 &#125; // 允许哪个访问者访问 public void accept(Ivisitor visitor) &#123; visitor.visit(this); &#125;&#125;public class ConcreteElement2 extends Element &#123; // 完善业务逻辑 public void doSomething() &#123; // 业务处理 &#125; // 允许哪个访问者访问 public void accept(Ivisitor visitor) &#123; visitor.visit(this); &#125;&#125;// 抽象访问者public interface Ivisitor &#123; // 可以访问哪些对象 public void visitor (ConcreteElement1 el1); public void visitor (ConcreteElement2 el2);&#125;// 具体访问者public class Visitor implements Ivisitor &#123; // 访问el1元素 public void visit(ConcreteElement1 el1) &#123; el1.doSomething; &#125; // 访问el2元素 public void visit(ConcreteElement2 el2) &#123; el2.doSomething(); &#125;&#125;// 结构对象 产生不同的元素对象，可以用工厂方式模式模拟public class ObjectStruture &#123; // 对象生成器，通过工厂方法模式模拟 public static Element createElement() &#123; Random random = new Random(); if(random.nextInt(100) &gt;50) &#123; return new ConcreteElement1(); &#125; else &#123; return new ConcreteElement2(); &#125; &#125;&#125;// 场景类public class Client &#123; public static void main(String[] args) &#123; for(int i = 0; i&lt;10; i++) &#123; // 获取元素对象 Element el = ObjectStruture.createElement(); // 接受访问者访问 el.accept(new Visitor()); &#125; &#125;&#125; 应用优点 符合单一职责原则。具体元素角色负责数据的加载，访问者类负责报表的展现，职责明确。 优秀的扩展性。报表不同只需要修改visit方法。 灵活性非常高。 缺点 具体元素对访问者公布细节，不符合迪米特法则。 具体元素变更比较困难。 违背了依赖倒置原则，访问者依赖的是具体元素，而不是抽象元素。 使用场景 一个对象结构包含很多类对象，他们又有不同的接口，而你想对这些对象实施一些依赖于其具体类的操作，也就是说用迭代器模式已经不能胜任的情景。 需要对一个对象结构中的对象进行不同并且不相关的操作，而你想避免让这些操作“污染”这些对象的类。 总结：在这种地方一定要考虑使用访问者模式：业务规则要求遍历多个不同的对象，迭代器只能访问同类或同接口的数据，而访问者模式是对迭代器模式的扩充，可以遍历不同的对象，然后执行不同的操作。访问者模式还可以充当拦截器的角色。 最佳实践访问者模式一种集中规整模式，特别适用于大规模重构的项目。通过访问这么欧式可以很容易吧一些进行梳理，达到最终目的——功能集中化。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——备忘录模式]]></title>
    <url>%2F2018%2F03%2F14%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引： 备忘录模式是我们设计上的“月光宝盒”，可以让我们回到需要的年代；是程序数据的“后悔药”，吃了它就可以返回上一个状态；是设计人员的定心丸，确保即使在最坏的情况下也能获得最近的对象状态。 定义备忘录模式提供了一种弥补真实世界缺陷的方法，让“后悔药”在程序的世界中真实可行，其定义如下： 在不破坏封装性的前提下，捕获一个对象的内部状态，并在改对象之外保存这个状态，这样以后就可将该对象的恢复到原先保存的状态。——行为类 备忘录模式就是一个对象的备份模式，提供了一种程序数据的备份方法，其通用类图如下： 下面简单介绍类图中的几个角色： Originator发起人角色：记录当前时刻的内部状态，负责定义哪些属于备份范围的状态，负责创建和恢复备忘录数据。 Memento备忘录角色：负责存储Originator发起人对象的内部状态，在需要的时候提供发起人需要的内部状态。 Caretaker备忘录管理员角色：对备忘录进行管理，保存和提供备忘录。 下面是它的通用源代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 发起人角色public class Originate &#123; // 内部状态 private String state = ""; public String getState() &#123; return state; &#125; public void setState(String state) &#123; this.state = state; &#125; // 创建一个备忘录 public Memento createMemento() &#123; return new Memento(this.state); &#125; // 恢复一个备忘录 public void restoreMemento(Memento _memento) &#123; this.setState(_memento.getState()); &#125;&#125;// 备忘录角色public class Memento &#123; // 发起人内部状态 private String state = ""; // 构造函数传递 public Memento(String _state) &#123; this.state = _state; &#125; public String getState() &#123; return state; &#125; public void setState(String state) &#123; this.state = state; &#125;&#125;// 备忘录管理者public class CareTaker &#123; // 备忘录对象 private Memento memento; public Memento getMemento() &#123; return memento; &#125; public void setMemento(Memento memento) &#123; this.memento = memento; &#125;&#125;// 场景类public class Client &#123; public static void main(String[] args) &#123; // 定义发起人 Originator originator = new Originator(); // 定义出备忘录管理员 Caretaker caretaker = new Caretaker(); // 创建一个备忘录 caretaker.setMemento(originator.createMemento()); // 恢复一个备忘录 originator.restoreMemento(caretaker.getMemento()); &#125;&#125; 应用使用场景 需要保存和恢复数据的相关状态场景。 提供一个可回滚的操作。 需要监控的副本场景。 数据库连接的事务管理就是用的备忘录模式。 注意事项 备忘录的生命周期 备忘录创建出来就要在“最近”的代码中使用，要主动管理它的生命周期，建立就要使用，不使用就要立刻删除其引用，等待垃圾回收器对它的回收处理。 备忘录性能 不要在频繁建立备份的场景中使用备忘录模式，原因有而：一是控制不了备忘录建立的对象数量；二是大对象的建立是要消耗资源的，系统的性能需要考虑。 扩展clone方式的备忘录发起人角色融入了发起人角色和备份路角色，利用clone()方法克隆出来的对象充当备忘录对象。但是由于存在深拷贝和浅拷贝的问题，在复杂的场景下它会让你的程序逻辑异常混乱，因此Clone方式的备忘录模式适用于比较简单的场景。 多状态的备忘录模式将多个状态转换到HashMap中，方便备忘录角色存储。 多备份的备忘录将备份的数据存入到HashMap中，并给每个不同的备份一个不同的key。 最佳实践大家主要的还是记住数据库的事务用的是备忘录模式就好了。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——门面模式]]></title>
    <url>%2F2018%2F03%2F13%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E9%97%A8%E9%9D%A2%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：怎样保证“金玉其外，败絮其中”，门面模式可以达到你的要求！ 定义要求一个子系统的外部与其内部的通信必须通过一个统一的对象进行。门面模式提供一个高层次的接口，使得子系统更易于使用。——结构类 门面模式注重统一的对象，也就是提供一个访问子系统的接口，除了这个接口不允许有任何访问子系统的行为发生，其通用类图如下： 下面简单介绍类图中的两个角色： Facade门面角色：客户端调用这个角色的方法，此角色知晓子系统的所有功能和责任。一般情况下，本角色会将所有从客户端发起的请求委派到相应的子系统去，也就是说该角色没有实际的业务逻辑，只是一个委托类。 Subsystem Classes子系统所有类角色：可以同时有一个或者多个子系统。每个子系统都不是一个单独的类，而是一个类的集合，子系统不知道门面的存在。 下面是它的通用源码：123456789101112131415161718192021222324252627282930313233343536// 子系统public class Class A &#123; public void doSomethingA() &#123; // 业务逻辑 &#125;&#125;public class ClassB &#123; public void doSomethingB() &#123; // 业务逻辑 &#125;&#125;public class ClassC &#123; public void doSomethingC() &#123; // 业务逻辑 &#125;&#125;// 门面对象public class Facade &#123; // 被委托的对象 private ClassA a = new ClassA(); private ClassB b = new ClassB(); private ClassC c = new ClassC(); // 提供给外部访问的方法 public void methodA() &#123; this.a.doSomethingA(); &#125; public void methodB() &#123; this.b.doSomethingB(); &#125; public void methodC() &#123; this.c.doSomethingC(); &#125;&#125; 应用优点 减少系统的相互依赖。所有的依赖都是对门面对象的依赖，与子系统无关。 提供了灵活性。不管子系统内部如何变化，只要不影响到门面对象，任你自由活动。 提供安全性。想让你访问子系统的那些业务就开通那些逻辑，不在门面上开通的方法，你休想访问到。 缺点门面模式最大的缺点就是不符合开闭原则，没有对修改关闭，对扩展开放。 使用场景 为一个复杂的模块或子系统提供一个供外界访问的接口。 子系统相对独立——外界对子系统的访问只要黑箱操作即可。 预防低水平人员带来的风险扩散。 注意事项 一个系统可以有多个门面。比如下面的情况： 门面已经庞大到不能忍受的程度 子系统可以提供不同访问路径 门面不参与子系统内的业务逻辑。 最佳实践门面模式是一个很好的封装方法，很多情况都可以使用到，如下面的情况： 一个子系统比较复杂，就可以封装出一个或多个门面，项目结构简单，扩展性非常好。 对于一个比较大的项目，为了避免人员带来的风险，也可以使用门面模式，技术水平差的成员，尽量安排独立的模块，然后把他写的程序封装到一个门面李，尽量让其他项目成员不用看到这些人的代码。看也看不懂，哈哈。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——观察者模式]]></title>
    <url>%2F2018%2F03%2F12%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：被观察者做出动作了，然后通知观察者做出反应。观察者模式就是这么简单！ 定义观察者模式又称发布订阅模式。 定义对象间一种一对多的依赖关系，使得每当一个对象改变状态，则所有它依赖的对象都会得到通知并被自动更新。行为类 下面是它的通用类图： 下面简单介绍一下类图中的几个角色： Subject被观察者：定义观察者必须实现的职责，它必须能够动态地增加、取消观察者。管理观察者并通知观察者。 Observer观察者：观察者接受到消息后，即进行update操作，对接收的信息进行处理。 下面是它的通用源代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// 被观察者public abstract class Subject &#123; // 定义一个观察者数组 private Vector&lt;Observer&gt; observerVector = new Vector&lt;Observer&gt;(); // 增加一个观察者 public void addObserver(Observer o) &#123; this.observerVector.add(o); &#125; // 删除一个观察者 public void deleteObserver(Observer 0) &#123; this.observerVector.remove(o); &#125; // 通知所有观察者 public void notifyObservers() &#123; for (Observer o : this.observerVector) &#123; o.update(); &#125; &#125;&#125;// 具体被观察者public class ConcreteSubject extends Subject &#123; // 具体的业务 public void doSomething() &#123; // do somthing super.notifyObservers(); &#125;&#125;// 观察者public interface Observer &#123; // 更新方法 public void update();&#125;// 具体观察者public class ConcreteObserver implements Observer &#123; // 实现更新方法 public void updatea()&#123; System.out.println("接到消息，并进行处理"); &#125;&#125;// 场景类public class Client &#123; public static void main(String[] args) &#123; // 场景一个被观察者 ConcreteSubject subject = new ConcreteSubject(); // 定义一个观察者 Observer obs = new ConcreteObserver(); // 观察者观察被观察者 subject.addObserver(obs); // 观察者开始活动了 subject.doSomething(); &#125;&#125; 应用优点 观察者和被观察者之间是抽象耦合的，不管是增加观察者都非常容易扩展。 建立一套触发机制。容易在单一职责下构建一条触发链。 缺点观察者模式需要考虑一下开发效率和运行效率问题，一个被观察者，多个观察者，开发和调试就会比较复杂，而且在Java中消息的通知默认是顺序执行的，一个观察者卡壳，会影响整体的执行效率。在这种情况下，一般考虑采用异步的方式。 使用场景 关联行为场景。这种关联行为时可以拆分的。 事件多级触发场景。 跨系统的消息交换场景，如消息队列的处理机制。 注意事项 广播链。在一个观察者模式中最多出现一个对象既是观察者又是被观察者，也就是说消息最多被转发一次。（和责任链的区别在于广播链在消息传播过程中消息是可变的） 异步处理问题。如果观察者比较多，处理时间长，我们就需要用异步。异步处理需要考虑到线程安全和队列问题。 扩展Java世界中的观察者模式在JDK中已经提供了java.util.Observable实现类（被观察者）以及java.util.Observer接口（观察者）。大家要记住在java的世界里横行时，多看看API，有很大的帮助，很多东西Java已经帮我们设计了一个良好的框架。 项目中真实的观察者模式在系统设计中会对观察者模式进行改造或改装，主要在以下3个方面： 观察者和被观察者之间的消息沟通 被观察者状态改变会触发观察者的一个行为，同时会传递一个消息给观察者，这是正确地，但是在实际中一般的做法是：观察者中update方法会接受两个参数，一个是被观察者，一个是DTO（数据传输对象），DTO一般是一个纯洁的JavaBean，由被观察者生成，由观察者消费。 观察者响应方式 为了解决观察者的快速响应有以下两个办法： 采用多线程技术 缓存技术（同步架构） 被观察者尽量自己做主 被观察者的状态改变不一定要通知观察者，所以doSomething方法可以被重载，增加一个doSomething(boolean isNotifyObs)方法，决定是否通知观察者，而不是在消息到达观察和才判断是否要消费。 订阅发布模型顾名思义就是消息的发布者发布一个消息，然后利用消息队列通知订阅者做出反应。这相当于观察者模式的升级版。 最佳实践观察者模式在实际项目中和生活中非常常见，如下面的例子： 文件系统：在一个目录下新建立一个文件，这个动作会同时通知目录管理器增加该目录。文件是一个被观察者，目录管理器是一个被观察者。 广播收音机：电台在广播，收音机在收听。电台是一个被观察者，收音机是一个被观察者。参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——组合模式]]></title>
    <url>%2F2018%2F03%2F10%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：部分类可以组成整体类，然后拥有一个统一的接口，这就是组合模式。 定义将对象组合成树形结构以表示“部分-整体”的层次结构，使得用户对单个对象和组合对象的使用具有一致性。——结构类 组合模式也叫合成模式，有时又叫做部分——整体模式，主要用来描述部分和整体的关系。下面是它的通用类图： 接下来简单介绍类图的几个类： Component抽象构建角色：定义参加组合对象的共有方法和属性，可以定义一些默认的行为或属性。 Leaf叶子构件：叶子对象，其下再也没有其他的分支，遍历的最小单位。 Composite树枝构件：树枝对象，它的作用是组合树枝节点和叶子节点形成一个树形结构。 下面是它的通用源代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// 抽象构建public abstract class Component &#123; // 个体和整体都具有的共享 public void doSomething()&#123; // 编写逻辑业务 &#125;&#125;// 树枝构件public class Composite extends Component &#123; // 构件容器 private ArrayList&lt;Component&gt; componentArrayList = new ArrayList&lt;Component&gt;(); // 增加一个叶子构件或树枝构件 public void add(Component component) &#123; this.componentArrayList.add(component); &#125; // 删除一个叶子构件或树枝构件 public void remove(Component component) &#123; this.componentArrayList.remove(component); &#125; // 获得分支下的所有叶子构件和树枝构件 public ArrayList&lt;Component&gt; getChildren() &#123; return this.componentArrayList; &#125;&#125;// 树叶节点public class Leaf extends Component &#123; public void doSomething() &#123; // 覆写父类方法 &#125;&#125;// 场景类public class Client &#123; public static void main(String[] args) &#123; // 创建一个根节点 Composite root = new Composite(); root.doSomething(); // 创建一个树枝节点 Composite branch = new Composite(); // 创建一个叶子节点 Leaf leaf = new Leaf(); // 建立整体 root.add(branch); branch.add(leaf); &#125; // 通过递归遍历树 public static void display(Composite root) &#123; for(Component c : root.getChildren()) &#123; if (c instanceof Leaf) &#123; c.doSomething(); &#125; else &#123; display((Composite) c); &#125; &#125; &#125;&#125; 我们可以从场景类看出组合模式破坏了依赖倒转原则，树枝和树叶直接使用了实现类。 应用优点 高层模块调用节点，一棵树机构中的所有节点都是Component。 节点自由增加，容易扩展，符合开闭原则。 缺点与依赖倒置原则冲突，限制了接口的影响范围。 使用场景 维护和展示部分-整体关系的场景，如树形菜单，文件和文件夹管理。 从一个整体能够独立出部分模块或功能的场景。 注意事项只要是树形结构或者体现局部和整体的关系的时候，要考虑组合模式。 最佳实践组合模式在项目中到处都有，比如页面结构，XML结构等等。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——迭代器模式]]></title>
    <url>%2F2018%2F03%2F08%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：提起迭代器，大家一定能想到Java的Iterator，不错，我们这次讲的迭代器模式就是目前大部分语言都已经实现的迭代器。 定义它提供一种方法访问一个容器对象中各个元素，而又不需要暴露该对象的内部细节。——创造类 迭代器是为容器服务的，能容纳对象的所有类型都可以称为容器。迭代器模式提供了遍历 容器的方便性，容器主要管理增减元素就可以了，需要遍历时交由迭代器进行。目前基本上不会单独写一个迭代器。下面是它的通用类图： 下面简单介绍类图中的几个角色： Iterator抽象迭代器：抽象迭代器负责定义访问和遍历元素的接口。 ConcreteIterator具体迭代器：实现迭代器接口，完成容器元素的遍历。 Aggregate抽象容器：容器角色负责提供创建具体迭代器角色的的接口，必然提供一个类似createIterator()这样的方法，在Java中一般是iterator()方法。 ConcreteAggregate具体容器：实现容器接口定义的方法，创建出容纳迭代器的对象。 下面是迭代器模式的通用源代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788// 抽象迭代器public interface Iterator &#123; // 遍历到下一个元素 public Object next(); // 是否已经遍历到尾部 public boolean hasNext(); // 删除当前指向的元素 public boolean remove();&#125;// 具体迭代器public class ConcreteIterator implements Iterator &#123; private Vector vector = new Vector(); // 定义当前游标 public int cursor = 0; @SuppressWarnings("checked") public ConcreteIterator(Vector _vector) &#123; this.vector = _vector; &#125; // 判断是否到达尾部 public boolean hasNext() &#123; if (this.cursor == this.vector.size()) &#123; return false; &#125; else &#123; return true; &#125; &#125; // 返回下一个元素 public Object next() &#123; Object result = null; if (this.hasNext()) &#123; result = this.vector.get(this.cursor++); &#125; else &#123; result = null; &#125; return result; &#125; // 删除当前元素 public boolean remove() &#123; this.vector.remove(this.cursor); return true; &#125;&#125;// 抽象容器public interface Aggregate &#123; // 是容器必然有元素的增加 public void add(Object object); // 减少元素 public void remove(Object object); // 由迭代器来遍历所有的元素 public Iterator iterator();&#125;// 具体容器public class ConcreteAggregate implements Aggregate &#123; // 容纳对象的容器 private Vector vector = new Vector(); // 增加一个元素 public void add(Object object) &#123; this.vector.add(object); &#125; // 返回迭代器对象 public Iterator iterator() &#123; return new ConcreteIterator(this.vector); &#125; // 删除一个元素 public void remove(Object object) &#123; this.remove(object); &#125;&#125;// 场景类public class Client &#123; public static void main(String[] args) &#123; // 声明容器 Aggregate agg = new ConcreteAggregate(); // 产生对象数据放进去 agg.add("abc"); agg.add("aaa"); agg.add("1234"); // 遍历一下 Iterator iterator = agg.iterator(); while(Iterator.hasNext()) &#123; System.out.println(iterator.next()); &#125; &#125;&#125; 应用只要不是在使用那些古董级的编程语言，都不用自己动手写迭代器。 最佳实践如果你是做Java开发，尽量不要自己写迭代器模式。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——适配器模式]]></title>
    <url>%2F2018%2F03%2F08%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：适配器模式在生活中非常常见，比如你的笔记本上的电源适配器，通过它笔记本可以使用在110~220V之间变化的电源，而笔记本还可以正常工作。 定义将一个类的接口变换成客户端期待的另一种接口，从而使原本因接口不匹配而无法再一起工作的两个类能够在一起工作。——结构类 下面是它的通用类图： 下面简单介绍类图中的几个类： Target目标角色：该角色定义吧其他类转化为何种接口，也就是我们期望的接口。 Adaptee源角色：需要转化的角色，通过适配器角色的包装可以成为一个新角色。 Adapter适配器角色：它的职责就是通过继承或者类关联的方式把源角色转化为目标角色。 下面是他的通过源码：123456789101112131415161718192021222324252627282930313233343536373839// 目标角色public interface Target &#123; // 目标角色有自己的方法 public void request();&#125;// 目标角色的实现类public class ConcreteTarget implements Target &#123; public void request() &#123; System.out.println("if you need any help,please call me!"); &#125;&#125;// 源角色public class Adaptee &#123; // 原有的业务逻辑 public void doSomething() &#123; System.out.println("I`m kind of busy,leave me alone,please!"); &#125;&#125;// 适配器橘色public class Adapter extends Adaptee implements Target &#123; public void request() &#123; super.doSomething(); &#125;&#125;// 场景类public class Client &#123; public static void main(String[] args) &#123; // 原有的业务逻辑 Target target = new ConcreteTarget(); target.request(); // 现在增加了适配器角色的业务逻辑 Target target2 = new Adapter(); target2.request(); &#125;&#125; 应用优点 适配器模式可以让两个没有任何关系的类一起运行 提高了类的透明性，源角色对于高层模块是透明的 提高了类的复用度，源角色在原系统中还是可以正常使用的 灵活性非常好，不需要适配器的时候删除掉这个适配器即可 使用场景当你有动机修改一个已经投产中的接口时，适配器可能是最适合的你模式。比如系统扩展了，需要使用一个已有或新建立的类，当这个类又不符合系统的接口，那么就可以使用适配器模式。 注意事项适配器模式最好在详细设计阶段不要考虑它，它不是为解决还处在开发阶段的问题，而是解决正在服役的项目问题。 最佳实践适配器模式是一个补救模式，通常用来解决接口不相容的问题。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——策略模式]]></title>
    <url>%2F2018%2F03%2F07%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：将所有方法封装起来，要用什么方法就打开什么方法，这就是策略模式。 定义定义一组算法，将每个算法都封装起来，并且使他们之间可以互换。——行为类 我们先看它的类图： 简单介绍类图中的几个类： Context封装角色，也叫上下文角色，起承上启下封装作用，屏蔽高层模块对策略、算法的直接访问。 Strategy抽象策略角色，定义每个策略或算法必须具有的方法和属性。 ConcreteStrategy具体策略角色，实现抽象策略的操作，该类含有具体的算法。 下面是它的通用源码：12345678910111213141516171819202122232425262728293031323334353637383940414243// 抽象的策略角色public interface Strategy &#123; // 策略模式的运算法则 public void doSomething();&#125;// 具体角色类public class ConcreteStrategy1 implements Strategy &#123; public void doSomething() &#123; System.out.println("具体策略1的运算法则"); &#125;&#125;public class ConcreteStrategy2 implements Strategy &#123; public void doSomething() &#123; System.out.println("具体策略2的运算法则"); &#125;&#125;// 封装角色public class Context &#123; // 抽象策略 private Strategy strategy = null; // 构造函数设置具体策略 public Context(Strategy _strategy) &#123; this.strategy = _strategy; &#125; // 封装后的策略方法 public void doAngthing() &#123; this.strategy.doSomething(); &#125;&#125;// 场景类public class Client &#123; public static void main(String[] args) &#123; // 声明一个具体的策略 Strategy strategy = new ConcreteStrategy1(); // 声明上下文对象 Context context = new Context(strategy); // 执行封装后的方法 context.doAngthing(); &#125;&#125; 策略模式实质是采用了面向对象的继承和多态机制。但是一个类实现多个接口很正常，所以识别出抽象策略接口是系统分析师的价值所在。策略模式和代理模式的区别是策略模式的封装角色和被封装的策略类不用是同一个接口。 应用优点 算法可以自由切换 避免使用多重条件判断 扩展性良好 缺点 策略类数量增多，复用可能性小 所有策略类都需要对外暴露，上层模块需要知道有哪些策略，违背了迪米特法则 使用场景 多个类只有在算法或行为上稍有不同的场景 算法需要自由切换的场景 需要屏蔽算法规则的场景 注意事项如果系统中的一个策略家族的具体策略数量超过4个，则需要考虑使用混合模式，解决策略类膨胀和对外暴露问题。 最佳实践策略模式在项目中会经常使用，但是它具有一个致命缺陷：所有的策略都需要暴露出去。在实际项目中，我们一般通过工厂方法模式来实现策略类的声明。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——装饰模式]]></title>
    <url>%2F2018%2F03%2F07%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：想给某些类增加一些功能，有些人可能会想到直接修改类，但是要求不影响子类，这就需要用到装饰模式了。 定义动态地给一个对象添加一些额外的职责。就增加功能来说，装饰模式相比生成子类更为灵活。——结构类 装饰模式和代理模式很像，它的通用类图如下： 下面简单说说类图中的4个对象： Component是一个接口或者抽象类，就是定义我们最核心的对象，也是最原始的对象。 ConcreteComponent是最核心的对象的实现，我们要装饰的就是它。 Decorator装饰对象，它里面不一定有抽象的方法，但是它的属性里必然有一个private变量指向Component。 ConcreteDecorator是装饰对象的实现类。 装饰模式的具体实现代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public abstract class Component &#123; // 抽象的方法 public abstract void operate();&#125;public class ConcreteComponent exgtends Component &#123; // 具体实现 @Override public void operate() &#123; System.out.println("do something"); &#125;&#125;// 抽象装饰类，如果只有一个装饰类，则可以没有抽象装饰者public abstract class Decorator extends Component &#123; private Component component = null; // 通过构造函数传递被修饰者 public Decorator(Component _component) &#123; this.component = _component; &#125; // 委托给被修饰者执行 @Override public void operate() &#123; this.component.operate(); &#125;&#125;// 具体装饰类public class ConcreteDecorator1 extends Decorator &#123; // 定义被修饰者 public ConcreteDecorator1(Component _component) &#123; super(_component); &#125; // 定义自己的修饰方法 private void method1() &#123; System.out.println("method1 修饰"); &#125; // 重写父类的operate方法 public void operate() &#123; this.method1(); super.operate(); &#125;&#125;public class ConcreteDecorator2 extends Decorator &#123; // 定义被修饰者 public ConcreteDecorator2(Component _component) &#123; super(_component); &#125; // 定义自己的修饰方法 private void method2() &#123; System.out.println("method2 修饰"); &#125; // 重写父类的operate方法 public void operate() &#123; this.method2(); super.operate(); &#125;&#125;// 场景类public class Client &#123; public static void main(String[] args) &#123; Component component = new ConcreteComponent(); // 第一次修饰 component = new ConcreteDecorator1(component); // 第二次修饰 component = new ConcreteDecorator2(component); // 修饰后运行 component.operate(); &#125;&#125; 应用优点 装饰类和被修饰类可以独立发展，而不会相互耦合。 装饰模式是继承关系的一个替代方案。 装饰模式可以动态地扩展一个实现类的功能。 缺点多层的装饰是比较复杂的。 使用场景 需要扩展一个类的功能，或给一个类增加附加功能。 需要动态地给一个对象增加功能，这些功能可以再动态地撤销的。 需要为一批兄弟类进行改装或加装功能。 最佳实践 装饰模式是对继承的有力补充。 在业务变更的时候，增强类的功能。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——责任链模式]]></title>
    <url>%2F2018%2F03%2F07%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：一个问题对应一个解决方法，你一般需要去找到对应的方法，现在有一种方法就是你不管遇到什么问题只要交给第一个解决方法就可以了，美滋滋，这就是责任链模式。 定义使多个对象都有机会处理请求，从而避免了请求的发送者和接受者之间的耦合关系。将这些对象连成一条链，并沿着这条链传递该请求，直到有对象处理它为止。——行为类 责任链模式的重点在“链”上，由一条链去处理相似的请求在链中决定谁来处理这个请求，并返回相应的结果。其通用类图如下： 责任链模式的核心在链上，“链”是由多个处理者ConcreteHandle组成的，它的通用源码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394// 抽象处理者public abstract class Handler &#123; private Handler nextHandler; // 每个处理者都必须对请求做出处理 public final Response handleMessage(Request request) &#123; // final关键字参考模板模式的模板方法 // 判断是否是自己的处理级别 if (this.getHandlerLevel().equals(request.getRequestLevel())) &#123; response = this.echo(request); &#125; else &#123; // 不属于自己的处理级别 // 判断是否有下一个处理者 if (this.nextHandler != null) &#123; response = this.nextHandler.handleMessage(request); &#125; else &#123; // 没有适当处理者，业务自行处理 &#125; &#125; return response; &#125; // 设置下一个处理者 public void setNext(Handler _handler) &#123; this.nextHandler = _handler; &#125; // 每个处理者都有一个处理级别 protect abstract Level getHandlerLevel(); //每个处理者都必须实现处理任务 protect abstract Response echo(Request request);&#125;// 具体处理者public class Concretehandler1 extends Handler &#123; // 定义自己的处理逻辑 protected Response echo(Request request) &#123; // 完成处理逻辑 return null; &#125; // 设置自己的处理级别 protected Level getHandlerLevel() &#123; // 设置自己的处理级别 return null; &#125;&#125;public class Concretehandler2 extends Handler &#123; // 定义自己的处理逻辑 protected Response echo(Request request) &#123; // 完成处理逻辑 return null; &#125; // 设置自己的处理级别 protected Level getHandlerLevel() &#123; // 设置自己的处理级别 return null; &#125;&#125;public class Concretehandler3 extends Handler &#123; // 定义自己的处理逻辑 protected Response echo(Request request) &#123; // 完成处理逻辑 return null; &#125; // 设置自己的处理级别 protected Level getHandlerLevel() &#123; // 设置自己的处理级别 return null; &#125;&#125;// 模式中有关框架代码public class Level &#123; // 定义一个请求和处理等级&#125;public class Request &#123; // 请求的等级 public Level getRequestLevel() &#123; return null; &#125;&#125;publci class Request &#123; // 处理者返回的数据&#125;// 场景类public class Client &#123; public static void main(String[] args) &#123; // 声明所有的处理节点 Handler handler1 = new ConcreteHandler1(); Handler handler2 = new ConcreteHandler2(); Handler handler3 = new ConcreteHandler3(); // 设置链中的阶段顺序1--&gt;2--&gt;3 handler1.setNext(handler2); handler2.setNext(handler3); // 提交请求，返回结果 Response response = handler1.handlerMessage(new Request()); &#125;&#125; 在实际应用中，一般会有一个封装类对责任模式进行封装，直接返回链中的第一个处理者，具体链的设置不需要高层模块关系，这样，简化了高层次模式的调用，减少模块间的耦合，提高系统的灵活性。 应用优点将请求和处理分开，请求者可以不用知道谁处理的，处理者可以不用知道请求的全貌，两者解耦。 缺点 性能问题，每个请求都是从链头遍历到链尾，在链比较长的时候，性能就会出现问题。 调试不方便，调试逻辑复制。 注意事项链中节点数量需要控制，避免出现超长链的情况，一般做法是在Handler中设置一个最大节点数量，在setNext方法中判断是否已经超过其阈值，超过则不允许该链建立。 最佳实践 融合模板方法模式，每个实现类只要实现两个方法：echo方法处理请求和getHandlerLevel获得处理级别，符合单一职责原则和迪米特法则。 责任链模式的核心它屏蔽了请求的处理过程，只要你把请求抛给责任链的第一个处理者，最终会返回一个处理结果，作为请求者不用知道需要谁来处理。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——命令模式]]></title>
    <url>%2F2018%2F03%2F06%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：作为领导人只要发布命令即可，而不用在发布命令的时候还要去找到实施的人，我相信领导人一定超级高兴，因为实施的人已经包含在命令里了。这就是命令模式。 定义将一个请求封装成一个对象，从而让你使用不同的请求把客户端参数化，对请求排队或者记录请求日志，可以提供命令的撤销和恢复功能。——行为类 命令模式是一个高内聚模式。它的封装性非常好，把请求方（Invoker）和执行方（Receiver）封开了。 它的通用类图如下： 通用代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677// 通用Receiver类public abstract class Receiver &#123; // 抽象接收者，定义每个接收者都必须完成的业务 public abstract void doSomething();&#125;// 具体的Receiver类，可以是N个，和业务有关public class ConcereteReceiver1 extends Receiver &#123; // 每个接收者都必须处理一定的业务逻辑 public void doSomething()&#123;&#125;&#125;public class ConcereteReceiver2 extends Receiver &#123; // 每个接收者都必须处理一定的业务逻辑 public void doSomething()&#123;&#125;&#125;// 抽象的Command类public abstract class Command &#123; // 每个命令类都必须有一个执行命令的方法 public abstract void execute();&#125;// 具体的Command类public class ConcreteCommand1 extends Command &#123; //关联，对哪个Receiver类进行命令处理 private Receiver receiver; // 构造函数传递接收者 public ConcreteCommand1(Receiver _receiver) &#123; this.receiver = _receiver; &#125;; // 必须实现一个命令 public void execute() &#123; // 业务处理 this.receiver.doSomething(); &#125;&#125;public class ConcreteCommand2 extends Command &#123; //关联，对哪个Receiver类进行命令处理 private Receiver receiver; // 构造函数传递接收者 public ConcreteCommand2(Receiver _receiver) &#123; this.receiver = _receiver; &#125;; // 必须实现一个命令 public void execute() &#123; // 业务处理 this.receiver.doSomething(); &#125;&#125;// 调用者Invoker类public class Invoker &#123; private Command command; // 接受命令 public void setCommand(Command _command) &#123; this.command = _command; &#125; // 执行命令 public void action()&#123; this.command.execute(); &#125;&#125;// 场景类public class Client &#123; public static void main(String[] args) &#123; // 首先声明调用者Invoker Invoker invoker = new Invoker(); // 定义接收者 Receiver receiver = new ConcreteReceiver1(); // 定义一个发送给接受者的命令 Command command = new ConcreteCommand1(receiver); // 把命令交给调用者去执行 invoker.setCommand(command); invoker.action(); &#125;&#125; 应用优点 类间解耦：调用者与接收者之间没有任何依赖关系，调用者实现功能时只需要调用Command抽象类的execute方法即可，不需要了解是哪个接收者执行。 可扩展性：Command的子类非常容易扩展。 命令模式结合其他模式会更优秀，例如责任链模式，模板方法模式。 缺点有N个命令就会有N个Command的子类，这样这个类就会膨胀了。 使用场景只要是你认为是命令的地方就可以采用命令模式。 最佳实践根据开发场景要求可以有多个接收者，那就需要用集合类型来封装Command类了。该设计模式最大的优点就是高层模式不需要知道接收者，Perfect！ 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——中介者模式]]></title>
    <url>%2F2018%2F02%2F10%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E4%B8%AD%E4%BB%8B%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：多个对象相互依赖，关系错综复杂，我们经常会感到无从下手，如果这个时候出现一个对象，能够协调各个对象的关系，并且其他对象只要与这个对象交流，那还不是美滋滋，这就是中介者模式。 定义用一个中介对象封装一系列的对象交互，中介者使各对象不需要显示地相互作用，从而使其耦合松散，而且可以独立得改变他们之间的交互。——行为类 它的通用类图如下： 从类图中看，中介者模式由以下几部分组成： Mediator抽象中介者角色：定义统一的接口，用于各同事角色之间的通信。 ConcreteMediator具体中介者角色：依赖于各个同事角色，协调各同事角色实现协作行为。 Colleague同事角色：每一个同事角色都知道中介者角色，而且与其他的同时角色通信的时候，一定要通过中介者角色协作。同事类的行为分两种：一是同事本身的行为（本身行为），二是必须依赖中介者才能完成的行为（依赖方法）。 它的通用源码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 通用抽象中介者// 在该抽象类中，我们利用了同事实现类注入，是因为同事类虽然有抽象，但是没有每个同事必须要实现的方法。public abstract class Mediator &#123; // 定义同事类 protect ConcreteColleague1 c1; protect ConcreteColleague2 c2; // 通过getter/setter方法吧同事类注入进来 ... 省略get、set方法 // 中介者模式的业务逻辑 public abstract void doSomething1(); public abstract void doSomething2();&#125;// 通用中介者public class ConcreteMediator extend Mediator &#123; @Override public void doSomething1() &#123; // 调用同事类的方法 super.c1.selfMethod1(); super.c2.selfMethod2(); &#125; @Override public void doSomething2() &#123; // 调用同事类的方法 super.c1.selfMethod1(); super.c2.selfMethod2(); &#125;&#125;// 抽象同事类public abstract class Colleague &#123; protected Mediator mediator; public Colleague(Mediator _mediator) &#123; this.mediator = _mediator; &#125;&#125;// 具体同事类 1,2 类似public class ConcreteColleague1 extends Colleague &#123; // 通过构造函数传递中介者，因为同事类必须要有中介者 public ConcreteColleague1(Mediator _mediator) &#123; super(_mediator); &#125; // 自有方法 public void selfMethod1()&#123; // 处理自己的业务逻辑 &#125; // 依赖方法 public void depMethod1()&#123; // 自己不能处理的业务逻辑，委托给中介者处理 super.mediator.doSomething1(); &#125;&#125; 应用优点减少类间的依赖，把原有的一对多的依赖变成了一对一的依赖。 缺点同事类越多，中介者的逻辑就越复杂。 使用场景中介者模式适用于多个对象之间紧密耦合的情况，紧密耦合的标准是：在类图中出现了蜘蛛网状结构。在这种情况下一定要考虑使用中介者模式，这有利于把蜘蛛网梳理为星型结构，使原本复杂混乱的关系变得清晰简单。但是我们需要量力而行，避免中介者过于复杂化。 实际应用 机场调度中心 MVC框架的C协调M和V 媒体网关——中转站 中介服务 最佳实践可以在如下的情况下尝试使用中介者模式: N个对象之间产生相互的依赖关系（N &gt; 2） 多个对象有依赖关系，但是依赖的行为尚不确定或者有发生改变的可能。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——原型模式]]></title>
    <url>%2F2018%2F02%2F10%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：由一个正本创建多个副本，并可以进行适当的修改，这就是原型模式。 定义用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。——创造类 下面是它的通用类图： 原型模式的核心是一个clone方法，通过该方法进行对象的拷贝，Java提供了一个Cloneable接口标识这个对象是可拷贝的，在JVM中具有这个标识的对象才有可能被拷贝，但是只有在覆盖clone方法之后才可以被拷贝。 它的通用代码如下：1234567891011121314151617181920212223242526// 抽象原型类public abstract class Prototype implements Cloneable &#123; // 覆写父类Object方法 @Override public Prototype clone() &#123; Prototype prototype = null; try &#123; prototype = (Prototype) super.clone(); &#125; catch (CloneNotSupportedException e) &#123; // 异常处理 &#125; return prototype; &#125;&#125;// 具体原型类public class ConcretePrototype extends Prototype &#123;&#125;// 场景类public class Client &#123; Prototype prototype = new ConcretePrototype(); // 复制一个对象 Prototype prototype1 = prototype.clone();&#125; 应用优点 性能优良。原型模式是在内存二进制流的拷贝，要比直接new一个对象性能好的多，特别是要在一个循环体内产生大量的对象时， 逃避构造函数的约束。是优点也是缺点。 使用场景 资源优化场景。因为类的初始化需要消耗非常多的资源。 性能和安全要求的场景。因为通过new产生一个对象需要非常繁琐的数据准备和访问权限。 一个对象多个修改者。这样次就能避免并发带来数据混乱的问题。 原型模式很少单独出现，一般是与工厂方法模式一起出现，通过clone的方法创建一个对象，然后由工厂方法提供给调用者。 注意事项 构造函数不会执行。因为Object类的clone方法的原理是从内存中以二进制流的方式进行拷贝，重新分配一个内存块。 浅拷贝和深拷贝 浅拷贝：只拷贝本对象，其对象内部的数组、引用对象等都不拷贝，还是指向原生对象的内部元素地址。 深拷贝：在浅拷贝的基础上，对私有的类变量进行独立的拷贝。 使用原型模式时，引用的成员变量必须满足两个条件才不会被拷贝：一是类的成员变量，二是必须是一个可变的引用对象。 对象的clone和对象内的final关键字是有冲突的。要使用clone方法，类的成员变量上不要增加final关键字。 最佳实践原型模式先产生一个包含大量信息的类，然后可以拷贝出副本，修正细节信息，建立了一个完整的个性对象。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——代理模式]]></title>
    <url>%2F2018%2F02%2F09%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：如果你不想干就找个代理帮你干好了，就像游戏不想自己升级就找个代理帮你升级好了，这就是代理模式。 定义为其他对象提供一种代理以控制对这个对象的访问。——结构类。 它的通用类图如下： 我们可以看到类图中的三个角色： Subject抽象主题角色：它可以是抽象类也可以是接口，是一个最普通的业务类型定义。 RealSubject具体主题角色：也叫做被委托角色、被代理角色。 Proxy代理主题角色：也叫做委托类、代理类。它负责对真实角色的应用，把所有抽象主题类定义的方法限制委托给真实主题角色实现，并且在真实主题角色处理完毕前后做预处理和善后处理工作。 下面是它的通用实现代码：12345678910111213141516171819202122232425262728293031323334353637383940414243// 抽象主题类public interface Subject &#123; // 定义一个方法 public void request();&#125;// 真实主题类public class RealSubject implements Subject &#123; // 实现方法 @Override public void request() &#123; // 业务逻辑处理 &#125;&#125;// 代理类public class Proxy implements Subject &#123; // 要代理哪个实现类 private Subject subject = null; // 默认被代理者 public Proxy() &#123; this.subject = new Proxy(); &#125; // 通过构造函数传递被代理者 public Proxy(Subject _subject) &#123; this.subject = _subject; &#125; // 实现接口中定义的方法 @Override public void request() &#123; this.before(); this.subject.request(); this.after(); &#125; // 预处理 private void before() &#123; // do something &#125; // 善后处理 private void after() &#123; // do something(); &#125;&#125; 应用优点 职责清晰，真实的角色就是实现实际的业务逻辑，不用关心其他非本职责的事务，通过后期的代理完成一件事务。 高扩展性，无论具体角色怎么变化。 使用场景典型的Spring AOP 扩展普通代理要求只能访问代理角色，而不能访问真实角色，真实角色的创建是在代理的内部创建的。在该模式下，调用者只知代理而不用知道真实的角色是谁，屏蔽了真实角色的变更对高层模块的影响。 ps：在实际项目中，一般是通过约定来禁止new一个真实的角色。 强制代理要求必须通过真实角色找到一个代理角色，否则不能直接访问，即要求真实角色有一个赋予自己一个代理的方法。 代理增强一个类可以实现多个接口，代理类也可以实现多个主题接口，实现不同的任务。而且代理的目的是在目标对象方法的基础上做增强，这种增强的本质通常是对目标对象的方法精心拦截和过滤。代理类可以为真是角色预处理消息、过滤消息、消息转发、事后处理消息等功能、 动态代理动态代理是在实现阶段不用关心代理谁，而是在运行阶段才指定代理哪一个对象，即面向切面编程，也叫AOP。 下面是它的通用类图： 两条独立发展的线路。动态代理实现代理的职责，业务逻辑Subject实现相关的逻辑功能，两者没有必然的相互耦合的关系。通知Advice从另一个切面切入，最终在高层模块Client进行耦合，完成逻辑的封装任务。下面是他的通用实现代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768// 抽象主题public interface Subject &#123; // 业务操作 public void doSomething(String str);&#125;// 真实主题public class RealSubject implements Subject &#123; // 业务操作 public void doSomething(String str) &#123; System.out.println("do Something!----&gt;" + str); &#125;&#125;// 动态代理的Handlerpublic class MyInvocationHandler implements InvocationHandler &#123; // 被代理的对象 private Object target = null; // 通过一个构造函数传递一个对象 public MyInvocationHandler(Object _obj) &#123; this.target = _obj; &#125; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; return method.invoke(this.target,args); &#125;&#125;// 动态代理类public class DynamicProxy&lt;T&gt; &#123; public static &lt;T&gt; T newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) &#123; // Spring AOP知识。 if (true) &#123; // 执行一个前置通知 (new BeforeAdvice()).exec(); &#125; // 执行目标，并返回结果 return (T) Proxy.newProxyInstance(loader,interfaces,h); &#125;&#125;// 通知接口及实现public interface IAdvice &#123; // 通知只有一个方法，执行即可 public void exec();&#125;public class BeforeAdvice implements IAdvice &#123; public void exec() &#123; System.out.println("我是前置通知，我被执行了！"); &#125;&#125;// 动态代理的场景类public class Client &#123; public static void main(String[] args) &#123; // 定义一个主题 Subject subject = new RealSubject(); // 定义一个Handler InvocationHandler invocationHandler = new MyInvocationHandler(subject); // 定义主题的代理 Subject proxy = DynamicProxy.newProxyInstance(subject.getClass().getClassLoader(),subject.getClass().getInterfaces(),invocationHandler); // 代理的行为 proxy.doSomething("Finish"); &#125;&#125;// 输出我是前置通知，我被执行了！do Something!----&gt;Finish subject.getInterfaces()是查找该类的所有接口，然后实现接口的所有方法，然后又InvocationHandler实现该类的所有的方法，由其invoke方法接管所有方法的实现。其动态调用过程如下： Client -&gt; dynamicProxy -&gt; MyInvocationHandler -&gt; RealSubject 从上面可以看出要实现动态代理的首要条件时：被代理类要实现一个接口。 最佳实践代理模式应用得非常广泛，大到一个系统框架、企业平台，小到代码片段、事务处理，都会用到代理模式。特别是在Sping AOP里面，如果调试看到$Proxy()这个东西，它应该就是一个动态代理了。 在学习AOP框架时，弄清楚几个名词就成：切面（Aspect）、切入点（JoinPoint）、通知（Advice）、织入（weave）就足够了。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——建造者模式]]></title>
    <url>%2F2018%2F02%2F08%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：生产一个产品，它必然有很多零部件，不同的组装顺序和零部件个数可能会导致不同的产品，通过控制这些顺序与个数可以达到快速生成不同产品的目的，就可以使用建造者模式。 定义建造者模式也叫做生成器模式。 将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。——创造类 通用类图如下： 在建造者模式中，有如下4个角色： Product产品类：通常是实现了模板方法模式，也就是有模板方法和基本方法。这个可以看之前写的模板方法模式。 Builder抽象建造者：规范产品的组件，一般是由子类实现。 ContreteBuilder具体建造者：实现抽象类定义的所有方法，并返回一个组建好的对象。 Director导演类：负责安排已有模块的顺序，然后告诉Builder开始建造。 我们可以看到下面的源码：12345678910111213141516171819202122232425262728293031323334353637383940// 产品类 通常由模板方法模式实现public class Product &#123; // 一个方法相当于产品的一个零件 public void doSomething() &#123; // 独立业务处理 &#125;&#125;// 抽象建造者public abstract class Builder &#123; // 设置产品的不同部分(包括零件种类和顺序)，以获得不同的产品 public abstract void setPart(); // 建造产品 public abstract Product bulidProduct();&#125;// 具体建造者public class ContreteBuilder extends Builder &#123; private Product product = new Product(); @Override public void setPart() &#123; // 产品类内部逻辑 &#125; @Override public Product buildProduct() &#123; return product; &#125;&#125;// 导演类，起到封装的作用，避免高层模块深入到建造者内部的实现类。public class Director &#123; private Builder builder = new ContreteBuilder(); public Product getProduct() &#123; builder.setPart(); return builder.buildProduct(); &#125;&#125; 应用优点 封装性，使用建造者模式可以使客户端不必知道产品内部组成的细节。 建造者独立，容易扩展。 使用场景 相同方法，不同执行顺序，产生不同事件结果时，可以采用建造者模式。 多个部件或零件，都可以装配到一个对象中，但是产生不同的效能，可以使用建造者模式。 产品类中的调用顺序不同产生不同的效能，可以使用建造者模式。 注意事项建造者模式关注的是零件类型和装配工艺（顺序），这是它与工厂方法模式最大不同的地方。 最佳实践在使用建造者模式的时候考虑一下模板方法模式，别孤立地思考一个模式，僵化得套用一个模式会让你受害无穷。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——模板方法模式]]></title>
    <url>%2F2018%2F02%2F08%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：少写代码，大家一定觉得很有吸引力。而且还是先确定一个框架，再写其中的部分，这么结构清晰地写代码，大家一定会觉得更有吸引力，那么我想模板方法模式可以达到你的需求。 定义定义一个操作中的算法的框架，而将一些步骤延迟到子类中。使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。——行为类 下面是他的通用类图： 其中AbstractClass叫做抽象模板，它的方法分为两类： 基本方法：由子类实现的方法，并且在模板方法被调用。 模板方法：一般是一个具体方法，实现对基本方法的调度，完成固定的逻辑。 为了防止恶意的操作，一般模板方法都加上final关键字，不允许被覆写。 而ConcreteClass属于具体模板，实现父类所定义的抽象方法。 下面再看看他的通用代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// 抽象模板类public abstract class AbstrctClass &#123; // 基本方法 protected abstract void doSomething(); // 基本方法 protected abstract void doAngthing(); // 模板方法 final public void templateMethod() &#123; // 调用基本方法，完成相关逻辑 this.doAnything(); this.doSomething(); &#125;&#125;// 具体模板类public class ContreteClass1 extends AbstractClass &#123; // 实现基本方法 @Override protected void doAngthing() &#123; // 业务逻辑处理 &#125; @Override protected void doSomething() &#123; // 业务逻辑处理 &#125;&#125;public class ContreteClass2 extends AbstractClass &#123; // 实现基本方法 @Override protected void doAngthing() &#123; // 业务逻辑处理 &#125; @Override protected void doSomething() &#123; // 业务逻辑处理 &#125;&#125;// 场景类public class Client &#123; public static void main (String[] args) &#123; AbstractClass class1 = new ConcreteClass1(); AbstractClass class2 = new ConcreteClass2(); // 调用模板方法 class1.templateMethod(); class2.templateMethod(); &#125;&#125; 抽象模板中的基本方法尽量设计为protected类型，符合迪米特原则。实现类若非必要，尽量不要扩大父类中的访问权限。 应用优点 封装不变部分，扩展可变部分。 提取公共部分代码，便于维护。 行为由父类控制，子类实现。符合开闭原则。 缺点是优点也是缺点：子类对父类产生了影响。 使用场景 多个子类有公有的方法，并且逻辑基本相同。 重要、复杂的算法，可以把核心算法设计为模板方法，周边的相关细节功能则由各个子类实现。 重构时，模板方法模式一个常用的模式，把相同的代码抽取到父类中，然后通过钩子函数约束其行为。有了钩子方法的模板方法模式才是完美的。 ps：钩子方法就是子类实现的一个方法，可以利用其返回值决定公共部分的执行结果。 最佳实践 父类如何调用子类的方法（极度不建议这么做） 把子类传递到父类的有参构造函数中，然后调用。 使用反射的方式调用。 父类调用子类的静态方法。 但是通过模板方法模式就可以变相地实现父类调用子类的方法。 在开源框架中，它提供了一个抽象类，然后开源框架写了一堆子类。如果你需要扩展，可以继承这个抽象类，然后覆写protected方法，再调用一个类似execute方法，就完成了扩展开发。相信大家一定深有感触。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——抽象工厂模式]]></title>
    <url>%2F2018%2F02%2F07%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：在开发应用的时候为了适应不同的操作系统以及不同数据库时，我们总会显得力不从心。而抽象工厂模式为了我们提供了优秀的解决方案。 定义为创建一组相关或相互依赖的对象提供一个接口，而且无须指定他们的具体类。——创造类 它的通用类图如下： 为了展示通用的源代码，将原来的通用类图扩展为如下类图： 下面是基于类图的代码:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273// 抽象产品类 ProductA与ProductB类似;1,2代表产品等级public abstract class AbstractProductA &#123; // 每个产品共有方法 public void shareMethod() &#123; ... &#125; // 每个产品相同方法，不同实现 public abstract void doSomething();&#125;// 产品A1的实现类public class ProductA1 extends AbstractProductA &#123; @Override public void doSomething() &#123; System.out.println("产品A1的实现方法"); &#125;&#125;// 产品A2的实现类public class ProductA2 extends AbstractProductA &#123; @Override public void doSomething() &#123; System.out.println("产品A2的实现方法"); &#125;&#125;// 抽象工厂类 有N个产品族，在抽象工厂类就有N个创建方法public abstract class AbstractCreator &#123; // 创建A产品家族 public abstract AbstractProductA createProductA(); // 创建B产品家族 public abstract AbstractProductB createProductB();&#125;// 有M个产品等级就应该有M个实现工厂类，在每个实现工厂中，实现不同产品族的生产任务// 产品等级1的实现类public class Creator1 extends AbstractCreator &#123; // 只生产产品等级为1的A产品 public AbstractProductA createProductA() &#123; retrurn new ProductA1(); &#125; // 只生产产品等级为1的B产品 public AbstractProductB createProductB() &#123; retrurn new ProductB1(); &#125;&#125;// 产品等级2的实现类public class Creator2 extends AbstractCreator &#123; // 只生产产品等级为2的A产品 public AbstractProductA createProductA() &#123; retrurn new ProductA2(); &#125; // 只生产产品等级为2的B产品 public AbstractProductB createProductB() &#123; retrurn new ProductB2(); &#125;&#125;// 场景类public class Client &#123; public static void main(String[] args) &#123; // 定义两个工厂 AbstractCreator creator1 = new Creator1(); AbstractCreator creator2 = new Creator2(); // 产生A1对象 AbstractProductA a1 = creator1.createProductA(); // 产生A2对象 AbstractProductA a2 = creator2.createProductA(); // 产生B1对象 AbstractProductB b1 = creator1.createProductB(); // 产生B2对象 AbstractProductB b2 = creator2.createProductB(); &#125;&#125; 主要是要理解产品族以及产品等级的关系。 应用优点 封装性，它只需要了解接口。 产品族的约束为非公开状态。 缺点扩展非常困难。如果要新增一个产品，需要修改AbstractCreator类以及它的实现类。这严重违反了开闭原则。 使用场景如果一个对象族都有相同的约束，就可以使用抽象工厂模式。例如linux和windows下得编辑器和不同数据库的规范操作。 注意事项上面的扩展困难是指产品族扩展困难，但是产品等级扩展还是容易的。 最佳实践在涉及不同操作系统，不同数据库的时候非常适合抽象工厂模式，因为它可以屏蔽掉操作系统或数据库对应用的影响。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——工厂方法模式]]></title>
    <url>%2F2018%2F02%2F06%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：在面向对象的思维中，万物皆对象，就像有女蜗造人，我们也可以用工厂方法模式造对象。 定义定义一个用于创建对象的接口，让子类决定实例化哪一个类。工厂方法使一个类的实例化延迟到子类。——创造类 工厂方法模式的通用类图如下： 下面是一个比较实用的通用源码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// 抽象产品类public abstract class Product &#123; // 产品类的公共方法 public void method1() &#123; // 业务逻辑处理 &#125; //抽象方法 public abstract void method2();&#125;// 具体产品类public class ContreteProduct1 extends Product &#123; @Override public void method2() &#123; // 业务逻辑处理 &#125;&#125;public class ContreteProduct2 extends Product &#123; @Override public void method2() &#123; // 业务逻辑处理 &#125;&#125;// 抽象工厂类public abstract class Creator &#123; /* * 创建一个产品对象，其输入参数类型可以自行设置 * 通常为String, Enum, Class等，当然也可以为空 */ public abstract &lt;T extends Product&gt; T createProduct(Class&lt;T&gt; c);&#125;// 具体工厂类public class ContreteCreator extends Creator &#123; public abstract &lt;T extends Product&gt; T createProduct(Class&lt;T&gt; c) &#123; Product product = null; try &#123; product = (Product) Class.forName(c.getName()).newInstance(); &#125; catch (Exception e) &#123; // 异常处理 &#125; return （T）product; &#125;&#125;// 场景类public class Client &#123; public static void main(String[] args) &#123; Creator creator = new ContreteCreate(); Product product = creator.createProduct(ContreteProduct1.class); /* * 继续业务处理 */ &#125;&#125; 应用优点 良好的封装性，代码结构清晰。 扩展性非常优秀，要增加一个新的产品，只要实现Product接口。 屏闭产品类。只要关心产品的接口即可，例如换数据库只要换驱动即可。 符合迪米特法则（只要知道产品的接口即可）；符合依赖倒置原则（值依赖产品的抽象类即可）；符合里氏替换原则（使用产品子类可以替换产品父类）。 使用场景 只要使用new的地方都可以使用工厂方法模式，但是要考虑代码的复杂度。 需要灵活的，可扩展的框架时（有多个产品可选且可以随时增加时），可以考虑工厂方法模式。 工厂方法模式可以用在异构项目中。 可以使用在测试驱动开发的框架下。 工厂方法模式的扩展 缩小为简单工厂模式 实质是去掉了创造者接口，使具体创造者直接依赖产品接口。缺点是扩展比较困难，不符合开闭原则。 升级为多个工厂类 实质是为了结构清晰，我们为每个产品定义一个创造者，然后由调用者自己去选择与那个工厂方法关联。 替代单例模式 代码如下： 123456789101112131415161718192021public class SingletonFactory &#123;private static Singleton singleton;static &#123; try &#123; Class c1 = Class.forName(Singleton.class.getName()); // 获得无参构造 Constructor constructor = c1.getDeclaredConstructor(); //设置无参构造是可访问的 constructor.setAccessible(true); // 产生一个实例对象 singleton = (Singleton) constructor.newInstance(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125;public static Singleton getSingleton() &#123; return singleton;&#125;&#125; 延迟初始化 所谓延迟初始化即一个对象被消费完毕后，并不立刻释放，工厂类保持其初始状态，等待再次被使用。其实质，是利用一个Map保存创造过的对象，如果在Map容器已经有的对象，则直接取出返回；如果没有，则根据需要的类型产生一个对象并放入到Map容器中，以方便下次调用。 最佳实践孰能生巧，熟练掌握该设计模式，多思考工厂方法如和应用，而且工厂方法模式可以与其他模式混合使用，变化出无穷的优秀设计。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之禅——单例模式]]></title>
    <url>%2F2018%2F02%2F06%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%E2%80%94%E2%80%94%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[引：如果每个人可以走的路只有一条，如果每个人想要的东西都是一个(单例模式)，那么人应该都不会迷茫了吧。虽然解决了迷茫，但是也抹杀了多样性，有好有坏，各有所见。 定义确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例。——创造类 下面是它的通用类图： 代码实现有两种，如下：12345678910111213// 饿汉式单例 线程安全public class Singleton &#123; private static final Singleton = new Singleton(); // 限制产生多个对象 private Singleton() &#123; ... &#125; // 通过该方法获得实例对象 public static Singleton getSingleton() &#123; return singleton; &#125; // 类中其他方法尽量是static public static void doSomething &#123; ... &#125;&#125; 12345678910111213141516// 懒汉式单例 线程不安全public class Singleton &#123; private static final Singleton = null; // 限制产生多个对象 private Singleton() &#123; ... &#125; // 通过该方法获得实例对象 public static Singleton getSingleton() &#123; if (singleton = null) &#123; singleton = new Singleton(); &#125; return singleton; &#125; // 类中其他方法尽量是static public static void doSomething &#123; ... &#125;&#125; 应用优点 减少内存开支 减少系统的性能开销 避免对资源的多重占用 缺点 扩展困难，由于它需要自行实例化 不利于测试，由于单例没完成，不能测试 与单一职责有冲突 使用场景 要求生成唯一序列号的环境 在整个项目中需要一个共享访问带你或共享数据 创建一个对象需要消耗的资源过多，如访问IO和数据库 需要定义大量的静态常量和静态方法（如工具类）的环境 注意事项 在高并发的情况下，请注意单例模式的线程同步问题，选择合适的实现模式。 不可以复制，即不实现Cloneable接口。 最佳实践在Spring中，每个Bean默认就是单例的，这样的优点是Spring容器可以管理这些Bean的生命周期，决定什么时候销魂，销毁的时候要如何处理，等等。如果采用非单例模式，则Bean初始化后的管理交由J2EE容器，Spring容器不在跟踪管理Bean的生命周期。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[先吹响口号_6大设计原则]]></title>
    <url>%2F2018%2F02%2F01%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E5%85%88%E5%90%B9%E5%93%8D%E5%8F%A3%E5%8F%B7-6%E5%A4%A7%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[引：先有6大设计原则，后有23种设计模式。让我们先吹响这先行的口号。 单一职责原则 SRP定义就一个类或接口而言，应该有且只有一个原因引起类的变更。 例子关于电话通话的接口，有三个过程：拨号、通话、挂机。代码如下：12345678public interface IPhone &#123; //拨通电话 public void dial(String phoneNumber); //通话 public void chat(Onbject o); //挂机 public void hangup();&#125; 但是IPhone这个接口不是只有一个职责，它包含了两个职责：一个是协议管理，一个是数据传送。所以我们改为下面设计的类图： 好处 类的复杂性降低，实现什么职责都有清晰明确的定义 可读性提高，复杂度降低，那当然可读性提高了 可维护性提高，可读性提高了，那当然更容易维护了 变更引起的风险降低 最佳实践接口一定要做到单一职责，类的设计尽量做到只有一个原因引起变化。 里氏替换原则 LSP定义 正宗定义：如果对每一个类型为S的对象o1，都有类型为T的对象o2，使得以T定义的所有程序P在所有的对象o2都代换成o1时，程序P的行为没有发生变化，那么类型S是类型T的子类型。（感觉《Java设计模式之禅》的翻译错误） 通俗定义：所有引用基类的地方必须能透明地使用其子类的对象（只要父类能出现得地方子类就可以出现；有子类出现的地方，父类未必能适应）。 规则 子类必须完全实现父类的方法。（如果子类不能完整地实现子类的方法，或者父类的某些方法在子类中已经发生“畸变”，则建议断开父子继承关系，采用依赖、聚合、组合灯关系来代替继承。） 子类可以有自己的个性。 覆盖或实现父类的方法时输入参数可以被放大。（子类中方法的前置条件（方法中输入参数）必须与超类中被覆写的方法的前置条件相同或者更宽松。） 覆写或实现父类的方法时输出结果可以被缩小。 疑问（多态是否违背LSP？）如果继承的目的是为了多态，而多态的前提就是子类覆盖并重新定义父类的方法，为了符合LSP，我们应该将父类定义为抽象类，并定义抽象方法，让子类重新定义这些方法，当父类是抽象类时，父类就是不能实例化，所以也不存在可实例化的父类对象在程序里。也就不存在子类替换父类实例时逻辑不一致的可能。 最佳实践在项目中，采用里氏替换原则时，尽量避免子类的“个性”，一旦子类有了“个性”，这个子类和父类之间的关系就难调和，把子类当做父类使用，子类的“个性”被抺杀了，把子类单独作为一个业务来使用，则会让代码间的耦合关系变得扑朔迷离–缺乏类替换的标准。 依赖倒置原则 DIP定义高层模块不应该依赖底层模块，两者都应该依赖其抽象。抽象不应该依赖细节。细节应该依赖抽象。（不可以分割的原子逻辑就是底层模块，原子逻辑的再组装就是高层模块。抽象就是指接口或抽象类。细节就是实现类。） Java语言表现：模块间的依赖通过抽象产生，实现类之间不发生直接的依赖关系，其依赖关系是通过接口或抽象类产生的。接口或抽象类不依赖实现类。实现类依赖接口或抽象类。——面向接口编程(OOD)。 依赖的三种写法 构造函数传递依赖对象(构造函数注入) 123456789101112131415public interface IDriver &#123; public void drive();&#125;public class Driver implements IDriver &#123; private ICar car; //构造函数注入 public Drive(ICar _car) &#123; this.car = _car; &#125; public void drive() &#123; this.car.run(); &#125;&#125; Setter方法传递依赖对象（Setter依赖注入） 12345678910111213141516public interface IDriver &#123; public void setCar(ICar car); public void drive();&#125;public class Driver implements IDriver &#123; private ICar car; //setter注入 public void setCar(ICar car) &#123; this.car = car; &#125; public void drive() &#123; this.car.run(); &#125;&#125; 接口声明依赖对象(接口注入) 12345678910public interface IDriver &#123; public void drive(ICar car);&#125;public class Driver implements IDriver &#123; //接口注入 public void drive(ICar car) &#123; car.run(); &#125;&#125; 最佳实践 每个类尽量都有接口或抽象类，或者抽象类和接口两者都具备。 变量的表面类型（定义的类型）尽量是接口或者是抽象类。 任何类都不应该从具体类派生。 尽量不要覆写基类的方法。 结合里氏替换原则使用（多态） 我们在实际的项目中使用依赖倒置原则需要审时度势，不哟啊抓住一个原则不放，每一个原则的优点都是有限度的，并不是放之四海而皆准的真理，所以别为了遵循一个原则而放弃了一个项目的终极目标：投产上线和盈利。 接口隔离原则 ISP定义客户端不应该依赖他不需要的接口。类间的依赖关系应该建立在最小的接口上。（实例接口：class；类接口：interface） 约束 接口要尽量小。（根据接口隔离原则拆分接口时，首先必须要满足单一职责原则。） 接口要高内聚。（在接口中尽量少公布public方法。） 定制服务。（设计时需要为各个访问者定制服务（接口）。） 接口设计时有限度的。（接口的设计粒度要协调开发难度和可维护性。） 最佳实践 一个接口只服务于一个子模块或业务逻辑。 通过业务逻辑压缩接口中的public方法，经常回顾接口。 已经被污染的接口，尽量去修改，如果变更风险较大，则采用适配器模式进行转化处理。 了解环境，拒绝盲从。 迪米特法则 LoD LKP定义一个对象应该对其他对象有最少的了解。（类解耦） 含义 只与朋友交流 朋友类的定义：出现在成员变量、方法的输入输出参数的类称为成员朋友类。 所以在原类的方法中不能出现非朋友的类，JDK API提供的类除外。 朋友间也是有距离的 尽量不要对外公布太多的public方法和非静态的public变量。 是自己的就是自己的 如果过一个方法放在本类中，既不增加类间关系，也对本类不产生负面影响，那就放置在本类中。 谨慎使用Serializable 防止客户端和服务器端类不同步。 最佳实践迪米特法则的核心是类间解耦，弱耦合，只有弱耦合了以后，类的复用率才可以提高。其要求的结果就是产生大量的中转或跳转类，导致系统的复杂性提高，同时也为维护带来了难度，在采用迪米特法则时需要反复权衡，既做到让结构清晰，又要做到高内聚低耦合。当一个类跳转两次以上才能访问到另一个类，就需要重构了。 开闭原则 OCP定义一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。 PS: 3W原则（what：是什么；why：为什么；How：怎么做） 是什么开闭原则告诉我们应该尽量通过扩展软件实体来实现变化，而不是通过修改已有的代码来完成变化，它是为软件实体的未来事件而制定的对现行开发设计进行的约束规则。 开闭原则对扩展开放，对修改关闭，并不以为着不做任何修改，低层模块的变更，必然要有高层模块的进行耦合，否则就是一个孤立无意义的代码片段。 一个项目的基本路径：项目开发、重构、测试、投产、运维，其中的重构可以对原有的设计和代码进行修改，运维尽量减少对原有代码的修改，保持历史代码的纯洁性，提高系统的稳定性。 为什么 简化测试：如果改变软件内容, 需要将所有的测试流程都执行一遍, 如 单元测试, 功能测试, 集成测试等, 如果只是扩展, 只单独测试扩展部分即可。 提高复用性：所有逻辑都从原子逻辑组合, 原子逻辑粒度越小, 复用性越大; 这样避免相同逻辑存在, 修改时需要修改多个此相同逻辑。 提高可维护性：维护一个类最好的方式是扩展一个类, 而不是修改一个类, 如果需要修改需要读懂源码才能修改, 扩展的话只需要了解即可, 直接继承扩展。 怎么做 抽象约束 通过接口或抽象类可以约束一组可能变化的行为，并且实现对扩展开放。其中包括三层含义：第一，通过接口或抽象类约束扩展，对扩展进行边界设定，不允许出现在接口或抽象类不存在的public方法；第二，参数类型，引用对象尽量使用接口或者抽象类，而不是实现类；第三，抽象层尽量保持稳定。 元数据控制模块行为 通过配置参数（从文件或者数据库中来）来控制行为，例如spring配置文件的构造函数注入配置。 制定项目章程 约定优于配置。 封装变化 对变化的封装包含两层含义：第一，将相同的变化封装到一个接口或抽象类中；第二，将不同的变化封装到不同的接口或抽象类中。23个设计模式都是从各个不同的角度对变化进行封装的。 最佳实践 开闭原则只是一个原则，适当时候也可以进行补充。 项目规章非常重要。 预知变化，项目需要具有可扩展性。 总结把上面6大原则的首字母（里氏替换原则和迪米特法则的首字母重复，只取一个）联合起来就是SOLID（稳定的），其代码的含义就是把这6个原则结合使用的好处：建立稳定灵活，健壮的设计，而开闭原则又是重中之中，是最基础的原则，是其他5大原则的精神领袖。 参考 《设计模式之禅》]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UML_Java类图]]></title>
    <url>%2F2018%2F01%2F27%2F%E5%B7%A5%E5%85%B7%2FUML-Java%E7%B1%BB%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[引：在看源码或者很多技术书籍的时候都避免不了看到类图，时间长了总会忘了含义，在这里就总结一下，方便以后回顾。这里使用的工具是startUML。 UMLUML： 统一建模语言（Unified Modeling Language）。在 UML 系统开发中有三个主要的模型： 功能模型：从用户的角度展示系统的功能，包括用例图。 对象模型：采用对象，属性，操作，关联等概念展示系统的结构和基础，包括类图、对象图、包图。 动态模型：展现系统的内部行为。包括时序图，活动图，状态图。 类图类图使用类来描述系统的静态结构，类图包含类和它们之间的关系，它描述系统内所声明的类，但它没有描述系统运行时类的行为。 在UML类图中，类一般由三部分组成：类名、属性以及操作。 类名每个类都必须有一个名字，类名是一个字符串。 属性属性是指类的性质，即类的成员变量。类可以有任意多个属性，也可以没有属性。 格式为： 【可见性】 属性名 【：类型】 【=初始值】 【{属性字符串}】 可见性：在UML中public类型用符号“+”表示，private类型用“-”表示，protected类型用“#”表示。 属性字符串：用来指定关于属性的其他信息，任何希望添加属性定义字符串但又没有合适地方可以加入的规则都可以放在属性字符串里，例如类变量。 操作操作是类的任意一个实例对象都可以使用的行为，操作是类的成员方法。 格式为：【可见性】 操作名 【{参数列表}】 【：返回类型】 【{属性字符串}】 类之间的关系关联关系关联关系(Association)是类与类之间最常用的一种关系，它是一种结构化关系，用于表示一个类与另一个类之间有联系。 在 UML 类图中，用实线连接有关联的的类。在实现关联关系时，通常将一个类的对象作为另一个类的属性。 单向关联类的关联关系可以是单向的，单向关联用带箭头的实线表示。如下图：1234567public class Person &#123; private Address address;&#125;public class Address &#123;&#125; 双向关联默认情况下，关联是双向的。如下图：1234567public class Order &#123; private Product product;&#125;public class Product &#123; private Order order;&#125; 自关联在系统中可能会存在一些类的属性对象类型为该类本身，这种特殊的关联关系称为自关联。如下图：123public class Node &#123; private Node node;&#125; 重数性关联重数性关联关系又称为多重性关联关系，表示一个类的对象与另一个类的对象连接的个数。在 UML 中多重性关系可以直接在关联直线上增加一个数字表示与之对应的另一个类的对象的个数。如下图： 其中数字的种类及含义如下表： 表示方式 表示含义 1..1 表示另一个类的一个对象只与一个该类对象有关系 0..* 表示另一个类的一个对象与零个或多个该类对象有关系 1..* 表示另一个类的一个对象与一个或多个该类对象有关系 0..1 表示另一个类的一个对象没有或只与一个该类对象有关系 m..n 表示另一个类的一个对象与最少m、最多n个该类对象有关系 (m&lt;=n) 聚合关系聚合关系表示一个整体与部分的关系。通常在定义一个整体类后，再去找出这个整体类的一些成员类，该整体类和成员类之间就形成了聚合关系。 在聚合关系中，成员类是整体类的一部分，即成员对象是整体对象的一部分，但是成员对象可以脱离整体对象独立存在。在UML中，聚合关系用带空心菱形的直线表示。如下图：123456789101112131415public class Car &#123; private Engine engine; public Car(Engine engine) &#123; this.engine = engine; &#125; public setEngine(Engine engine) &#123; this.engine = engine; &#125;&#125;public class Engine &#123;&#125; 组合关系组合关系也表示类之间整体和部分的关系，但是组合关系中部分和整体具有统一的生存期。一旦整体对象不存在，部分对象也将不存在，部分对象与整体对象之间具有同生共死的关系。 在组合关系中，成员类是整体类的一部分，而且整体类可以控制成员类的生命周期，即成员类的存在依赖于整体类。在UML中，组合关系用带实心菱形的直线表示。如下图：1234567891011public class Head &#123; private Eye eye; public Head() &#123; this.eye = new Eye(); &#125;&#125;public class Eye &#123;&#125; 依赖关系依赖关系是一种使用关系，特定事物的改变有可能会影响到使用该事物的其他事物，在需要表示一个事物使用另一个事物时使用依赖关系。大多数情况下，依赖关系体现在某个类的方法使用另一个类的对象作为参数。在UML中，依赖关系用带箭头的虚线表示，由依赖的一方指向被依赖的一方。如下图：1234567891011public class Driver &#123; public drive(Car car) &#123; car.move(); &#125;&#125;public class Car &#123; public move() &#123; ... &#125;&#125; 泛化关系泛化关系也就是继承关系，也称为“is-a-kind-of”关系，泛化关系用于描述父类与子类之间的关系。在UML中，泛化关系用带空心三角形的直线来表示。如下图： 实现关系实现关系是类实现了接口，类中的操作实现了接口中所声明的操作。在UML中，类与接口之间的实现关系用带空心三角形的虚线(mac中的startUML画不出来，大家将就着看)来表示。如下图： 总结理解类图有助于我们更好的去看技术书籍，以及源码，这是必备技能，get it！ 参考 UML 及 StarUml]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>UML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发_12_原子变量与非阻塞同步机制]]></title>
    <url>%2F2018%2F01%2F25%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%2FJava%E5%B9%B6%E5%8F%91-12-%E5%8E%9F%E5%AD%90%E5%8F%98%E9%87%8F%E4%B8%8E%E9%9D%9E%E9%98%BB%E5%A1%9E%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[引：原子变量与非阻塞同步机制相比于基于锁的方案可以拥有更高的性能和可伸缩性。 锁的劣势 通过使用一致的锁定协议来协调对共享状态的访问，可以确保无论哪个线程持有守护变量的锁，都能采用独占方式来访问这些变量，并且对变量的任何修改对随后获得这个锁的其他线程都是可见的。但是当在锁上存在激烈的竞争时，调度开销与工作开销的比值会非常高。 volatile变量是一种更轻量级的同步机制，但是虽然他们提供了相似的可见性保证，但不能用于构建原子的复合操作。因此，当一个变量依赖其他的变量时，或者当变量的新值依赖旧值时，就不能使用volatile。 硬件对并发的支持 独占锁是一种悲观技术——它假设最坏的情况，并且只有在确保其他线程不会找出干扰的情况下才能执行下去。 比较并交换（CAS，硬件指令）是一种乐观的技术——通过这种方法可以在不发生干扰的情况下完成更新操作，不过这种方法需要借助检查机制来判断在更新过程中是否存在其他线程的干扰，如果存在，这个操作将失败，并且可以重试（也可以不重试）。 下面是模拟CAS操作代码：1234567891011121314151617181920// CAS含义：我认为V的值应该是A，如果是，那么把值更新为B，否则不修改并告诉V的值实际是多少public class SimulatedCAS &#123; private int value; public synchronized int get() &#123; return value; &#125; public synchronized int compareAndSwap(int expectedValue, int newValue) &#123; int oldValue = value; if (oldValue == expectedValue) &#123; value = new Value; &#125; return oldValue; &#125; public synchronized boolean compareAndSet(int expectedValue, int newValue) &#123; return (expectedValue == compareAndSwap(expectedValue, newValue)); &#125;&#125; CAS的优点：当竞争程序不高时，性能远远高于基于锁的方案。 CAS的缺点：它将使调用者处理竞争问题（通过重试、回退、放弃），而在锁中能自动处理竞争问题（线程在获得锁之前将一直阻塞）。 原子变量类原子变量类在发生竞争的情况下能提供更高的可伸缩性，因为它直接利用了硬件对并发的支持（比较并交换指令）。 共有12个原子变量类：可分为四组：标量类、更新器类、数组类以及复合变量类。最常用的原子变量类就是标量类：AtomicInteger、AtomicLong、AtomicBoolean以及AtomicReference。 原子变量与锁适用的不同并发场景： 在中低程序的竞争、锁占用时间不长的情况下，原子变量能提供更高的可伸缩性。 而在高强度的竞争下，锁能够更有效的地避免竞争。 非阻塞算法无阻塞算法： 如果在某种算法中，一个线程的失败或者挂起不会导致其他线程也失败或挂起，那么这种算法就被称为无阻塞算法。 无锁算法： 如果在算法的每个步骤中都存在某个线程能够执行下去，那么这种算法被称为无锁算法。 如果在算法中仅将CAS用于协调线程之间的操作，并且能正确地实现，那么它既是无阻塞算法，又是无锁算法。 利用CAS并发指令可以实现非阻塞的同步容器，例如实现非阻塞的栈、非阻塞的链表以及原子的域更新器等。 总结 非阻塞算法通过底层的并发原语（例如比较并交换）来维持线程的安全性。这些底层的原语通过原子变量类向外公开，从而为整数和对象引用提供原子的更新操作。 在JVM从一个版本升级到下一个版本的过程中，并发性能主要提升都来自于对非阻塞算法的使用。 参考 《Java并发编程实战》]]></content>
      <categories>
        <category>Java并发编程实战</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发_11_构建自定义同步工具]]></title>
    <url>%2F2018%2F01%2F24%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%2FJava%E5%B9%B6%E5%8F%91-11-%E6%9E%84%E5%BB%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[引：创建状态依赖的类的最简单的方法通常是在类库中现有状态依赖类的基础上进行构造。但如果类库没有提供你需要的功能，我们还可以使用Java语言和类库提供的底层机制来构造自己的同步机制，包括内置的条件队列、显式的Condition对象以及AbstractQueuedSynchronizer框架。 状态依赖性管理程序在做某一个操作之前，需要依赖另一个操作的完成或者状态的就绪，这样的一种关系就叫做“状态依赖”。 状态依赖的实现类,例如FutureTask、Semaphore和BlockingQueue等。在这些类的一些操作中有着基于状态的前提条件，例如，不能从一个空队列删除元素，或者获取一个尚未结束的任务的计算结果，在这些操作可以执行之前，必须等待队列进入“非空”状态，或者任务进入“已完成”状态。 依赖状态的操作可以一直阻塞直到可以继续执行，这比使他们先失败再实现起来要更为方便且更不容易出错。而内置的条件队列就可以是线程一直阻塞，直到对象进入某个线程可以继续执行的状态，并且当被阻塞的线程可以执行时再唤醒他们。 使用条件队列条件队列：它使得一组线程（称之为等待线程集合）能够通过某种方式来等待特定的条件变为真。传统的队列是一个个数据，而与之不同的是，条件队列中的元素是一个个正在等待相关条件的线程。 Object中的wait、notify和notifyAll方法构成了内部条件队列的API。 对象的内置锁与内部条件是相互关联的，要调用对象X中的条件队列的任何一个方法，必须持有对象X上的锁。 Object.wait会自动释放锁，并请求操作系统挂起当前线程，从而使其它线程能够获得这个锁并修改对象的状态。当被挂起的线路醒来时，它将在返回之前重新获取锁。（需要重新竞争，并没有优先获取权） 使用条件队列构造有界缓存示例如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960//未加任何约束的缓冲队列public abstract class BaseBoundedBuffer&lt;V&gt; &#123; private final V[] buf;//缓存 private int tail;//队尾 private int head;//队首 private int count;//元素个数 protected BaseBoundedBuffer(int capacity) &#123; this.buf = (V[]) new Object[capacity]; &#125; protected synchronized final void doPut(V v) &#123;//入队 buf[tail] = v;//在队尾添加 if (++tail == buf.length)//如果满了，从头开始 tail = 0; ++count; &#125; protected synchronized final V doTake() &#123;//出队 V v = buf[head];//从队首取出 buf[head] = null;//GC if (++head == buf.length)//如果到尾了，则从头开始 head = 0; --count; return v; &#125; public synchronized final boolean isFull() &#123;//队列是否满 return count == buf.length; &#125; public synchronized final boolean isEmpty() &#123;//队列是否空 return count == 0; &#125;&#125;@ThreadSafepublic class BoundedBuffer&lt;V&gt; extends BaseBoundedBuffer&lt;V&gt; &#123; // 条件谓词：not-full(!isFull()) // 条件谓词：not-empty(!isEmpty()) public BoundedBuffer(int size) &#123; super(size); &#125; // 阻塞并直到: not-full public synchronized void put(V v) throws InterruptedException &#123; while (isFull())//如果满，则等待 wait(); doPut(v); notifyAll();//并在放入后马上通知其他线程 &#125; // 阻塞并直到: not-empty public synchronized V take() throws InterruptedException &#123; while (isEmpty())//如果为空，则等待 wait(); V v = doTake(); notifyAll(); return v; &#125;&#125; 条件谓词条件谓词是使某个操作成为状态依赖操作的前提条件。在有界缓存中，只有当缓存不为空时，take方法才能执行，否则必须等待。对take方法来说，它的条件谓词就是“缓存不为空”，take方法在执行之前必须首先测试该条件谓词。 条件等待存在的三元关系： 包括加锁、wait方法和一个条件谓词。在条件谓词中包含多个包含多个状态变量，而状态变量由一个锁来保护，因此在测试条件谓词之前必须先持有这个锁，锁对象与条件队列对象（即调用wait和notify等方法所在的对象）必须是同一个对象。 每一次wait调用都会隐式地与特定的条件谓词关联起来。当调用某个特定条件谓词的wait时，调用者必须已经持有与条件队列相关的锁，并且这个锁必须保护着构成条件谓词的状态变量。 过早唤醒wait方法的返回并不一定意味着线程正在等待的条件谓词已经变真了，因为也许是因为与同一条件队列相关的另一个条件谓词变成了真。 当使用条件等待时要满足的条件（Object.wait或Condition.wait） 通常都有一个条件谓词——包括一些对象状态的测试，线程在执行前必须首先通过这些测试。 在调用wait之前测试条件谓词，并且从wait中返回时再次进行测试。 在一个循环中调用wait。 确保使用与条件队列相关的锁来保护构成条件谓词的各个状态变量。 当调用wait/notify/notifyAll等方法时，一定要持有与条件队列相关的锁。 在检查条件谓词之后以及开始执行相应的操作之前，不要释放锁。 丢失的信号丢失的信号： notify或者notifyAll操作发生在wait之前，就会造成通知信号的丢失，最终wait永远都得不到恢复或者不得不等待下一次重新通知而延迟了恢复时间。 通知每当在等待一个条件时，一定要确保在条件谓词变为真时通过某种方式发出通知 发出通知的线程应该尽快地释放锁，从而确保正在等待的线程尽可能快地解除阻塞。如果这些等待中线程此时不能重新获得锁，那么无法从wait返回。 只有同时满足以下两个条件时，才能用单一的notify而不是notifyAll： 所有等待线程的类型都相同。只有一个条件谓词与条件队列相关，并且每个线程在wait返回后将执行相同的操作。 单进单出。在条件变量上的每次通知，最多只能唤醒一个线程来执行。 显式的Condition对象内置条件队列的局限性：每个内置锁都只能有一个相关联的条件队列，因而在像BoundBuffer这种类中，多个线程可能在同一个条件队列上等待不同的条件谓词，并且在最常见的加锁模式下公开条件队列对象。 显示条件队列的优势：可以编写一个带有多个条件谓词的并发对象，或者获得除了条件队列可见性之外的更多控制权，这是一种灵活的选择；对于每个Lock，可以有任意数量的Condition对象。Condition对象继承了相关的Lock对象的公平性，对于公平的锁，线程会依照FIFO顺序从Condition await中释放。 特别注意：Condition对象中，三个与条件队列相关的API是：await,signal,signalAll。 下面是使用显示的Condition对象实现的有界缓存:123456789101112131415161718192021222324252627282930313233343536373839public class ConditionBoundedBuffer&lt;T&gt; &#123; protected final Lock lock = new ReentrantLock(); private final Condition notFull = lock.newCondition();//条件：count &lt; items.length private final Condition notEmpty = lock.newCondition();//条件：count &gt; 0 private final T[] items = (T[]) new Object[100]; private int tail, head, count; public void put(T x) throws InterruptedException &#123; lock.lock(); try &#123; while (count == items.length) notFull.await();//等到条件count &lt; items.length满足 items[tail] = x; if (++tail == items.length) tail = 0; ++count; notEmpty.signal();//通知读取等待线程 &#125; finally &#123; lock.unlock(); &#125; &#125; public T take() throws InterruptedException &#123; lock.lock(); try &#123; while (count == 0) notEmpty.await();//等到条件count &gt; 0满足 T x = items[head]; items[head] = null; if (++head == items.length) head = 0; --count; notFull.signal();//通知写入等待线程 return x; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; AbstractQueuedSynchronizerAbstractQueuedSynchronizer是一个用于构建锁和同步器的框架，许多同步器都可以通过AQS很容易并且高效地构造出来。例如：ReentrantLock、Semaphore、CountDownLatch、ReentrantReadWriteLock、SynchronousQueue和FutureTask。 下面是AQS中获取操作和释放操作的标准形式：1234567891011121314151617181920212223boolean acquire() throws InterruptedException&#123; while (当前状态不允许获取操作) &#123; if (需要阻塞获取请求) &#123; 如果当前线程不在队列中，则将其插入队列 阻塞当前线程 &#125; else 返回失败 &#125; 可能更新同步器的状态 如果线程位于队列中，则将其移出队列 返回成功&#125;void release()&#123; 更新同步器的状态 if (新的状态允许某个被阻塞的线程获取成功) 解除队列中一个或多个线程的阻塞状态&#125; 总结要实现一个依赖状态的类——如果没有满足依赖状态的前提条件，那么这个类的方法必须阻塞，那么最好的方式是基于现有类库来构建，例如Semaphore.BlockingQueue或CountDownLatch。然而，有时候现有的类库不能提供足够的功能，在这种情况下，可以使用内置的条件队列、显式的Condition对象或者AbstractQueuedSynchronizer来构建自己的同步器。内置条件队列与内置锁是紧密绑定在一起的，这是因为管理状态依赖性的机制必须与确保状态一致性的机制关联起来。同样，显式的Condition与显式地Lock也是紧密地绑定在一起的，并且与内置条件队列相比，还提供了一个扩展的功能集，包括每个锁对应于多个等待线程集，可中断或不可中断的条件等待，公平或非公平的队列操作，以及基于时限的等待。 参考 《Java并发编程实战》]]></content>
      <categories>
        <category>Java并发编程实战</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发_10_显示锁]]></title>
    <url>%2F2018%2F01%2F24%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%2FJava%E5%B9%B6%E5%8F%91-10-%E6%98%BE%E7%A4%BA%E9%94%81%2F</url>
    <content type="text"><![CDATA[引：Java5.0以后提供了一种新的协调对共享对象的访问机制——ReentrantLock。它并不是用来替代内置锁的方法，而是当内置加锁不适用时，作为一种可选择的高级功能。 ReentrantLockReentrantLock实现了Lock接口，并提供了与synchronized相同的互斥性和内存可见性，但是通常能提供更好的活跃性或性能。下面是Lock接口代码：12345678public interface Lock &#123; void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();&#125; 为什么要创建一种与内置锁如此相似的新加锁价值？是由于内置锁具有以下的局限性： 无法中断一个正在等待获取锁的线程。 内置锁必须在获取锁的代码块中释放，这就简化了编码工作，并且与异常处理操作实现了很好的互动，但却无法实现非阻塞结构的加锁规则。 下面是Lock接口的标准使用形式：123456789Lock lock = new ReentrantLock();...lock.lock();try &#123; //更新对象状态 //捕获异常，并在必要时恢复不变性条件&#125; finally &#123; lock.unlock(); //“定时炸弹”，一定要记得释放Lock&#125; 轮询锁与定时锁可定时的与可轮询的锁获取模式是由tryLock方法实现的，与无条件的锁获取模式相比，它具有更完善的错误恢复机制。在内置锁中，死锁是一个严重的问题，恢复程序的唯一办法是重新启动程序，而防止死锁的唯一方法就是在构造程序时避免出现不一致的锁顺序。可定时的与可轮询的的锁提供了另一种选择，避免死锁的发生。通过重新获取及释放锁来避免死锁。 可中断的锁操作获取操作可中断的锁操作获取操作是有lockInterruptibly或者tryLock方法实现的，如果在可中断的锁获取操作中抛出了InterruptedException，那么可以使用标准的try-finally加锁模式。 非块结构的加锁我们通过Lock的使用结构可以知道，我们通过ReentrantLock可以灵活的实现锁的粒度。 公平性大多数情况下，非公平锁的性能要高于公平锁的性能，原因是后者为了实现公平，会有更多的线程上下文切换成本。 当持有锁的时间较长，或者请求锁的平均时间间隔较长，那么应该使用公平锁。在这些情况下，允许“插队”带来的吞吐量提升（当锁处于可用的状态时，线程却还处于被唤醒的过程中）则可能不会出现。 在synchronized和ReentrantLock之间进行选择在一些内置锁无法满足需求的情况下，ReentrantLock可以作为一种高级工具。当需要一些高级功能时才应该使用ReentrantLock，这些功能包括：可定时的、可轮询的与可中断的锁获取操作，公平队列（默认非公平），以及非块结构的锁。否则，还是应该优先使用synchronized。 读-写锁在读-写锁的加锁策略中，允许多个读操作同时进行，但每次只允许一个写操作。 ReentrantReadWriteLock为读锁和写锁都提供了可重入的加锁语义。ReentrantReadWriteLock在构造时可以选择是一个非公平的锁（默认）还是一个公平的锁。在公平的锁中，等待时间最长的线程将优先获得锁。在非公平的锁中，线程获得访问许可的顺序是不确定的。写线程可以降级为读线程，但是读线程不可以升级为写线程（因为多个读线程都不会放弃自己的读取锁而导致死锁）。 适用场景： 当锁的持有时间较长并且大部分操作都不会修改被守护的资源时，那么读-写锁能提高并发性。如果写操作也很频繁，那可能独占锁更合适一些，因为写操作太多，竞争会很激烈，再加上协调读写锁，性能反而不如独占锁了。 下面展示用读-写锁来包装Map：123456789101112131415161718192021222324252627282930public class ReadWriteMap&lt;K, V&gt; &#123; private final Map&lt;K, V&gt; map; private final ReadWriteLock lock = new ReentrantReadWriteLock(); private final Lock r = lock.readLock(); private final Lock w = lock.writeLock(); public ReadWriteMap(Map&lt;K, V&gt; map) &#123; this.map = map; &#125; public V put (K key, V value) &#123; w.lock(); try &#123; return map. put(key, value); &#125; finally &#123; w.unlock(); &#125; &#125; // 对remove(),putAll(),clear()等方法执行同样的操作 public V get(Object key) &#123; r.lock(); try &#123; return map.get(key); &#125; finally &#123; r.unlock(); &#125; &#125; // 对其他只读的Map方法执行相同的操作&#125; 总结 与内置锁相比，显示的Lock提供了一些扩展功能，在处理锁的不可用性方法有着更高的灵活性。但ReentrantLock不能完全替代synchronized，只有在synchronized无法满足需求时，才应该使用它。 读-写锁运行多个读线程并发地访问被保护的对象，当访问以读取操作为主的数据结构时，它能提高程序的可伸缩性。 参考 《Java并发编程实战》]]></content>
      <categories>
        <category>Java并发编程实战</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发_9_性能和可伸缩性]]></title>
    <url>%2F2018%2F01%2F24%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%2FJava%E5%B9%B6%E5%8F%91-9-%E6%80%A7%E8%83%BD%E5%92%8C%E5%8F%AF%E4%BC%B8%E7%BC%A9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[引：线程最主要的目的是提高程序的运行性能，虽然我们希望获得更好的性能，但始终要把安全性放在第一位。首先要保证程序的正常运行，然后仅当程序的性能需求和测试结果要求程序执行得更快时，才应该设法提高它的运行速度 性能和可伸缩性提升性能意味着用更少的资源做更多的事。这些资源包括CPU时钟周期、内存、网络带宽、I/O带宽、数据库请求、磁盘空间以及其他资源。 尽管就是用多个线程的目标是提升整体性能，但与单线程相比，使用多个线程会引入一些额外的开销。造成这些开销的操作包括：线程之间的协调（例如加锁、触发信号以及内存同步等），增加上下文切换，线程的创建和销毁、以及线程的调度等。 为了通过并发获得更好的性能，需要： 更有效地利用现有处理资源 在出现新的处理资源时使程序尽可能地利用这些新资源 从性能监视角度来看，CPU需要尽可能保持忙绿状态 应用程序性能的衡量指标 服务时间、等待时间用于衡量程序的“运行速度”，即某个指定的任务单元需要“多快”才能处理完成。 生产量、吞吐量用于衡量程序的“处理能力”，即在给定计算机资源的情况下，能完成“多少”工作。 性能的提高就是使应用程序，1）对任务单元的处理速度更快，2）资源一定的情况下，完成更多的工作 可伸缩性定义当增加计算资源时（例如CPU、内存、存储容量或I/O带宽），程序的吞吐量或者处理能力能相应地增加。 评估各种性能权衡因素服务器应用程序的指标是可伸缩性、吞吐量和生成量；交互式应用程序指标是多快。 避免不成熟的优化（由于需求不明确），首先使程序正确，然后再提高运行速度——如果它还运行得不够快。 Amdahl定律Amdahl定律： 在增加计算资源的情况下，程序在理论上能够实现最高加速比，这个值取决于可并行组件与串行组件所占的比重。假定F是必须被串行执行的部分，那么根据Amdahl定律，在包含N个处理器的机器中，最高的加速比为：1Speedup &lt;= 1 / ( F + (1-F) / N ) 当N趋近于无穷大时，最大的加速比趋近于1/F。因此，如果程序有50%的计算需要串行执行，那么最高的加速比只能是2（而不管有多少个线程可用） 注意：在所有并发程序中都包含一些串行部分。 我们评估一个算法时，要考虑算法在数百个或数千个处理器的情况下的性能表现，从而对可能出现的可伸缩性局限有一定程度的认识。 线程引入的开销在多个线程的调度和协调过程中都需要一定的性能开销：对于为了提升性能而引入的线程来说，并行带来的性能提升必须超过并发导致的开销。 上下文切换如果可运行的线程数大于CPU数量，那么操作系统最终会将某个运行的线程调度出来，从而使其他线程能够使用CPU，这将导致一次上下文切换，在这个过程中将保存当前运行线程的执行上下文，并将新调度进来的线程的执行上下文设置为当前上下文。 当线程由于等待某个发生竞争的锁而被阻塞时，JVM通常会将这个线程挂起，并允许它被交换出去。如果线程频繁地发生阻塞，那么他们将无法使用完整的调度时间片。在程序中发生越多的阻塞，CPU密集型的程序就会发生越多的上下文切换，从而增加调度开销，并因此而降低吞吐量。 内存同步同步操作的性能开销包括多个方面。在synchronized和volatile提供的可见性保证中可能会使用一些特殊的指令，即内存栅栏。内存栅栏可以刷新缓存，使缓存无效，刷新硬件的写缓冲，以及停止执行管道。内存栅栏可能同样会对性能带来间接地影响，应为它会抑制一些编译器的优化。在内存栅栏中，大多数操作是不能被重排序的。 不要过度担心非竞争同步带来的开销。这个基本的机制已经非常快了，并且JVM还能进行额外的优化以进一步降低或开销。因此，我们应该将优化的重点放在那些发生锁竞争的地方。 阻塞当在锁上发生竞争时，竞争失败的线程肯定会阻塞，JVM在实现阻塞行为时，可以采用自旋等待（指通过循环不断尝试获取锁，直到成功）或者通过操作系统挂起被阻塞的线程。这两种方式的效率高低，要取决于上下文切换的开销以及在成功获取锁之前需要等待的时间。 等待时间较短：适合采用自旋等待方式 等待时间较长：适合采用线程挂起方式 减小锁的竞争串行操作会降低可伸缩性，并且上下文切换也会降低性能。在锁上发生竞争时将同时导致这两种问题，因此减少锁竞争会提高性能和可伸缩性。 在并发程序中，对可伸缩性的最主要威胁就是独占方式的资源锁。 有两个因素将影响在锁上发生竞争的可能性： 锁的请求频率 每次持有锁的时间 如果两者的乘积很小，那么大多数获取锁的操作都不会发生竞争。 有三种方式可以降低锁的竞争程度： 减少锁的持有时间 降低锁的请求频率 使用带有协调机制的独占锁，这些机制允许更高的并发性 缩小锁的范围（“快进快出”）其实质是减少锁的持有时间。，同时根据Amdahl定律，这样消除了限制可伸缩性的一个因素，因为串行代码的总量减少了。 注意： 在实际情况中，仅当可以将一些“大量”的计算或阻塞操作从同步代码块移出时，才应该考虑同步代码块的大小。 减小锁的粒度另一种减小锁的持有时间的方式是降低线程请求的频率（从而减小发生竞争的可能性）。这可以通过锁分解和锁分段等技术来实现。 锁分解如果一个需要保护多个相互独立的状态变量，那么可以将这个锁分解为多个锁，并且每个锁只保护一个变量，从而提高可伸缩性，并最终降低每个锁的请求频率。看到下面的代码变化：123456789// 原代码：通过内置锁保护了users和queries两个状态变量public class ServerStatus &#123; public final Set&lt;String&gt; users; public final Set&lt;String&gt; queries; public synchronized void addUser(String u) &#123; users.add(u); &#125; public synchronized void addQuery(String q) &#123; queries.add(q); &#125;&#125; 123456789101112131415161718// 修改代码：通过锁分解分开保护了users和queries两个状态变量public class ServerStatus &#123; public final Set&lt;String&gt; users; public final Set&lt;String&gt; queries; public void addUser(String u) &#123; synchronized (users) &#123; users.add(u); &#125; &#125; public void addQuery(String q) &#123; synchronized (queries) &#123; queries.add(q); &#125; &#125;&#125; 对竞争适中的锁进行分解时，实际上是把这些转变为非竞争的锁，从而有效地提高性能和可伸缩性。 锁分段由于在一个拥有多个处理器的系统中，锁分解仍然无法给可伸缩性带来极大的提高，这个时候就出来锁分段技术。 锁分段： 将锁分解技术进一步扩展为对一组对象上的锁进行分解。 例子：在ConcurentHashMap的实现中使用了一个包含16个锁的数组，每个锁保护所有散列桶的1/16，其中第N个散列桶有第（N mod 16）个锁来保护。正是这项技术使得CouncurentHashMap能够支持多达16个并发的写入器。 锁分段的劣势：与采用单个锁来实现独占访问相比，要获得多个锁来实现独占访问将更困难整个容器，例如当ConcurrentHashMap需要扩展映射范围等。 避免热点域如果将一些反复计算的结果缓存起来，那么将会引入一些“热点域”。而这些热点域往往会限制可伸缩性。 例子：参考ConcurrentHashMap里边将热点域size分成多个值，当我们需要获取全局size的时候，就临时把这些值加起来就是，虽然可能得不到一个准确的值，但大大提高了并发性，是划算的。 一些代替独占锁的方法放弃使用独占锁，从而有助于使用一种友好并发的方式来管理共享状态。例如，使用并发容器、读-写锁、不可变对象以及原子变量。 监测CPU的利用率当测试可伸缩性时，通常要确保处理器得到充分利用。 如果CPU没有得到充分利用，那么需要找出其中的原因（vmstat,mpstat查询CPU使用情况）。可能的原因如下： 负载不充足。可以在测试时增加负载，并检查利用率，响应时间和服务时间等指标的变化。如果产生足够多的负载使应用程序达到饱和，那么可能需要大量的计算机能耗，并且问题可能在于客户端系统是否具有足够的能力，而不是被测试系统。 IO密集。可以通过iostat或者perfmon来判断某个应用程序是否是磁盘I/O密集型的，或者通过监测应用的通信流量来判断它是否需要高带宽。 外部限制。如果应用程序依赖于外部服务，比如数据库或web服务，那么性能瓶颈可能并不在你自己的代码中。 锁竞争。使用分析工具可以知道在程序中存在何种程度的锁竞争。比如进行线程栈帧转储，来观察是不是有“waiting to lock monitor”之类的关键字。 在CPU保持忙碌状态之后，我们试试增加CPU的数量，比如从4核换到8核，看是否能增加处理能力，如此就可以得出结论：增加CPU可以提高程序的处理能力，类似的其它资源验证过程也是类似的。 向对象池说“不”早期垃圾回收机制很慢，效率很低，很多程序通过对象池来降低垃圾回收的压力。但现在的垃圾回收机制已经很快了。在并发程序中，对象池的表现更加糟糕。 减小上下文切换的开销传统网络模式下，同步阻塞IO将导致上下文切换，同时，一个连接一个线程将导致更多的上下文切换，改进方法如下： 将阻塞IO操作从处理请求的线程分离出来，放到专门的线程中去处理。 使用nio，多路复用机制，实现可以由有限线程池来处理所有的连接请求。 总结由于使用线程通常是为了充分利用多个处理器的计算能力，因此在并发程序性能的套路那种，通常更多地将重点放在吞吐量和可伸缩性上，而不是服务时间。Amdahl定律告诉我们，程序的可伸缩性取决于在所有代码中必须被串行化执行的代码比例。因为Java程序中串行操作的主要来源是独占方式的资源锁，因此通常可以通过以下方式来提高可伸缩性：减少锁的持有时间，降低锁的粒度，以及采用非独占的锁或非阻塞锁来代替独占锁。 参考 《Java并发编程实战》 并发编程实战学习笔记（八）——性能与可伸缩性]]></content>
      <categories>
        <category>Java并发编程实战</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发_8_避免活跃性危险]]></title>
    <url>%2F2018%2F01%2F22%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%2FJava%E5%B9%B6%E5%8F%91-8-%E9%81%BF%E5%85%8D%E6%B4%BB%E8%B7%83%E6%80%A7%E5%8D%B1%E9%99%A9%2F</url>
    <content type="text"><![CDATA[引：在安全性和活跃性之间通常存在着某些制衡。我们使用加锁机制来确保线程安全，但如果过度地使用加锁，则可能导致顺序死锁。同样，我们使用线程池和信号量来限制对资源的使用，但这些被限制的行为可能会导致资源死锁。Java应用程序无法从死锁中恢复过来，因此在设计时一定要排除那些可能导致死锁出现的条件。 死锁最简单的死锁：当线程A持有锁L并想获得锁M的同时，线程B持有锁M并尝试获得锁L，那么这两个线程将永远等待下去。 数据库解决死锁问题： 当它检测到一组事务发生了死锁时（通过在表示等待关系的有向图中搜索循环），将选择一个牺牲者并放弃这个事务。作为牺牲者的事务会释放它所持有的资源，从而使其他事务继续进行。应用程序可以重新执行被强制终止的事务，而这个事务现在可以成功完成，因为所有跟它竞争资源的事务都已经完成了。 JVM解决死锁问题：当一组Java线程发生死锁时，“游戏”将到此结束——这些线程永远不能使用了。 锁顺序死锁示例代码如下：12345678910111213141516171819202122// 注意：容易发生死锁！public class LeftRightDeadLock &#123; private final Object left = new Object(); private final Object right = new Object(); public void leftRight() &#123; synchronized (left) &#123; synchronized (right) &#123; doSomething(); &#125; &#125; &#125; public void rightLeft() &#123; synchronized (right) &#123; synchronized (left) &#123; doSomething(); &#125; &#125; &#125;&#125; 解决方法： 如果所有线程以固定的顺序来获得锁，那么在程序中就不会出现锁顺序死锁问题。 动态死锁问题示例代码如下：123456789101112131415// 注意：容易发生死锁！public void transferMoney(Account fromAccount, Account toAccount, DollarAmount amount) throws InsufficientFundsException&#123; synchronized (fromAccount) &#123; synchronized (fromAccount) &#123; if (fromAccount.getBalance().compareTo(amount)) &#123; throw new InsufficientFundsException(); &#125; else &#123; fromAccount.debit(amount); toAccount.credit(amount); &#125; &#125; &#125;&#125; 解决方法： 通过一致哈希算法或者其它方式来统一锁顺序，使未知顺序变为已知顺序。对于极少数的哈希冲突，可以使用“加时赛”锁来解决。解决代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142private static final Object tieLock = new Object();public void transferMoney(final Account fromAcct, final Account toAcct, final DollarAmount amount) throws InsufficientFundsException&#123; class Helper&#123; public void transfer throws InsufficientFundsException&#123; if(fromAcct.getBalance().compareTo(amount) &lt; 0)&#123; throw new InsufficientFundsException(); &#125;else&#123; fromAcct.debit(amount); toAcct.credit(amount); &#125; &#125; &#125; int fromHash = System.identifyHashCode(fromAcct); int toHash = System.identityHashCode(toAcct); if(fromHash &lt; toHash)&#123; synchronized(fromAcct)&#123; synchronized(toAcct)&#123; new Helper.transfer(); &#125; &#125; &#125;else if (fromHash &gt; toHash) &#123; synchronized(toAcct)&#123; synchronized(fromAcct)&#123; new Helper().transfer(); &#125; &#125; &#125; else &#123; synchronized(tieLock)&#123;//加时赛锁来解决问题 synchronized(fromAcct)&#123; synchronized(toAcct)&#123; new Helper().transfer(); &#125; &#125; &#125; &#125;&#125; 在协作对象之间发生的死锁示例代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// 注意：同步方法获得的是对象锁class Taxi &#123; @GuardedBy("this") private Point location, destination; private final Dispatcher dispatcher; public Taxi(Dispatcher dispatcher) &#123; this.dispatcher = dispatcher; &#125; public synchronized Point getLocation() &#123; return location; &#125; public synchronized void setLocation(Point location) &#123; this.location = location; if (location.equals(destination)) dispatcher.notifyAvailable(this); &#125; public synchronized Point getDestination() &#123; return destination; &#125; public synchronized void setDestination(Point destination) &#123; this.destination = destination; &#125;&#125;class Dispatcher &#123; @GuardedBy("this") private final Set&lt;Taxi&gt; taxis; @GuardedBy("this") private final Set&lt;Taxi&gt; availableTaxis; public Dispatcher() &#123; taxis = new HashSet&lt;Taxi&gt;(); availableTaxis = new HashSet&lt;Taxi&gt;(); &#125; public synchronized void notifyAvailable(Taxi taxi) &#123; availableTaxis.add(taxi); &#125; public synchronized Image getImage() &#123; Image image = new Image(); for (Taxi t : taxis) image.drawMarker(t.getLocation()); return image; &#125;&#125; 尽管没有任何方法会显式地获得两个锁，但是setLocation和getImage等方法的调用者都会获得两个锁，所以有可能造成死锁。 注意： 如果在持有锁的情况下调用某个外部方法时，那么就需要警惕死锁。 开放调用开放调用： 如果在调用某个方法时不需要持有锁，那么这种调用被称为开放调用。 通过开放调用解决在协作对象之间发生的死锁，代码如下：12345678910111213141516171819202122232425262728293031323334353637383940class Taxi &#123; @GuardedBy("this") private Point location, destination; private final Dispatcher dispatcher; ... public synchronized Point getLocation() &#123; return location; &#125; public void setLocation(Point location) &#123; boolean reachedDestination; synchronized (this) &#123; this.location = location; reachedDestination = location.equals(destination); &#125; if (reachedDestination) dispatcher.notifyAvailable(this); &#125;&#125;class Dispatcher &#123; @GuardedBy("this") private final Set&lt;Taxi&gt; taxis; @GuardedBy("this") private final Set&lt;Taxi&gt; availableTaxis; ... public synchronized void notifyAvailable(Taxi taxi) &#123; availableTaxis.add(taxi); &#125; public synchronized Image getImage() &#123; Set&lt;Taxi&gt; copy; sychronized (this) &#123; copy = new HashSet&lt;Taxi&gt;(taxis); &#125; Image image = new Image(); for (Taxi t : copy) image.drawMarker(t.getLocation()); return image; &#125;&#125; 解决的方法思路就是：缩小锁的粒度。 缺点：可能丢失操作原子性，此时需要通过协议来实现原子性，而不是通过加锁。 资源死锁独占类型的访问都可以和加锁操作类比，看起来就像需要获得锁才能访问。 如果一个任务需要连接两个数据库，并且在请求这两个资源时不会始终遵循相同的顺序，那么线程A可能持有与数据库D1的连接，并等待与数据库D2的连接，而线程B持有D2的连接并等待与D1的连接。资源池越大，就越不容易出现这种类型的死锁。 线程饥饿死锁。如果某些任务需要等待其它任务的结果，那么这些任务往往是产生线程饥饿死锁的主要来源，有界线程池/资源池与相互依赖的任务不能一起使用。 死锁的避免与诊断如果必须获取多个锁，那么在设计时必须考虑锁的顺序：尽量减少潜在的加锁交互数量，将获取锁时需要遵循的协议写入正式文档并始终遵循这些协议。 在细粒度锁的程序中，可以通过一种两阶段策略来检查代码中的死锁：首先，找出在什么地方将获取多个锁（使这个集合尽量小），然后对所有这些实例进行全局分析，从而确保他们在整个程序中获取锁的顺序保持一致。尽可能使用开发调用。 支持定时的锁当定时锁失败时，你并不需要知道失败的原因。至少你能记录所发生的失败，以及关于这次操作的其它有用信息，并通过一种更平缓的方式来重新启动计算，而不是关闭整个进程。 如果在获取锁时超时，那么可以释放这个锁，然后后退并在一段时间后并再次尝试，从而消除了死锁发生的条件，使程序恢复过来。（这项技术只有在同时获取两个锁时才有效，如果在嵌套的方法调用中请求多个锁，那么即使你知道已经持有了外层的锁，也无法释放它。） 通过线程转储信息来分析死锁JVM会通过线程转储来帮助是被死锁的发生。在生成线程转储信息之前，JVM将在等待关系图中通过搜索循环来找出死锁。如果发现了一个死锁，则获取相应的死锁信息，理由在死锁中涉及哪些锁和线程，以及这个锁的获取操作位于程序的哪些位置。 其他活跃危险饥饿当线程由于无法访问它所需要的资源而不能继续执行时，就发生了“饥饿”，引发饥饿的最常见资源就是CPU时钟周期。 要避免使用线程优先级，因为这会增加平台依赖性，并可能导致活跃性问题，在大多数并发应用程序中，都可以使用默认的线程优先级。 活锁活锁是另一种形式的活跃性问题，该问题尽管不会阻塞线程，但也不能继续执行，因为线程将不断重复执行相同的操作，而且总会失败。 活锁通常发生在处理事务消息的应用程序中：如果不能成功地处理某个消息，那么消息处理机制将会回滚整个事务，并将它重新放到队列的开头。如果消息处理器在处理某种特定类型的消息时存在错误并导致它失败，那么会出一直存在“处理-出错-回滚-处理”的循环中。 解决方法：在重试机制中引用随机性。 总结活跃性故障是一个非常严重的问题，因为当出现活跃性故障时，除了中止应用程序之外没有其他任何机制可以帮助从这种故障恢复过来。最常见的活跃性故障是锁顺序死锁。在设计时应该避免锁顺序死锁：确保线程在获取多个锁采用一致的顺序。最好的解决方法是在程序中始终使用开放调用。这将大大减少需要同时持有多个锁的地方，也更容易发现这些地方。 参考 《Java并发编程实战》]]></content>
      <categories>
        <category>Java并发编程实战</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发_7_线程池的使用]]></title>
    <url>%2F2018%2F01%2F22%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%2FJava%E5%B9%B6%E5%8F%91-7-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[引：之前介绍了Executor任务执行框架的使用，它不仅简化了任务与线程的生命周期管理，而且还提供了一种简单灵活的方式将任务的提交和任务的执行策略解耦开来。但是深入下去，我们需要对线程池进行配置和调优，并且分析再使用任务执行框架时需要注意的各种危险。 在任务与执行策略之间的隐性耦合不是所有任务都能适用所有的执行策略的，有些类型的任务需要明确地指定执行策略，包括： 依赖性任务：提交给线程池的任务需要依赖其他的任务，我们需要避免线程饥饿死锁。 使用线程封闭机制的任务：任务要求其执行策略所在的Executor是单线程的。 对响应时间敏感的任务：GUI应用程序对于响应时间是敏感的。 使用ThreadLocal的任务：Executor会重用线程，所偶一使用ThreadLocal会没有意义。 只有当任务都是同类型的并且是相互独立时，线程池的性能才能达到最佳。 在一些任务中，需要拥有或排除某种特定的执行策略。如果某些任务依赖于其他的任务，那么会要求线程池足够大，从而确保他们依赖任务不会被放入等待队列中或被拒绝，而采用线程封闭机制的任务需要串行执行。 线程饥饿死锁在线程池中，如果任务依赖于其他任务，那么可能产生死锁。在单线程的Executor中，如果一个任务将另一个任务提交到同一个Executor，并且等待这个被提交任务的结果，那么通常会引发死锁。第二个任务停留在工作队列中，等待第一个任务完成，而第一个任务又无法完成，因为它在等待第二个任务的完成。在更大的线程池中，如果所有正在执行任务的线程都由于等待其他仍处于工作队列中的任务而阻塞，也会发生同样的问题。这种现象叫做线程饥饿死锁（Thread Starvation Deadlock），只要线程池中的任务需要无限期等待一些必须由池中其他任务才能提供的资源或条件，例如某个任务等待另一个任务的返回值或执行结果，那么除非线程池足够大，否则将发生线程饥饿死锁。 每当提交了一个有依赖性的Executor任务时，要清楚地知道可能会出现线程饥饿死锁，因此需要在代码或配置Executor的配置文件中记录线程池的大小限制或配置限制。 运行时间较长的任务如果任务阻塞时间过长，那么即使不出现死锁，线程池的响应性也会变得糟糕。执行时间较长的任务不仅会造成线程池堵塞，甚至会增加执行时间较短任务的服务时间。如果线程池中的数量远小于在稳定状态下执行时间较长任务的数量，那么到最后可能所有线程都会运行这些执行时间较长的任务，从而影响整体的响应性。 缓解这个问题的技术就是限定等待资源的时间，而不是无限制等待。例如Thraed.join(),BlockingQueue.put()、CountDownLatch.await()等，如果等待超时，可以把任务标识为失败，然后终止任务或将任务重新放回队列以便随后执行。 设置线程池的大小线程池的理想大小取决于被提交任务的类型以及所部署系统的特性。 只要避免过大和过小两种极端情况，如果线程池过大，那么大量的线程将在相对很少的CPU和内存资源上发生竞争，这不仅会导致更高的内存使用量，而且还可能耗尽资源。如果线程池过小，那么导致许多空闲的处理器无法执行工作，从而降低吞吐率。 要想正确设置线程池的大小，必须分析计算环境、资源预算和任务的特性。 对于计算密集型的任务，在拥有N个处理器的系统上，当线程池的大小为N + 1时，通常能实现最优的利用率。 对于包含I/O操作或者其他阻塞操作的任务，由于线程并不会一直执行，因此线程池的规模应该更大。要正确地设置线程池的大小，必须估算出任务的等待时间与计算时间的比值。有个公式：1234N = CPU的数量 = Runtime.getRuntime().availableProcessors();U = 预期CPU利用率W/C = 等待时间,计算时间之比（wait time / compute time）线程池的最优大小 = N * U * （1 + W/C） 配置ThreadPoolExecutor如果newCachedThreadPool、newFixedTheadPool和newScheduledTheadPool等工厂方法返回的ThreadPoolExecutor无法满足需求，可以通过ThreadPoolExecutor的构造函数来实例化一个对象，并根据自己需求来定制。构造函数如下：1234567public ThreadPoolExecutor(int corePoolSize, //线程池的基本大小 int maximumPoolSize, //最大大小 long keepAliveTime, //存活时间 TimeUnit unit, //时间单位 BlockingQueue&lt;Runnable&gt; workQueue, //工作队列 ThreadFactory threadFactory, //线程工厂 RejectedExecutionHandler handler) &#123;...&#125; 线程的创建与销毁通过调节线程池的基本大小和存活时间，可以帮助线程池回收空闲线程占有的资源，从而使得这些资源可以用于执行其他工作。 管理队列任务如果新请求的到达速率超过了线程池的处理速率，那么新到来的请求将会在一个由Executor管理的Runnable队列中等待，而不会像线程那样去竞争CPU资源。 ThreadPoolExecutor允许提供一个BlockingQueue来保存等待执行的任务。基本的任务排队方法有3种：无界队列、有界队列和同步移交。 一种更稳妥的资源管理策略时使用有界队列，例如ArrayBlockingQueue、有界LinkedBlockingQueue、PriorityBlockingQueue。有界队列有助于避免资源耗尽的情况发生，但又带来新的问题：当队列满后，新的任务怎么办？在使用有界的工作队列时，队列的大小和线程池的大小必须一起调节，如果线程池较小而队列较大，那么有助于减少内存使用量，降低CPU使用率，同时减少上下文切换，但代价是限制了吞吐量。 对于非常大的或者无界的线程池，可以使用SynchronousQueue来避免任务排队，它可以直接将任务从生产者移交给工作者线程。SynchronousQueue并不是一个真正的队列，而是一种在线程之间进行移交的机制。要将一个元素放入SynchronousQueue中，必须由另一个线程正在等待接受这个元素。如果没有线程正在等待，并且线程池的当前大小小于最大值，那么ThreadPoolExecutor会创建一个新的线程来处理这个任务。否则，根据饱和策略，这个任务将被拒绝。直接使用移交将更高效，因为任务直接移交给执行它的线程，而不是先放到队列，然后再由工作线程从队列中提取任务。只有当线程池是无界的或者可以拒绝任务时，SynchronousQueue才有实际价值。在newCachedThreadPool中就是使用了SynchronousQueue。 当使用像LinkedBlockingQueue或ArrayBlockingQueue这样FIFO队列时，任务的执行顺序与它们的到达顺序相同。如果想进一步控制任务执行顺序，还可以使用PriorityBlockingQueue，这个队列根据优先级来安排任务，任务的优先级是通过自然顺序或者Comparator来定义的。 只有当任务相互独立时，为线程池或工作队列设置界限才是合理的 。如果任务之间有依赖性，那么有界的线程池或队列会导致线程饥饿死锁问题，此时应该使用无界的线程池，如newCachedThreadPool。 对于Executor，newCachedThreadPool工厂方法是一种很好的默认选择，他能提供比固定大小的线程池更好的排队性能。当需要限制当前任务的数量以满足资源管理需要求时，可以选择固定大小的线程池。 饱和策略当有界队列被填满后，饱和策略开始发挥作用，ThreadPoolExecutor的饱和策略可以通过调用setRejectedExecutionHandler来修改。 当工作队列被填满后，没有预定义的饱和策略来阻塞ececute。通过使用Semaphore（信号量）来限制任务的到达率可以实现饱和策略的功能。 线程工厂每当线程池需要创建一个线程时，都是通过线程工厂方法来完成的。在TheadFactory中只定义了一个方法newThread，每当线程池需要创建一个新线程时都会调用这个方法。 在调用构造函数后再定制ThreadPoolExecutor在调用完ThreadPoolExecutor的构造函数后，仍然可以通过设置函数来修改大多数传递给他的构造函数的参数，如果Executor是通过Executors中的某个工厂方法创建的，那么可以通过将结果的类型转换为ThreadPoolExecutor以访问设置器。 扩展ThreadPoolExecutorThreadPoolExecutor是可扩展的，它提供了几个可以在子类化中改写的方法：beforeExcute，afterExecute和terminated，这些方法可以用于扩展ThreadPoolExecutor的行为。 在这里方法中可以添加日志、计时、监视或统计信息收集功能。 总结对于并发执行的任务，Executor框架是一种强大且灵活的框架。它提供了大量可调节的选项。我们要根据实际情况对这些参数进行调节。 参考 《Java并发编程实战》]]></content>
      <categories>
        <category>Java并发编程实战</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发_6_取消与关闭]]></title>
    <url>%2F2018%2F01%2F22%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%2FJava%E5%B9%B6%E5%8F%91-6-%E5%8F%96%E6%B6%88%E4%B8%8E%E5%85%B3%E9%97%AD%2F</url>
    <content type="text"><![CDATA[引：任务和线程的启动很容易，在大多数时候，我们都会让他们运行直到结束，然而，有时候我们希望提前结束任务或线程，但是Java没有提供任何机制来安全地终止线程，只是提供了中断，这是一种协作机制，能够使一个线程终止另一个线程的工作。所以需要我们能很完善地处理失败、关闭和取消等过程。 任务取消如果外部代码能在某个操作正常完成之前将其置入“完成”状态，那么这个操作就可以称为可取消的。取消这个操作的原因有很多： 用户请求取消。用户点击图形界面程序的“取消”按钮。 有时间限制的操作。某个程序需要在有限时间内完成搜索任务，当超时时，需要取消搜索任务。 错误。当一个爬虫程序发生错误时，那么搜索任务都会取消。 关闭。在立即关闭的过程中，当前的任务则可能被取消。 在Java中没有一种安全的抢占式方法来停止线程，因此也就没有安全的抢占式方法来停止任务，只有一些协作式的机制，使请求取消的任务和代码都遵循一种协商好的协议。 其中一种协作机制能设置某个“已请求取消”标志，而任务将定期地查看该标志。如果设置了这个标志，那么任务将提前结束。代码如下:12345678910111213141516public class Task implement Runnable &#123; // 为了使这个过程能可靠得工作，标志cancelled必须为volatile类型 private volatile boolean cancelled; public void run() &#123; while(!cancelled) &#123; &#125; &#125; public void cancel() &#123; cancelled = true; &#125;&#125; 中断如果在上面代码中while里面出现了一个阻塞的方法，那么在调用cancel方法来设置cancelled状态，当却检查不到标志，因为它无法从阻塞的方法恢复过来。如下面的代码：123456789101112131415161718192021222324public class BrokenPrimeProducer extends Thread &#123; private final BlockingQueue&lt;BigInteger&gt; queue; private volatile boolean cancelled = false; BrokenPrimeProducer(BlockingQueue&lt;BigInteger&gt; queue) &#123; this.queue = queue; &#125; public void run() &#123; try &#123; BigInteger p = BigInteger.ONE; while (!cancelled) &#123; // 如果生产者的速度超过消费者的处理速度，队列将被填满，put方法会被阻塞 queue.put(p = p.nextProbablePrime()); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public void cancel() &#123; cancelled = true; &#125;&#125; 所以我们会想到一些线程中断这种协作机制，它利用了特殊的阻塞库用来是实现任务取消，注意：如果在取消之外的其他操作中使用中断，都是不合适的，并且很难支撑起更大的应用。下面是Thread的中断方法:123456789101112// 每个线程都有一个boolean类型的中断状态，当中断线程时，这个线程的中断状态将被设置为truepublic class Thread &#123; // 中断目标线程 public void interrupt() &#123;&#125; // 清除当前线程的中断状态 public static boolean interrupted() &#123;&#125; // 返回目标线程的中断状态 public boolean isInterrupted() &#123;&#125;&#125; 阻塞库的方法，如Thread.sleep和Object.wait等都会检查线程何时中断，并且在发生中断时返回。响应中断执行的操作包括：清除中断状态，抛出InterruptedException。JVM不保证阻塞方法检测到中断的速度，但通常响应速度还是非常快的。 注意：调用interrupt并不意味着立即停止目标线程正在进行的工作，而只是传递了请求中断的消息。然后由线程在下一个合适的时刻中断自己（这些时刻也被称为取消点）。有些方法，例如wait、sleep和join等，将严格处理这种请求，当他们收到中断请求或者在开始执行时发现某个已被设置好的中断状态，将抛出一个异常。示例如下：1234567891011121314151617181920212223public class BrokenPrimeProducer extends Thread &#123; private final BlockingQueue&lt;BigInteger&gt; queue; BrokenPrimeProducer(BlockingQueue&lt;BigInteger&gt; queue) &#123; this.queue = queue; &#125; public void run() &#123; try &#123; BigInteger p = BigInteger.ONE; // 在阻塞的put方法调用中以及在循环开始处查询中断状态时，都会检查中断标志 while (!Thread.currentThread().isInterrupted()) &#123; queue.put(p = p.nextProbablePrime()); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public void cancel() &#123; interrupt(); &#125;&#125; 中断策略最合理的中断策略是某种形式的线程级取消操作或者服务级取消操作：尽快退出，在必要时清理，通知某个所有者该线程已经退出。此外还可以建立其他的中断策略，例如暂停服务或重新开始服务。 任务不应该对执行该任务的线程的中断策略做出假设。无论任务把中断视为取消，还是其他某个中断响应操作，都应该小心的保存线程的中断状态，如果除了将InterruptException传递给调用者外还需要执行其他操作，那么应该在捕获InterruptException之后恢复中断状态。 线程只能由其所有者中断，所有者可以将线程的中断策略信息封装到某个合适的取消机制中，例如关闭方法中。 响应中断在调用可中断的阻塞函数时，有两种实用策略可用于处理InterruptException： 传递异常：从而使你的方法也称为了可中断的阻塞方法。 恢复中断状态：从而使调用栈中的上层代码能够对其进行处理。 只有是实现了线程中断策略的代码才可以屏蔽中断请求。在常规的任务和库代码中都不应该屏蔽中断请求。 通过Future来实现取消使用ExecuorService.submit方法将返回一个Future来描述任务，Future有一个cancel方法。cancle方法有一个参数mayInterruptIfRunning,如果设置为true，那么就表示取消操作是否成功（这只是表示任务是否能够接受中断，而不是表示任务是否能够检测并处理中断）。如果为false，表示如果任务还没有运行，那么就不要运行它。代码如下：12345678910111213141516171819public class TimedRun &#123; private static final ExecutorService taskExec = Executors.newCachedThreadPool(); public static void timedRun(Runnable r,long timeout, TimeUnit unit) throws InterruptedException &#123; Future&lt;?&gt; task = taskExec.submit(r); try &#123; task.get(timeout, unit); &#125; catch (TimeoutException e) &#123; // 接下来任务将被取消 &#125; catch (ExecutionException e) &#123; // 如果在任务执行和中抛出了异常，那么重新抛出该异常 throw launderThrowable(e.getCause()); &#125; finally &#123; //如果任务已经结束，那么执行取消操作也不会带来任何影响 task.cancel(true); // 如果任务正在运行，那么将被中断 &#125; &#125; &#125; 处理不可中断的阻塞在java库中，很多阻塞的方法都是通过提前返回或者是抛出InterruptedException来响应中断请求的，然而并非所有的可阻塞方法或者阻塞机制都能响应中断。 比如一个线程由于执行同步的Socket IO 或者等待获得内置锁而阻塞，那么中断请求只能设置线程的中断状态，除此之外没有其他任何作用，对于那些执行不可中断操作而被阻塞的线程，可以使用类似于中断的手段来停止这些线程，但这要求我们必须知道线程阻塞的原因，然后通过重写非标准的取消操作。 停止基础线程的服务应用程序通常会创建多个线程的服务，例如线程池。正确地封装原则是：除非拥有某个线程，否则不能对该线程进行操控，线程池是其工作线程的所有者，如果要中断这些线程，那么应该使用线程池。线程的所有权是不可以传递的：应用程序可以拥有服务，服务可以拥有工作者线程，但应用程序并不能拥有工作者线程，因此应用程序不能直接停止工作者线程。相反，服务应用提供生命周期方法来关闭它自己以及它所拥有的线程，在ExecutorService中提供了shutdown和shutdownNow方法。 例子：日志服务 方式：通过调用log方法将日志消息放入某个队列中，并由其他线程来处理； 停止该服务的方式：通过原子方式来检查关闭请求，并且有条件地递增一个计数器来保存提交信息的权利； 关闭ExecutorService Service封装在某个更高级别的服务中，并且该服务能提供其自己的生命周期方法。 毒丸对象 毒丸是指一个放在队列上的对象，其含义是：当得到这个对象时，立即停止； 限制：只有在生产者和消费者的数量都已知的情况下，才可以使用“毒丸”对象； 当生产者和消费者数目较大时，这种方法变得难以使用。 例子：只执行一次的服务 场景：某个方法需要处理一批任务，并且当所有任务都处理完后才返回，可以通过一个私有的Executor来简化服务的生命周期管理，其中该Executor的生命周期是由这个方法控制的 shutdownNow的局限性 当通过shutdownNow来强行关闭ExecutorService时，尝试取消正在执行的任务，并返回所有已经提交但未开始的任务。但无法在关闭过程中知道正在执行的任务的状态。除非任务本身会执行某种检查。 处理非正常的线程终止在并发程序中,是无法做到一直观察控制台的, 例如:你的web应用部署到服务器上,难道你要派个人一直去观察控制台? 任何代码都可能抛出一个RuntimeExecption,每当调用另一个方法时,都要对它的行为保持怀疑,不要盲目地认为它一定会抛出在方法原型中声明的某个已检查异常。对调用的代码越不熟悉,就越应该对其代码行为保持怀疑。 典型的线程池工作者线程结构代码如下：123456789101112public void run()&#123; Throwable throw = null; try&#123; while(!isInterrupted)&#123; runTask(getTaskFromWorkQueue()); &#125; &#125; catch (Throwable e)&#123; thrown = e; &#125; finally&#123; threadExited(this,thrown); &#125;&#125; 如果任务抛出了一个未检查的异常,那么它将使线程终结,但会首先通知框架该线程已经终结.然后,框架可能会用新的线程来代替这个工作线程。 将异常写入日志的UncaughtExecptionHandler代码如下：123456public class Thread.UncaughtExecptionHandler&#123; public void uncaughtException(Thread t,Throwable e)&#123; Logger logger = Logger.getAnonymousLogger(); Logger.log(Level.SEVERE,"Thread terminated with exception: "+ t.getName(),e); &#125;&#125; 在运行时间较长的应用程序中,通常会为所有线程的未捕获异常指定同一个异常处理器,并且该异常处理器至少会将异常信息记录到日志中。 JVM关闭JVM既可以正常关闭，也可以强行关闭。正常关闭的触发方式有多种，包括：当最后一个“正常（非守护）”线程结束时，或者调用了System.exit时，或者通过其他特定于平台的方法关闭时（例如发送了SIGINT信号或Ctrl-C）。虽然可以通过这些标准方法来正常关闭JVM，但也可以通过调用Runtime.halt或者在操作系统中“杀死”JVM进程来强行关闭JVM。 关闭钩子在正常关闭中，JVM首先调用所有已注册的关闭钩子，关闭钩子是指通过Runtime.addShutdownHook注册的但尚未开始的线程。JVM不能保证关闭钩子的调用顺序。在关闭应用程序线程时,如果有线程仍然在运行,那么这些线程接下来将与关闭进程并发执行. 关闭钩子应该是线程安全:它们在访问共享数据时,必须使用同步机制,小心避免死锁。 关闭钩子可以用于实现服务或应用程序的清理工作，例如删除临时文件，或者清除无法由操作系统自动清除的资源。 守护线程有时候，你希望创建一个线程来执行一些辅助工作，但又不希望这个线程阻碍了JVM的关闭，这种情况就需要使用守护线程。 线程分为两种: 普通线程和守护线程,在JVM启动时启动创建的所有线程中,除了主线程以外，其他的线程都是守护线程。例如垃圾回收器，当创建一个新的线程时，它将继承创建它的线程的类型。 我们应该尽可能少地使用守护线程–很少有操作能够在不进行清理的情况下被安全地抛弃,特别是在执行I/O操作的任务,那么将是一种非常危险的行为; 并且守护线程不能用来替代应用程序管理程序中各个服务的生命周期 终结器当不再需要内存资源时，可以通过垃圾回收器来回收它们，但对于其他一些资源，例如文件句柄或套接字句柄，当不再需要它们时,必须显式交还给操作系统。为了实现这个功能，垃圾回收器对那些定义了finalize方法的对象会进行特殊处理: 在垃圾回收期释放它们后，调用它们的finalize方法，从而保证一些持久化的资源被释放。 由于终结器可以在某个JVM管理的线程中运行，因此终结器访问任何状态都可能被多个线程访问，这样就必须对其访问操作进行同步。终结器并不能保证它们将在何时甚至是否会运行，并且复杂的终结器带来性能上的巨大开销。编写正确的终结器是非常困难的。在大多数情况下，通过使用finally代码块和显式的close方法能够比终结器更好的管理资源。 避免使用终结器 总结在任务、线程、服务以及应用程序等模块中的生命周期结束问题，可能会增加他们在设计和实现时的复杂性。Java并没有提供某种抢占式的机制来取消操作或者总结线程。相反，它提供了一种协作式的中断机制来实现取消操作，但这要依赖于如何构建取消操作的协议，以及能否始终遵循这些协议。通过使用FutureTask和Executor框架，可以帮助我们构建可取消的任务和服务。 参考 《Java并发编程实战》]]></content>
      <categories>
        <category>Java并发编程实战</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发_5_任务执行]]></title>
    <url>%2F2018%2F01%2F15%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%2FJava%E5%B9%B6%E5%8F%91-5-%E4%BB%BB%E5%8A%A1%E6%89%A7%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[引：在大多数并发应用程序都是围绕“任务执行”来构造的：任务通常是一些抽象且离散的工作单元。通过把应用程序的工作分解到多个任务中，可以简化程序的组织结构，提供一种自然的事务边界来优化错误恢复过程，以及提供一种自然的并行工作结构来提升并发性。 在线程中执行任务要使服务器应用程序同时表现出良好的吞吐量和快速的响应性，应该选择清晰的任务边界以及明确的任务执行策略（见后面）。 串行地执行任务最简单的调度任务策略就是在单个线程中串行地执行各项任务。但串行处理机制通常都无法提供高吞吐率或快速响应性。 显示地为任务创建线程通过为每个请求创建一个新的线程来提供服务，从而实现更高的响应性。但为每个任务分配一个线程也存在一些缺陷。 无限创建线程的不足 线程生命周期的开销非常高。线程的创建过程需要时间，这就延迟了请求的处理，并且需要JVM和操作系统提供一些辅助操作。 资源消耗。如果可运行线程数量多于可用处理器的数量，那么有些线程会闲置就会占用许多内存，如果大量线程在竞争CPU还会产生其他的性能消耗。 稳定性。在可创建线程的数量上有一个阈值，这个阈值随着平台不同而不同，并且受多个因素制约，包括JVM的启动参数、Thread构造函数中请求的栈大小，以及底层操作系统对线程的限制等。如果超过这个限制，就很可能有OOM异常。 Executor框架线程池简化了线程的管理工作，并且java.util.concurrent提供了一种灵活的线程池作为Executor框架的一部分。在java类库中，任务执行的不是Thread，而是Executor。其代码如下：123public interface Executor &#123; void execute(Runnable command);&#125; Executor框架提供了一种标准的方法将任务的提交过程与执行过程解耦开来，并用Runnable来表示任务。Executor的实现还提供了对生命周期的支持，以及统计信息收集/应用程序管理机制和性能监视等机制。Executor基于生产者-消费者模式，提交任务的操作相当于生产者，执行任务的线程相当于消费者。 示例：基于Executor的Web服务器可以看到下面的代码：1234567891011121314151617class TaskExecutorWebServer &#123; private static final int NTHREAD = 100; private static final Executor exe = Executors.newFixedThreadPool(NTHREAD); public static void main(String[] args) &#123; ServerSocket socket = new ServerSocket(80); while(true) &#123; final Socket connection = socket.accept(); Runnable task = new Runnable() &#123; public void run() &#123; handleRequest(connection); &#125; &#125;; exec.execute(task); &#125; &#125;&#125; 在TaskExecutionWebServer中，通过使用Executor，将请求处理任务的提交与任务的实际执行解耦开来，并且只需要采用另一种不同的Executor实现，就可以改变服务器的行为。 将TaskExecutorWebServer改为显示地为任务创建线程：123456// 为每个请求都创建新线程的Executorpublic class ThreadPerTaskExecutor implements Executor &#123; public void execute(Runnable r) &#123; new Thread(r).start(); &#125;&#125; 将TaskExecutorWebServer改为串行地执行任务：123456// 以同步方式执行所有任务的Executorpublic class WithinThreadExecutor implements Executor &#123; public void execute(Runnable r) &#123; r.run(); &#125;&#125; 执行策略各种执行策略都是一种资源管理工具，最佳策略取决于可用的计算资源以及对服务质量的需求。通过限制并发任务的数量，可以确保应用程序不会由于资源耗尽而失败，或者由于在稀缺资源发生竞争而严重影响性能。通过将任务的提交于任务的执行分离开来，有助于在部署阶段选择与可用硬件资源最匹配的执行策略。 每当看到下面形式的代码时，并且希望获得一种更灵活的执行策略时，考虑使用Executor来代替Thread：1new Thread(runnable).start(); 线程池线程池是指管理一组相同工作线程的资源池。线程池是与工作队列密切相关的，其中在工作队列中保存了所有等待执行的任务。工作线程的任务很简单： 从工作队列中获取一个任务，执行任务，执行完后返回线程池并等待下一个任务。 “在线程池中执行任务”比“为每个任务分配一个线程”优势更多。通过重用现有的线程而不是创建新线程，可以减少在线程创建与销毁的开销。另一个好处是请求到来时，不会再因为要等待线程创建而延迟，也就提高了响应性。通过适当调整线程池的大小，可以创建足够多的线程以便处理器保持忙碌状态，同时还可以防止过多线程互相竞争资源而使应用程序耗尽内存。 类库提供了一个灵活的线程池以及一些有用的默认配置。可以通过调用Executors中的静态工厂方法之一来创建一个线程池： newFixedThreadPool：创建一个固定长度的线程池，每当提交一个任务时就创建一个线程，直到达到线程池的最大数量，这时线程池的规模将不再变化。（如果某个线程由于发生了未预期的Exception而结束，那么线程池会补充一个新的线程）。 newCachedThreadPool：创建一个可缓存的线程池，如果线程池的当前规模超过了处理需求时，那么将回收空闲的线程，而当需求增加时，则可以添加新的线程，线程池的规模不存在任何限制。 newSingleThreadExecutor：是一个单线程的Executor，它创建单个工作线程来执行任务，如果这个线程异常结束，会创建另一个线程来替代。它能确保依照任务在队列中的顺序来串行执行。 newScheduledThreadPool：创建了一个固定长度的线程池，而且以延迟或定时的方式执行任务，类似于Timer。 从“为每个任务分配一个线程”策略变为基于线程池的策略，将对应用程序的稳定性产生重大影响：Web服务器不会再在高负载情况下失败。由于服务器不会创建数千个线程来争夺有限的CPU和内存资源，因此服务器的性能将平缓地降低。通过使用Executor，可以实现各种调优/管理/监视/记录日志/错误报告和其他功能，如果不使用任务执行框架，那么要增加这些功能是非常困难的。 Executor的生命周期Executor的实现通常会创建线程来执行任务，但JVM只有在所有非守护线程全部终止之后才会退出，如果无法正确关闭Executor，那么JVM将无法结束。 由于Executor以异步方式来执行任务，因此在任何时刻，之前提交任务的状态不是立即可见的。有些任务可能已经完成，有些可能正在运行，而其他的任务可能在队列中等待执行。当关闭应用程序时，可能采用平缓的方式（完成所有已经启动的任务，并且不再接受任何新的任务），也可能采用粗暴方式（直接所有都关掉）。Executor视为应用程序提供服务的，因此它们也是可关闭的，并把在关闭操作中受影响的任务的状态返回给应用程序。 为了解决执行任务的生命周期问题，ExecutorService接口扩展了Executor，添加了一些用于生命周期管理的方法：12345678public interface ExecutorService extends Executor &#123; void shutdown(); List&lt;Runnable&gt; shutDownNow(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; // ......其他用于任务提交的便利方法&#125; ExectuorService的生命周期有三种状态：运行、关闭和已终止。ExecutorService在创建时处于运行状态，shutdown方法执行优雅地关闭:不再接受新的任务，同时等待已经提交的任务执行完成–包括那些还未开始执行的任务。shutdownNow方法执行粗暴的关闭：它将尝试取消所有运行中的任务，并且不再启动队列中尚未开始执行的任务。 例如支持关闭操作的Web服务器：12345678910111213141516171819202122232425262728293031323334class LifecycleWebServer &#123; private final ExecutorService exec = ...; public void start() throws IOException &#123; ServerSocket socket = new ServerSocket(80); while(!exec.isShutdown()) &#123; try &#123; final Socket conn = socket.accept(); exec.execute(new Runnable() &#123; public void run() &#123; handleRequest(conn); &#125; &#125; ); &#125; catch (RejectedExecutonException e) &#123; if (!exec.isShutdown()) &#123; log("task submission rejected", e); &#125; &#125; &#125; &#125; public void stop() &#123; exec.shutdown(); &#125; void handleRequest(Socket connection) &#123; Request req = readRequest(connection); if (isShutdownRequest(req)) &#123; stop(); &#125; else &#123; dispatchRequest(req); &#125; &#125;&#125; 延迟任务与周期任务Timer类负责管理延迟任务以及周期任务，然而，Timer存在一些缺陷，因此应该考虑使用ScheduledThreadPoolExecutor来代替它，可以通过ScheduledThreadPoolExecutor的构造函数或Executors.newScheduledThreadPool工厂方法来创建该类的对象。它很少被使用，主要的缺陷有： Time在执行所有定时任务时只会创建一个线程，会破坏其他TimeTask的定时精确性。 如果TimeTask抛出一个未检查的异常，那么Time将表现出糟糕的行为。 找出可利用的并行性下面将展示一个逐步利用并行性的浏览器程序中的页面渲染功能，它的作用是将HTMl页面回执到图像缓存中。 最简单的方法是对HTML文档进行串行处理，遇到图像引用，就通过网络获取它，然后再将其绘制到图像缓存中。但是这种方式需要等待很长时间。 另一种串行方式是先绘制文本元素，然后再开始下载图像，如下面的代码：12345678910111213// 图片下载过程的部分时间都是在等待I/O操作执行完成，没有充分利用CPUpublic class SingleThreadRenderer &#123; void renderPage(CharSequence source) &#123; renderText(source); List&lt;ImageData&gt; imageData = new ArrayList&lt;ImageData&gt;(); for (ImageInfo imageInfo : scanForImageInfo(source)) &#123; imageData.add(imageInfo.downloadImage()); &#125; for (ImageData data : imageData) &#123; renderImage(data); &#125; &#125;&#125; Executor使用Runnable作为其基本的任务表示形式，但是Runnable是一种有很大局限的抽象，虽然run能写入到日志文件或者将结果放入到某个共享的数据结构，但它不能返回一个值或抛出一个受检查的异常。 许多任务实际上都是存在延迟的计算—— 执行数据库查询，从网络上获取资源，或者计算某个复杂的功能。对于这些任务，Callable是一种更好的抽象：它认为主入口点（即call）将返回一个值，并可能抛出一个异常。 Runnable和Callable描述的都是抽象的计算任务。这些任务通常都是有范围的，即都有一个明确的起点，并且最终会结束。Executor执行的任务又四个生命周期阶段：创建/提交/开始/完成。由于有些任务可能要执行很长的时间，因此通常希望能够取消这些任务。在Executor框架中，已提交但尚未开始的任务可以取消，但对于那些已经开始执行的任务，只有当它们响应中断时，才能取消。 Future表示一个任务的生命周期，并提供了相应的方法来判断是否已经完成或取消，以及获取任务的结果和取消任务等。在Future规范中包含的隐含意义是，任务的生命周期只能前进，不能后退。当某个任务完成后，它就永远停留在“完成”状态上。 可以通过许多方法创建一个Future来描述任务。ExecutorService中的所有submit方法都将返回一个Future，从而将一个Runnable或Callable提交给Executor，并得到一个Future用来获得任务的执行结果或者取消任务。还可以显式地为某个指定的Runnable或Callable实例化一个FutureTask。 123456789101112131415161718192021222324252627282930313233343536373839// FutureReaderer使得渲染文本与下载图像数据的任务并发执行public class FutureRenderer &#123; // 1.创建ExecutorService ExecutorService executorService = Executors.newCachedThreadPool(); void renderPage(CharSequence source) &#123; final List&lt;ImageInfo&gt; imageInfos = scanFooImageInfo(source); // 2.创建Callable任务 Callable&lt;List&lt;ImageData&gt;&gt; task = new Callable&lt;List&lt;ImageData&gt;&gt;() &#123; public List&lt;ImageData&gt; call() &#123; List&lt;ImageData&gt; result = new ArrayList&lt;ImageData&gt;(); for (ImageInfo imageInfo : imageInfos) &#123; result.add(imageInfo); &#125; return result; &#125; &#125;; // 3. 提交Callable任务，获得Future Future&lt;List&lt;ImageData&gt;&gt; future = (Future) executorService.submit(task); // 渲染文本 renderText(source); // 4. 调用get获取结果，并处理异常 try &#123; List&lt;ImageData&gt; imageData = future.get(); for (imageData data : imageData) &#123; RenderableImage(data); &#125; &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); future.cancel(true); &#125; catch (ExecutionException e) &#123; throw launderThrowable(e.getCause()); &#125; &#125;&#125; get方法的行为取决于任务的状态（尚未开始，正在执行，已完成）。如果任务已经完成，那么get会立即返回或者抛出一个Exception，如果任务没有完成，那么get将阻塞并直到任务完成。如果任务抛出了异常，那么get将该异常封装为ExecutionException并重新抛出。如果任务被取消，那么get将抛出CancellationException。 如果将两个任务A和B分配给两个工人，但A的执行时间是B的10倍，那么整个过程也只能加速9%。最后，当在多个工人之间分解任务时，还需要一定的任务协调开销：为了使任务分解能提高性能，这种开销不能高于并行性实现的提升。所以只有当大量互相独立且同构的任务可以并发进行处理时，才能体现出将程序的工作负载分配到多个任务中带来的真正性能提升。 如果向Executor提交了一组计算任务，并且希望在计算完成后获得结果，那么可以保留与每个任务关联的Future，然后反复使用get方法，同时将参数timeout指定为0，从而通过轮训来判断任务是否完成。这种方法虽然可行，但有些繁琐。幸好有CompletionService（完成服务）。 CompetionService将Executor和BlockingQueue的功能融合在一起，可以将Callable任务提交给它来执行，然后使用类似于队列操作的take和poll等方法来获得已完成的结果，而这些结果会在完成时被封装为Future。ExecutorCompletionService实现了CompletionService，并将计算部分委托给一个Executor。123456789101112131415161718192021222324252627282930313233343536// 通过CompletionService从两方面来提高页面渲染器的性能：缩短总运行时间以及提高响应性。其实现是为每一幅图像都创建一个独立的任务。public class Renderer &#123; // 1.创建一个ExecutorService private final ExecutorService executorService = Executors.newCachedThreadPool(); Renderer(ExecutorService executor) &#123; this.executor = executor; &#125; void renderPage (CharSequence source) &#123; List&lt;ImageInfo&gt; info = scanForImageInfo(source); // 2. 创建ExecutorCompletionService CompletionService&lt;ImageData&gt; completionService = new ExecutorCompletionService&lt;ImageData&gt;(executorService); // 3. 为每幅图片创建一个独立任务 for(final ImageInfo imageInfo: info) &#123; completionService.submit(new Callable&lt;ImageData&gt;() &#123; public ImageData call() &#123; return imageInfo.downloadImage(); &#125; &#125;); &#125; // 渲染文本 renderText(source); // 4. 获取Future，调用get try &#123; for(int i=0, n=info.size(); t&lt;n; t++) &#123; Future&lt;ImageData&gt; future = completionService.take(); ImageData imageData = future.get(); RenderImage(imageData); &#125; &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); &#125; catch (ExecutionException e) &#123; throw launderThrowable(e.getCause()); &#125; &#125;&#125; 有时候，如果某个任务无法在指定时间内完成，那么将不再需要它的结果，此时可以放弃这个任务。在支持时间限制的Future.get中支持这种需求：当结果可用时，它将立即返回，如果在指定时限内没有计算出结果，那么将抛出TimeoutException。在使用限时任务时需要注意，当这些任务超时后应该立即停止，从而避免为继续计算一个不再使用的结果而浪费计算资源。Future如果一个限时的get方法抛出了TimeoutException，那么可以通过Future来取消任务。1234567891011121314151617Page renderPageWithAd() throws InterruptedException &#123; long endNanos = System.nanoTime() + TIME_BUDGET; Future&lt;Ad&gt; future = exec.submit(new FetchAdTask()); Page page = renderPageBody(); Ad ad; try &#123; long timeLeft = endNanos - System.nanoTime(); ad = f.get(timeLeft, NANOSECONDS); // 设定时间 &#125; catch (ExecutionException e) &#123; ad = DEFAULT_AD; &#125; catch (TimeoutException e) &#123; ad = DEFAULT_AD; f.cancel(true); //取消任务 &#125; page.setAd(ad); return page;&#125; 总结Executor框架可以将任务提交与执行策略解耦开来，当需要创建线程来执行任务时，可以考虑使用Executor，同时考虑Callable和Future。要想将应用程序分解为不同的任务并发执行时，必须定义清晰的任务边界。 参考 《Java并发编程实战》]]></content>
      <categories>
        <category>Java并发编程实战</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发_4_基础构建模块]]></title>
    <url>%2F2018%2F01%2F14%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%2FJava%E5%B9%B6%E5%8F%91-4-%E5%9F%BA%E7%A1%80%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[引：JDK提供的东西效率应该是可以保证的，所以我们要学会去使用JDK自带的并发基础构建模块，以及理解在使用这些模块来构建应用程序时的一些常用模式。 同步容器类同步容器类包括Vector和Hashtable。这些类实现线程安全的方式是：将他们的状态封装起来，并对每个公有方法都进行同步，使得每次只有一个线程能访问容器的状态。 同步容器类的问题先看下面的代码：123456789public static Object getLast(Vector list) &#123; int lastIndex = list.size() - 1; return list.get(lastIndex);&#125;public static void deleteLast(Vector list) &#123; int lastIndex = list.size() - 1; list.remove(lastIndex);&#125; 这些方法看起来没有问题，但是如果线程A在执行deleteLast, 线程B在执行getLast，list中有10个元素，刚好B在执行list.size()和get(lastIndex)之间，线程A执行完了remove(lastIndex), 那么线程B在执行get(lastIndex)时就会抛出ArrayIndexOutOfBoundsException。 由于同步容器类要遵守同步策略，即客户端加锁，因此在创建一些新的操作时，只要我们知道应该使用哪一个锁，那么这些新操作就与容器的其他操作一样都是原子操作。如下面的代码：12345678910111213public static Object getLast(Vector list) &#123; synchronized(list) &#123; int lastIndex = list.size() - 1; return list.get(lastIndex); &#125;&#125;public static void deleteLast(Vector list) &#123; synchronized(list) &#123; int lastIndex = list.size() - 1; list.remove(lastIndex); &#125;&#125; 在调用size和相应的get之间，Vector的长度可能会发生变化，这种风险在对Vector中的元素进行迭代时仍然会出现，如下面的代码：12345// 可能抛出ArrayIndexOutOfBoundsException的迭代操作for (int i = 0; i &lt; vector.size(); i++) &#123; doSomething(vetor.get(i));&#125; 我们可以通过在客户端加锁来解决不可靠迭代的问题，但是要牺牲一些伸缩性。通过在迭代期间持有Vector的锁，可以防止其他线程在迭代期间修改Vector。如下面的代码：12345synchronized (vector) &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; doSomething(vetor.get(i)); &#125;&#125; 迭代器与ConcurrentModificationException对容器类进行迭代的标准方式是使用Iterator，然而，如果有其他线程并发地修改容器，那么即使是使用迭代器也无法避免地需要在同步容器上加锁。在设计同步容器类的迭代器时并没有考虑到并发修改的问题，它们的迭代器是“及时失败”的，所以当它们发现容器在迭代过程中发生变化，就会抛出一个ConcurrentModificationException异常。这种fail-fast机制并不是一种完备的处理机制，而只是“善意地”捕获并发错误，因此只能作为并发问题的预警指示器。它们采取的实现方式是将计数器变化与容器关联起来：如果在迭代期间计数器被修改，那么hasNext或next将抛出ConcurrentModificationException。然而，这种检查是在没有同步的情况下进行的，因此可能会看到失效的值，而迭代器可能并没有意识到已经发生了修改。要想避免出现ConcurrentModificationException，就必须在迭代过程中持有容器的锁。 然而，有时候开发人员并不希望在迭代器间对容器加锁。例如，某些线程在可以访问容器之前，必须等待迭代过程结束，如果容器规模很大，或者在每个元素上执行操作的时间很长，那么这些线程就需要长时间等待。持有锁的时间越长，那么在锁上的竞争就越激烈，如果许多线程都在等待锁被释放，那么将极大地降低吞吐量和CPU的利用率。 另一种替代方法是“克隆”容器，并在副本上进行迭代。由于副本被封闭在线程内，因此其他线程不会在迭代期间对其进行修改，这样就避免了抛出ConcurrentModificationException，不过在克隆过程中仍然要加锁（以防在此期间被克隆容器被其他线程修改，那样克隆出来的容器就是失效的容器），所以也会增加性能开销。所以这种方法的好坏取决于多个因素：容器的大小，在每个元素上执行的操作，迭代操作相对于容器上其他操作被调用的频率，以及在响应时间和吞吐量等方面的需求。 隐藏迭代器虽然加锁可以防止迭代器抛出ConcurrentModificationException，但必须记住在所有对共享容器进行迭代的地方都需要加锁。实际情况更复杂，因为在某些情况下，迭代器会隐藏起来。 如下例，标准容器的toString方法将迭代容器，并在每个元素上调用toString来生成容器内容的格式化表示：123456789101112131415161718public class HiddenIterator &#123; @GuardedBy("this") private final Set&lt;Integer&gt; set = new HashSet&lt;Integer&gt;(); public synchronized void add(Integer i) &#123; set.add(i); &#125; public synchronized void remove(Integer i) &#123; set.remove(i); &#125; public void addTenThing() &#123; Random r = new Random(); for (int i=0; i&lt; 10; i++) &#123; set.add(r.nextInt()); &#125; System.out.println("DEBUG: added ten elements to " + set); &#125;&#125; addTenThings方法可能会抛出ConcurrentModificationException，因为toString对set进行了迭代，而且没加锁。如果状态与保护它的同步代码之间相隔越远，那开发人员就越容易忘记在访问状态时使用正确的同步。如果HiddenIterator用synchronizedSet来包装HashSet，并且对同步代码进行封装，那么就不会抛出异常了。容器的hashCode和equals等方法也会间接地执行迭代操作，同样，containsAll, removeAll和retainAll等方法，以及把容器作为参数的构造函数，都会对容器进行迭代，所有这些间接的迭代操作都可能抛出ConcurrentModificationException。 并发容器同步容器将所有对容器状态的访问都串行化，以实现它们的线程安全性，这样的代价就是严重降低并发性，当多个线程竞争容器的锁时，吞吐量将严重降低。Java 5.0提供了多种并发容器类来改进同步容器的性能。通过并发容器来代替同步容器，可以极大地提高伸缩性并降低风险。 Java 5.0增加了ConcurrentHashMap，用来替代基于hash的同步map，增加了CopyOnWriteArrayList，用来替代以遍历操作为主要操作的同步List。在新的ConcurrentMap接口中增加了一些常用的复合操作，例如“putIfAbsent”,replace, 和 conditional remove。 Java 5.0还增加了两个新的集合类型，Queue和BlockingQueue。 Java 6.0增加了ConcurrentSkipListMap来替换同步的SortedMap，增加了ConcurrentSkipListSet替换SortedSet（例如TreeMap和TreeSet） ConcurrentHashMap与HashMap一样，ConcurrentHashMap也是一个基于HashCode的Map，但它使用了一种完全不同的加锁策略来提供更高的并发性和伸缩性。ConcurrentHashMap并不是将每个方法都在同一把锁上同步并使得每次只有一个线程访问容器，而是使用一个种粒度更细的加锁机制来时间共享，叫做分段锁。在这种机制下，任意数量的读取线程可以并发地访问这个map，执行读取操作的线程和执行写入操作的线程可以并发地访问map，并且一定数量的写入线程可以并发地修改Map。 而且ConcurrentHashMap提供的迭代器不会抛出ConcurrentModificationException，因此不需要再迭代过程中对容器加锁。它返回的迭代器具有弱一致性，而并非“及时失败”。弱一致性的迭代器可以容忍并发的修改，当创建迭代器时会遍历已有的元素，并可以在迭代器被构造后将修改操作反映给容器。 与Hashtable和synchronized-Map相比，ConcurrentHashMap有着更多的优势以及更少的劣势。因此在大多数情况下，用ConcurrentHashMap来代替同步Map能进一步提高代码的可伸缩性，只有当应用程序需要给map加锁以进行独占访问时，才应该放弃使用ConcurrentHashMap。 额外的原子Map操作由于ConcurrentHashMap不能被加锁来执行独占访问，因此也无法使用客户端加锁来创建新的原子操作。但是一些常见的复合操作，如“如没有则添加（put-if-absent）”,”若相等则移除（remove-if-equals）”,”若相等则替换（replace-if-equals）”等，都已经在ConcurrentMap接口中有声明，所以如果需要为现有的同步Map添加这样的功能，就应该考虑使用ConcurrentMap了。 CopyOnWriteArrayListCopyOnWriteArrayList用于替代同步list，在某些情况下提供了更好的并发性能，并且在迭代器间不需要对容器进行加锁或复制。（类似地，CopyOnWriteArraySet的作用是替代同步set） Copy-On-Write容器的线程安全性在于，只要正确地发布一个实际不可变的对象，那么在访问该对象时就不需要进一步的同步了。 Copy-On-Write从字面上看就是，Write的时候总是要Copy，所以在每次修改时，都会创建并重新发布一个新的容器副本。而CopyOnWriteArrayList容器的迭代器会保留一个指向原始数组的引用，遍历的也是原始数组，而其他线程修改的是这个原始数组的副本，所以也不会影响原始数组，原始数组不会改变，也就不会有ConcurrentModificationException了，并且返回的元素和迭代器创建时的元素完全一致。 显然，每当修改容器时都会复制原始数组，这需要一定开销，特别是当容器的规模较大时。仅当迭代器操作多于修改操作时，才应该使用“写入时复制”容器。 阻塞队列和生产者-消费者模式基于阻塞队列构建的生产者-消费者设计中：当数据生成时，生产者把数据放入队列，而当消费者准备处理数据时，将从队列中获取数据。阻塞队列简化了生产者-消费者设计的实现过程，它支持任意数量的生产者和消费者。 在构建高可靠的应用程序时，有界队列是一种强大的资源管理工具：它们能抑制并防止产生过多的工作项，使应用程序在负荷过载的情况下变得更加健壮。 BlockingQueue有多种实现：LinkedBlockingQueue和ArrayBlockingQueue是FIFO队列，与LinkedList和ArrayList相似，但比同步list有更好的并发性能。PriorityBlockingQueue是一个按优先级排序的队列，当你希望按照某种顺序而不是FIFO来处理元素时，这个队列非常有用，PriorityBlockingQueue既可以根据元素的自然顺序来比较元素，也可以使用Comparator来比较。最后一个BlockingQueue是SynchronousQueue，它并不是一个真正的队列，因为它不会为队列中元素维护存储空间。它维护的是一组线程，这些线程在等待着把元素加入或移出队列。以洗盘子为例，相当于没有盘架，直接将洗好的盘子放入下一个空闲的烘干机中，它可以直接交付工作，从而降低了将数据从生产者移动到消费者的延迟。因为SynchronousQueue没有存储功能，因此put和take会一直阻塞，直到有另一个线程已经准备好参与到交付过程中。仅当有足够多的消费者，并且总有一个消费者准备好获取交付的工作时，才适合使用同步队列。 串行线程封闭对于可变对象，生产者-消费者这种设计与阻塞队列组合在一起使得把对象从生产者转移给消费者变得容易。线程封闭对象只能由单个线程拥有，但可以通过安全地发布该对象来转移所有权。在所有权转移后，就只有新线程能获得这个对象的访问权限，并且发布对象的线程不会再访问它。这种安全的发布确保了对象状态对于新的所有者来说是可见的，并且由于最初的所有者不会再访问它，所以这个对象又被封闭在新的线程中，新线程可以对该对象做任意修改，因为它具有独占的访问权。 对象池利用了串行线程封闭，将对象借给一个请求线程。只要对象池包含足够的内部同步来安全地发布池中的对象，并且只要客户代码本身不会发布池中的对象，或者在将对象返回给对象池后就不再使用它，那么就可以安全地在线程之间传递所有权。 双端队列与工作密取Java 6增加了两种容器类型，Deque&amp;BlockingQueue。Deque是一个双端队列，实现了在队列头和队列尾的高效插入和移除。 双端队列适用于另一种相关模式，即工作密取（Work Stealing）。（不懂） 同步工具类同步器可以是任何一个对象，只要它根据其自身的状态来协调线程的控制流就可以叫同步器。阻塞队列可以作为同步器，其他类型的同步器还包括信号量(Semaphore)/栅栏（Barrier）以及闭锁（Latch）。 所有的同步器都包含一些特定的结构化属性：它们封装了一些状态，这些状态将决定使用同步器的线程是继续执行还是等待，此外还提供了一些方法对状态进行操作，以及另一些方法用于高效地等待同步器进入到预期状态。 闭锁闭锁时一种同步器，可以延迟线程的进度直到线程到达终止状态。闭锁的作用相当于一扇门：在闭锁到达terminal状态前，这扇门一直是关闭的，没有任何线程通过，而当到达terminal状态时，这扇门就会打开允许所有线程通过。当闭锁达到terminal状态，它的状态就不会再改变，因此这扇门会永远打开。闭锁可以用来确保某些活动直到其他活动都完成后才继续执行。例如： 确保某个计算在其需要的所有资源都初始化之后才继续执行 确保某个服务在其依赖的所有其他服务都已经启动之后才启动 等待某个操作的所有参与者都就绪再继续执行 CountDownLatch是一种灵活的闭锁，可以在上述各种情况中使用，它可以使一个或多个线程等待一组事件发生。countDown方法递减计数器，表示有一个事件已经发生了，而await方法等待计数器达到零，这表示所有需要等待的事件都已经发生。如果计数器的值非零，那么await会一直阻塞直到计数器为零，或者等待中的线程中断，或者等待超时。例如下面的代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class TestHarness &#123; public long timeTasks(int nThreads, final Runnable task) throws InterruptedException &#123; final CountDownLatch startGate = new CountDownLatch(1); final CountDownLatch endGate = new CountDownLatch(nThreads); for(int i = 0; i &lt; nThreads; i++) &#123; Thread t = new Thread() &#123; public void run() &#123; try &#123; startGate.await(); try &#123; task.run(); &#125; finally &#123; endGate.countDown(); &#125; &#125; catch (InterruptedException ignored) &#123;&#125; &#125; &#125;; t.start(); &#125; long start = System.nanoTime(); startGate.countDown(); endGate.await(); long end = System.nanoTime(); return end-start; &#125; public static void main(String[] args) &#123; Runnable task = new Runnable() &#123; @Override public void run() &#123; System.out.println("ing"); &#125; &#125;; try &#123; long interval = new TestHarness().timeTasks(3, task); System.out.println(interval); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125; 启动门将使得主线程能够同时释放所有工作线程，而结束门则使主线程能够等待最后一个线程执行完成。 FutureTaskFutureTask也可以用作闭锁，它可以处于下面3种状态：等待运行、正在运行和运行完成。Future.get的行为取决于任务的状态，如果任务已经完成，那么get会立即返回结果，否则get将阻塞直到任务进行完成状态。 信号量计数信号量用来控制同时访问某个特定资源的操作数量，或者同时执行某个指定操作的数量。计数信号量还可以用来实现某种资源池，或者对容器施加边界。 Semaphore管理着一组虚拟的permits，许可的初始数量通过构造函数指定。在执行操作前先acquire permits（只要有剩余的许可就可以），在使用完后会release这个许可。如果没有获得permit，acquire方法将一直阻塞到有许可或指导被中断或超时。release方法将返回一个permit给信号量。 Semaphore也可以将任何一种容器变成有界阻塞容器。信号量的计数值会初始化为容器容量的最大值，add操作在向容器添加一个元素之前，首先获取一个permit，然后再添加，如果添加失败，那么会释放许可，如果成功就不释放了。同样，remove操作会释放一个许可，来使更多的元素能够添加到容器中。代码如下：1234567891011121314151617181920212223242526272829303132public class BoundedHashSet&lt;T&gt; &#123; private final Set&lt;T&gt; set; private final Semaphore sem; public BoundedHashSet(int bound) &#123; this.set = Collections.synchronizedSet(new HashSet&lt;T&gt;()); sem = new Semaphore(bound); &#125; public boolean add(T o) throws InterruptedException &#123; sem.acquire(); boolean wasAdded = false; try &#123; wasAdded = set.add(o); &#125; finally &#123; if (!wasAdded) &#123; sem.release(); &#125; &#125; return wasAdded; &#125; public boolean remove(Object o) &#123; boolean wasRemoved = set.remove(o); if (wasRemoved) &#123; sem.release(); &#125; return wasRemoved; &#125;&#125; 栅栏闭锁可以启动一组相关的操作，或者等待一组相关的操作结束。闭锁时一次性对象，一旦进入终止状态，就不能被重置。 栅栏类似于闭锁，它能阻塞一组线程直到某个事件发生。栅栏与闭锁的关键区别在于，所有线程必须同时到达栅栏位置，才能继续执行。闭锁用于等待事件发生，而栅栏用于等待其他线程。 构建高效且可伸缩的结果缓存下面的几个代码段将逐步构架一个高效且可伸缩的缓存：123456789101112131415161718192021222324252627282930313233// Memoizer1存在一个可伸缩的问题，每次只有一个线程能够执行compute。public interface Computable&lt;A,V&gt; &#123; V compute(A arg) throws InterruptedException;&#125;public class ExpensiveFunction implements Computable&lt;String, BigInteger&gt;&#123; @Override public BigInteger compute(String arg) throws InterruptedException &#123; //在经过长时间的计算后 return new BigInteger(arg); &#125;&#125;public class Memoizer1&lt;A, V&gt; implements Computable&lt;A, V&gt; &#123; private final Map&lt;A, V&gt; cache = new HashMap&lt;A, V&gt;(); private final Computable&lt;A, V&gt; c; public Memoizer1(Computable&lt;A, V&gt; c) &#123; this.c = c; &#125; @Override public synchronized V compute(A arg) throws InterruptedException &#123; V result = cache.get(arg); if (result == null) &#123; result = c.compute(arg); cache.put(arg, result); &#125; return result; &#125;&#125; 1234567891011121314151617181920// 会存在重复计算的问题public class Memoizer2&lt;A, V&gt; implements Computable&lt;A, V&gt; &#123; private final Map&lt;A, V&gt; cache = new ConcurrentHashMap&lt;A, V&gt;(); private final Computable&lt;A, V&gt; c; public Memoizer2(Computable&lt;A, V&gt; c) &#123; this.c = c; &#125; @Override public V compute(A arg) throws InterruptedException &#123; V result = cache.get(arg); if (result == null) &#123; result = c.compute(arg); cache.put(arg, result); &#125; return result; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/*利用FutureTask来减少重复计算的问题,但是由于if判断中依然存在非原子的“先检查再执行”的操作，所以还是会存在重复计算的问题*/ public class Memoizer3&lt;A, V&gt; implements Computable&lt;A, V&gt; &#123; private final Map&lt;A, Future&lt;V&gt;&gt; cache = new ConcurrentHashMap&lt;A, Future&lt;V&gt;&gt;(); private final Computable&lt;A, V&gt; c; public Memoizer3(Computable&lt;A, V&gt; c) &#123; this.c = c; &#125; @Override public V compute(final A arg) throws InterruptedException &#123; Future&lt;V&gt; f = cache.get(arg); if (f == null) &#123; Callable&lt;V&gt; eval = new Callable&lt;V&gt;() &#123; @Override public V call() throws InterruptedException &#123; return c.compute(arg); &#125; &#125;; FutureTask&lt;V&gt; ft = new FutureTask&lt;V&gt;(eval); f = ft; cache.put(arg,ft); ft.run(); &#125; try &#123; return f.get(); &#125; catch (ExecutionException e) &#123; throw launderThrowable(e.getCause()); &#125; &#125; /** * 强制将未检查的Throwable转化为RuntimeException * @param t * @return */ public static RuntimeException launderThrowable(Throwable t) &#123; if (t instanceof RuntimeException) &#123; return (RuntimeException) t; &#125; else if (t instanceof Error) &#123; throw (Error) t; &#125; else &#123; throw new IllegalStateException("Not unchecked",t); &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738// **最终版**// 利用复合操作“若没有则添加”可以解决Memoizer3的问题public class Memoizer4&lt;A, V&gt; implements Computable&lt;A, V&gt; &#123; private final Map&lt;A, Future&lt;V&gt;&gt; cache = new ConcurrentHashMap&lt;A, Future&lt;V&gt;&gt;(); private final Computable&lt;A, V&gt; c; public Memoizer4(Computable&lt;A, V&gt; c) &#123; this.c = c; &#125; @Override public V compute(final A arg) throws InterruptedException &#123; while (true) &#123; Future&lt;V&gt; f = cache.get(arg); if (f == null) &#123; Callable&lt;V&gt; eval = new Callable&lt;V&gt;() &#123; @Override public V call() throws InterruptedException &#123; return c.compute(arg); &#125; &#125;; FutureTask&lt;V&gt; ft = new FutureTask&lt;V&gt;(eval); f = ft; cache.putIfAbsent(arg, ft); ft.run(); &#125; try &#123; return f.get(); &#125; catch (CancellationException e) &#123; cache.remove(arg, f); //为了解决缓存污染问题，当计算被取消或者失败时，就从缓存中remove &#125; catch (ExecutionException e) &#123; throw launderThrowable(e.getCause()); &#125; &#125; &#125;&#125; 总结构建一个高效且具有伸缩性的基础模块还是有点难度的，我们要考虑的东西比较多，我们要利用已有的基础模块合理构建。 参考 《Java并发编程实战》 《Java并发编程实践》（四）—- 构建阻塞 图解集合3：CopyOnWriteArrayList]]></content>
      <categories>
        <category>Java并发编程实战</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发_3_对象的组合]]></title>
    <url>%2F2018%2F01%2F13%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%2FJava%E5%B9%B6%E5%8F%91-3-%E5%AF%B9%E8%B1%A1%E7%9A%84%E7%BB%84%E5%90%88%2F</url>
    <content type="text"><![CDATA[引：我们不希望每一次访问内存都进行分析以确保程序是线程安全的，而是希望将一些现有的线程安全组件组合为更大规模的组件或程序。 设计线程安全的类 在设计线程安全类的过程中，需要包含以下三个基本要素： 找出构成对象状态的所有变量 找出约束状态变量的不变性条件 建立对象的并发访问管理策略 同步策略规定了如何将不变性、线程封闭、加锁机制等结合起来以维护线程的安全性，并且规定了哪些变量由哪些锁来保护。要确保开发人员可以对这个类进行分析与维护，就必须将同步策略写成正式文档。 收集同步需求要确保类的线程安全性，就需要确保它的不变性条件不会再并发访问时被破坏，这就需要对其状态进行推断。在许多类中都定义了一些不可变条件，用于判断状态是有效的还是无效的。同样，在操作中还包含一些后验条件来判断状态转换是否有效。当下一个状态需要依赖当前状态时，这个操作就必须是一个复合操作。如果不了解对象的不变性与后验条件，那么就不能确保线程安全性，要满足状态变量的有效值或状态转换上的各种约束条件，就需要借助于原子性与封装性。 依赖状态的操作类的不变性条件和后验条件限制了对象的有效状态已经状态转换的有效性。有些对象包含一些基于状态的先验条件，例如，不能从空队列中移除一个元素。如果在操作中包含基于状态的先验条件，那么这个操作就叫做依赖状态操作。 在并发程序中要一直等到先验条件为真然后再进行操作，可以使用现有库的类（阻塞队列[Blocking Queue]或信号量[Semaphore]）来实现依赖状态的行为。 状态的所有权多数情况下，所有权与封装性是相互关联的：对象封装它拥有的状态，也对它封装的状态拥有所有权。状态变量的所有者将决定采用何种加锁协议来维持变量状态的完整性。所有权意味着控制权。如果发布了某个可变对象的引用，那么原来的所有者就不再独占控制权了，就变成共享控制权了。 实例封闭封装简化了线程安全类的实现过程，它提供了一种实例封装机制，也简称为封闭。将数据封装在对象内部，就可以将数据的访问限制在对象的方法上，从而更容易确保线程在访问数据时总能持有正确的锁。 可以看下面的例子：1234567891011121314@ThreadSafepublic class PersonSet &#123; @GuardedBy("this") private final Set&lt;Person&gt; mySet = new HashSet&lt;&gt;(); public synchronized void addPerson(Person p) &#123; mySet.add(p); &#125; public synchronized boolean containsPerson(Person p) &#123; return mySet.contains(p); &#125;&#125; PersonSet类说明了如何通过将mySet封闭在一个类属性中以及使用加锁机制使一个类成为线程安全的。PersonSet的状态由HashSet来管理，而HashSet不是线程安全的，但由于mySet是私有的并且不会逸出，因此HashSet被封闭在PersonSet中。唯一能访问mySet的代码路径是addPerson和containsPerson两个方法，在执行它们时都要获得PersonSet的内置锁，所以PersonSet的状态完全由它的内置锁保护，因而PersonSet是一个线程安全的类。 线程封闭的作用可以将非线程安全的类转化为线程安全的类。可以利用到装饰器模式。封闭机制更易于构造线程安全的类，因为在分析线程安全性时可以只分析该类而不用检查整个程序。 Java监视器模式Java的内置锁也称为监视器锁或监视器。所以使用内置锁来保证线程安全性的模式就叫做Java监视器模式。遵循Java监视器模式的对象会把对象的所有可变状态都封装起来，并由对象自己的内置锁来保护。Java监视器模式仅仅是一种编写代码的乐队，对于任何一种锁对象，只要自始至终都使用该锁对象，都可以用来保护对象的状态。（不知道是不是只要读和写方法只要都保持同步就好了？） 线程安全的委托（需要好好理解的，日后加深）在某些情况下，通过多个线程类组合而成的类是线程安全的，而在某些情况下，这仅仅是一个好的开端，但却是线程不安全的（由于没有维持不变性约束）。 如果一个类是由多个独立且线程安全的状态变量组成，并且在所有的操作中都不包含无效状态转换，那么可以将线程安全性委托给这些状态变量。 如果一个状态变量是线程安全的，也不参与任何不变性条件，也没有操作上的状态变换，那这个变量就可以发布出去。 在现有的线程安全类中添加功能Java类库包中包含许多有用的“基础模块”类，通常，我们应该优先选择重用这些现有的类而不是创建新的类：重用能降低开发工作量、开发风险（因为现有的类都已经通过测试）以及维护成本。我们需要在不破坏线程安全性的情况下添加一个新的操作。 要添加一个新的原子操作，最安全的方法是修改原始类，但这通常无法做到，因为可能无法访问或修改类的源代码。如果直接将新方法添加到类中，那么意味着实现同步策略的所有代码仍然处于一个源文件中，从而更容易维护。另一种方法是用子类扩展这个类，但这样的话同步策略的实现就分布在了多个需要单独维护的源文件中，如果父类修改了同步策略选择不同的锁来保护它的状态变量，那子类也需要跟着变。如下面的代码：1234567891011// 扩展Vector并增加一个“若没有则添加”方法public class BetterVector&lt;E&gt; extends Vector&lt;E&gt; &#123; public synchronized boolean putIfAbsent(E x) &#123; boolean absent = !contains(x); if (absent) &#123; add(x); &#125; return absent &#125;&#125; 客户端加锁机制第三种策略是扩展类的功能，但并不是扩展类本身，而是将扩展方法放在一个辅助类（Helper class）中。代码如下：1234567891011public class ListHelper&lt;E&gt; &#123; public List&lt;E&gt; list = Collections.synchronizedList(new ArrayList&lt;E&gt;()); ... public synchronized boolean putIfAbsent(E x) &#123; boolean absent = !list.contains(x); if(absent) &#123; list.add(x); &#125; return absent; &#125;&#125; putIfAbsent用的是ListHelper的内置锁，但list用的肯定不是ListHelper的锁，尽管所有的list操作都被声明为synchronized，但却是不一样的锁，这就无法确保当putIfAbsent执行时另一个线程不会修改这个list。 要想使这个方法正确执行，必须使list在实现客户端加锁或外部加锁时使用同一个锁。客户端加锁是指，对于使用某个对象X的客户端代码，使用X本身用于保护其状态的锁来保护这段客户端代码。要使用客户端加锁，就必须知道对象X使用的是哪一个锁。在Vector和同步封装器类的文档中指出，它们通过使用Vector或封装器容器的内置锁来支持客户端加锁。所以修改后的putIfAbsent如下：12345678910111213public class ListHelper&lt;E&gt; &#123; public List&lt;E&gt; list = Collections.synchronizedList(new ArrayList&lt;E&gt;()); ... public boolean putIfAbsent(E x) &#123; synchronized(list) &#123; boolean absent = !list.contains(x); if(absent) &#123; list.add(x); &#125; return absent; &#125; &#125;&#125; 组合更好地为现有类添加原子操作的方法是：组合。示例如下：1234567891011121314151617public class ImprovedList&lt;T&gt; implements List&lt;T&gt; &#123; private final list&lt;T&gt; list; public ImprovedList(List&lt;T&gt; list) &#123; this.list = list; &#125; public synchronized boolean putIfAbsent(T x) &#123; boolean contains = list.contains(x); if(!contains) &#123; list.add(x); &#125; return !contains; &#125; public synchronized void clear() &#123; list.clear(); &#125;&#125; ImprovedList通过自身的内置锁增加了一层额外的加锁。它并不关心List是否是线程安全的，即使List不是线程安全的或者修改了它的加锁实现，ImprovedList也会提供一致的加锁机制来实现线程安全性。事实上，我们使用了Java监视器模式来封装现有的List，并且只要在类中拥有指向底层List的唯一外部引用，就能确保线程安全性。 总结设计一个线程安全的类方法有很多种，这里提到了三点：实例封闭、线程委托、复用现有基础类。但是具体实现线程安全都不一样，需要按实际情况来确定。 参考 《Java并发编程实战》]]></content>
      <categories>
        <category>Java并发编程实战</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发_2_对象的共享]]></title>
    <url>%2F2018%2F01%2F13%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%2FJava%E5%B9%B6%E5%8F%91-2-%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%85%B1%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[引：为了能够安全地由多个线程同时访问某个对象，我们就需要学会在共享和发布对象时，构建一个线程安全类或者通过java.util.concurrent类库来构建。 可见性在读操作和写操作在不同线程执行时，我们无法确保执行读操作的线程能适时地看到其他线程写入的值，所谓“不可见”。为了确保多个线程之间对内存写入操作的可见性，必须使用同步机制。 先看下面的代码：12345678910111213141516171819public class NoVisibility &#123; private static boolean ready; private static int number; private static class ReaderThread extends Thread &#123; public void run() &#123; while(!ready) &#123; Thread.yield(); &#125; System.out.println(number); &#125; &#125; public static void main(String[] args) &#123; new ReaderThread().start(); number = 42; ready = true; &#125;&#125; 这段代码不能保证输出42，可能输出0，因为读线程可能看到了写入ready的值，但却没有看到之后写入的number的值，这种现象称为“重排序”，它的意思是代码的顺序可能因为优化而发生重排序。 失效数据失效数据：当读线程查看一个变量是，可能会得到一个已经失效的值。除非在每次访问变量时都使用同步，否则很可能获得该变量的一个失效值。更糟糕的是，失效值可能不会同时出现：一个线程可能得到某个变量的最新值，而获得另一个变量的失效值。 下面的代码不是线程安全的：12345678910111213@NonThreadSafepublic class MutableInteger &#123; private int value; public int get() &#123; return value; &#125; public void set(int value) &#123; this.value = value; &#125;&#125; get和set都是在没有同步的情况下访问value，所以失效值问题很容易出现：如果某个线程在调用了get，那么另一个正在调用get的线程可能会看到更新后的value值，也可能看不到。要使MutableInteger成为一个线程安全的类，必须对set和get都进行同步。 非原子的64位操作最低安全性（out-of-thin-air-safety）:当线程在没有同步的情况下读取变量时，可能会得到一个失效值，但至少这个值是由之前某个线程设置的值，而不是一个随机值。 例外：对于非volatile类型的long和double变量，JVM允许64位的读操作和写操作分解为两个32位的操作。那么很有可能会读到某个值的高32位和另一个值的低32位。所以在多线程程序中使用共享且可变的long和double等类型的变量是不安全的，除非使用关键字volatile来声明他们，或者用锁保护起来。 volatile变量volatile变量可以确保将变量的更新操作通知到其他线程。并且会禁止重排序，因此在读取volatile类型的变量时总会返回最新写入的值。volatile通常用作某个操作完成。发生中断或者状态的标志。它只能保证可见性，但是不能保证原子性。 当且仅当满足所有条件时，才应该使用volatile变量： 对变量的写入操作不依赖变量的当前值（比读到的还要新的值），或者你能保证只有当个线程更新变量的值。 该变量不会与其他状态变量一起纳入不变性条件中。 在访问变量时不需要加锁。 发布和逸出“发布（Publish）”对象：使对象能够在当前作用域之外的代码中使用。例如：将一个指向该对象的引用保存到其他代码可以访问的地方（公有的静态变量中） “逸出（Escape）”：当某个不应该发布的对象被发布。例如：在对象构造完成之前就发布对象 发布对象的最简单方法是将对象的引用保存到一个公有的静态变量中，以便任何类和线程都能看见该对象，如下面代码：12345public static Set&lt;Secret&gt; knownSecrets;public void initialize() &#123; knownSecrets = new HashSet&lt;Secret&gt;();&#125; 当发布某个对象时，可能会间接地发布其他对象。如果将一个Secret对象添加到集合knownSecrets中，那么同样会发布这个对象，因为任何代码都可以遍历这个集合，并获得对这个新Secret对象的引用。同样，如果从非私有方法中返回一个引用，那么同样会发布返回的对象。如下面的代码：123456class UnsafeStates &#123; private String[] states = new String[] &#123;"AK","AL"...&#125;; public String[] getStates() &#123; return states; &#125;&#125; 另一种将一个对象或者它内部的状态publish出去的方式就是publish这个对象所在类的内部类，如下例子,但是会将this对象的引用escape出去。因为当ThisEscape将EventListener publish出去，它就显示地将外部类ThisEscape实例对象也公布出去了，因为内部类实例保存了外部类实例的隐藏引用。所以会把this escape出去。1234567891011public class ThisEscape &#123; public public ThisEscape(EventSource source) &#123; source.registerListener( new EventListener() &#123; public void onEvent(Event o) &#123; doSomething(o);// 由于这个线程是异步的，所有EventSource可能还没有构造完 &#125; &#125;); &#125;&#125; 当内部EventListener实例发布时，在外部封装的ThisEscape实例也逸出了，当且仅当对象的构造函数返回时，对象才处于可预测的和一致的状态。一个常见的使this引用在构造过程中逸出的错误是在构造函数中启动一个线程。如果想在构造函数中注册一个事件监听器或启动线程，可以使用一个私有的构造函数和一个公共的工厂方法，从而避免不正确的构造过程：123456789101112131415161718public class SafeListener &#123; private final EventListener listener; private SafeListener() &#123; listener = new EventListener() &#123; public void onEvent(Event o) &#123; doSomething(o); &#125; &#125; &#125; public static SafeListener newInstance(EventSource source) &#123; SafeListener safeListener = new SafeListener(); source.registerListener(safeListener); return safeListener; &#125;&#125; 线程封闭当访问共享的可变数据时，通常需要同步。一种避免使用同步的方式就是不共享数据。如果仅在单线程内访问数据，就不需要同步。这种技术被称为线程封闭。 线程封闭的一个常见应用是从池中拿JDBC Connection。在典型的服务器应用中，一个线程从池中获取connection对象，用它来处理一个单独的请求，处理完后归还该connection，又放入池中。Connection池是不会把相同的connection对象分配给不同的线程的，这种模式就显式地将那个connection封闭在一个线程中。 局部变量和ThreadLocal类就是用来维护线程封闭特性的，但即便有这些现成的特性，程序员仍有义务去保证封闭在线程中的对象不会从线程中逸出 Ad-hoc线程封闭这种线程封闭是指，维护线程封闭性的职责完全由程序实现来承担。这种技术很脆弱，因此程序中尽量少用它。 栈封闭栈封闭式线程封闭的一种特例，在栈封闭中，只能通过局部变量才能访问对象。局部变量的固有属性之一就是封闭在执行线程中，它们位于执行线程的栈中，其他线程无法访问这个栈。栈封闭比Ad-hoc线程封闭更易于维护，也更加健壮。可以看看下面的例子：123456789101112131415161718public int loadTheArk(Collections&lt;Animal&gt; candidates) &#123; SortedSet&lt;Animal&gt; animals; int numPairs = 0; Animals candidate = null; animals = new TreeSet&lt;Animal&gt;(new SpeciesGenderComparator()); animals.addAll(candidates); for(animals a : animals) &#123; if (candidate == null || !candidate.isPotentialMate(a)) &#123; candidate = a; &#125; else &#123; ark.load(new AnimalPair(candidate, a)); ++numPairs; candidate = null; &#125; &#125; return numPairs; &#125; 上面代码中的numPairs不会破坏线程封闭性，因为任何方法都无法获得对基本类型的引用，所以基本类型的局部变量始终封闭在线程内。但是对于对象引用的线程封闭，就需要一些额外的工作确保对象引用不会逸出。在上例中实例化了一个TreeSet,并用animals引用指向它，因为只有一个引用指向这个Set，而且这个引用是局部变量，所以这个对象引用也被封闭在线程中。但是如果把这个animals公布（publish）出去，线程封闭性就会破化。 ThreadLocal类维护线程封闭性的一种更规范的方式是使用ThreadLocal. ThreadLocal提供了get和set方法，这些方法为每个使用该变量的线程都存有一份独立的副本，因此get总是返回由当前执行线程在调用set时设置的最新值。 例如，在单线程应用程序中可能会维持一个全局的数据库连接，并在程序启动时初始化这个连接对象，从而避免在调用每个方法时都要传递一个Connection对象。由于JDBC的连接对象不一定是线程安全的，因此，当多线程应用程序在没有协同的情况下使用全局变量时，就不是线程安全的。通过将JDBC的连接保存到ThreadLocal对象中，每个线程都会拥有属于自己的连接，如下：123456789private static ThreadLocal&lt;Connection&gt; connectionHolder = new ThreadLocal&lt;&gt;()&#123; public Connection initialValue() &#123; return DriverManager.getConnection(DB_URL); &#125;&#125;;public static Connection getConnection() &#123; return connectionHolder.get();&#125; 当某个线程初次调用ThreadLocal.get方法时，会调用initialValue()方法来获取初始值。从概念上讲，可以将ThreadLocal视为包含了Map对象，其中保存了只属于该线程的值。当线程终止后，这些值就会作为垃圾被回收掉。 不变性如果某个对象在创建之后状态就不能被修改，那这个对象就被称为不可变对象。不可变对象一定是线程安全的。不可变对象只有一种状态，而且这种状态由构造函数来控制。 当满足一下条件的时候，对象才是不可变的： 对象创建以后其状态就不能修改 对象的所有域都是final类型 对象是正确创建的（在对象的创建过程中，this引用没有逸出） 不可变对象仍然可以在内部使用可变对象来管理它们的状态。如下例：12345678910111213141516@Immutablepublic final class ThreeStooges &#123; private final Set&lt;String&gt; stooges = new HashSet&lt;&gt;(); public ThreeStooges() &#123; stooges.add("Moe"); stooges.add("Larry"); stooges.add("Curly"); &#125; public boolean isStooge(String name)&#123; return stooges.contains(name); &#125;&#125; Final域正如“除非需要更高的可见性，否则应将所有的域都声明为私有域”一样，“除非需要某个域是可变的，否则应将其声明为final域”也是一个良好的编程习惯。 使用Volatile类型来发布不可变对象为了保证操作的原子性，可以将多个状态转化为包含多个状态的不可变对象，然后使用volatile来保持可见性，从而保证了线程安全。如下面的例子：1234567891011121314151617181920212223242526272829303132public class VolatileCachedFactorizer implements Servlet&#123; private volatile OneValueCache cache = new OneValueCache(null, null); public void service(ServletRequest req, ServletResponse resp) &#123; BigInteger i = extractFromRequest(req); BigInteger[] factors = cache.getFactors(i); if (factors == null) &#123; factors = factor(i); cache = new OneValueCache(i, factors); &#125; encodeIntoResponse(resp, factors); &#125;&#125;class OneValueCache &#123; private final BigInteger lastNumber; private final BigInteger[] lastFactos; public OneValueCache(BigInteger i, BigInteger[] factors) &#123; lastNumber = i; lastFactos = Arrays.copyOf(factors, factors.length); &#125; public BigInteger[] getFactors(BigInteger i) &#123; if (lastNumber == null || !lastNumber.equals(i)) &#123; return null; &#125; else &#123; return Arrays.copyOf(lastFactos, lastFactos.length); &#125; &#125;&#125; 安全发布在某些情况下我们希望在多个线程间共享对象，此时必须确保安全地进行共享。 不正确的发布：可见性出现问题例子：12345678910111213141516public Holder hoder;public void initialize() &#123; holder = new Holder(42);&#125;public class Holder &#123; private int n; public Holder(int n) &#123; this.n = n; &#125; public void assertSanity() &#123; if(n != n) &#123; throw new AssertionError("This statement is false"); &#125; &#125;&#125; 因为除了发布对象的线程外，其他线程可以看到的Holder域可能是一个失效值。 不可变对象与初始化安全性任何线程都可以在不需要额外同步的情况下安全地访问不可变对象，即使在发布这些对象时没有使用同步。 安全发布的常用模式要安全地发布一个对象，那它的引用和状态必须同时对其他线程可见。一个正确构造的对象可以通过以下方式安全地发布： 在静态初始化函数中初始化对象的引用 把对象的引用保存在volatile类型的域或者AtomicReference对象中 将对象的引用保存到某个正确构造的final对象的域中 将对象的引用保存到一个由锁保护的域中 使用静态初始化函数通常是最简单最安全的发布方式:1public static Holder holder = new Holder(42); 静态初始化器由JVM在类的初始化阶段执行，由于JVM内部存在在同步机制，因此通过这种方式初始化的任何对象都哦可以被安全发布。 事实不可变对象如果对象在技术上来看是可变的，但其状态在发布之后不会再改变，那么这种对象成为“实际不可变对象”，在这些对象发布之后，程序之需要将它们视为不可变对象即可。所以如果确认某些对象是实际不可变对象，就可以简化开发减少同步从而提升性能。 可变对象如果对象在构造后可以被修改，那么安全发布只能确保这个对象在发布当时状态的可见性，为了保证线程安全，就需要在每次对象访问时也使用同步来确保后续修改操作的可见性。对象的发布方式取决于它的可变性： 不可变对象可以通过任何机制来发布； 事实不可变对象必须通过安全方式来发布 可变对象必须通过安全方式来发布，并且必须是线程安全的或由某个锁保护起 安全的共享对象在并发程序中使用共享对象是，可以使用一些实用的策略： 线程封闭。线程封闭的对象只能由一个线程拥有，对象被封闭在该线程中，并且只能由这个线程修改。 只读共享。在没有额外同步的情况下，共享的只读对象可以由多个线程并发访问，但任何线程都不能修改它。共享的只读对象包括不可变对象和实际不可变对象。 线程安全共享。线程安全的对象在其内部实现同步，因此多个线程可以通过对象的公有接口来进行访问而不需要进一步的同步。 保护对象。被保护的对象只能通过持有特定的锁来访问。保护对象包括封装在其他线程安全对象中的对象，以及已发布的并且由某个特定锁保护的对象。 总结由于对象需要共享，所以要注意发布的安全性，以及对不可以变对象的合理应用。 参考 《Java并发编程实战》 java并发编程实践学习（四）对象的发布和逸出之this逃逸]]></content>
      <categories>
        <category>Java并发编程实战</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发_1_线程安全性]]></title>
    <url>%2F2018%2F01%2F12%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%2FJava%E5%B9%B6%E5%8F%91-1-%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7%2F</url>
    <content type="text"><![CDATA[引：要编写线程安全的代码，其核心在于要对状态访问操作进行管理，特别是对“共享的(Shared)”和“可变的(Mutable)”状态的访问。而对象的状态是指存储在状态变量（类变量和成员变量）中的数据。“共享”意味着变量可以由多个线程同时访问，而“可变”则意味着变量的值在其生命周期可以发生变化。 什么是线程的安全性线程安全性简单点说就是所见即所知，这是对正确性的认识。在书中还有一个比较长的定义： 当多个线程访问某个类时，不管运行时环境采用何种调度方法或者这些线程将如何交替执行， 并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确地行为， 那么这个类是线程安全的。 自己再开始也简单介绍了对象的状态，这里需要明确一点： 无状态的对象一定是线程安全的。 原子性 原子操作：不可再分割为几个操作的操作 竞态条件：由于不恰当的执行时序而出现不正确的结果（不是原子操作引起的） 竞态条件的类型： 先检查后执行，例如延迟初始化 读取-修改-写入，例如统计命中数操作 复合操作：将几个操作变为一个原子操作，在java.util.concurrent.atomic包中包含了一些原子变量类，用于实现在数值和对象引用上的原子状态转换。 在无状态的类中添加一个状态时，如果该状态完全由线程安全的对象来管理，那么这个类仍然是线程安全的。 加锁机制要保持状态的一致性，就需要在单个原子操作中更新所有相关的状态变量。 内置锁Java提供了一种内置的锁机制来支持原子性：同步代码块。同步代码块包括两部分：一个“作为锁”的对象引用，一个“作为由这个锁保护”的代码块。这个锁称为内置锁或监视器锁。线程在进入同步代码块之前会自动获得锁，并且在退出同步代码块时自动释放锁。Java的内置锁相当于一种互斥体，最多只有一个线程能够持有这种锁。由于每次只能有一个线程执行内置锁保护的代码块，因此，有这个锁保护的同步代码块会以原子方式执行。 重入内置锁是可重入的，如果某个线程试图获得一个已经有它自己持有的锁，这个请求将会成功，“重入”意味着获取锁的操作的粒度是“线程”。 重入的一种是实现方法是：为每个锁关联一个获取计数值和一个所有者线程。当计数值为0时，这个锁就被认为是没有被任何线程持有。当线程请求一个未被持有的锁时，JVM将记下锁的持有者，并且将获取计数值置为1。如果同个线程再次获取这个锁，计数值将递增，而当线程退出同步代码块时，计数器会相应地递减，当计数值为0时，这个锁将被释放。 用锁来保护状态 只把复合操作包装在synchronized块中并不够，如果对一个变量的访问需要使用同步，那所有访问该变量的地方都要加上同步。而且在使用锁来实现对变量的同步时，所有访问该变量的地方都要使用同一把锁。 获取一个对象关联的锁并不能阻止其他线程访问该对象，只有所有线程都获取的是相同的锁才能确保该对象被串行访问。所以每个共享的可变变量要被同一把锁保护。并非所有数据都需要锁的保护，只有被多个线程同时访问的可变数据才需要通过锁来保护。 一种常见的加锁约定是，将所有的可变状态都封装在对象内部，并通过对象的内置锁对所有访问可变状态的代码进行同步，使得在该对象上不会发生并发访问。 活跃性与性能这里展示两个代码： 利用同步方法实现锁的代码：1234567891011121314151617181920import java.math.BigInteger;public class SynchronizedFactorizer implements Servlet &#123; @GuardedBy(this) private BigInteger lastNumber; @GuardedBy(this) private BigInteger[] lastFactors; public synchronized void service(ServletRequest req, ServletResponse resp) &#123; BigInteger i = extractFromRequest(req); if(i.equals(lastNumber)) &#123; encodeIntoResponse(resp, lastFactors); &#125; else &#123; BigInteger[] factors = factor(i); lastNumber = i; lastFactors = factors.clone(); encodeIntoResponse(resp, factors); &#125; &#125;&#125; 通过缩小同步代码块的作用范围实现锁的代码：123456789101112131415161718192021222324252627282930313233343536373839import java.math.BigInteger;import com.sun.org.apache.bcel.internal.generic.IF_ACMPEQ;@ThreadSafepublic class CachedFactorizer implements Servlet&#123; @GuardedBy(this) private BigInteger lastNumber; @GuardedBy(this) private BigInteger[] lastFactors; @GuardedBy(this) private long hits; @GuardedBy(this) private long cacheHits; public synchronized long getHits() &#123; return hits; &#125; public synchronized double getCachedHits() &#123; return (double)cacheHits /(double) hits; &#125; public void service(ServletRequest req, ServletResponse resp) &#123; BigInteger i = extractFromRequest(req); BigInteger[] factors = null; synchronized (this) &#123; ++hits; if(i.equals(lastNumber)) &#123; ++cacheHits; factors = lastFactors.clone(); &#125; &#125; if(factors == null) &#123; factors = factor(i); //花费时间长的代码不要持有锁，相当于两个同步代码块的界限 synchronized (this) &#123; lastNumber = i; lastFactors = factors.clone(); &#125; &#125; encodeIntoResponse(resp, factors); &#125;&#125; 要判断同步代码块的合理大小，需要在各种设计需求之间进行权衡，包括安全性（这个需求必须要满足）、简单性和性能。我们需要权衡。 tip：当执行时间较长的计算或者可能无法快速完成的操作时（例如，网络I/O或控制台I/O），一定不要持有锁。 总结安全性需要保证，活跃性和性能也要在权衡之中。 参考 《Java并发编程实战》]]></content>
      <categories>
        <category>Java并发编程实战</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[人生之语言与数学]]></title>
    <url>%2F2018%2F01%2F11%2F%E7%94%9F%E6%B4%BB%2F%E4%BA%BA%E7%94%9F%E4%B9%8B%E8%AF%AD%E8%A8%80%E4%B8%8E%E6%95%B0%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[引：其实最近自己一直都在准备考试，结果突然脑海出现了关于对人生的杂想（可能想的高度太高了），自己没有及时写下来，现在基本上考完了，所以就想认真谈一下自己的思考。 人生我想大部人都是想着成功得过完这一生的，但是每个人都会迷茫，都会在某个时刻不知道自己想要什么，或者该怎么做。我想简单得把世界上的人归为这样两类。 话人生这里有一类人他们是靠情商和努力来获得成功的，说的通俗点就是走上行政或者做生意的，这类人对我们的世界是十分重要的，能说会道的人在哪都能吃得开吧。 行政人生行政现在对学历的要求也越来越高了，所以不管怎么样，我觉得这样的人还是要对考试保持敬畏，我个人觉得锻炼应试能力是十分有必要的，因为在升学或者入职，这都将起着置关重要的作用，我想也许不用把每块知识都弄的那么深，那么透，反而应该是学会总结，学会归类，学会预测以便花最少的时间或者最佳的结果。这里要提一下就是我们从小的学的语文这门科目了，不能说它多有用，但是对于提高我们的文笔还是很有帮助的，还有就是书写能力也会显得十分重要。 生意人生做生意或者说做销售，其实大部分的人都能感觉到实业越来越难做了，或者说是太稳固，墙外面的人很难挤进去，反而随着互联网的发展，线上的生意火好一些。这只是一种形式。真正想做大做好，你除了能说会道，我想掌握一口标准的普通话和一口流利的英语口语对生意的广度和未来都会有很好的帮助，所以语言能力需要好好的get。 学人生还有这一种人那就是通过学习和努力来改变人生，或者说是走技术路线的，当然这里也会分为两种人。 科研人生世界需要进步，那进步从何而来，我想其中的核心是来自一部分占比不高的人（科学家，至少是个博士吧）的努力。这里数学就会显得那么重要。当然数学会分很多方面，之前听到过一种说法就是数学其实一门哲学，信了它就是对的，不信它就是错的。说的其实也是十分的有道理，数学的对错其实是相对的，不是绝对的，要根据所处的领域基础，但是对于大部分我们所认识到的数学大多数还是同一个基础，就是我们大部分人从小到大所学的数学。然后我想说说自己对于数学的认知，我想说数学其实是一个工具，它对于无论是哪方面的科研都是很重要的，无论是工科还是经济学科。所以也就诞生了那么多交叉学科。这里又想提到计算机科学，其实计算机科学在科研方便起到的只是减少人类的工作量以及提高人所需要的计算能力。就像大数据其实是属于统计学科，但是结合到计算机，那么就变成了计算机的热门学科了。 经验人生世界的进步需要科学家，但是也少不了靠经验解决问题的专家，比如架构师，我想大概就是通过不断的实践来提高自己的解决问题的能力，而这不需要多好的科研能力或者说绝对的创新能力，只要多做多想，学会快又准确地解决问题就好了。我相信大部分人的智商都是差不多的，所以想在经验人生上取的小小的成功，真的是需要花很多时间来提升自己的经验。]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>人生</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM_14_线程安全与锁优化]]></title>
    <url>%2F2017%2F12%2F14%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-14-%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E9%94%81%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[引：面向对象的编程思想极大的提升了现在软件开发的生产效率和软件可以达到的规模，但是现实中对象在一项工作进行期间，会被不停地中断和切换，对象的属性可能会在中断期间被修改和变“脏”，所以我们在谈“高效并发”之前必须先保证并发的正确性和如何实现线程安全。 线程的安全在《Java Concurrency In Practice》一书中这样定义线程安全：当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下得调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确地结果，那这个对象是线程安全的。 它要求线程安全的代码都必须具备一个特征：代码本身封装了所有必要的正确性保障手段（如互斥同步等），令调用者无需关心多线程的问题，更无需自己采用任何措施来保障多线程的正确调用。 Java语言中的线程安全在讨论线程安全的时候，都会限定于多个线程之间存在共享数据访问这个前提，我们按照线程安全的“安全程度”由强至弱来排序，可以将Java语言中各种操作共享的数据分为以下5类：不可变、绝对线程安全、相对线程安全、线程兼容和线程对立。 不可变在Java语言中，不可变对象一定是线程安全的，无论是对象的方法实现还是方法调用者都不需要在采取任何的线程安全保障措施。 Java语言中，如果共享数据是一个基本类型数据，那么只要在定义时使用final关键字修饰它就可以保证它是不可变的。如果共享数据是一个对象，那就需要保证对象的行为不会对其状态产生任何影响才行。如String类、枚举类等（有需要继续探究的可以去看看这些类的源码），保证对象行为不影响自己状态最简单的途径就是讲对象带有状态的变量都声明为final。 绝对线程安全绝对线程安全需要完全满足《Java Concurrency In Practice》一书对线程安全的定义。这个定义其实是很严格的，一个类要达到“不管运行时环境如何，调用者都不要任何额外的同步措施”通常需要付出很大的代价，在Java API中标注自己是线程安全的类，大多数都不是绝对的线程安全。 相对线程安全相对线程安全就是我们通常意义上的线程安全，它需要保证这个对象单独操作是线程安全的，我们在调用的时候不需要做额外的保障措施，但是对于一些特定顺序的联系调用，就可能需要在调用端使用额外的同步手段来保障调用的正确性。下面就展示java.util.Vector（Vector只是加了个方法锁，保证一个时间只能调用方法一次）这个线程安全的容器的不安全可能，。123456789101112131415161718192021222324252627282930313233343536// 错误代码public class VectorTest &#123; private static Vector&lt;Integer&gt; vector = new Vector&lt;&gt;(); public static void main(String[] args) &#123; while (true) &#123; for (int i = 0; i &lt; 10; i++) &#123; vector.add(i); &#125; Thread removeThread = new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; vector.remove(i); &#125; &#125; &#125;); Thread printThread = new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; System.out.println(vector.get(i)); &#125; &#125; &#125;); removeThread.start(); printThread.start(); while (Thread.activeCount() &gt; 20); &#125; &#125;&#125; 运行分析：我在自己机器上没有发生异常，但是按照作者所说的是应该会出现数组越界异常的，这是因为如果另一个线程恰好在错误的时间删除了一个元素，导致序号为i已经不再可用的话，再用i访问数组就会抛出一个ArrayIndexOutOfBoundsException，如果要保证这段代码能正确执行下去，需要改成如下代码：12345678910111213141516171819202122232425262728293031323334353637383940// 对vector操作加上锁public class VectorTest &#123; private static Vector&lt;Integer&gt; vector = new Vector&lt;&gt;(); public static void main(String[] args) &#123; while (true) &#123; for (int i = 0; i &lt; 10; i++) &#123; vector.add(i); &#125; Thread removeThread = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (vector) &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; vector.remove(i); &#125; &#125; &#125; &#125;); Thread printThread = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (vector) &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; System.out.println(vector.get(i)); &#125; &#125; &#125; &#125;); removeThread.start(); printThread.start(); while (Thread.activeCount() &gt; 20); &#125; &#125;&#125; 在Java语言中，大部分线程安全类都属于这种类型，例如Vector、HashTable等。 线程兼容线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全使用，我们平常说的一个类不是线程安全的，绝大多数时候是指这一种情况。Java API中大部分的类都是属于线程兼容的，如与前面Vector和HashTable相对应的集合类ArrayList和HashTable等。 线程对立线程对立是指无论调用端是否采取了同步措施，都无法再多线程环境中并发使用代码，大部分原因是会产生死锁。 线程安全的实现方法线程安全的实现是通过代码编写以及利用虚拟机提供的同步和锁机制，而我们这主要是说一下虚拟机线程安全手段的运作过程。 互斥同步（阻塞同步）同步是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一个（或者是一些，使用信号量的时候）线程使用。而互斥是实现同步的一种手段，临界区、信号量（都没用过）、互斥量都是主要的互斥实现方式。互斥是因，同步是果；互斥是方法，同步是目的。主要的互斥同步手段有下面两种： 使用synchronizd关键字，synchronized关键字经过编译之后，会在同步块的前后分别形成 monitorenter 和 monitorexit 这个两个字节码指令，这两个字节码都需要一个 reference类型的参数来指明要锁定和解锁的对象；如果java程序中的synchronized明确指定了对象参数，那就是这个对象的reference；如果没有明确指定，那就根据synchronized修饰的实例方法还是类方法，去取对应的对象实例或Class对象来作为锁对象。在执行monitorenter指令时，如果这个对象没有锁定或当前线程已经拥有了那个对象的锁，锁的计数器加1，相应的，在执行monitorexit指令时会将锁计数器减1；当计数器为0时，锁就被释放了。对于monitorenter 和 monitorexit的行为描述中，有两点需要注意： synchronized同步块对同一条线程来说是可重入的，不会出现自己把自己锁死的问题。 同步块在已进入的线程执行完之前，会阻塞后面其他线程的进入。 使用java.util.concurrent（J.U.C）包中的重入锁（ReentrantLock）。synchronized 和 ReentrantLock 的区别： 一个表现为 API 层面的互斥锁（lock() 和 unlock() 方法配合 try/finally语句块来完成），另一个表现为原生语法层面的互斥锁；ReentrantLock增加了一些高级功能主要有以下3项： 等待可中断：指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮 助 。 公平锁：指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。 锁绑定多个条件：指一个 ReentrantLock对象可以同时绑定多个 Condition对象，而在 synchronized中，锁对象的wait() 和 notify() 或 notifyAll() 方法可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而ReentrantLock 则无需这样做，只需要多次调用 newCondition() 方法即可。 关于两者的性能在JDK1.6以后，两者基本持平了，所以提倡在synchronized能实现需求的情况下，优先考虑使用sychronized来进行同步锁。 非阻塞同步 阻塞同步与非阻塞同步的对比：阻塞同步是一种悲观的并发策略，总是认为只要不去做正确的同步措施（例如加锁）就会出现问题，所以会带来进行线程阻塞和唤醒的性能问题；非阻塞同步是一种基于冲突检测的乐观的并发策略，它是先进行操作，如果没有其他线程争用共享数据，那操作就是成功的，如果共享数据有争用，产生了冲突，那就再采取其他的补偿措施（最常见的补偿措施就是不断地重试，直到成功为止）。 非阻塞同步需要硬件指令集的发展：因为需要保证操作和冲突检测这两个步骤具备原子性，而这里原子性的实现是通过一条处理器指令完成的。这类指令常用的有： 测试并设置 获取并增加 交换 比较并交换（Compare-and-set,CAS） 加载链接/条件存储 我们可以从J.U.C下得原子类的操作来证明这一点。 无同步方案如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性，因此会有一些代码天生就是线程安全的。下面介绍两类线程安全代码： 可重入代码（纯代码）：，可以在代码执行的任何时刻中断它，转而去执行另外一段代码，而在控制权返回后，原来的程序不会出现任何错误。如何判断代码是否具备可重入性：如果一个方法，它的返回结果是可以预测的，只要输入了相同的数据，就都能返回相同的结果，那它就满足可重入性的要求，当然也就是线程安全的。 线程本地存储：如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能够保证在同一线程中执行？如果能保证，我们就可以把共享数据的可见范围限制在同一个线程内，这样，无需同步也可以保证线程间不出现数据争用问题。 锁优化各种锁优化技术都是为了在线程之间更加高效地共享数据，以及解决竞争问题。 自旋锁 为什么需要自旋锁：互斥同步对性能最大的影响是阻塞的实现，挂起线程和恢复线程的操作都需要转入内核态中完成，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程很不值得。 什么是自旋锁：为了让线程等待，我们只需让线程执行一个忙循环（自旋）而不放弃处理器时间，这项技术就是所谓的自旋锁。 自旋时间有一定限度：如果自旋超过了限定的次数仍然没有成功获得锁，就应当使用传统的方式去挂起线程了。自旋次数的默认值是10，用户可以用参数 -XX:PreBlockSpin 来更改。 自适应自旋锁：jdk1.6中引入了自适应的自旋锁。自适应意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定； 锁消除锁消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检查到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据：来源于逃逸分析的数据支持，如果判定在一段代码中，堆上的所有数据都不会逃逸出去从而被其他线程访问到，那就可以把它们当做栈上数据对待，认为它们是线程私有的，同步加锁自然就无须进行了。其中很多无用的同步措施都是Java API自带的。 锁粗化如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部。 轻量级锁 轻量级锁：使用操作系统互斥量来实现的传统锁通常被称为重量级锁，而这个轻量级锁的出现就是是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。 HotSpot虚拟机头Mark Word：它是实现轻量级锁和偏向锁的关键，它的内容如下表： 存储内容 标志位 转态 对象哈希码、对象年龄分代 01 未锁定 指向所记录的指针 00 轻量级锁定 指向重量级锁的指针 10 膨胀（重量级锁定） 空，不需要记录信息 11 GC标记 偏向线程ID、偏向时间戳、对象分代年龄 01 可偏向 在进入同步代码块时，轻量级锁加锁过程： 如果此同步对象没有被锁定（锁标志位为01状态）：虚拟机首先将在当前线程的栈帧中建立一个名为锁记录的空间，用于存储对象目前的Mark Word的拷贝（Displace Mark Word）。 然后，虚拟机将使用CAS 操作尝试将对象的 Mark Word 更新为指向Lock Record的指针。 如果这个更新工作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位将转变为 00，即表示此对象处于轻量级锁定状态； 如果这个更新失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果只说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明这个锁对象以及被其他线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁，锁标志的状态值变为 10，Mark Word中存储的就是指向重量级（互斥量）的指针，后面等待锁的线程也要进入阻塞 状态。 轻量级锁解锁过程： 如果对象的Mark Word仍然指向着线程的锁记录，那就用CAS 操作把对象当前的Mark Word和线程中复制的 Displaced Mark Word替换回来。 如果替换成功，整个同步过程就完成了。 如果替换失败，说明有其他线程尝试过获取该锁，那就要在释放锁的同时，唤醒被挂起的线程。 轻量级锁能提升程序同步性能的依据是：对于绝大部分的锁，在整个同步周期内都是不存在竞争的。 偏向锁 偏向锁的目的：消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。如果说轻量级锁是在无竞争的情况使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS 操作都不做了。 偏向锁的偏：它的意思是这个锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。 偏向锁过程：若当前虚拟机启用了偏向锁，那么，当锁对象第一次被线程获取的时候，虚拟机将会把对象头中的标志位设为01，即偏向模式；同时使用CAS操作把获取到这个锁的线程的ID 记录在对象的 Mark Word之中，如果CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作。当有另一个线程去尝试获取这个锁时，偏向模式就结束了，根据锁对象目前是否处于被锁定的状态，撤销偏向后恢复到未锁定（标志位为01）或轻量级锁定（标志位为00）的状态，后续的同步操作就如上面介绍的轻量级锁那样执行。 偏向锁是一个带有效益权衡性质的优化：偏向锁可以提高带有同步但无竞争的程序性能，但是如果程序中大多数的锁总是被多个不同的线程访问，那偏向模式是多余的。 总结关于线程安全我们可以有明确的定义，然后我们也知道了线程安全的实现方式，以及虚拟机为我们提供的各种锁优化。 参考 《深入理解Java虚拟机》]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM_13_Java内存模型与线程]]></title>
    <url>%2F2017%2F12%2F13%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-13-Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[引：并发处理的广泛应用是使得阿姆德尔定律替代摩尔定律成为计算机性能发展原动力的根本原因。由于计算机的运算速度和它的存储和通信子系统速度差距太大，所以才出现了并发，而并发绝对是Java运用很大的优势。我们绝对需要理解！ 硬件的效率与一致性由于计算机的存储设备与处理器的运算速度有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的告诉缓存来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步到内存之中，这样处理器就无须等待缓慢的内存读写了。 基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是也为计算机系统带来更高的复杂度，因为引入了一个新的问题：缓存一致性。为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作。下面是常用的内存模型图： 除了增加高速缓存之外，为了使得处理器的内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行乱序执行优化。 Java内存模型目的：让Java程序在各种平台下都能达到一致的内存访问效果。 主内存与工作内存Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。此处的变量与Java编程中所说的变量有所区别，它包括实例字段、静态字段和构成数组对象的元素，但不包括局部变量与方法参数，因为后者是线程私有的，不会被共享。 Java内存模型规定了所有的变量都存储在主内存中（此处的主内存与介绍物理硬件时的主内存可以类比，但是此处仅仅是虚拟机内存的一部分）。每条线程都有自己的工作内存（可以与处理器高速缓存类比），线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成，线程、主内存、工作内存三者的交互关系如下图： 这里的Java内存模型如果和Java运行时内存勉强对应，可以这样理解：主内存主要对应Java堆中的对象实例数据部分，而工作内存则对应于虚拟机栈中的部分区域。从更低层次上说，主内存直接对应于物理硬件内存，而工作内存优先存储于寄存器和高速缓存中。 内存间的交互操作Java内存模型中定义了以下8种操作来完成，虚拟机实现时必须保证下面提及的每一种操作都是原子的、不可再分的。 lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。 unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 read（读取）：作用于主内存变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用。 load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。 use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。 write（写入）：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。 如果要把一个变量从主内存复制到工作内存，那就要按顺序执行read和load操作，如果要把变量从工作内存同步回主内存，就要按照顺序地执行store和write操作。注意，Java内存模型只要求上述两个操作必须按顺序执行，而没有保证必须是连续执行。Java内存模型规定了在执行上述八种基本操作时必须满足时必须满足如下规则： 不允许read和load、store和write操作之一单独出现。 不允许一个线程丢弃它的最近的assign操作。 不允许一个线程无原因的（没有发生过任何assign操作）把数据从线程的工作内存同步到主内存中 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。 一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值。 如果一个变量事先没有被lock锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定住的变量。 对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store和write）。 这8种内存访问操作以及上述规则限定，再加上volatile的一些特殊规定，就已经完全确定了Java程序中哪些内存访问操作是并发是安全的。 对于volatile修饰的变量的特殊规则关键字volatile是Java虚拟机提供的最轻量级的同步机制。Java内存模型堆volatile专门定义了一些特殊的访问规则。当一个变量定义为volatile之后，它将具备以下两种特性： 保证此变量对所有线程的可见性：当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。由于volatile变量只能保证可见性，在不符合以下两条规则的运算场景中，我们仍然要通过加锁来保证原子性。 运算结果不依赖变量的当前值，或者只能保证只有单一的线程来保证原子性。 变量不需要与其他状态变量共同参与不变约束。（目前不理解） 禁止指令重排序优化：如果有两个或者更多CPU访问同一块内存，且其中有一个在观测另一个，那么它会通过设置内存屏障来使重排序时不能把后面的指令重排序到内存屏障之前访问。 volatile的意义：volatile变量读操作的消耗与普通变量几乎没有什么差别，但是写操作则可能慢一点，因为它需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行，不过即便如此，大多数场景下volatile得总开销仍然比锁低。 volatile的特殊规则就是：use/assign、load/store、read/write操作必须连续一起出现，即volatile修饰的变量不会被指令重排序优化。 对于long和double类型的变量的特殊规则Java内存模型要求对于lock、unlock、read、load、assign、use、store和write这八个操作都具有原子性，但是对于64位的数据类型（long和double），允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，即允许虚拟机实现选择可以不保证64位数据类型的load、store、read和write这四个操作的原子性，但是强烈建议虚拟机实现为具有原子性的操作。 原子性、可见性与有序性原子性由Java内存模型来直接保证的原子性变量操作包括read、load、assign、use、store和write这六个，我们大致可以认为基本数据类型的访问读写是具备原子性的。synchronized关键字可以实现原子性。 可见性可见性就是指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。volatile、synchronized以及final关键字都能实现可见性。 有序性Java程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句是指“线程内表现为串行的语义”，后半句是指“指令重排序”现象和“工作内存与主内存同步延迟”现象。volatile和synchronized关键字都能实现有序性。 先行发生原则先行发生是Java内存模型中定义的两项操作之间的偏序关系，如果说操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了小写、调用了方法等。 下面是Java内存模型下一些“天然的”先行发生关系，这些先行发送关系无须任何同步器协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来的话，他们就没有顺序性保障，虚拟机可以对它们进行随意重新排序： 程序次序规则（Program Order Rule）：在一个线程内，按照程序代码顺序，书写在前的操作先于书写在后面的操作。准确地说应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。 管程锁定规则（Monitor Lock Rule）：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是同一个锁，而“后面”是指时间上的先后顺序。 volatile变量规则（Volatile Variable Rule）：对一个volatile变量的写操作先行发生于后面对这个变量的读操作。“后面”是指时间上的先后顺序。 线程启动规则（Thread Start Rule）：Thread对象的start()方法先行发生于此线程的每一个动作。 线程终止规则（Thread Termination Rule）：线程中所有操作都先行发生于此线程的终止检测。 线程中断规则（Thread Interruption Rule）：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生。 对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize()方法的开始。 传递性（Transitivity）：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得到操作A先行发生于操作C。 Java与线程在Java里面谈论并发，大多数都与线程脱不开关系。我们需要知道在Java线程在虚拟机的实现。 线程的实现线程是比进程更轻量级的调度执行单位，线程的引入，可以把一个进程的资源分配和执行调度分开，各个线程既可以共享进程资源，又可以独立调度（线程是CPU调度的基本单位）。 实现线程主要有3种方式：使用内核线程实现、使用用户线程实现和使用用户线程加轻量级线程混合实现。 Java线程调度线程调度是指系统为线程分配处理器使用权的过程，主要调度方式有两种，分别是协同式线程调度和抢占式线程调度。 协同式线程调度：线程的执行时间由线程本身来控制，线程把自己的工作执行完毕后，要主动通知系统切换到另一个线程上去。好处是实现简单，没有线程同步问题；缺点是：线程执行时间不可控制，容易导致整个系统崩溃。 抢占式线程调度：每个线程将由系统来分配执行时间，线程的切换不由线程本身来决定。好处是线程执行之间可控，不会有一个线程导致整个进程阻塞的问题，Java使用的线程调度方式就是抢占式调度。这里说一下就是java线程优先级不太靠谱，原因是Java的线程是通过映射到系统的原生线程上来实现的，所以线程调度最终还是取决于操作系统。 线程状态转换Java语言定义了5种线程状态，在任意一个时间点，一个线程只能有且只有其中的一种状态，这5种状态分别是：新建，运行，无限期等待，限期等待，阻塞，结束。上述5种状态在遇到特定时间发生的时候回互相转换，他们的转换关系如下图： 总结虚拟机本身具有一套和线程相关内存模型，我们需要利用好它，特别是要理解线性发生原则以及volatil的一些特殊规则。 参考 《深入理解Java虚拟机》 Java内存模型]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM_12_晚期（运行期）优化]]></title>
    <url>%2F2017%2F12%2F12%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-12-%E6%99%9A%E6%9C%9F%EF%BC%88%E8%BF%90%E8%A1%8C%E6%9C%9F%EF%BC%89%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[引：之前说过Java中的JIT即时编译器在运行期的优化对于程序运行来说更重要，那我们就来看看这个即时编译器。本文提及的编译器、即时编译器都是指HotSpot虚拟机内的即时编译器，虚拟机也特指HotSpot虚拟机。 什么是即时编译器在部分的商用虚拟机中，Java程序最初是通过解释器来解释执行的，当虚拟机发现某个方法或代码块的运行特别频繁时，就会把这些代码认定为“热点代码”（Hot Spot Code）,为了提高 热点代码的执行效率，在运行时，虚拟机将会把这些代码编译成与本地平台相关的机器码，并进行各种层次的优化，完成这个任务的编译器 称为即时编译器（Just In Time Compiler,简称JIT编译器）。 HotSpot虚拟机内的即时编译器为什么要使用解释器与编译器并存的架构 解释器与编译器各有优势：当程序需要迅速启动和执行的时候，解释器可以首先发挥作用，省去编译的时间，立即执行。在程序运行后，随着时间的推移，编译器逐渐发挥作用，把越来越多的代码编译成本地代码之后，可以获得更高的执行效率，当程序运行环境中内存资源限制较大时，可以使用解释执行节约内存，反之可以使用编译执行来提高效率。 解释器可以作为编译器激进优化时的一个“逃生门”，可以通过逆优化退回到解释器状态继续执行。 HotSpot虚拟机内置编译器 Client Compiler(C1编译器)：使用“-client” 参数去强制指定虚拟机运行在Client模式。 Server Compiler(C2编译器)：使用“-server” 参数去强制指定虚拟机运行在Server模式。 虚拟机默认采用解释器与编译器搭配使用的方式（混合模式）。为了在程序响应速度和运行效率之间达到最佳平衡，HotSpot虚拟机会逐渐启用分层编译策略： 第0层：程序解释执行，解释器不开启性能监控功能，可触发第1层编译。 第1层：也称为C1编译，将字节码编译为本地代码，进行简单，可靠的优化，如果必要将加入性能监控的逻辑。 第2层（或2层以上）：也称为C2编译，也是将字节码编译为本地代码，但是会启用一些编译耗时较长的优化，甚至会根据性能监控信息进行一些不可靠的激进优化。 编译对象与触发条件编译对象（热点代码） 被多次调用的方法（JIT编译方式） 被多次执行的循环体（OSR编译方式） 热点探测 基于采样的热点探测：虚拟机周期地检查各个线程的栈顶，如果发现某个（或某些）方法经常出现在栈顶，那这个方法就是“热点方法”。优点是实现简单、高效，还可以很容易获取方法的调用关系（将调用堆栈展开即可），缺点就是很难精确得确认一个方法的热度，容易因为受到线程阻塞或者别的外界因素的影响而扰乱热点探测。 基于计数器的热点探测：虚拟机会每一个方法（甚至是代码块）建立计数器，统计方法的执行次数，如果执行次数超过一定的阈值就认定它是“热点方法”。缺点是实现麻烦，需要为每个方法建立并维护计数器，而且不能直接获取到方法的调用关系，优点是统计结果更加精确和严谨。 在HotSpot虚拟机中使用的是基于计数器的热点探测方法。因此它为每个方法准备了两类计数器：方法调用计数器（用于探测方法）和回边计数器（用于探测循环体）。这两个计数器都有一个确定的阈值，当计数器超过了阈值，就会提交编译请求。 编译过程在默认设置下，无论是方法调用产生的即时编译请求，还是OSR编译请求，虚拟机代码编译器还未完成之前，都依然将按照解释方式继续执行，而编译动作则在后台的编译线程中进行。 Client Compiler它是个三段式编译器，主要关注点在局部性的优化，放弃了许多耗时较长的全局优化手段。下面是三个阶段 字节码-&gt;高级中间代码（HIR）:使用静态单分配的形式来代表代码值，其中会完成方法内联、常量传播等优化。 HIR-&gt;低级中间代码（LIR）：会在HIR上完成空值检查消除、范围检查消除等优化，以便让HIR达到更高效的代码的表示形式。 LIR-&gt;机器代码：在平台相关的后端使用线性扫描算法在LIR上分配寄存器，并在LIR上做窥孔优化。 Server Compiler它是专门面向服务端的典型应用并为服务器端的性能配置特别调整过的编译器，也是一个充分优化过的高级编译器。它会执行所有经典的优化工作。它的寄存器分配器是一个全局图着色分配器，可以充分利用某些处理器架构上的大寄存器集合。 查看及分析即时编译结果这一块我没有去实践，但是这里写一个结论：在Java中空循环不能用作程序延时的手段，因为空循环会被优化消除。 编译优化技术Java程序员有一个共识：以编译方式执行本地代码比解释方式更快。这主要是因为虚拟机设计团队几乎把对代码的所有优化措施都集中在编译器之中了。关于HotSpot的优化技术列表可以参考《深入理解Java虚拟机》一书，这里也根据书上举的几个例子来看看其中的优化技术。 公共子表达式消除含义是：如果一个表达式E已经计算过了，并且从先前的计算到现在E中所有的变量的值都没有发生变化，那么E的这次出现就成为了公共子表达式。对于这种表达式，没有必要花时间再对它进行计算，只需要直接用前面计算过的表达式结果代替E即可。可以看看下面的优化历程：12345678// 源代码int d = (c * b) * 12 + a + (a + b * c);// 编译器检测到“c * b”和“b * c”是一样的表达式，这条表达式就变成下面这样了int d = E * 12 + a + (a + E);// 编译器还可能进行代数简化，把表达式变为：int d = E * 13 + a * 2; 大家肯定能发现，最后的表达式计算起来就可以节省时间了。 数组边界检查消除含义：虚拟机执行子系统每次数组的读写都带有一次隐含的条件判断操作，这对于拥有大量 数组访问的程序代码，无疑是一种性能负担。解决思路除了将数组边界检查优化尽可能把运行期检查提到编译期完成之外，还有另一种思路——隐式异常处理（try - catch）。可以看看代码：12345678910111213// 源代码if (foo != null) &#123; return foo.value&#125; else &#123; throw new NullPointException();&#125;// 编译器转换代码try &#123; return foo.value;&#125; catch(segment_fault) &#123; uncommon_trap();&#125; 这样可以避免每次去做非空检查。 方法内联它除了消除方法调用成本之外，它更重要的是位其他优化手段建立良好的基础，如果不做内联，就发现不了无用代码。。内联具有两种情况： 对于非虚方法：直接内联 对于虚方法：会使用“类型继承关系分析”（CHA）技术，虚拟机如果遇到虚方法就会向CHA查询此方法在当前程序下是否有多个目标版本可供选择，如果查询结果只有一个版本，就可以进行内联，不过这种内联属于激进优化，需要余留一个“逃生门”，称为守护内联；如果查出有多个版本的目标方法可供选择，则编译器还会使用内联缓存来完成方法内联。 逃逸分析它也是为其他优化手段提供依据的技术，它的基本行为就是分析对象动态作用域：当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他方法中，称为方法逃逸。甚至还有可能被外部线程访问到，例如复制给类变量或可以在其他线程中访问的实例变量，称为线程逃逸。 如果能证明一个对象不会逃逸到方法或者线程之外，则可能为这个变量进行一些高效的优化： 栈上分配：让对象直接在栈上分配内存，这样大量对象就会随着方法的结束而自动销毁了，垃圾收集系统的压力将会小很多。 同步消除：对变量实施的同步措施可以消除掉 标量替换：不能再分解的量称为标量（如：数值类型），可以继续分解的称为聚合量（如：对象），我们可以直接将对象拆分成标量存在栈上。 总结通过对于JIT编译的学习，我么可以知道哪些代码编译器是可以帮我们优化的，以及哪些代码是需要自己调节以便更合适编译器的优化。这样我们才可以写出更高效的代码。 参考 《深入理解Java虚拟机》]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM_11_早期（编译期）优化]]></title>
    <url>%2F2017%2F12%2F10%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-11-%E6%97%A9%E6%9C%9F%EF%BC%88%E7%BC%96%E8%AF%91%E6%9C%9F%EF%BC%89%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[引：之前简单的提到过java程序的使用首先要经过编译，然后再“解释”执行，这里我们就先看看它在编译期的过程。 编译概述java的编译期其实是一段“不确定”的操作过程，它有一下几种形式： 前端编译器：把.java文件转变为.class文件的过程，如：Sun的javac、Eclipse JDT中的增量式编译器。 虚拟机的后端运行期编译器（JIT编译器）：把字节码转变成机器码的过程，如HotSpotVM的C1、C2编译器。 静态提前编译器（AOT编译器）：直接把*.java文本编译为本地机器代码的过程：GNU Compiler for the Java、Excelsior JET。 我们平时所说的编译基本上都是指第一类，前端编译器。总的来说，Java中的JIT即时编译器在运行期的优化对于程序运行来说更重要，而前端编译器在编译器的优化过程对于程序编码来说关系更密切，相当多新生的Java语法特性，都是靠编译器的“语法糖”来实现的。 Javac编译器编译过程大致分为3个过程： 解析与填充符号表过程 插入式注解处理器的注解处理过程 分析与字节码生成过程 这3个过程之间的关系与交互顺序如下图： 解析与填充符号表过程其中解析步骤包括了经典程序编译原理找那个的词法分析和语法分析两个过程。 词法、语法分析 词法分析：将源代码的字符流转变为标记（Token）集合，单个字符是程序编写过程的最小元素，而标记是编译过程的最小元素，关键字、变量名、字面量、运算符都可以成为标记。 语法分析：根据Token序列构造抽象语法树，抽象语法树是一种用来描述程序代码语法结构的树形表示方式，语法树的每一个节点都代表着程序代码中的一个语法结构，例如包、类型、修饰符、运算符、运算符、接口、返回值甚至代码注释都可以是一个语法结构。如下图： 经过上面两个步骤编译器就基本不会再对源文件进行操作了。 填充符号表 符号表是由一组符号地址和符号信息构成的表格，类似k-v形式。符号表中登记的信息在编译的不同阶段都要用到。在语义分析中，符号表所登记的内容将用于语义检查和产生中间代码。在目标代码生成阶段，当对符号名进行地址分配时，符号表是地址分配的依据。 在Java源代码中，填空符号表过程的出口是一个待处理列表，包含了每一个编译单元的抽象语法数的顶级节点，以及package-info.java（如果存在）的顶级节点。 注解处理器JDK1.6之中提供了一组插入式注解处理器的标准API在编译期间对注解进行处理，可以把它看做是一组编译器插件，在这些插件中，可以读取、修改、添加抽象语法树中的任意元素。若这些插件在处理注解期间对语法树进行了修改，编译器将回到解析及填充符号表的过程重新处理，直到所有插入式注解处理器都没有再对语法树进行修改为止，每一次循环称为一个Round。如编译过程图的回环过程。 语义分析与字节码生成语法分析之后，编译器获得程序代码的抽象语法树表示，语法树能表示一个结构正确的源程序的抽象，但无法保证源程序是符合逻辑的，而语义分析的主要任务是对结构上正确地源程序进行上下文有关性质的审查，如类型审查。语义分析过程分为标注检查以及数据及控制流分析两个步骤。 标注检查标注检查步骤检查的内容包括诸如变量使用前是否已被声明，变量与赋值之前的数据类型能否匹配，还有一个重要的动作是常量折叠，如果我们在代码写了如下定义：1int a = 1 + 2; 在经过变量折叠之后，1 + 2会被折叠为字面量3。所以在代码里定义int a = 1 + 2比起直接定义int a = 3并不会增加程序运行期的运算量。 数据及控制流分析数据及控制流分析是对程序上下文逻辑更进一步的验证，它可以检查出诸如程序局部变量在使用前是否有赋值、方法的每条路径是否都有返回值、是否所有的受检异常都被正确处理了等问题，编译期的数据及控制流分析与类加载时的数据及控制流分析的目的基本上是一致的，但校验范围有所区别，有一些校验项只有在编译期或者运行期才能进行，如方法的参数以及局部变量的检查就只会在编译器检查。 解语法糖 语法糖：指在计算机语言中添加的某种语法，这种语法对语言的功能并没有影响，当时更方便使用，Java最常用的语法糖主要有泛型、变长参数、自动装箱、拆箱等 解语法糖：虚拟机运行时不支持这些语法，他们会在编译阶段还原回简单的基础语法结构。 字节码生成字节码生成是Javac编译过程的最后一个阶段，此阶段编译器还进行了少量的代码添加和转换工作。实例构造器()（不是默认构造函数）和类构造器()就是在这个阶段添加到语法树中的。完成了对语法树的遍历和调整之后，生成最终的Class文件。 Java语法糖的味道泛型与类型擦除 本质：参数化类型的应用，就是所操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法上，分别称为泛型类、泛型接口和泛型方法。 提出原因：先看下面的代码 12Object object = new Object();String str = (String)object; 由于编译器无法检查这个Object强制转换能否成功，为了防止保障强制类型的转换成功，避免ClassCaseException的风险转嫁到程序运行期之中，所以提出了泛型。 真实泛型：参数化类型无论在源码中还是编译后的中间语言都是存在的。 伪泛型：参数化类型只在源码中存在，而在中间语言不存在。可以看到下面的例子： 123456789101112// 泛型擦除的例子public class GenericTest &#123;public static void main(String[] args) &#123; Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); map.put("hello", "您好"); map.put("how are you?", "最近怎么样？"); System.out.println(map.get("hello")); System.out.println(map.get("how are you?")); &#125;&#125; 利用Beyond Compare反编译可以得到下面的代码: 123456789101112// 反编译后的代码public class GenericTest &#123;public static void main(String[] args) &#123; Map map = new HashMap&lt;&gt;(); map.put("hello", "您好"); map.put("how are you?", "最近怎么样？"); System.out.println(map.get("hello")); System.out.println(map.get("how are you?")); &#125;&#125; 有人可能像我一样，用jd反编译，发现泛型没有被擦除，我一开始很惊讶，后来找了参考，大家可以从参考部分看到该现象的解释，这里需要说明一点，就是由于Java泛型的引入，各种场景（虚拟机解析、反射等）下的方法调用都可能对原有的基础产生影响和新的需求，所以JCP（Java Community Process）组织对虚拟机规范做出了相应的修改，引入了诸如Signature、LocalVariabelTypeTable等新的属性用于解决伴随泛型而来的参数类型识别问题，从Signature属性的出现我们还可以得出结论：擦除泛型所谓的擦除，仅仅是对方法的Code属性中的字节码进行删除，实际上元数据中还是保留了泛型信息。 自动装箱、拆箱与遍历循环我们可以看看这些语法糖，编译的过程中做了什么处理：12345678910111213// 源代码public class BoxProcessTest &#123; public static void main(String[] args) &#123; List&lt;Integer&gt; list = Arrays.asList(1,2,3,4); int sum = 0; for (int i : list) &#123; sum += i; &#125; System.out.println(sum); &#125;&#125; 12345678910111213141516// 反编译后的代码public class BoxProcessTest&#123; public static void main(String[] args) &#123; List list = Arrays.asList(new Integer[] &#123; Integer.valueOf(1), Integer.valueOf(2), Integer.valueOf(3), Integer.valueOf(4) &#125;); int sum = 0; for (Iterator localIterator = list.iterator(); localIterator.hasNext();) &#123; int i = ((Integer)localIterator.next()).intValue(); sum += i; &#125; System.out.println(sum); &#125;&#125; 我们清楚的看到其实语法糖的最后还是用最基本的语法实现的，只是更利于我们写代码了。 再来看看自动装箱的陷阱：1234567891011121314151617public class BoxTest &#123; public static void main(String[] args) &#123; Integer a = 1; Integer b = 2; Integer c = 3; Integer d = 3; Integer e = 321; Integer f = 321; Long g= 3L; System.out.println(c == d); //true System.out.println(e == f); //false，如果Integer在-128到127之间会保存到常量池，此时Integer直接等于数字 System.out.println(c == (a + b)); //true System.out.println(c.equals(a + b)); //true System.out.println(g == (a + b)); //true System.out.println(g.equals(a + b)); //false &#125;&#125; 如果你对上面分不清楚的话，加上鉴于包装类的“==”运算在不遇到算术运算的情况下不会自动拆箱，以及它们的equals()方法不处理数据类型转型的关系，建议在实际编码找那个尽量避免这样使用自动装箱与拆箱。 条件编译Java语言实现条件编译的方法是使用条件为常量的if语句，案例如下：123456789101112// 源代码public class ConditionCompilerTest &#123; public static void main(String[] args) &#123; if (true) &#123; System.out.println("block 1"); &#125; else &#123; System.out.println("block 2"); &#125; &#125;&#125; 123456789// 反编译代码public class ConditionCompilerTest&#123; public static void main(String[] args) &#123; System.out.println("block 1"); &#125;&#125; 我们很清楚的看到编译后的代码就只剩true里面的代码块了，从而实现了条件编译。 总结通过上面的学习，我们可以从编译器的层次上了解Java源代码编译为字节码的过程，以及各种语法糖的前因后果。 参考 《深入理解Java虚拟机》 早期（编译期）优化 关于java泛型擦除反编译后泛型会出现问题]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM_10_虚拟机字节码执行引擎]]></title>
    <url>%2F2017%2F12%2F09%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-10-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AD%97%E8%8A%82%E7%A0%81%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[引：我们知道方法的代码的字节码是放在方法区的Code属性表里面，但是里面的字节码是怎么执行我们却不知道，这里通过理解虚拟机字节码执行引擎去看看这些字节码是怎么走的？ 概述物理机与虚拟机 物理机的执行引擎：直接建立在处理器、硬件、指令集、和操作系统层面上。 虚拟机的执行引擎：自己实现，可以自行制定指令集与执行引擎的结构体系，并且能够执行那些不被硬件直接支持的指令集格式。 虚拟机怎么执行代码 解释执行：通过解释器执行 编译执行：通过即时编译器产生本地代码执行 运行时栈帧结构栈帧是用于支持虚拟机进行方法调用和方法执行的数据结构，他是虚拟机运行时数据区中的虚拟机栈的栈元素，栈帧存储了方法的局部变量表、操作数栈、动态链接和方法返回地址等信息。每一个方法从调用开始至执行完成的过程，都对应着一个栈帧在虚拟机栈里面从入栈到出栈的过程。 一个线程的方法的调用链可能会很长，很多方法同时处于执行状态。对于执行引擎来说，在活动线程中，只有位于栈顶的栈帧才是有效的，称为当前栈帧，与这个栈帧相关联的方法称为当前方法，执行引擎运行的字节码指令都只针对当前栈帧进行操作，在概念模型上，典型的栈帧结构如下图： 接下来具体解释一下栈帧中的局部变量表、操作数栈、动态链接以及方法调用。 局部变量表 局部变量表示一组变量值存储空间，用于存放方法和方法内部定义的局部变量。 局部变量表的容量以变量槽Slot为单位。虚拟机规范说每个Slot都应该存放一个boolean、byte、char、int、float、reference或returnAddress类型的数据。long和double使用两个Slot。 reference类型在虚拟机中至少要实现能从该引用中直接或间接地查找到对象在Java堆中的数据存放的起始地址索引以及从该引用直接或者间接查找到对象所属数据类型在方法区中存储的类型信息。 虚拟机通过索引定位的方式使用局部变量表，如果执行的实例方法，那局部变量表中第0位索引的Slot默认是用于传递方法所属对象实例的引用，可以使用“this”来访问，其余参数按照参数表顺序排列。 局部变量表中的Slot是可以重用的，当某个变量除了它的作用域，那这个变量所对应的Slot就可以复用了，Slot的复用会直接影响到系统的垃圾收集行为，如下代码所示： 123456789101112// 例1// VM args : -verbose:gcpublic class StackFrameTest &#123; public static void main(String[] args) &#123; byte[] placeholder = new byte[64 * 1024 * 1024]; System.gc(); &#125;&#125; 输出结果： 12[GC (System.gc()) 68209K-&gt;66072K(125952K), 0.0019584 secs][Full GC (System.gc()) 66072K-&gt;65962K(125952K), 0.0069900 secs] 123456789101112// 例2// VM args : -verbose:gcpublic class StackFrameTest &#123; public static void main(String[] args) &#123; &#123; byte[] placeholder = new byte[64 * 1024 * 1024]; &#125; System.gc(); &#125;&#125; 输出结果 12[GC (System.gc()) 68875K-&gt;66072K(125952K), 0.0010138 secs][Full GC (System.gc()) 66072K-&gt;65962K(125952K), 0.0069811 secs] 12345678910111213// 例3// VM args : -verbose:gcpublic class StackFrameTest &#123; public static void main(String[] args) &#123; &#123; byte[] placeholder = new byte[64 * 1024 * 1024]; &#125; int a = 0; System.gc(); &#125;&#125; 输出结果 12[GC (System.gc()) 68875K-&gt;66072K(125952K), 0.0016694 secs][Full GC (System.gc()) 66072K-&gt;426K(125952K), 0.0054452 secs] placeholde能否被回收的根本原因是：局部变量的Slot是否还存有关于placeholder数组对象的引用。例1没有垃圾回收，例2代码虽然已经离开了placeholder的作用域，但是之后没有任何对局部变量表的读写操作，所有placeholder原来的Slot还没有被其他变量复用，所以GC Roots一部分的局部变量表仍然保持着对它的关联，当例3修改了局部变量表，那么就会进行垃圾回收了。 这里解释一个编码建议：不使用的对象应手动赋值null 我们看看下面的代码： 123456789101112// 例1// VM args : -verbose:gcpublic class StackFrameTest &#123; public static void main(String[] args) &#123; byte[] placeholder = new byte[64 * 1024 * 1024]; placeholder = null; System.gc(); &#125;&#125; 输出结果： 12[GC (System.gc()) 68875K-&gt;66072K(125952K), 0.0016915 secs][Full GC (System.gc()) 66072K-&gt;426K(125952K), 0.0058140 secs] 我们可以看到当placeholder赋值为null，会发生垃圾回收。 局部变量表没有赋初始值不能使用。 操作数栈 操作数栈常被称为操作栈，一个方法刚开始执行的时候是空的，在方法执行的过程中，会有各种字节码指令往操作数栈中写入和提取内容，例如，在做算术运算的时候是通过操作数栈来 进行的，又或者是在调用方法的时候通过操作数栈来进行参数传递的。 在概念模型中，两个栈帧是完全独立的，但在大多虚拟机的实现里会做一些优化处理，令两个栈帧的部分操作数出现一部分重叠，避免方法调用时额外的参数复制，如下图： Java虚拟机的解释执行引擎称为“基于栈的执行引擎”，其中的栈就是操作数栈。 动态链接 每个栈帧都包含一个执行运行时常量池中该栈帧所属方法的引用，持有这个引用就是为了支持方法调用过程中的动态链接。 Class文件的常量池存有大量的符号引用，一部分是在类加载中的解析阶段完成的，称为静态解析，另一部分是在每一次运行期间转化为直接引用，称为动态链接。 方法返回地址当一个方法开始执行后，只有两种方式退出这个方法。 正常完成出口：执行引擎遇到一个方法返回的字节码指令，调用者的PC计数器的值可以作为返回地址 异常完成出口：在方法执行过程中遇到异常，并且这个异常没有在方法体得到处理，它不会给调用者产生任何返回值，它的返回值是要通过异常处理器表来确定的。 方法调用方法调用不等同于方法执行，方法调用阶段唯一的任务就是确定被调用方法的版本。Class文件的编译过程不包含传统编译找那个的链接步骤，所以Java方法调用过程需要在类加载期间，甚至到运行期间才能确定目标方法的直接引用。 解析解析： 方法在程序真正运行之前就有一个可确定的调用版本，并且这个方法的调用在运行期是不可变的，这类方法的调用成为解析。 所有方法可以分为两类虚方法和非虚方法，其中非虚方法都可以在类加载的时候就会把符号引用解析为该方法的直接引用。 非虚方法：静态方法、私有方法、实例构造器、父类方法和final方法 虚方法：与非虚方法相反 解析调用一定是个静态的过程，在编译器就完全确定，在类装载的解析阶段就会把涉及的符号引用全部转变为可确定的直接引用，不会延迟到运行期再去完成。而分派调用则可能是静态也可能是动态的，根据分派的宗数量（方法的接收者与方法的参数统称为方法的总量）可分为单分派和多分派，这两种分派方式地组合可分为静态单分派、静态多分派、动态单分派、动态多分派。 分派静态分派1Human man = new Man(); 上面代码中Human称为变量的静态类型，或者叫做外观类型，后面的Man称为实际类型，静态类型是编译器可知，实际类型是运行期才能确定的。虚拟机在重载时是通过参数的静态类型而不是实际类型来作为判断依据的。 所有依赖静态类型来定位方法执行版本的分派动作称为静态分派，静态分派的典型应用是方法重载。静态分派发生在编译阶段，因此确定静态分派的动作实际上不是由虚拟机来执行的，另外，编译器虽然能确定出方法的重载版本，当在很多情况下这个重载版本不是“唯一的”，往往只能确定一个“更加合适的”版本，具体例子可以看看《深入理解Java虚拟机》。 动态分派在运行期根据实际类型确定方法执行版本的分派过程称为动态分派，典型应用是方法重写。它主要是通过invokevirturl指令来实现的。invokevirtual指令的运行时解析过程大致分为如下几个步骤： 找到操作数栈顶的第一个元素所指向的对象的实际类型，记作C。 如果在类型C中找到与常量中的描述符合简单名称都相符的方法，则进行访问权限校验，如果通过则返回这个方法的直接引用，查找过程结束；如果不通过，则返回java.lang.IllegalAccessError异常。 否则，按照继承关系从下往上依次对C的各个父类进行第2步的搜索和验证过程。 如果始终没有找到合适的方法，则抛出java.lang.AbstractMethodError异常。 单分派和多分派单分派是根据一个宗量对目标方法进行选择，多分派则是根据一个宗量对目标方法进行选择。我们结合下面的代码来理解：12345678910111213141516171819202122232425262728293031323334public class Dispatch &#123; static class QQ &#123;&#125; static class _360 &#123;&#125; public static class Father &#123; public void hardChoice(QQ arg) &#123; System.out.println("father choose qq"); &#125; public void hardChoice(_360 arg) &#123; System.out.println("father choose _360"); &#125; &#125; public static class Son extends Father &#123; public void hardChoice(QQ arg) &#123; System.out.println("son choose qq"); &#125; public void hardChoice(_360 arg) &#123; System.out.println("son choose _360"); &#125; &#125; public static void main(String[] args) &#123; Father father = new Father(); Father son = new Son(); father.hardChoice(new _360()); son.hardChoice(new QQ()); &#125;&#125; 输出结果：12father choose _360son choose qq 编译阶段编译器的选择过程（静态分派过程）：这时选择目标方法的依据有两点：一是静态类型是Father还是Son，二是方法参数是QQ还是360。因为是根据两个宗量进行选择，所有Java语言的静态分派属于多分派类型。 运行阶段虚拟机的选择过程（动态分派过程）：由于编译器已经已经决定目标方法的签名必须为hardChoice(QQ)，所以这时参数的静态类型，实际类型都对方法的选择不会构成影响，唯一可以影响虚拟机选择的因素只有此方法的接受者的实际类型是Father还是Son,因为只有一个宗量作为选择依据，所以Java语言的动态分派属于单分派类型。 jdk1.8之前的Java语言是一门静态多分派，动态单分派的语言。 虚拟机动态分派的实现由于动态分派是非常频繁的操作，而且动态分派的方法版本选择过程需要运行时在类的方法元数据中搜索合适的目标方法，因此虚拟机会进行优化。常用的方法就是为类在方法区中建立一个虚方法表（Virtual Method Table，在invokeinterface执行时也会用到接口方法表，Interface Method Table），使用虚方法表索引来替代元数据查找以提升性能。下图就是前面代码的虚方法表结构： 虚方法表中存放着各个方法的实际入口地址。如果某个方法在子类中没有被重写，那子类的虚方法表里面的地址入口和父类相同方法的地址入口是一致的，都指向父类的实现入口。如果子类重写了父类的方法，子类方法表中的地址会替换为指向子类实现版本的入口地址。在上图中，Son重写了Father的全部方法，所以Son的方法表替换了父类的地址。但是Son和Father都没有重写Object的方法，所以方法表都指向了Object的数据类型。为了程序实现上的方便，具有相同签名的方法，在父类和子类的虚方法表中都应该具有一样的索引号，这样当类型变换时，仅仅需要变更查找的方法表，就可以从不同的虚方法表中按索引转换出所需的入口地址。方法表一般在类加载的连接阶段进行初始化，准备了类的变量初始值后，虚拟机会把该类的方法表也初始化完毕。 动态类型语言支持动态类型语言的关键特征是它的类型检查的主体过程是在运行期间而不是编译期间，可以理解为变量无类型而变量值才有类型，Javascript就是这样的语言，而目前Java属于静态类型语言。当然Java也有它实现动态性的方法，这块知识点蛮大，就不展开说了。 基于栈的字节码解释执行引擎解释执行先看看编译过程流图： 上图最下面的那一条就是传统编译原理中程序代码到目标机器代码生成过程（C） 上图中间那一条就是解释执行的过程（Java） 基于栈的指令集与基于寄存器的指令集 基于栈的指令集：指令流中的大部分都是零地址指令（无显示参数），他们依赖操作数栈进行工作。 优点：可移植性，代码紧凑，编译器实现简单 缺点：执行速度稍慢（频繁访问内存） 基于寄存器的指令集：指令集依赖寄存器进行工作 基于栈的解释器执行流程其实就是按照指令解释执行，随便看了例子应该就能明白。 总结其实这里谈的主要还是解释执行，其中有一点很重要就是分派的概念，明白invokevirtual指令的执行过程。 参考 《深入理解Java虚拟机》 虚拟机字节码执行引擎]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM_9_类加载器]]></title>
    <url>%2F2017%2F12%2F06%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-9-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%2F</url>
    <content type="text"><![CDATA[引：之前一直在说类加载，类加载就需要类加载器，类加载最初是为了满足Java Applet，现在基本已经死掉了，但是类加载却在类层次划分、OSGi、热部署、代码加密等领域大放异彩，成为Java体系中一块重要的基石，可谓失之桑榆，收之东隅。 什么是类加载器？虚拟机设计团队把类加载阶段的“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便让应用程序自己去决定如何去获取所需要的类，实现这个动作的代码模块称为“类加载器”。 同一个Class文件，不同的类对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。换个说法：比较两个类是否“相等”，只是在这两个类是由同一个类加载器加载的前提下才有意义，如果这两个类源于同一个Class文件，被同一个虚拟机加载，只要加载他们的类加载器不同，那这两个类就必定不相等。 这里的相等包括：代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()方法返回结果，下面的代码展示了不同的类加载器对instanceof关键字运算的结果的影响。(下面的代码属于破坏双亲委派模型，只是为了验证类的命名空间)1234567891011121314151617181920212223242526272829303132public class ClassLoaderTest &#123; public static void main(String[] args) throws Exception &#123; ClassLoader myLoader = new ClassLoader() &#123; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; try &#123; String fileName = name.substring(name.lastIndexOf(".") + 1) + ".class"; InputStream is = getClass().getResourceAsStream(fileName); if (is == null) &#123; return super.loadClass(name); &#125; byte[] b = new byte[is.available()]; is.read(b); return defineClass(name,b,0,b.length); &#125; catch (IOException e) &#123; throw new ClassNotFoundException(name); &#125; &#125; &#125;; Object obj = myLoader.loadClass("com.todorex.demo.ClassLoaderTest").newInstance(); System.out.println(obj.getClass()); System.out.println(obj instanceof com.todorex.demo.ClassLoaderTest ); &#125;&#125; 运行结果：12class com.todorex.demo.ClassLoaderTestfalse 这里的false就证明了两个类虽然来自于同一个Class文件，但是由于使用的类加载器不同，就依然是两个独立的类。 双亲委派模型类加载器的类型Java虚拟机角度 启动类加载器，它本身是由C++语言实现，或者底层的关键方法是用C实现的。 所有其他类加载器，这些类加载器都由Java语言实现。 Java开发人员角度 启动类加载器：这个类加载器负责将存放在\lib目录中的，或者被-Xbootclasspath参数所指定的路径找那个的，并且是虚拟机识别的（按照文件名识别的）类库加载到虚拟机内存中。启动类加载器无法被Java程序直接使用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器，直接使用null即可。（不知道怎么用，知道的大佬请告知！！！！） 扩展类加载器：这个加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载\lib\ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以使用扩展类加载器。 应用程序类加载器：这个类加载器由sun.misc.Launcher$AppClassLoader实现，也称系统类加载器。它负责加载用户所指定的类路径java -classpath或-Djava.class.path的所有类，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 类加载器的双亲委派模型模型图 双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。这里的类加载器之间的父子关系一般不会以继承的关系来实现，而是都使用组合关系来复用父加载器的代码。（组合就是在一个类中调用另一个类的代码） 工作过程我相信这张图最清楚了： 我们可以由图看到以下过程： 自底向上检查类是否已经加载，若已加载，直接返回。 若所有父类都没有加载该类，则自顶向下尝试加载该类。 如果加载不成功，则抛出ClassNotFoundException异常。 我们可以从代码看看他是怎么实现的？ 先看ClassLoader函数的loadClass函数1234567891011121314151617181920212223242526272829303132333435363738protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // 先从缓存查找该class对象，找到就不用重新加载 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; //如果找不到，则委托给父类加载器去加载 c = parent.loadClass(name, false); &#125; else &#123; //如果没有父类，则委托给启动加载器去加载 c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // 如果都没有找到，则通过自定义实现的findClass去查找并加载 c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123;//是否需要在加载时进行解析 resolveClass(c); &#125; return c; &#125; &#125; 从该函数我们可以得知双亲委派模型会先递归去查找父加载器是否已经加载过该类了。如果父加载器都没有加载过该类，则开始调用fandClass()尝试去加载该类。由于启动类加载器不可知，我们可以去看看扩展类加载器的findClass()。我们可以看到下面的类图： 我接着我想去看看ExtClassLoader类里面的findClass()方法，结果发现没有，只要去他的父类URLClassLoader去找找，还好找到了，可以看看下面的代码：123456789101112131415161718192021222324252627282930protected Class&lt;?&gt; findClass(final String name) throws ClassNotFoundException&#123; final Class&lt;?&gt; result; try &#123; result = AccessController.doPrivileged( new PrivilegedExceptionAction&lt;Class&lt;?&gt;&gt;() &#123; public Class&lt;?&gt; run() throws ClassNotFoundException &#123; String path = name.replace('.', '/').concat(".class"); Resource res = ucp.getResource(path, false); if (res != null) &#123; try &#123; //defineClass()方法是用来将byte字节流解析成JVM能够识别的Class对象 return defineClass(name, res); &#125; catch (IOException e) &#123; throw new ClassNotFoundException(name, e); &#125; &#125; else &#123; return null; &#125; &#125; &#125;, acc); &#125; catch (java.security.PrivilegedActionException pae) &#123; throw (ClassNotFoundException) pae.getException(); &#125; if (result == null) &#123; throw new ClassNotFoundException(name); &#125; return result;&#125; 其实AppClassLoader的findClass()也是继承自URLCLassLoader，所以都是一样的，我们再结合最开始的loadClass()就可以很好的理解了上面双亲委派模型的工作流程了。 好处java随着它的类加载一起具备了一种带有优先级的层次关系，它能保证一个类在程序中各种类加载器环境中都是同一个类。 双亲委派模型的“双亲”在Java虚拟机英文文章里双亲委派模型的英文是Parent-Delegation Model，不知道为什么中文翻译会称他为双亲委派模型，可能是他一般都会找到一个爸爸去委托去处理吧。 破坏双亲委派模型目前为止，双亲委派模型主要出现过3次较大的“被破坏”的情况。 在JDK1.2之前，新建加载器都是通过重写loadClass()方法来区分不同的加载器,以及修改加载逻辑，这样就破坏了双亲委派模型的向上寻找父加载器去加载的规范，在JDK1.2之后为了向前兼容，ClassLoader添加了新的protect方法findCLass()方法，从而实现了在双亲委派模型上实现加载逻辑的修改。 线程上下文类加载器，如JNDI服务(没用过) 实现动态性，如OSGi(没用过) 总结有时候分析东西查看源码是必要的，还要利用一些工具去分析他们的继承关系。 参考 《深入理解Java虚拟机》 深入理解Java类加载器(ClassLoader) 深入理解Java类加载器(一)：Java类加载原理解析]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM_8_虚拟机类加载机制]]></title>
    <url>%2F2017%2F12%2F02%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-8-%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[引：在Class文件中描述的各种信息最终都需要加载到虚拟机之中之后才能运行和使用。而虚拟机如何加载这些Class文件？Class文件中的信息进入到虚拟机后会发生什么变化？ 概述虚拟机的类加载机制：虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型。 C/C++和Java链接的不同： C/C++：在编译时完成链接工作；降低了运行时的性能开销，但是也降低了运行时的灵活性。 Java：类型的加载、链接和初始化过程都是在程序运行期间完成的；增加了运行时的性能开销，但是增强了运行时的灵活性，使Java变成了可以动态扩展的语言。这里的动态扩展可以分为两点： 动态加载：用户可以通过Java预定义的或者自定义的类加载，让一个本地的应用程序可以在运行时在从网络或其他地方加载一个二进制流作为程序代码的一部分。 动态链接：如果编写一个面向接口的应用程序，可以等到运行时再指定其实际的实现类。 类加载的时机类的生命周期类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括： 其中链接包括下面三个部分： 生命周期中加载、验证、准备、初始化和卸载这5个阶段顺序是确定的，但是又是可以互相交叉混合式进行的。 类的初始化时机什么情况下需要开始类加载过程的第一阶段：加载？Java虚拟机规范没有进行强制约束，但是对初始化阶段，虚拟机规范则是严格规定了有且只有5种情况必须立即对类“初始化”。 遇到new、getstatic、putstatic或者invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要触发其初始化，生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候，读取或设置一个类的静态字段（被final修饰并且已在编译器把结果放在常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。 使用java.lang.reflect包的时候对类进行反射调用的时候，如果类没有进行过初始化，则需要触发其初始化。 当初始化一个类的时候，如果发现其父类还没有进行初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要制定一个要执行的主类（包含main方法的那个类），虚拟机会先初始化这个类。 如果一个java.lang.invoke.MethodHandle实例解析结果是REF_getStaic,REF_putStatic,REF_invokeStatic的方法句柄，并且这个句柄所对应的类没有进行过初始化，则需要先触发其初始化。（还没用过） 上面5种场景中的行为成为对一个类的主动引用，除此之外，所有应用类的方式都不会触发初始化，成为被动引用。下面是几个被动引用的场景： 通过子类引用父类的静态字段，不会导致子类初始化。 通过数组来定义引用类，不会触发此类的初始化。 常量在编译阶段会存入调用类的常量池中，本质上没有直接引用到定义常量的类，不会触发该类的初始化，因为在编译阶段通过常量传播优化，已经将其他类的常量存入到调用类的常量池了。 说一点接口与类初始化世时机的不同：在有且只有的5条中的第3条,当一个类在初始化时，要求其父类全部都已经初始化过了，但是接口在初始化时，不要求其父接口全部都完成了初始化，只有真正使用到父接口的时候（如引用接口中定义的常量）才会初始化。 类加载的过程Java虚拟机中类加载的全过程为： 加载虚拟机在加载阶段要干什么 通过一个类的全限定名来获取定义此类的二进制字节流。 将这个类的字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。 二进制字节流的来源 从ZIP包中读取，最终成为了日后JAR、EAR、WAR格式的基础。 从网络中获取，这个场景最典型的应用就是Applet（没用过）。 运行时计算生成，这个场景使用的最多的就是动态代理技术，生成代理类的二进制字节流。 由其他文件生成，典型场景是JSP应用，即由JSP文件生成对应的Class类。 加载阶段的注意点 非数组类的加载阶段是开发人员可控性最强的，加载阶段既可以使用系统提供的引导类加载器，也可以使用用户自定义的类加载器。 数组类本身不通过类加载器创建，它是由Java虚拟机直接创建的，但是最终还是要靠类加载器是创建数组类里面的元素类型，每个数组都会在加载数组元素的类加载器的类名称空间上被标识。 Java虚拟机规范没有规定类在方法区的具体数据结构，也没有规定生成的Class对象存储在哪里，对于HotSpot虚拟机而言，它被存放在方法区里面，jdk1.8以后应该在直接内存中吧。 加载阶段与连接阶段的部分内容（一部分字节码文件格式验证工作）是交叉进行的。 验证验证目的由于Class文件并不一定要求用Java源码编译而来，可以使用任何途径产生，所以安全性得不到保证，而验证的目的就是为了确保Class文件的字节流包含的信息符合虚拟机的要求，并且不会危害虚拟机自身的安全。 验证过程 文件格式验证 主要目的是保证输入的字节流能正确地解析并存储于方法区之内，格式上负荷一个Java类型信息的要求，这个阶段的验证是基于二进制字节流进行的，只有通过这个阶段的验证后，字节流才会进入内存的方法区中进行存储，所以后面的3个验证阶段全部是基于方法区的存储结构进行的，不会再直接操作字符流。 元数据验证 主要目的是对类的元数据信息进行语义校验，保证不存在不符合Java语言规范的元数据信息。 字节码验证 主要目的是通过数据流和控制流分析，确定程序语义是合法的，符合逻辑的，保证被校验类的方法在运行时不会做出危害虚拟机安全的事件。 符号引用验证 发生在解析阶段（将符号引用转化为直接引用），主要目的是确保解析动作能正常执行。 调优的地方如果所运行的代码都已经被反复使用和验证过，那么在实施阶段就可以考虑使用-Xverify:none参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，但是这里的初始值需要注意一下： 通常情况：初始值是数据类型的零值 类变量有fianl关键字修饰：初始值是ConstantValue属性所指定的值 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。这里解释一下直接引用和符号引用： 符号引用：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量。它的字面量形式明确定义在Java虚拟机规范的Class文件格式中。符号引用于虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存中。 直接引用：它可以是直接指向目标的指针、相对偏移量或者是一个能间接定位到目标的句柄。直接引用和虚拟机实现的内存布局相关，有了直接引用，那么引用的目标必定已经在内存中存在。 虚拟机规范中并未规定解析阶段发生的具体时间。所以虚拟机可以根据需要来判断到底是在类被加载器加载时就对常量池的符号引用进行解析，还是等到一个符号引用被使用前再去解析它。 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。 初始化类初始化时类加载过程的最后一步，到了初始化阶段，才真正开始执行类中定义的Java程序代码。在准备阶段，变量已经赋过一次系统要求的初始值，而在初始化阶段，则根据程序员通过程序制定的主观计划去初始化变量和其他资源，从另一个角度来表达：初始化阶段是执行类构造器clinit()方法的过程。下面是clinit()方法的注意点： clinit()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块中语句合并产生的，收集的顺序是有语句在源文件出现的顺序决定的，这里有很特别的一点：静态语句块中只能访问到定义在静态语句块之前的变量，定义在之后的变量，在前面的静态语句块可以赋值，但是不能访问，代码如下： 123456789public class Test &#123; static &#123; i =0; //正常编译 System.out.println(i); //提示“非法向前引用” &#125; static int i =1;&#125; clinit()方法不需要显式地调用父类构造器，虚拟机会保证在子类的clinit()方法执行前，父类的clinit()方法已经执行完毕。 由于父类的clinit()方法先执行，所以父类定义的静态语句块要优先于子类的变量赋值操作。 虚拟机会保证一个类的clinit()方法在多线程中被正确地加锁、同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的clinit()方法，其他线程都要阻塞等待，直到活动线程执行clinit()方法完毕。 总结类加载的5个阶段都很重要，对理解对象的创建过程有了更好的理解。 参考 《深入理解Java虚拟机》]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM_7_探秘类文件]]></title>
    <url>%2F2017%2F12%2F01%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-7-%E6%8E%A2%E7%A7%98%E7%B1%BB%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[引：java代码编译的结果从本地机器码转变为字节码，并且生成了类文件，那么这个类文件里面是什么东西呢？ JVM的无关性一般提到Java的好处，其中必定有一条是平台无关性，但是这个太狭隘了，其实它有两点无关性。 平台无关性Java在刚刚诞生之时就有一个著名的宣传口号：“一次编写，到处运行（Write Once, Run Anywhere）”。“与平台无关”的理想最终实现在操作系统的应用层上：其实就是Java虚拟机了，他可以载入和执行同一种平台无关的字节码，从而实现了程序的“一次编写，到处运行”。 语言无关性目前已经一大批能够在JVM运行语言了，就我自己知道并且使用过就有Groovy、Jython、Scala等。实现语言无关性的基础仍然是虚拟机和字节码存储格式。其他语言通过自己的编译把程序代码编程成符合Java虚拟机规范的Class文件即可。 类文件的结构Class文件是一组以8位字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑排列在Class文件之中，中间没有任何分隔符。Class文件只有两种数据类型：无符号数和表 无符号数：以u1，u2，u4，u8来分别代表1个字节，2个字节，4个字节和8个字节的无符号数，无符号数可以用来描述数字、索引引用、数值量或者按照UTF-8编码构成字符串值。 表：它是由多个无符号数或者其他表作为数据项构成的复合数据类型，所有表习惯地以“_info”结尾。 整个Class文件本质上就是一张表，它由下表所示的数据项构成。 类型 名称 数量 u4 魔数 1 u2 次版本号 1 u2 主版本号 1 u2 常量数量 1 cp_info 常量池 常量数量-1 u2 访问标志 1 u2 类索引 1 u2 父类索引 1 u2 接口数量 1 u2 接口索引集合 接口数量 u2 字段数量 1 field_info 字段表 字段数量 u2 方法数量 1 method_info 方法表 方法数量 u2 属性数量 1 attribute_info 属性表 属性数量 接下里稍微详细看看上面的数据： 不过按例子来吧，下面是一个简单的Java类1234567891011package com.todorex.demo;public class TestClass &#123; private int m; public int inc() &#123; return m+1; &#125;&#125; 先编译这个类得到TestClass.class文件，打开它可以下面的16进制数：12345678910111213141516171819cafe babe 0000 0034 0013 0a00 0400 0f090003 0010 0700 1107 0012 0100 016d 01000149 0100 063c 696e 6974 3e01 0003 28295601 0004 436f 6465 0100 0f4c 696e 654e756d 6265 7254 6162 6c65 0100 0369 6e630100 0328 2949 0100 0a53 6f75 7263 6546696c 6501 000e 5465 7374 436c 6173 732e6a61 7661 0c00 0700 080c 0005 0006 01001a63 6f6d 2f74 6f64 6f72 6578 2f64 656d6f2f 5465 7374 436c 6173 7301 0010 6a617661 2f6c 616e 672f 4f62 6a65 6374 00210003 0004 0000 0001 0002 0005 0006 00000002 0001 0007 0008 0001 0009 0000 001d0001 0001 0000 0005 2ab7 0001 b100 00000100 0a00 0000 0600 0100 0000 0600 01000b00 0c00 0100 0900 0000 1f00 0200 01000000 072a b400 0204 60ac 0000 0001 000a0000 0006 0001 0000 0009 0001 000d 00000002 000e 然后用javap 解析TestClass.class文件，得到：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253Classfile /Users/rex/IdeaProjects/JVMTest/src/com/todorex/demo/TestClass.class Last modified 2017-12-1; size 292 bytes MD5 checksum 337a51d3bebe0e9a82142a352eb0977e Compiled from "TestClass.java"public class com.todorex.demo.TestClass minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #4.#15 // java/lang/Object."&lt;init&gt;":()V #2 = Fieldref #3.#16 // com/todorex/demo/TestClass.m:I #3 = Class #17 // com/todorex/demo/TestClass #4 = Class #18 // java/lang/Object #5 = Utf8 m #6 = Utf8 I #7 = Utf8 &lt;init&gt; #8 = Utf8 ()V #9 = Utf8 Code #10 = Utf8 LineNumberTable #11 = Utf8 inc #12 = Utf8 ()I #13 = Utf8 SourceFile #14 = Utf8 TestClass.java #15 = NameAndType #7:#8 // "&lt;init&gt;":()V #16 = NameAndType #5:#6 // m:I #17 = Utf8 com/todorex/demo/TestClass #18 = Utf8 java/lang/Object&#123; public com.todorex.demo.TestClass(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object."&lt;init&gt;":()V 4: return LineNumberTable: line 6: 0 public int inc(); descriptor: ()I flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: aload_0 1: getfield #2 // Field m:I 4: iconst_1 5: iadd 6: ireturn LineNumberTable: line 9: 0&#125;SourceFile: "TestClass.java" 魔数 每个Class文件的头4个字节成为魔数 使用魔数来进行身份识别（文件类别），因为如果使用文件名来识别，安全性太低，由于文件名可以随意改动。 Class文件的魔数的获得就有“浪漫气息”，值为0xcafebabe,上面16进制文件也可以看到。这让自己想起了高中用的三星手机打开qq就是一杯咖啡的标志。 Class文件的版本接下来第5，6个字节显示的是次版本号，7，8字节显示的是主版本号。 高版本的JDK可以向下兼容以前版本的Class文件，但不能运行以后版本的Class文件。 常量池在版本号之后的是常量池入口。 常量池是Class文件结构中与其他项目关联最大的数据类型，也是占Class文件空间最大的数据项目之一。 常量池常量的数据不是固定的，在最前面的Class文件组成可以看到有一个常量数量项，这个容量计数是从1而不是0开始的，比如上面的十六进制的值为0x0013(19)就代表有18个常量。 常量池主要存放两大类变量 字面量：文本字符串、声明为final的常量值等 符号引用：（编译原理的概念） 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 常量池的每一项常量都是表，常量的顺序可以参照javap解析出来的常量顺序，在JDK1.7以后共有14种不同类型的表，他们共同点是表的第一位是一个u1类型的标志位（tag），具体的标志对应的类型参照书《深入理解Java虚拟机》。这里提一下CONSTANT_UTF8_info这个表： 类型 名称 数量 u1 tag 1 u2 length 1 u1 bytes length length值说明了UTF-8编码的字符串长度是多少字节，他后面跟着的长度为length字节的连续数据是一个使用UTF-8缩略编码表示的字符串。而u2最大值是65535，所以说如果Java程序如果定义了超过64KB（大约）英文字符的变量或者方法名，将无法编译。 UTF-8缩略编码和UTF-8编码的区别：UTF-8编码都是使用3个字节编码，而UTF-8缩略编码可以使用1或2或3个字节编码。 访问标志在常量池结束之后，紧接着的两个字节代表访问标志，这个标志用于识别一些类或者接口层次的访问信息，包括：这个Class是类还是接口；是否定义public类型；是否定义为abstract类型；如果是类的话，是否被声明为final等，访问标志一共有16个标志位可以使用，当前只定义了8个。 类索引、父类索引、接口索引集合 类索引、父类索引都是u2类型的数据，类索引、父类索引都是指向一个CONSTANT_Class_info的类描述符常量 接口索引集合是一组u2类型的数据的集合，它入口的第一项是u2的接口计数器，后面就是具体接口索引 Class文件有这三项数据来确定这个类的继承关系 字段表集合接下来是字段表，字段表用于描述接口或者类中声明的变量，包括类级变量以及实例级变量，不包括方法内部声明的局部变量。我们看一下一个字段表的构成： 类型 名称 数量 u2 访问标志 1 u2 简单名称索引 1 u2 描述符索引 1 u2 属性数量 1 attribute_info 属性表 属性数量 根据上表我们解析一下其中的含义： 访问标志：它和之前的访问标志很类似。 简单名称索引：它指向一个CONSTANT_UTF8_info类型的常量，这里面存储了本字段的名字信息，像javap解析后的第5个常量m。 描述符索引：用来描述字段的数据类型，像javap解析后的第6个常量I,代表了基本类型int 属性表（可能有ConstantValue表 下面是字符表的注意点： 字段表集合不会列出从超类或者父接口继承而来的字段。 字段表有可能列出原本Java代码之中不存在的字段，譬如在内部类中为了保持对外部类的访问性，会自动添加执行外部类实例的字段。（不懂，大佬请指教） Java语言中字段是无法重载的，名称必须不一样，但是对于字节码来说，如果两个字段的描述符不一致，那么字段重名是合法的。 方法表集合接下来是方法表，方法表的内容和字段表几乎完全一致。其中坑顶也看一下方法表的构成： 类型 名称 数量 u2 访问标志 1 u2 简单名称索引 1 u2 描述符索引 1 u2 属性数量 1 attribute_info 属性表 属性数量 这里解释一下和字段表不一样的地方 简单名称索引：它指向一个CONSTANT_UTF8_info类型的常量，这里面存储了本字段的名字信息，像javap解析后的第11个常量inc。 描述符索引：它的作用是用来描方法的参数列表（包括数量、类型以及顺序）和返回值，像javap解析后的第12个常量()I,表示的就是一个返回值为int的方法。 属性表：这里肯定存放了Code属性表（方法里的Java代码） 下面是方法表的注意点： 如果父类方法在子类没有被重写，方法表集合中就不会出现来自父类的方法信息。 可能会出现由编译器自动添加的方法，最典型的有类构造器“”方法和实例构造器“”方法，就像javap解析后的第11个常量。 在Java语言中，要重载一个方法，需要相同的简单名称和与原方法不同的Java代码的方法特征签名，这里需要解释一下Java特征签名和JVM特征签名： Java特征签名：方法名称、参数顺序 JVM特征签名：Java特征签名、方法返回值以及受查异常表 属性表集合最后就是属性表集合了，在Class文件、字段表、方法表都可以携带自己的属性表集合，以及用于描述某些场景专有的信息。属性表集合不要求各个属性具有严格的顺序，并且只要不与已有属性名重复就好。 上面程序的例子出现过几个属性表：Code、LineNumberTable、SourceFile、ConstantValue，接下来我们详细说一下： Code属性Java程序方法体中的代码经过Javac编译器处理后，最终变为字节码指令存储在Code属性内，Code属性出现在方法表属性集合之中，我们先看看Code属性表的结构： 类型 名称 数量 u2 属性名索引 1 u4 属性长度 1 u2 操作数栈深度的最大值 1 u2 局部变量表所需的存储空间 1 u4 Java方法代码字节码指令长度 1 u1 Java方法代码字节码 Java方法代码字节码指令长度 u2 显式异常表长度 1 exception_info 显式异常表 显式异常表长度 u2 属性个数 1 attribute_info 属性表 属性个数 接下来我们说明一下几个关键项： 属性名索引：它是一项指向CONSTANT_UTF8_info型的索引，常量值固定为“Code”，就像上面javap解析出来的常量池的第9个。 属性长度：固定为整个属性表长度减去6个字节。 操作数栈深度的最大值：在方法执行的任意时刻，操作数栈都不会超过这个深度，虚拟机运行的时候需要根据这个值来分配栈栈中的操作数栈深度。 局部变量表所需的存储空间：它的单位是Slot，局部变量表存储了方法参数（包括实例方法中的隐藏参数this）、显示异常处理器的参数（try-catch检查的异常）、方法体中定义的局部变量，Javac编译器会根据变量的作用域来分配Slot，然后计算出需要的存储空间大小。 Java方法代码字节码指令长度和Java方法代码字节码：存储了Java源程序编译后生成的字节码指令，目前Java虚拟机规范已经定义了约200条编码值对应的指令含义。 PS：如果把一个Java程序中的信息分为代码（Code，方法体里面的Java代码）和元数据（Metadata，包括类、字段、方法定义以及其他信息）两部分，那么在整个Class文件，Code属性用来描述代码，所有其他数据项目都用于描述元数据。 显式异常表：用于显示try-catch代码块要检查的异常 LineNumberTable它的使用位置是在Code属性，用于描述Java源码行号与字节码行号之间的对应关系，当抛出异常的时候堆栈会显示出错的行号。 SourceFile它的使用位置是类文件，用于记录生成这个Class文件的源码文件名称，当抛出异常的时候会显示出错代码所属的文件名。 ConstantValue它的使用位置是字段表，作用是通知虚拟机自动为静态变量赋值，只有static关键字修饰的变量（类变量）才可以使用这项属性，虚拟机对于类变量和实例变量赋值的方式有所不用。 实例变量：在实例构造器方法中进行 类变量：在类构造器方法中或者使用ConstantValue属性 目前Sun Javac编译器的选择是：如果同时使用final和static来修饰一个变量，并且这个常量的数据类型是基本类型或者String类型，就生成ConstantValue属性来进行初始化，如果这个变量没有被final修饰，或者并非基本类型或者字符串，则将会选择在方法中进行初始化。 总结通过上面的分析，我们一定能清楚的知道Class文件是什么以及Class文件包含什么东西，再也不怕了！！ 参考 《深入理解Java虚拟机》]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM_6_JVM调优实战]]></title>
    <url>%2F2017%2F11%2F30%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-6-JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[引：带着浅尝基本的Java诊断工具就这样把《深入理解Java虚拟机》的调优部分看完了，似懂非懂，我想待自己经历过一次性能调优，结合自身经历再来好好总结一番吧。 此处暂时省略一万字。。。]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM_5_内存分配策略]]></title>
    <url>%2F2017%2F11%2F30%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-5-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[引：一直在说Java的垃圾回收，既然有回收，那么当然会有分配。 Java技术体系中所提倡的自动内存管理可以归结为自动化地解决了两个问题： 给对象分配内存 回收分配给对象的内存 之前垃圾回收已经讲了很多，接下来我们详细地来看看内存分配 内存分配总说对象的内存分配，主要是在堆上分配，对象主要分配在新生代的Eden区上，如果启动了本地线程的分配缓冲，将按线程优先在TLAB上分配，少数情况下（大对象）也可能直接分配在老年代中，分配的规则不是百分百固定的，其细节取决于当前使用的是哪一种垃圾收集器组合，还有虚拟机中与内存相关的参数的设置。 对象优先在Eden分配 大多数情况，对象在新生代Eden区分配。当Eden区没有足够空间进行分配时，虚拟机会发起一次MinorGC。 当MinorGC发现复制的对象大于Survivor区时，会通过分配担保机制提前转移到老年代中。 大对象直接进入老年代所谓大对象是指需要大量连续内存空间的Java对象，如数组。 虚拟机提供了一个-XX:PretenureSizeThreshold参数，令大于这个设置值的对象直接在老年代分配，避免了在Eden区及Survivor区之间发生大量的内存复制。（新生代采用复制算法收集内存） 长期存活的对象将进入老年代虚拟机给每个对象定义了一个对象年龄计数器。如果对象在Eden出生并经过第一次MinorGC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，并且对象年龄设置为1.对象在Survivor中每度过一次MinorGC，年龄就增加一岁，当他的年龄达到一定程度（默认15岁），就将被晋升到老年代中。对象的年龄阈值，可以通过参数-XX：MaxTenuringThreshold设置。 动态对象年龄判定虚拟机不是永远要求对象的年龄必须达到MaxTenuringThreshold才晋升到老年代，如果Survivor空间中相同年龄所有对象大小总和大于Survivor空间的一半，年龄大于或等于改年龄的对象就可以直接进入老年代。 空间分配担保策略虽然有空间分配担保，但是也需要考虑老年代能否装下由于担保转存的内存大小，所以这个空间分配担保也需要一定的策略。 在发生MinorGC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间 如果上面条件成立，那么MinorGC就是安全的，可以进行 如果上面条件不成立，虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。 如果允许担保失败，就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小 如果大于，将尝试进行一次MinorGC 如果小于，或者HandlePromotionFailure设置为不允许冒险，那这时需要进行一次FullGC 在jdk 6 update 24之后的规则是只要老年代的连续空间大于新生代对象的总大小或者历次晋升平均大小就会进行MinorGC，否则进行FullGC。 总结通过上面我们可以知道JAVA虚拟机是怎么自动进行内存分配的，然后在进行GC之后，内存是怎么转换的。 参考 《深入理解JAVA虚拟机》]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM_4_垃圾收集策略]]></title>
    <url>%2F2017%2F11%2F29%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-4-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[引：Java与C++之间有一堵内存动态分配与垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人却想出来。那我们就先来看看JVM到底是怎么进行垃圾收集的？ 垃圾回收，回收哪里？之前介绍过Java内存运行时区域的各个部分，其中程序计数器、虚拟机栈、本地方法栈3个区域随线程而生，随线程而灭，这几个区域的内存分配和回收都具有确定性，方法结束或者线程结束，内存自然就跟着回收了，但是Java堆和方法区（元空间）则不一样，我们只有在运行期间才知道会创建哪些对象，这部分内存的分配和回收都是动态的，所有垃圾回收就是回收这里。 对象已死么？垃圾收集器在对堆进行回收前，第一件事就是要确定这些对象之中还有那些还“存活”者，哪些已经“死去”（即不可能再被任何途径使用的对象）。 引用计数算法 给每个对象添加一个引用计数器，每当有一个地方引用它时，计数器就加一；当引用失效时，计数器值就减一；任何时刻计数器为0的对象就是不可能再被使用的。 可达性分析算法（Java使用） 通过一系列称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径被称为引用链，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。 在Java语言中，可作为GC Roots的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象 方法区中类静态属性应用的对象 方法区中常量引用的对象 本地方法栈中JNI（即一般说的Native方法）引用的对象 引用类型 强引用：类似”Object obj = new Object()”这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。 软引用：用来描述还有用但非必须的对象，对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。它是通过SoftReference类来实现软引用的。 弱引用：用来描述非必需对象的，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象，它是通过WeakReference类来实现弱引用的。 虚引用：只要发生垃圾回收，它就会被收集，它唯一的目的就是能在这个对象被收集器回收时收到一个系统通知，它是用过PhantomReference类来实现虚引用。 方法区（元空间）的回收类和其元数据的生命周期和其对应的类加载器是相同的。话句话说，只要类加载器存活，其加载的类的元数据也是存活的，因而不会被回收掉。准确的来说，每一个类加载器的存储区域都称作一个元空间，所有的元空间合在一起就是我们一直说的元空间。当一个类加载器被垃圾回收器标记为不再存活，其对应的元空间会被回收。在元空间的回收过程中没有重定位和压缩等操作。但是元空间内的元数据会进行扫描来确定Java引用。 垃圾收集算法标记-清除算法流程： 标记出所有需要回收的对象 在标记完成后统一回收所有被标记的对象 不足： 效率问题 标记和清除两个过程效率都不高 空间问题 标记清除以后会产生大量不连续的空间碎片，无法存储大对象 复制算法流程： 将可用内存按容量分为大小相同的两块 在第一块分配内存，并标记出所有需要回收的对象 当第一块内存用完了，将所有活着的对象复制到另外一块上 将第一块所使用过的内存空间一次性清除 好处：解决了空间碎片问题 不足：降低了空间利用率 现在的商业虚拟机都用这种收集算法来回收新生代，因为新生代中的对象98%是“朝生夕死”的，所以不需要1:1划分空间,而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还活着的对象那个一次性复制到另一块Survivor空间上，最后清理掉前两块空间。HotSpot虚拟机默认Eden和Survivor的大小比例为8:1，所以只有10%的内存会被“浪费”，当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保。 内存的分配担保是指如果放着存活对象的Survivor空间没有足够空间放上一次新生代收集下来的存活对象时，这些对象将直接通过分配担保机制进入老年代。 标记-整理算法适合老年代 流程： 标记出所有需要回收的对象 让所有存活的对象都向一端移动 直接清理掉端边界以外的内存 分代收集算法将内存划分为老年代和新生代。老年代中存放寿命较长的对象，新生代中存放“朝生夕死”的对象。然后在不同的区域使用不同的垃圾收集算法。 总结从上面我们了解了对象存活判定算法和垃圾回收算法，但是不同虚拟机的具体实现还是不同的，而且不同的垃圾收集器的内存回收的具体实现也是不同的，我们要因机而议。 参考 《深入理解Java虚拟机》 JDK8 从永久代到元空间]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM_3_OutOfMemoryError异常现场]]></title>
    <url>%2F2017%2F11%2F29%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-3-OutOfMemoryError%E5%BC%82%E5%B8%B8%E7%8E%B0%E5%9C%BA%2F</url>
    <content type="text"><![CDATA[引：之前面对JVM运行内存的分析，总会提到出现OutMemoryError异常，接下来我们详细看下常出现这种异常的现场。 Java堆溢出我们通过限制Java堆的大小为20MB,不可扩张（将堆得最小值-Xms参数与最大值-Xmx参数设置为一样即可避免堆自动扩展），通过参数-XX：+HeapDumpOnOutOfMemoryError可以让虚拟机在出现内存溢出异常时Dump（备份）出当前的内存堆转储快照以便时候分析处理。 代码如下：1234567891011121314//VM Args: -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryErrorpublic class HeapOOM &#123; static class OOMobject &#123; &#125; public static void main(String[] args) &#123; List&lt;OOMobject&gt; list = new ArrayList&lt;&gt;(); while (true) &#123; list.add(new OOMobject()); &#125; &#125;&#125; 运行结果：12345java.lang.OutOfMemoryError: Java heap spaceDumping heap to java_pid81611.hprof ...Heap dump file created [27573572 bytes in 0.121 secs]Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3210)... 我们很容易在输出结果中看到Java heap space OOM出现在堆中。我们要解决这个区域的异常主要是通过内存映像分析工具（很多）对Dump出来的堆转储快照进行分析，重点确认是内存泄漏（Memory leak）还是内存溢出（Memory Overflow）。 内存泄漏：被分配的内存的对象不会被回收，永久占据内存。 解决方法：通过工具查看泄漏对象到GC Roots的引用链。 内存溢出：无法申请到内存。 解决方法：检查虚拟机的堆参数（-Xmx与-Xms），与机器物理内存对比看是否还可以调大，从代码上检查是否存在某些对象生命周期过长的情况，尝试减少程序运行期的内存消耗。 虚拟机栈和本地方法栈溢出我们说过HotSpot虚拟机中并不区分虚拟机栈和本地方法栈，所以设置本地方法栈大小是无效的，栈容量只由-Xss参数设定，在Java虚拟机规范中描述了两种异常 StackOverflowError异常：如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出此异常。 OutOfMemoryError异常：如果虚拟机在扩展栈使无法申请到足够的内存空间，将抛出此异常。 我个人想如果单线程中栈的内存大小等于总内存大小，那么上面两种异常应该是等价的吧，但是基本上是不可能的。所以单线程中出现得基本上都是StackOverflowError异常。 单线程代码如下：1234567891011121314// VM args: -Xss128kpublic class HeapOOM &#123; static class OOMobject &#123; &#125; public static void main(String[] args) &#123; List&lt;OOMobject&gt; list = new ArrayList&lt;&gt;(); while (true) &#123; list.add(new OOMobject()); &#125; &#125;&#125; 运行结果：123stack lenth:18855Exception in thread &quot;main&quot; java.lang.StackOverflowError at com.todorex.demo.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:10) 这里抄一下书的结论：在单个线程下，无论是由于栈帧太大还是虚拟机容量太小，当内存无法分配的时候，虚拟机抛出的都是StackOverflowError异常。 多线程代码如下：12345678910111213141516171819202122232425// VM args: -Xss2Mpublic class JavaVMStackOOM &#123; private void dontStop() &#123; while (true) &#123; &#125; &#125; public void stackLeakByThread() &#123; while (true) &#123; Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; dontStop(); &#125; &#125;); thread.start(); &#125; &#125; public static void main(String[] args) &#123; JavaVMStackOOM javaVMStackOOM = new JavaVMStackOOM(); javaVMStackOOM.stackLeakByThread(); &#125;&#125; 我在自己的机器上没有运行出来，可能需要点时间，不过机器变卡了，我想其实这里解释一下就好，它应该会抛出OutOfMemoryError异常。 解释：首先操作系统分给每个进程的内存是有限制的，所以总的方法栈的大小也是有限制的，但是每个线程都需要方法栈，所以线程建立的越多，剩余的方法栈内存就越小，一直创建线程，进程所拥有的内存终将被耗尽，到最后就会抛出OutOfMemoryError异常。 注意：线程数和方法栈大小是成反比的，所以在开发多线程的应用时应该特别注意，如果不能减少线程数或者更换64位虚拟机的情况下，就只能通过减少最大堆和减少栈容量来换取更多的线程了。 方法区（元空间）和运行时常量池溢出运行时常量池溢出在之前的博客也提到过在jdk1.6以及之前运行时常量池是放在方法区中的，存的是对象，所以可以设置虚拟机参数-XX:PermSize和-XX:MaxPermSize来限制方法区的大小，来模拟常量池溢出，但是jdk1.7及以后运行时常量池被移除了方法区，常量池存储的不再是对象，而是对象的引用，真正的对象存储在堆中，我们改变虚拟机参数为：-Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError运行下面程序：1234567891011// VM args:-Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryErrorpublic class RuntimeConstantPoolOOM &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); int i = 0; while (true) &#123; list.add(String.valueOf(i++).intern()); &#125; &#125;&#125; 运行结果：123java.lang.OutOfMemoryError: GC overhead limit exceededDumping heap to java_pid10818.hprof ...Heap dump file created [25172419 bytes in 0.251 secs] 上面结果提示GC开销超过限制，默认的话，如果你98%的时间都花在GC上并且回收了才不到2%的空间的话，虚拟机就会抛这个异常。 其实我们之前也提起过在JDK1.8及以后，字符串常量池从永久代移到到元空间中，元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制，但可以通过以下参数来指定元空间的大小：-XX:MetaspaceSize，初始空间大小，达到该值就会触发垃圾收集进行类型卸载，同时GC会对该值进行调整，如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize时，适当提高该值。-XX:MaxMetaspaceSize，最大空间，默认是没有限制的。除了上面两个指定大小的选项以外，还有两个与 GC 相关的属性：-XX:MinMetaspaceFreeRatio，在GC之后，最小的Metaspace剩余空间容量的百分比，减少为分配空间所导致的垃圾收集，-XX:MaxMetaspaceFreeRatio，在GC之后，最大的Metaspace剩余空间容量的百分比，减少为释放空间所导致的垃圾收集，具体验证代码如下：1234567891011// VM args: -XX:MetaspaceSize=4M -XX:MaxMetaspaceSize=4Mpublic class RuntimeConstantPoolOOM &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); int i = 0; while (true) &#123; list.add(String.valueOf(i++).intern()); &#125; &#125;&#125; 运行结果：12Error occurred during initialization of VMOutOfMemoryError: Metaspace 关于这个字符串常量池的实现问题，还真的会出现一个很意思的问题或者说是一个很奇怪的问题。代码如下：123456789101112131415// jdk:1.8public class RuntimeConstantPoolOOM &#123; public static void main(String[] args) &#123; String str1 = new StringBuilder("计算机").append("软件").toString(); System.out.println(str1.intern() == str1); String str2 = new StringBuilder("ja").append("va").toString(); System.out.println(str2.intern() == str2); String str3 = new StringBuilder("ma").append("in").toString(); System.out.println(str3.intern() == str3); &#125;&#125; 运行结果：123truefalsefalse jdk1.6中，intern()方法会把首次遇到的字符串实例复制在永久代，返回的也是永久代中这个字符串实例的引用，而由StringBuilder创建的字符串实例在Java堆上，所以必然不是同一个引用。而在jdk1.7及以后，intern()的实现不会再复制实例，只是在常量池中记录首次出现得实例的引用，因此intern()返回的由StringBuilder创建的那个字符串是同一个实例，而关于上面的运行结果，我想java和main之前都是在字符串常量池中都有他的引用了，所以返回的都是false。 方法区溢出方法区用于存放Class的相关信息，如类名，访问修饰符，常量池，字段描述，方法描述等，基本的思路是运行时产生大量的类去填充方法区，下面是借助CGLib（cglib和asm的依赖有个坑，选择cglib2.2,asm3.1亲测可用）来操作字节码运行时生成大量的动态类，这种场景在Spring，Hibernate中经常出现，需要多注意，本人使用的JDK1.8，所以测试的是方法区的变迁元空间，代码实现如下：123456789101112131415161718192021222324// VM args:-XX:MetaspaceSize=4M -XX:MaxMetaspaceSize=4Mpublic class JavaMethodAreaOOM &#123; public static void main(String[]args) &#123; while (true) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(OOMObject.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() &#123; public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; return methodProxy.invokeSuper(o, objects); &#125; &#125;); OOMObject oomObject = (OOMObject) enhancer.create(); oomObject.sayHi(); &#125; &#125; static class OOMObject&#123; public void sayHi()&#123; System.out.println("hi"); &#125; &#125;&#125; 结果输出：12Error occurred during initialization of VMOutOfMemoryError: Metaspace 这类异常经常出现在web应用中，需要多注意。 本机直接内存溢出DirectMemory容量可通过-XX:MaxDirectMemorySize指定，如果不指定，则默认与Java堆最大值（-Xmx指定）一样，在《深入理解Java虚拟机》中用了以下代码：1234567891011121314// VM args:-Xmx20M -XX:MaxDirectMemorySize=10Mpublic class DirectMemoryOOM &#123; private static final int _1MB = 1024*1024; public static void main(String[] args) throws Exception&#123; Field unsafeField = Unsafe.class.getDeclaredFields()[0]; unsafeField.setAccessible(true); Unsafe unsafe = (Unsafe) unsafeField.get(null); while (true) &#123; unsafe.allocateMemory(_1MB); &#125; &#125;&#125; 但是在自己电脑中没有运行成功，反而让自己的电脑死机了，这个地方还是没有弄懂？？？？？？，希望懂的大佬给我点支持。 这个异常在使用NIO中可能会出现，所以在使用的时候需要多注意。 总结在总结得过程中，知道了各个内存区域可能会出现OOM的情况，重要的是了解了方法区在jdk1.6到1.7到1.8的变迁，有兴趣的人可以深入了解。 参考 《深入理解Java虚拟机》 CGLIB介绍与原理 Java8内存模型—永久代(PermGen)和元空间(Metaspace) 深入探究JVM | 探秘Metaspace]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM_2_HotSpot对象揭秘]]></title>
    <url>%2F2017%2F11%2F21%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-2-HotSpot%E5%AF%B9%E8%B1%A1%E6%8F%AD%E7%A7%98%2F</url>
    <content type="text"><![CDATA[引：总有些人会思考对象是如果创建、如何布局、以及如何访问的？对于这些问题，我们必须把讨论范围限定在具体的虚拟机和集中在某一个内存区域才有意义。基于实用原则，我们以常用的虚拟机HotSpot和常用的内存区域Java堆为例。 对象的创建Java程序创建对象不过是一个new关键字而已，而在虚拟机中，创建了一个对象却经历了一系列过程。 虚拟机遇到一条new指令时，首先去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，如果没有就会抛出ClassNotFoundException，并且检查这个符号引用代表的类是否已被加载、解析和初始化过，如果没有，那必须先执行相应的类加载过程。 类加载检查通过后，虚拟机为新生对象分配内存，对象所需内存的大小在类加载完成后便可以完全确定。 这里有两种内存分配方式：（由采用的垃圾收集器是否带有压缩整理的功能决定） 指针碰撞 假设Java堆的内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离。 空闲列表 假如Java堆中的内存并不是完整的，已使用的内存和空闲的内存相互交错，虚拟机就必须维护一个列表，记录那些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给实例，并更新列表上的记录。 解决在并发情况下不安全的方案: 对分配内存空间的动作进行同步处理——虚拟机采用CAS配上失败重试的方式保证更新操作的原子性 把内存分配的动作按线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲，只有需要重新分配的时候才同步锁定 虚拟机将分配到的内存空间都初始化为零值（默认初始化），保证了对象实例在Java代码中可以不赋初始值就可以使用。 设置对象头 利用构造函数进行初始化 对象的内存布局对象头 存储对象自身的运行时数据（哈希码，GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等），官方称为“Mark Word”，它被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，他会根据对象的状态复用自己的存储空间，具体见《深入理解Java虚拟机》。 类型指针（可选）即对象指向它的元数据（方法区）的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例 数组长度（可选）如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通java对象元数据信息确定Java对象的大小，但是从数组数据无法确定数据大小 实例数据存储所有成员变量，无论是父类继承下来的，还是在子类定义的。 存储顺序会受到虚拟机分配策略参数和字段在源码定义的顺序的影响。HotSpot默认的分配策略为相同宽度的字段总是被分配到一起（如long和double），在这个前提下，父类先于子类，若CompactFields参数为true，那么子类之中较窄的变量也可能插入到父类变量的空隙中（是因为一个slot太大） 对齐填充（可选）起到占位符的作用，确保对象的长度为8字节的整数倍 HotSpot VM的自动内存管理系统要求对象起始位置必须是8字节的整数倍，由于对象头一定是8字节的整数倍，所以利用占位符可以达到数据部分也是8字节的整数倍。从而达到对象的长度是8字节的整数倍。（有点绕口啊，哈哈） 对象的访问定位我们通常都会使用Java对象，我们基本上都是通过虚拟机栈上的reference数据来操作堆上的具体对象，而栈上只是一个指向对象的引用，对象的具体访问方式取决于虚拟机，目前有以下两种访问方式： 通过句柄访问对象可以看下面的图：使用句柄访问，Java堆中会划分出一块内存来作为句柄池，reference存储的就是对象的句柄地址，而句柄包含了对象实例数据与类型数据各自的具体地址信息。 通过直接指针访问对象可以看下面的图：使用直接指针访问，Java堆对象的布局中就要考虑如何放置访问类型数据的相关信息，而reference中存储的直接就是对象地址。 两者对比 通过句柄访问对象可以当对象被移动之后只会改变句柄中的实例数据指针，而reference本身不需要改变。 使用直接指针访问可以加快Java对象的访问，HotSpot就是使用直接指针访问对象的方式。 总结这里讲的对象重点还是在虚拟机执行部分，关于Class文件的讲解没有涉及到，但它却是十分重要的，日后会提及。 参考 深入理解JVM(二)——揭开HotSpot对象创建的奥秘]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM_1_JVM内存区域]]></title>
    <url>%2F2017%2F11%2F20%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM-1-JVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[引：总是提到堆呀，栈呀，常量池呀，但是Java虚拟机内的Java模型却总是理解不清楚，这次就总结一下。 Java内存区域组成这里讲的是Java虚拟机在执行Java程序的过程中会把它所管理的内存划分五大区域。 程序计算器 Java虚拟机栈 本地方法栈 Java堆 方法区 下面也把来自深入理解Java虚拟机的图片贴一下： 接着我们重点理解一下这五大区域。 程序计数器什么是程序计数器 程序计数器是一块较小的内存空间，他可以看做当前线程所执行的字节码的行号指示器。 如果线程在执行一个Java方法的时候，这个计数器记录的是正在执行的虚拟机字节码指令地址，如果正在执行的是Native方法，这个计数器值则为空。 程序计数器的作用 单线程的时候：通过改变这个计数器的值来选取下一条需要执行的字节码指令，从而实现分支、循环、跳转、异常处理、线程回复等基础功能。 多线程的时候：当每个线程都有独立的程序计数器，则线程切换后就能回复到正确的执行位置。PS： Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的。 程序计数器的特点 存储空间较小 线程私有，每个线程都有一个程序计数器 唯一一个没有规定任何OutOfMemoryError情况的区域 生命周期与线程相同 Java虚拟机栈什么是Java虚拟机栈Java虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧用于存储局部变量表（包括基本数据类型，对象引用和returnAddress,其中long和double会占据2个局部变量空间，其他只占用一个）、操作数栈、动态链接、方法出口等信息。每个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。 Ps： 人们常说的Java内存区分为“堆”和“栈”，“堆”存放对象（可以），“栈”只是值其中的局部变量表（不可以），这是不正确的。 Java虚拟机栈的特点 线程私有，生命周期与线程相同 如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常 虚拟机栈可以动态扩展，也可以固定长度，在动态扩展的时候如果无法申请到足够的内存，就会抛出OutOfMemoryError异常 本地方法栈什么是本地方法栈本地方法栈描述的是本地方法执行的内存模型，它发挥的作用与虚拟机栈发挥的作用是非常相似的，如Sun HotSpot虚拟机直接把本地方法栈和虚拟机栈合二为一，它与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 Java堆什么是Java堆 Java堆是存放对象实例的内存区域 几乎所有对象实例都在这里分配内存 Java堆的特点 Java虚拟机管理的内存中最大的一块 线程共享，在虚拟机启动时创建 垃圾收集器管理的主要区域，从内存回收的角度来看，由于现在收集器都采用分代收集算法，所以可分为新生代和老年代，再细致一点可以分为Eden空间、From Survivor空间和To Survivor空间等。从内存分配来看，线程共享的Java堆可能划分出多个线程私有的分配缓存区TLAB,进一步划分的目的是为了更好地回收内存，或者更快的分配内存 实现中可以固定大小，也可以是可扩展的，如果在堆中没有内存完成实例的分配，并且堆也无法再扩展时，就会抛出OutOfMemoryError异常 方法区什么是方法区 Java虚拟机规范把方法区描述为堆的一个逻辑部分。 他用于存储被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码 方法区的特点 线程共享，在虚拟机启动时创建 永久代是因为HotSpot选择将GC分代收集器扩展到方法区，或者使用永久代来实现方法区，对于HotSpot官方发布的路线图信息，现在也有放弃永久代逐步采用Native Memory来实现方法区的规划了，并且已经把原本放在永久代的字符串常量池移除 不需要连续的内存，可以选择固定大小或者可扩展，还可以选择不实现垃圾回收 内存回收的主要目标主要是针对常量池的回收和对类型的卸载，但是回收效率低 当方法区无法满足内存分配的需求的时候，将抛出OutOfMemoryError的异常 运行时常量池 Class文件除了包含类的版本字段、方法、接口等描述信息外，还有一项信息是常量池 常量池用于存放编译期间生成的各种字面量和符号引用，这部分内容在类加载后进入运行时常量池中存放 运行时常量池相对于Class文件常量池具有动态性，Java语言不要求只有Class文件中的常量池的内容才能进入运行时常量池，运行时也可能将新的常量放入池中，如String类的intern方法 当常量池无法再申请内存时将会抛出OutOfMemoryError异常 PS： jdk1.7的常量池移到了堆中，同时在jdk1.8中移除整个永久代，取而代之的是一个叫元空间（Metaspace）的区域 直接内存 通过一个存储在Java堆中的DirectByteBuffer对象最为这块内存的引用进行操作，这个可以显著提高性能，因为避免了在Java堆和Native堆中来回复制数据 案例是NIO类引入一种基于通道与缓存区的I/O方式，它可以使用Native函数库直接分配对外内存，然后通过DirectByteBuffer进行操作 本机直接内存的分配不会受到Java堆大小的限制，但是会受到本机总内存大小和处理器寻址空间的限制，也可能会抛出OutOfMemoryError异常 总结本篇文章是参考《深入理解Java虚拟机》第二版所写，当时作者用的是jdk1.7，结果现在jdk1.9都出了，最大的改变就是方法区了，目前还没有能力改正，也就将就了，望作者早日更新，或者自己成为大牛，将这部分重新整理。 参考 深入理解JVM(一)——JVM内存模型 Java 8: 从永久代（PermGen）到元空间（Metaspace）]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot静态资源的处理]]></title>
    <url>%2F2017%2F10%2F20%2F%E7%BC%96%E7%A8%8B%2Fspringboot%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E7%9A%84%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[引：由于springboot架构遇到了图片的上传处理，以及之后的前台显示，所以就理解了一下其中关于静态资源的处理。 默认的静态资源处理在每次启动springboot的项目的时候，我们都可以在控制台看见下面的语句输出：1232017-10-20 16:06:50.540 INFO 36443 --- [ restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2017-10-20 16:06:50.540 INFO 36443 --- [ restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2017-10-20 16:06:50.569 INFO 36443 --- [ restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler] 这里面就用到了springboot默认的静态资源处理。 其中默认配置的/**映射到/static（或/public、/resources、/META-INF/resources） 其中默认配置的/webjars/**映射到classpath:/META-INF/resources/webjars/ PS：上面的 static、public、resources 等目录都在 classpath: 下面（如 src/main/resources/static） 在访问静态资源的时候，这些目录也会有一个查找顺序（优先级）：这里测试过发现他们的优先级是：META/resources &gt; resources &gt; static &gt; public 自定义静态资源处理配置方式 通过配置文件（application.properties）配置1234# 默认值为 /**spring.mvc.static-path-pattern=# 默认值为 classpath:/META-INF/resources/,classpath:/resources/,classpath:/static/,classpath:/public/ spring.resources.static-locations=这里设置要指向的路径，多个使用英文逗号隔开， 当我们要设置成我们的目录：/myresource/**，我们需要这样设置:12spring.mvc.static-path-pattern=/**spring.resources.static-locations=classpath:/META-INF/resources/,classpath:/resources/,classpath:/static/,classpath:/public/,classpath:/myresource/ 当我们设置过映射路径时候，如果还是/**,那么默认的映射就失效了，我们需要重新把原来的路径也添加上。这里的配置路径只可以设置一个。 通过配置类配置12345678@Configurationpublic class MyWebAppConfigurer extends WebMvcConfigurerAdapter&#123; @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler("/myresource/**").addResourceLocations("file:/var/alldata/image/"); super.addResourceHandlers(registry); &#125;&#125; 可以通过这个方式设置多个配置路径。 配置内外目录 内部目录 做法是添加映射路径 classpath:/路径 方式见通过配置文件配置 外部目录 想一想如果将上传的图片继续存在jar包中会有那些问题？ 网络数据与程序代码不能分离 数据传到jar里速度慢 数据备份麻烦 有了以上的考虑我们会想到将上传的数据放在磁盘的目录上。 做法是添加映射路径 file:/var/alldata/images 方式见通过配置类配置 总结springboot倡导的是习惯优于配置，大部分时候我们用他默认的配置就好了，但是他也提供了方便的配置类，需要我们好好学习。 参考 Spring Boot 静态资源处理 Springboot 之 静态资源路径配置]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac中环境变量的配置]]></title>
    <url>%2F2017%2F09%2F21%2F%E5%B7%A5%E5%85%B7%2Fmac%E4%B8%AD%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E7%9A%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[引：在使用ubuntu和mac这么久之后，环境变量的几个文件还弄不清楚，真是汗颜，这里记录一下，下次不会乱改。 环境变量的作用 使用场景在命令行直接通过命令执行程序，这些程序就多了，最常见就有java，npm，maven，git,如果我们不配置环境变量的话，就需要到程序的安装目录去执行相关命令，大家都会感觉超级麻烦，加入要使用多个程序的话，要么去切换目录，要么就多开几个命令行窗口。顿时就会感觉超级无奈有么有？ 具体作用配置完程序的环境变量之后就可以无所欲为了，可以在任何目录下直接执行我们所要的程序了，是不是顿时感觉方便许多，基本上所有人都知道吧。 环境变量的配置单次环境变量配置假如你出了个意外，在命令行中突然不能使用各种命令了，也没事，至少接下来可以让你短暂的使用一些命令，命令行窗口关闭之后就失效了，我们要做的只是直接在命令行中输入： export PATH=/usr/bin:/usr/sbin:/bin:/sbin 当然后面你也能够添加一些你自己想要使用的程序命令。 环境变量文件配置 环境变量的写法 export PATH=$JAVA_HOME/bin:$PATH 环境变量文件优先级 /etc/profile /etc/bashrc /etc/paths ~/.bash_profile ~/.bash_login ~/.profile ~/.bashrc其实后三个文件我也没怎么看到过，主要讲一下前面三个 环境变量文件详解 /etc/profile：全局配置文件，不管是哪一个用户登录，都会读取该文件（但是超级不建议修改，容易出现大问题，想试试什么大问题，自己体会） /etc/bashrc 全局配置文件，bash shell执行时，不管是何种方式，都会读取此文件（一般在这个文件中添加系统级环境变量） ~/.bash_profile：每个用户都可使用该文件输入专用于自己使用的shell信息,当用户登录时,该文件仅仅执行一次!（一般在这个文件中添加用户级环境变量） 立即生效环境变量配置 source ~/.bash_profile 软连接自己一开始也会特别的惊讶，自己在mac上没有设置环境变量有的时候也可以直接就访问到了某些文件。这个是为什么呢？答案是用了软连接。 查看加载文件rexdeMacBook-Pro:etc rex$ cat /etc/paths /usr/local/bin /usr/bin /bin /usr/sbin /sbin 然后就可以去看这些文件夹下面的东西了，弄不清楚也没关系，其实就是软链接。开机后，mac会自动加载paths文件下面的这些目录。在这些文件夹下面建立软连接，可以达到同样的效果（日后学习）。 软连接查看在拥有软连接的目录下使用下面命令 ls -li 406876 lrwxr-xr-x 1 root wheel 73 7 9 2016 jar -&gt; /System/Library/Frameworks/JavaVM.framework/Versions/Current/Commands/jar 406877 lrwxr-xr-x 1 root wheel 79 7 9 2016 jarsigner -&gt; /System/Library/Frameworks/JavaVM.framework/Versions/Current/Commands/jarsigner 406878 lrwxr-xr-x 1 root wheel 74 7 9 2016 java -&gt; /System/Library/Frameworks/JavaVM.framework/Versions/Current/Commands/java 406879 lrwxr-xr-x 1 root wheel 75 7 9 2016 javac -&gt; /System/Library/Frameworks/JavaVM.framework/Versions/Current/Commands/javac 406880 lrwxr-xr-x 1 root wheel 77 7 9 2016 javadoc -&gt; /System/Library/Frameworks/JavaVM.framework/Versions/Current/Commands/javadoc 建立软连接等自己看了linux的相关知识再来说吧。 总结希望下次自己再也不要因为环境变量配置错出各种问题了，thanks god！ 参考：Mac 中环境变量的配置和理解]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>环境变量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github Pages+Hexo SEO引擎优化]]></title>
    <url>%2F2017%2F07%2F16%2F%E5%B7%A5%E5%85%B7%2FGithub-Pages-Hexo-SEO%E5%BC%95%E6%93%8E%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[引：写的博客自然想让人看到，但是但是自己为了想独立管理（冠冕堂皇）选择了GIthub Pages+Hexo来搭建自己的博客，结果发现自己的博客在百度，谷歌都无法搜到，那时候我才知道自己缺少了SEO。 百度优化登录百度站长 在里面我们可以发现各种向百度提交的方法，这一切都是为了让百度的爬虫更好的爬取我们的网页。 通过baidumapsite.xml自动提交 这里推荐一个博文：Hexo NexT 主题SEO优化指南 通过主动提交 这里推荐一个自动化工具：exo插件之百度主动提交链接 谷歌优化登录谷歌站长 通过map.site自动提交 这里面推荐一个博文：生成sitemap站点地图 总结自己在谷歌配置是成功的，但是在百度并没有成功，可能是因为github真的把百度给干了。自己还是等开学转到自己的服务器上吧。慢慢SEO！！！！ PS:Hexo博客的搭建的可以参考这一篇 搭建Hexo博客中碰到的坑]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>seo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[新系统开发环境的一系列配置]]></title>
    <url>%2F2017%2F07%2F15%2F%E7%94%9F%E6%B4%BB%2F%E6%96%B0%E7%B3%BB%E7%BB%9F%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E7%9A%84%E4%B8%80%E7%B3%BB%E5%88%97%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[引：总是不可避免的重装系统，人的脑子不可能那么好记住所有的操作，既然不想自己自己用博客记下所有操作，那么就把别人的博客（自己踩过）记录下来，以后备用。 window篇 JDK——java开发者起步 JDK的安装与环境变量的配置 Node——前端好基友 Node.js安装及环境配置之Windows篇 Sublime3——轻量级编辑器 Sublime Text3安装与插件配置 git——分布式版本控制工具 Git安装教程 Idea——java开发利器 IntelliJ IDEA注册码 Maven——项目依赖管理利器 Maven Windows10安装 Mac篇待写 Ubuntu篇待写 双系统Win10和Ubuntu16.04双系统安装详解]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅尝Apache Camel]]></title>
    <url>%2F2017%2F07%2F15%2F%E7%BC%96%E7%A8%8B%2F%E6%B5%85%E5%B0%9DApache-Camel%2F</url>
    <content type="text"><![CDATA[引：最近项目有一个需求就是定时将一台服务器的文件传到另一个服务器，一开始想的竟然想的是用http去下载，后来在万老师的指点下，采取用ftp服务器（源文件所在地）与ftp客户端（源文件去向）的形式来处理，自己小试了一下，还不错！ Apache Camel简介Apache Camel是Apache基金会下的一个开源项目,它是一个基于规则路由和处理的引擎，提供企业集成模式的Java对象的实现，通过应用程序接口 或称为陈述式的Java领域特定语言(DSL)来配置路由和处理的规则。其核心的思想就是从一个from源头得到数据,通过processor处理,再发到一个to目的的。 这个from和to可以是我们在项目集成中经常碰到的类型:一个FTP文件夹中的文件,一个MQ的queue（jms）,一个HTTP request/response,一个webservice等等. Apache Camel架构 其实理解起来很简单：始端》（过滤器+路由处理器）》终端 Apache Camel核心概念 endpoint,所谓的endpoint,就是一种可以接收或发送数据的组件。可以支持多种协议，如jms,http,file等。 processor,它是用来处理具体业务逻辑的组件。 route,用来路由，指示数据从哪里来到哪里去，中间用哪个processor处理。 exchange,processor之间用exchange对象来传送数据，有点像jms,通俗一点就像上学时传的小纸条,所以：exchange对象就是processor，endpoint所有camel组件之间传送数据的小纸条:)。 filter，用来确定哪些东西可以传递，哪些东西不可以传递。 Apache Camel例子（以ftp为例）老师指导的例子，是结合Springboot的，放在github上了。ApacheCamleDemo 里面包括了动态路由和单路由的例子，稍微结合Springboot就可以理解并改成自己的代码。 什么时候用Apache Camel参考网上的说法：camel就是企业信息集成框架，它提供了很多简单好用而又强大的组件，用户可以根据场景来选择不同的EIP（企业集成模式）来实现自己的需求，以响应快速变化的业务。可以把它当成企业信息总线（ESB）的轻量级实现。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>ApacheCamel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java ftp 上传下载的坑]]></title>
    <url>%2F2017%2F07%2F15%2F%E7%BC%96%E7%A8%8B%2Fjava-ftp-%E4%B8%8A%E4%BC%A0%E4%B8%8B%E8%BD%BD%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[引：还是项目需要，要定时执行一个文件下载业务，一开始方向有点错，但是还好纠正过来了，采用ftp下载，但是ftp下载也有各种坑！ 准备jar包：commons-net ftp上传程序：1234567891011121314151617181920212223242526272829303132333435363738public static boolean uploadFile( String url,//服务器主机号 int port,//服务器端口 String username,//用户名 String password,//密码 String path, //上传路径Mar String filename,//上传为服务器上的文件名 InputStream //input本地上传的文件流) &#123; boolean success = false; FTPClient ftp = new FTPClient(); try &#123; int reply;MarkDown ftp.connect(url, port);//连接FTP服务器 //如果采用默认端口，可以使用ftp.connect(url)的方式直接连接FTP服务器 ftp.login(username, password);//登录 reply = ftp.getReplyCode(); if (!FTPReply.isPositiveCompletion(reply)) &#123; ftp.disconnect(); return success; &#125; ftp.changeWorkingDirectory(path); ftp.storeFile(filename, input); input.close(); ftp.logout(); success = true; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (ftp.isConnected()) &#123; try &#123; ftp.disconnect(); &#125; catch (IOException ioe) &#123; &#125; &#125; &#125; return success;&#125; 测试代码：123File file = new File(&quot;/var/test.txt&quot;);InputStream is = new FileInputStream(file);uploadFile(&quot;127.0.0.1&quot;,21,&quot;test&quot;,&quot;123456&quot;,&quot;/var/data/test&quot;,&quot;testdemo.txt&quot;,is); ftp下载程序：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public static boolean downFile(String url, //FTP服务器hostnameint port,//FTP服务器端口String username, //FTP登录账号String password, //FTP登录密码String remotePath,//FTP服务器上的相对路径String fileName,//要下载文件关键字String localPath//下载后保存到本地的路径) &#123; FTPClient ftpClient = null; boolean success = false; try &#123; ftpClient = new FTPClient(); ftpClient.connect(url, port);// 连接FTP服务器 ftpClient.login(username, password);// 登陆FTP服务器 ftpClient.setControlEncoding("gb2312"); // 中文支持 ftpClient.setFileType(FTPClient.BINARY_FILE_TYPE);//设置文件格式 ftpClient.enterLocalPassiveMode(); logger.info(ftpClient.getReplyCode()); if (!FTPReply.isPositiveCompletion(ftpClient.getReplyCode())) &#123; logger.warn("未连接到FTP，用户名或密码错误。"); ftpClient.disconnect(); &#125; else &#123; logger.info("FTP连接成功。"); &#125; ftpClient.changeWorkingDirectory(remotePath); FTPFile[] fs = ftpClient.listFiles(); File file = new File(localPath); if(!file.exists())&#123; file.mkdirs(); &#125; for(FTPFile ff:fs)&#123; if(ff.getName().contains(fileName))&#123; File localFile = new File(localPath+"/"+ff.getName()); if (localFile.exists())&#123; continue; &#125; OutputStream os = new FileOutputStream(localFile); long time1 = System.currentTimeMillis(); boolean b = ftpClient.retrieveFile(new String(ff.getName().getBytes("gb2312"),"ISO8859-1"), os); os.flush(); os.close(); &#125; &#125; ftpClient.logout(); success = true; &#125; catch (SocketException e) &#123; e.printStackTrace(); logger.warn("FTP的IP地址可能错误，请正确配置。"); &#125; catch (IOException e) &#123; e.printStackTrace(); logger.warn("FTP的端口错误,请正确配置。"); &#125; finally &#123; if (ftpClient.isConnected()) &#123; try &#123; ftpClient.disconnect(); &#125; catch (IOException ioe) &#123; &#125; &#125; &#125; return success;&#125; 测试程序：1downFile(&quot;127.0.0.1&quot;,21,&quot;test&quot;,&quot;123456&quot;,&quot;、var/data/test&quot;,&quot;demo&quot;,&quot;/var/alldata&quot;); 一些坑 客户端接受的编码 1ftpClient.setControlEncoding(&quot;gb2312&quot;); // 中文支持 如果服务器上的文件名有中文，一定要加上这一句，具体编码要根据服务器的编码。 客户端接受的文件类型 1ftpClient.setFileType(FTPClient.BINARY_FILE_TYPE);//设置文件格式 文件类型要根据下载的文件格式来定 服务器端口设置 1ftpClient.enterLocalPassiveMode(); 调用FTPClient.enterLocalPassiveMode();这个方法的意思就是每次数据连接之前，ftp client告诉ftp server开通一个端口来传输数据，防止在新端口对外部不通，因为ftp server可能每次开启不同的端口来传输数据，但是在linux上，由于安全限制，可能某些端口没有开启，所以就出现阻塞。 最大的坑（下载出0kb的文件：实质就是retrieveFile方法执行失败） 1ftpClient.retrieveFile(new String(ff.getName().getBytes(&quot;gb2312&quot;),&quot;ISO8859-1&quot;), os) 一定要给文件名换编码，让它识别中文，具体编码也是根据实际情况而定。 总结ftp客户端的速度也是要根据网速来的，可能比一般http快，但是面对网速慢的情况也是无可奈何！]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>ftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[js原型和原型链]]></title>
    <url>%2F2017%2F07%2F13%2F%E7%BC%96%E7%A8%8B%2Fjs%E5%8E%9F%E5%9E%8B%E5%92%8C%E5%8E%9F%E5%9E%8B%E9%93%BE%2F</url>
    <content type="text"><![CDATA[引：刚刚说了闭包，那就不放过js的另一大难点了——js原型以及原型链。 谈谈神图镇楼：自己写了好几遍内容，但是自己发现还是不能系统的理解，自己也写不了多好，看来要到自己安心写前端的时候，再来补上了。 参考 最详尽的 JS 原型与原型链终极详解（一） 最详尽的 JS 原型与原型链终极详解（二） 最详尽的 JS 原型与原型链终极详解（三） 个人感觉上面的文章还不错，可能还缺了继承那块的讲解，等自己再来的时候一起补上吧！！！！]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>原型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈js闭包]]></title>
    <url>%2F2017%2F07%2F12%2F%E7%BC%96%E7%A8%8B%2F%E6%B5%85%E8%B0%88js%E9%97%AD%E5%8C%85%2F</url>
    <content type="text"><![CDATA[引：最近项目前端用了angular2，里面使用的TypeScript,其实很多和Java挺像的，学起来还是挺快的。但是里面的很多变量的原理都是根据闭包来实现的，那就好好了解一下闭包。 闭包定义根据Mozilla开发者文档定义： 闭包是指向独立变量的“函数”,用通俗的话说就是会“记住”它创建时的环境。 闭包涉及的主要概念 作用域链 作用域链是函数在定义的时候创建的,用于寻找使用到的变量的值的一个索引。它内部的规则是,把函数自身的本地变量放在最前面,把自身的父级函数中的变量放在其次,把再高一级函数中的变量放在更后面,以此类推直至全局对象为止.当函数中需要查询一个变量的值的时候,js解释器会去作用域链去查找,从最前面的本地变量中先找,如果没有找到对应的变量,则到下一级的链上找,一旦找到了变量,则不再继续.如果找到最后也没找到需要的变量,则解释器返回undefined. 内存回收机制 一个函数在执行开始的时候,会给其中定义的变量划分内存空间保存,以备后面的语句所用,等到函数执行完毕返回了,这些变量就被认为是无用的了.对应的内存空间也就被回收了.下次再执行此函数的时候,所有的变量又回到最初的状态,重新赋值使用.但是如果这个函数内部又嵌套了另一个函数,而这个函数是有可能在外部被调用到的.并且这个内部函数又使用了外部函数的某些变量的话.这种内存回收机制就会出现问题.如果在外部函数返回后,又直接调用了内部函数,那么内部函数就无法读取到他所需要的外部函数中变量的值了.所以js解释器在遇到函数定义的时候,会自动把函数和他可能使用的变量(包括本地变量和父级和祖先级函数的变量(自由变量))一起保存起来.也就是构建一个闭包,这些变量将不会被内存回收器所回收,只有当内部的函数不可能被调用以后(例如被删除了,或者没有了指针),才会销毁这个闭包,而没有任何一个闭包引用的变量才会被下一次内存回收启动时所回收. 闭包现象123456789var results = [];for (var i = 0; i &lt;3; i++) &#123;results[i] = function() &#123;console.log(i);&#125;&#125;results[0](); //3results[1](); //3results[2](); //3 解析：其实这里return出来的是一个function（我们可以理解为他是一个字符串，还没有执行），等到我们去执行他的时候，只保存了他上一级的作用域链里面的i的索引,那个时候i已经是3了。 闭包解决让内部函数在循环创建的时候立即执行,并且捕捉当前的索引值,然后记录在自己的一个本地变量里.然后利用返回函数的方法,重写内部函数,让下一次调用的时候,返回本地变量的值,改进后的代码:1234567891011var results = [];for (var i = 0; i &lt;3; i++) &#123;results[i] = (function(j) &#123;return function()&#123;console.log(j);&#125;&#125;)(i);&#125;results[0](); //0results[1](); //1results[2](); //2 我们发现通过立即执行表达式就可以解决闭包的现象得到我们想要得到的现象。 闭包应用闭包与静态变量前面就说TypeScript与Java很像，所以类中的静态变量也是有的。 TypeScript代码：12345678910111213141516class Counter &#123;private static COUNTER = 0;constructor() &#123;&#125;private changeBy(val) &#123;Counter.COUNTER +=val;&#125;public increment() &#123;this.changeBy(1);&#125;public decrement() &#123;this.changeBy(-1);&#125;public value() &#123;return Counter.COUNTER;&#125;&#125; 编译之后的js代码:123456789101112131415161718var Counter = (function () &#123;function Counter() &#123;&#125;Counter.prototype.changeBy = function (val) &#123;Counter.COUNTER += val;&#125;;Counter.prototype.increment = function () &#123;this.changeBy(1);&#125;;Counter.prototype.decrement = function () &#123;this.changeBy(-1);&#125;;Counter.prototype.value = function () &#123;return Counter.COUNTER;&#125;;Counter.COUNTER = 0;return Counter;&#125;()); 从js代码可以看书静态变量COUNTER是属于Counter类的，并不属于对象原型。所有Counter实例都共享Counter的同一个闭包上下文环境（COUNTER）。所以COUNTER会表现像单例一样。 闭包和私有成员TypeScript由于性能原因并没有使用闭包来模拟私有变量，他使用过编译检查机制来形成私有变量的特性。但是我们可以使用闭包来实现私有变量。 js代码如下：123456789101112131415161718function makeCounter() &#123;var COUNTERR = 0;function Counter() &#123;&#125;function changeBy(val) &#123;COUNTER += val;&#125;;Counter.prototype.increment = function () &#123;this.changeBy(1);&#125;;Counter.prototype.decrement = function () &#123;this.changeBy(-1);&#125;;Counter.prototype.value = function () &#123;return COUNTER;&#125;;return new Counter();&#125;; 从上面的代码可以看出，每一个新的makeCounter实例都拥有自己的上下文环境，其他实例访问不了。 总结学习这么久的js发现，其实闭包真的无处不在，需要好好学习，好好总结，如有不对，也希望大家能够指出。 参考链接：js中闭包原理谈和原型及例子 书籍：Learning TypeScript中文版]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>闭包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java日志那些事]]></title>
    <url>%2F2017%2F07%2F12%2F%E7%BC%96%E7%A8%8B%2FJava%E6%97%A5%E5%BF%97%E9%82%A3%E4%BA%9B%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[引：一直都知道日志文件很重要，可以记录一些相关信息，但是可能是程序需要调试的内容太少，也或者是项目太小，所以看看控制台的信息就够了，但是这次接触的项目越来越大，控制台额信息越来越多，经常会看不到自己想要看到的信息时，这个时候使用日志就发现十分得有必要了！ 日志的好处 方便调试(如上) 方便发现系统运行中的错误 存储业务数据，便于日后分析 日志实现方式 自己实现类通过io存储到文件中 使用log4j将日志输入到控制台，文本文件，一集数据库中。 使用jdk自带的logging.jar包中方法（同一作者还有lognback） 使用slfj，它提供了上述两种方法的接口。 日志的输出(以log4j为例) 输入到控制台 运行程序：1234567891011public class LoggerTest &#123;public static Logger logger1 = Logger.getLogger(LoggerTest.class);public static void main(String[] args) &#123;logger1.trace(&quot;我是logger1，trace&quot;);logger1.debug(&quot;我是logger1，debug&quot;);logger1.info(&quot;我是logger1，info&quot;);logger1.warn(&quot;我是logger1，warn&quot;);logger1.error(&quot;我是logger1，error&quot;);logger1.fatal(&quot;我是logger1，fatal&quot;);&#125;&#125; 配置文件如下：123456789### 设置级别和目的地(这里多个目的地) ###log4j.rootLogger = DEBUG,CONSOLE### 这里的com.todorex是包，也就是在这个包记录日志时，是只记录debug及以上级别的日志log4j.logger.com.todorex=DEBUG### 输出到控制台 ###log4j.appender.CONSOLE = org.apache.log4j.ConsoleAppenderlog4j.appender.CONSOLE.Target = System.outlog4j.appender.CONSOLE.layout = org.apache.log4j.PatternLayoutlog4j.appender.CONSOLE.layout.ConversionPattern = %d&#123;ABSOLUTE&#125; %5p %c&#123;1&#125;:%L - %m%n 控制台输出:1234511:35:09,969 DEBUG LoggerTest:12 [main:0]- 我是logger1，debug11:35:09,972 INFO LoggerTest:13 [main:3]- 我是logger1，info11:35:09,972 WARN LoggerTest:14 [main:3]- 我是logger1，warn11:35:09,972 ERROR LoggerTest:15 [main:3]- 我是logger1，error11:35:09,972 FATAL LoggerTest:16 [main:3]- 我是logger1，fatal 输入到日志文件运行程序同上；配置文件如下：1234567891011121314151617181920### 设置级别和目的地(这里可以多个目的地) ###log4j.rootLogger = trace,demoLoglog4j.logger.com.todorex=DEBUG### 输出到控制台 ###log4j.appender.CONSOLE = org.apache.log4j.ConsoleAppenderlog4j.appender.CONSOLE.Target = System.outlog4j.appender.CONSOLE.layout = org.apache.log4j.PatternLayoutlog4j.appender.CONSOLE.layout.ConversionPattern = %d&#123;ABSOLUTE&#125; %5p %c&#123;1&#125;:%L [%t:%r]- %m%n### 输出到日志文件（文件目录一定要是绝对路径且存在） ###log4j.appender.demoLog = org.apache.log4j.DailyRollingFileAppenderlog4j.appender.demoLog.File =/var/alldata/mylog.loglog4j.appender.demoLog.Append = true## 只输出DEBUG级别以上的日志log4j.appender.demoLog.Threshold = DEBUG#&apos;.&apos;yyyy-MM-dd: 每天产生一个新的文件log4j.appender.demoLog.DatePattern = &apos;.&apos;yyyy-MM-ddlog4j.appender.demoLog.layout = org.apache.log4j.PatternLayoutlog4j.appender.demoLog.layout.ConversionPattern = %-d&#123;yyyy-MM-dd HH:mm:ss&#125; [%t:%r] - [%p] [%c&#123;1&#125;:%L] [%M] %m%n 文件内容同控制台输出，但是却比控制台清楚得多，不会被乱七八糟的信息给遮盖。 输入到数据库 运行程序:1234567public class LoggerTest &#123;public static void main(String[] args) &#123;Logger logger = Logger.getLogger(LoggerTest.class);logger.info(&quot;good&quot;);logger.debug(&quot;success&quot;);&#125;&#125; 配置文件：1234567891011log4j.rootLogger=trace,CONSOLE,demoLog# com.todorex包下面所有的日志输出的级别设为DEBUGlog4j.logger.com.todorex=DEBUG# 数据库输出log4j.appender.demoLog=org.apache.log4j.jdbc.JDBCAppenderlog4j.appender.demoLog.driver=com.mysql.jdbc.Driverlog4j.appender.demoLog.URL=jdbc:mysql://127.0.0.1:3306/testlog4j.appender.demoLog.user=rootlog4j.appender.demoLog.password=root# 在数据库对应的位置建一个对应的log表log4j.appender.demoLog.sql=insert into log(level,category,thread,time,location,note) values(&apos;%p&apos;,&apos;%c&apos;,&apos;%t&apos;,&apos;%d&#123;yyyy-MM-dd HH:mm:ss:SSS&#125;&apos;,&apos;%l&apos;,&apos;%m&apos;) 数据库的具体内容就不贴出来了，和普通看到的一样。 总结其实日志用几次就知道它的好了，自己也是在慢慢学习！]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jpa实体映射关系]]></title>
    <url>%2F2017%2F06%2F15%2F%E7%BC%96%E7%A8%8B%2Fjpa%E5%AE%9E%E4%BD%93%E6%98%A0%E5%B0%84%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[引：其实距离自己上次写数据库操作已经1个多月了，之前接触的就是Hibernate，这次接触jpa，就把几种对应关系理清。 映射策略注：这次举的例子都是User和Car的 外键关联简介：两个表的关系定义在其中一个表中 @OneToOne方法一：123@OneToOne(cascade=CascadeType.ALL, fetch=FetchType.EAGER)@JoinColumn(name = "user_id")private Car car; 通过在Car表中加入一个外键，实现两者关系。方法二：12@OneToOne(cascade = CascadeType.ALL,fetch = FetchType.EAGER,mappedBy = "Car")private User user; 通过在Car类中用MappedBy声明让User进行维护。 @OneToMany123@OneToMany(cascade=CascadeType.ALL, fetch=FetchType.EAGER)@JoinColumn(name = "user_id")private Set&lt;Car&gt; cars; 通过在Car表中加入一个外键，实现一对多关系。 @ManyToMany12@OneToMany(cascade=CascadeType.ALL, fetch=FetchType.EAGER)private Set&lt;Car&gt; cars; 这个是采用默认的表关联 表关联简介：两个表的关系通过一张中间表来来关联 @OneToMany12345@OneToMany(cascade=CascadeType.ALL, fetch=FetchType.EAGER)@JoinTable(name = "user_car",joinColumns=&#123;@JoinColumn(name = "user_id")&#125;,inverseJoinColumns = &#123;@JoinColumn(name = "car_id")&#125;)private Set&lt;Car&gt; cars; 通过JoinTable来确定一张中间表，joinColumns里面放父表的属性，inverseJoinColumns放子表的属性 @ManyToMany12345@ManyToMany(cascade=CascadeType.ALL, fetch=FetchType.EAGER)@JoinTable(name = "user_car",joinColumns=&#123;@JoinColumn(name = "user_id")&#125;,inverseJoinColumns = &#123;@JoinColumn(name = "car_id")&#125;)private Set&lt;Car&gt; cars; 解释如@OneToMany 一些属性cascade属性 CascadeType.PERSIST：级联新建 CascadeType.REMOVE：级联删除 CascadeType.REFRESH：级联刷新 CascadeType.MERGE：级联更新 CascadeType.ALL：包括上面四项 fetch属性 FetchType.EAGER：相当于禁用懒加载，推荐开发使用 FetchType.LAZY：懒加载，默认值，推荐部署使用 总结父表是提供主键的，子表是利用父表的主键来设置外键的，维护方是Owner，被维护方是Owned。提示自己一个傻逼的问题，插入数据要先往两张表中插入数据，在往中间表插入数据，不然会报错~]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>sping</tag>
        <tag>jpa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot项目调试angular2]]></title>
    <url>%2F2017%2F06%2F01%2F%E7%BC%96%E7%A8%8B%2Fspringboot%E9%A1%B9%E7%9B%AE%E8%B0%83%E8%AF%95angular2%2F</url>
    <content type="text"><![CDATA[引：在接触 springboot和angular2的前后端项目的时候，我发现自己会先把angular2的项目编译好之后放在springboot的resource目录下的static文件夹下运行，虽然这样可以，但是对于前端来调试代码实在不方便。在百度网上的方法之后可以采用如下代理的方式。 问题 angular2启动的服务默认为http://localhost:4200 springboot启动的服务默认为http://localhost:8080 如果我们直接设置angular2访问的路径为http://localhost:8080就会出现跨域访问的问题。请求不到数据。 解决在angular2项目的根目录下面新建一个proxy.config.json123456&#123;&quot;/api&quot;: &#123;&quot;target&quot;: &quot;http://localhost:8081&quot;,&quot;secure&quot;: false&#125;&#125; 然后在启动项目的时候采用下面的命令 ng serve –proxy-config proxy.config.json 通过这样的代理访问就能能够实现跨域访问请求数据。 总结通过上面的方法方便了开发调试，不错，终于要开始写代码了！]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>angular2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Angular2入门]]></title>
    <url>%2F2017%2F05%2F24%2F%E7%BC%96%E7%A8%8B%2FAngular2%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[引：由于老师暑假的项目前端代码需要用到Angular2，作为一个后端开发者也是需要了解一丢丢的。 Angular简介在经过简单的了解与使用之后，感觉 到Angular2的强大与伟大，配的上说是一个优秀的前端框架。Angular2实现了前端一直提倡的组件化开发还解决了大部分项目路由混乱的问题。它还有具有MVC分层架构和依赖注入等一系列优秀的特性。现在贴上Angular2的一张架构图：上图描述了Angular2中8大主要构造块的关系，他们具体的理解，可以参考这篇博文。如果还有什么不理解，那我们可以相信实践见真知。 Angular起步在这次学习中，我终于理解了前辈们所说的入门一门技术就好的方法就是去看官方文档了，Angular2的官网文档里面有中文版的，相信大家一定很开心吧。当然没有中文版也是要看的，比较都是最基础的入门，不要惧怕英文。 在这次按照官方文档的教程（英雄编辑器）出现了两个问题，这里也说明一下：1. angular-in-memory-web-apia模块不存在 解决方法：通过命令行安装 npm i angular-in-memory-web-api 2.1234567create(name: string): Promise&lt;Hero&gt; &#123;return this.http.post(this.heroesUrl, JSON.stringify(&#123;name: name&#125;), this.headers).toPromise().then(res =&gt; res.json().data as Hero).catch(this.handleError);&#125; 这里的post方法中的第三个参数应该是this.headers,而不是像官方文档中的那样。 总结如果遇到不懂得问候多看看文档吧，相信自己可以的，然后就是实践见真知了。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
        <tag>Angular2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简谈entity，model，domain]]></title>
    <url>%2F2017%2F05%2F23%2F%E7%BC%96%E7%A8%8B%2F%E7%AE%80%E8%B0%88entity%EF%BC%8Cmodel%EF%BC%8Cdomain%2F</url>
    <content type="text"><![CDATA[引：前两天听到关于entity和domain包的区别，好像之前自己也没有在意过，今天看看网上的信息总结一下。 entity（实体）这好像是最常用的package命名了，package的类一般都是和数据库的表对应的。一个实体，一张表，其字段的类型也是对应的。 model（模型）最初接触到它的时候是Struts的模型驱动，用于接受和显示前台的数据对象。我们要根据实际情况来确定模型的类。 domain（域）说实话，这个包名用得不怎么多，在网上显示它在国外的网站用的比较多，它主要是用于存储一个业务对象（模块对象）。 总结正确命名包名，有助于后续代码的维护，以及后来开发者的维护，最重要的是能衔接行业的规范。慢慢来！]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贪心算法]]></title>
    <url>%2F2017%2F05%2F17%2F%E7%AE%97%E6%B3%95%2F%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[引：上次看到过钟华老师的一个基于贪心算法的毕业设计，一直很好奇，今天终于能看看它了，只是知其然，不知所以然。 贪心算法总说贪心算法在每一步都会做出看起来是最佳的选择，也就是说会做出局部最优的选择，希望以此能够得到最优解。 活动选择问题贪心选择我们要选择这样一个活动，选出它之后身下的资源能够被尽量多的其他任务所用，即选择最早结束的活动。 递归贪心算法算法思路：用两个数组s和f表示活动的开始和结束时间。下表k是我们要求解的子问题，以及问题规模n，代码如下：12345678910111213141516171819202122232425262728293031import java.util.ArrayList;import java.util.List;public class ActivitySelector &#123;public int[] s = new int[]&#123;1,3,0,5,3,5,6,8,8,2,12&#125;;public int[] f = new int[]&#123;4,5,6,7,9,9,10,11,12,14,16&#125;;public List&lt;Integer&gt; list = new ArrayList&lt;&gt;();public void recursiveActivitySelector(int[] s, int[] f,int k,int n)&#123;if(list.size()==0)&#123;list.add(1);&#125;int m = k+1;while (m&lt;n &amp;&amp; s[m]&lt;f[k])&#123;m = m+1;&#125;if(m&lt;n)&#123;list.add(m+1);recursiveActivitySelector(s, f, m, n);&#125; else &#123;return ;&#125; &#125;public static void main(String[] args) &#123;ActivitySelector activitySelector = new ActivitySelector();activitySelector.recursiveActivitySelector(activitySelector.s, activitySelector.f, 0, activitySelector.f.length);for (Integer i : activitySelector.list) &#123;System.out.println(i);&#125;&#125;&#125; 迭代贪心算法这个过程是假设输入活动的结束时间是已经排好序的，代码如下：123456789101112131415161718192021222324252627import java.util.ArrayList;import java.util.List;public class GreedyActivitySelector &#123;public int[] s = new int[]&#123;1,3,0,5,3,5,6,8,8,2,12&#125;;public int[] f = new int[]&#123;4,5,6,7,9,9,10,11,12,14,16&#125;;public List&lt;Integer&gt; list = new ArrayList&lt;&gt;();public void greedActivitySelector(int[] s,int[] f)&#123;int n = s.length;list.add(1);int k = 1;for (int m = 1; m &lt; n; m++) &#123;if(s[m]&gt;=f[k])&#123;list.add(k);k = m;&#125;&#125;&#125;public static void main(String[] args) &#123;ActivitySelector activitySelector = new ActivitySelector();activitySelector.recursiveActivitySelector(activitySelector.s, activitySelector.f, 0, activitySelector.f.length);for (Integer i : activitySelector.list) &#123;System.out.println(i);&#125;&#125;&#125; 贪心算法原理设计贪心算法的过程 确定问题的最优子结构 设计一个递归算法 证明一个贪心选择，则只剩下一个子问题 证明贪心选择总是安全的 设计一个递归算法实现贪心策略 将递归算法转换为迭代算法 证明一个贪心算法是否能求解一个最优化问题？具有下面性质就ok？ 贪心选择性质 我们可以通过做出局部最优选择来构造全局最优解 最优子结构 如果一个问题的最优解包含子问题的最优解 总结一步一步慢慢贪心，和做人是一样的，但是总的来说还是要考虑全局的！！！]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>算法导论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划]]></title>
    <url>%2F2017%2F05%2F17%2F%E7%AE%97%E6%B3%95%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[引：慢慢就步入了算法导论的高级设计与分析技术模块，先来看看动态规划。ps:快毕业的心情org。 动态规划总说动态规划虽然与分治方法相似，但是它能够解决子问题重叠的情况，这样就提高了效率。它通常是用来求解最优化的问题。求得是一个最优解。一般按如下4个步骤来设计一个动态规划算法。 刻画一个最优解的结构特征 递归地定义最优解的值 计算最优解的值，通常采用自底向上的方法 利用计算出的信息构造出一个最优解 钢条切割先看以前常用的分治方法即自顶向下方法,代码如下：12345678910111213141516171819202122232425262728public class CutRod &#123;//a[i]表示长度为i的钢条利润是多少public int[] a = new int[]&#123;1,5,8,9,10,17,17,20,24,30&#125;;//自顶向下递归设计public int cutRod(int[] a,int n) &#123;if(n == 0)&#123;return 0;&#125;int q = 0;for (int i = 0; i&lt;n; i++)&#123;q = max(q,a[i]+cutRod(a,n-1-i));&#125;return q;&#125;//求最大值函数public int max(int a, int b)&#123;if(a&gt;b)&#123;return a;&#125; else &#123;return b;&#125;&#125;public static void main(String[] args) &#123;CutRod cut = new CutRod();int lost = cut.cutRod(cut.a,10);System.out.println(lost);&#125;&#125; 问题：反复地用相同的参数值对自身进行递归调用，造成了运行时间为n的指数函数。 为了解决这个问题，我们可以采用动态规划方法求解最优钢条切割问题。 采用带备忘的自顶向下法核心是利用一个数组存储已经求解过的最优解，避免了重复的计算，具体的代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class MemoizedCutRod &#123;//a[i]表示长度为i的钢条利润是多少public int[] a = new int[]&#123;1,5,8,9,10,17,17,20,24,30&#125;;//带备忘的自顶向下函数public int memoizedCutRod(int[] a,int n)&#123;//创建一个备忘的数组存储一个之前计算过的最优解int[] r = new int[n];//初始化数组for (int i : r) &#123;i = 0;&#125;//借助辅助函数计算return memoizedCutRodAux(a, n, r);&#125;//带备忘的自顶向下法辅助函数public int memoizedCutRodAux(int[] a,int n,int[] r) &#123;//定义利润int q = 0;if(n == 0)&#123;return 0;&#125;//判断原先是否已经计算过，若计算过就不用再计算if(r[n-1] &gt;0)&#123;return r[n-1];&#125;else &#123;for (int i = 0; i&lt;n; i++)&#123;q = max(q,a[i]+memoizedCutRodAux(a, n-1-i, r));&#125;&#125;r[n-1] = q;return q;&#125;//求最大值函数public int max(int a, int b)&#123;if(a&gt;b)&#123;return a;&#125; else &#123;return b;&#125;&#125;public static void main(String[] args) &#123;MemoizedCutRod cut = new MemoizedCutRod();int lost = cut.memoizedCutRod(cut.a, 10);System.out.println(lost);&#125;&#125; 采用由底向上的方法核心是从小算到大算出每一个长度的最优解，然后返回想要的长度的最优解。代码如下： 123456789101112131415161718192021222324252627282930public class BottomUpTopCutRod &#123;//a[i]表示长度为i的钢条利润是多少public int[] a = new int[]&#123;1,5,8,9,10,17,17,20,24,30&#125;;public int bottomUpTopCutRod(int[] a, int n)&#123;int[] r = new int[n+1];//长度为0的时候，收益为0r[0] = 0;int q = 0;for(int i = 0; i&lt;n; i++)&#123;for(int j = 0; j&lt;=i; j++)&#123;q = max(q,a[j]+r[i-j]);&#125;r[i+1] = q;&#125;return r[n];&#125;//求最大值函数public int max(int a, int b)&#123;if(a&gt;b)&#123;return a;&#125; else &#123;return b;&#125;&#125;public static void main(String[] args) &#123;BottomUpTopCutRod cut = new BottomUpTopCutRod();int lost = cut.bottomUpTopCutRod(cut.a, 10);System.out.println(lost);&#125;&#125; 优势：实现了运行时间复杂度n*n 动态规划原理适用应用动态规划方法求解的最优化问题应该具备的两个要素：最优子结构和子问题重叠 最优子结构如果一个问题的最优解包含其子问题的最优解，我们就称这个问题具有最优子结构性质。例如：无权最短路径。 重叠子问题如果递归算法反复求解相同的子问题，我们就称最优化问题具有重叠子问题性质。例如钢条切割。 总结慢慢懂一点小算法思想。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>算法导论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[观《驴得水》呻吟]]></title>
    <url>%2F2017%2F05%2F11%2F%E7%94%9F%E6%B4%BB%2F%E8%A7%82%E3%80%8A%E9%A9%B4%E5%BE%97%E6%B0%B4%E3%80%8B%E5%91%BB%E5%90%9F%2F</url>
    <content type="text"><![CDATA[引：其实当身边同学都在打游戏的时候，我却不能静下心来了，内心仍然是浮躁，既然不能改论文，所以自己就找电影看吧。自认为自己是一个不懂得享受的人，所以在大脑思索良久之后，决定观看好久之前评价还不错的电影《驴得水》。 总说我不知道该以什么角度来评价这部电影，但这部电影给我感受是深刻，至少在灵魂上还是有一定的冲击，感觉作者与导演把每个角色想要表达的思想基本上都表达出来了，下面我也将按这些角色把在我身上能够体会到的思想说一下，至少在我心里，这是一部好电影。 角色思想校长这个一个有抱负的校长，但是却又特别的自私，为了达成自己的抱负，他选择了屈服，虽然在某些片段来说，他有一点想反抗，如他不能忍受裴魁山去骂张一曼，但是那一点反抗却是那么无力，到最后他选择了屈服，屈服到了让自己的女儿去做牺牲。关于这个角色我不想做太多评价，他总说以大局为重，或许在生活中很多人都会这么做，自私到可以牺牲掉很多。 裴魁山这个角色应该就是现在很多人所说的腹黑吧，自己得不到，就宁愿把他毁掉，他从不介意张一曼的出身愿意娶她，到指着他的鼻子骂，这个转变让很多人心凉，追不到还能做朋友么，他的回答告诉我们，他不搞她已经是最好的结果了。爱一个可以随时为她着想，恨一个人希望所有人都恨他。 铜匠也许他后面变得很坏，但是我从头到尾都认为他是这部剧最可怜的人，他原来是一个单纯至极的人，命运使然他加入到了一个骗子集团吧，因为单纯才会认为张一曼会喜欢他吧，因为单纯所以期望太高，这导致在张一曼骂他牲口之后开始最强烈的抱负。但是有一点他这个觉得传递了不好的概念，有知识不是为了更好的抱负，而是应该为了更好的帮助别人，虽然他的行为可以理解，但是却不提倡，从他到最后还是想去美国学习，可以看出他还是很想学习的，想脱离文盲这个行列。 张一曼这是一个不畏世俗的眼光，勇敢追求自由的女子，也不能说是道德败坏吧，虽然和有妇之夫搞一起不太好，但是他自己也有自己的原则，就像他一开始不愿意将她和铜匠的事情说出来一样，他有自己一定的原则。但是在校长的屈服下，也造就了他的悲剧，最后开枪自杀了。 周铁男这个角色也是反映了一部分人，他喜欢孙佳，但是一直没有说出来，也算单纯耿直的人，平时脾气挺冲，在别人要动孙佳的时候也立马站了出来，可惜在擦过枪子的之后，他选择了屈服，他慢慢开始收敛自己，只是为了能够活下去，他甚至可以认忍受孙佳去嫁给铜匠，所以说，所谓的爱在现实的生与死之间是那么的不堪。 孙佳这个人或许是这部剧中完全没有污点的人吧，应该也是导演想表达的正面形象，他是唯一一个把驴得水当做人看的人，也是第一个想揭发整个阴谋的人，面对这一切，她说过去的都让他过去的话，那么只能越来越错，不能让错误一直延续下去。莫名戳中内心。 特派员一个目不识丁，却假装英国留学回来的官员，所谓的民间教育家的评选，不过是教育部敛财的名头，从被骗到一起骗说明政府的腐败与强势，从十万到三万，我们看到了心凉。 总结主要人物各有各的责任，他们都反应了这个世界上的一部分人，所以感受很深，点评不当之处，也希望大家担待。好吧，呻吟到此结束。]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>电影</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[选择算法]]></title>
    <url>%2F2017%2F05%2F10%2F%E7%AE%97%E6%B3%95%2F%E9%80%89%E6%8B%A9%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[引：300000是不是一个小目标，不知道为了目的还是目的，只想好好努力，功利也好，安慰也罢！ 期望为线性时间的选择算法算法思想： 检查数组是否只有一个数，如是，只好返回该数 采用随机分割将数组氛围a[p..q-1]和a[q+1..r]并返回主元q 检查如果该主元就是我们要找的数，就返回 判断前半部分的个数，如果要找的顺序大于前面的个数，就递归调用后面的数组，否则递归调用前面的数组 代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import java.util.Random;public class Randomized_select &#123;public int randomized_select(int[] a,int p, int r,int i)&#123;//如果分割到只剩一个元素了，那么就是这个了if(p == r)&#123;return a[p];&#125;//随机分割int q = randompartition(a, p, r);//确定q是第几小的数int k = q-p+1;if(k == i) &#123;return a[q];&#125;else if(k&lt;i)&#123;//递归调用后半部分的数return randomized_select(a, q+1, r, i-k);&#125; else &#123;//递归调用前半部分的数return randomized_select(a, p, q-1, i);&#125; &#125;//分割函数public int partition(int[] a,int p,int r)&#123;int x = a[r];int i = -1;int temp = 0;for (int j = 0; j &lt; a.length-1; j++) &#123;if(a[j]&lt;x)&#123;i=i+1;temp = a[i];a[i] = a[j];a[j] = temp;&#125;&#125;temp = a[i+1];a[i+1] = x;a[r] = temp;return i+1;&#125;//随机分割 public int randompartition(int[] a,int p,int r)&#123;int temp = 0;Random random = new Random();int i = random.nextInt(r);temp = a[i];a[i] = a[r];a[r] = temp;return partition(a, p, r);&#125;public static void main(String[] args) &#123;int[] a = new int[]&#123;3,2,9,0,7,5,4,8,6,1&#125;;Randomized_select select = new Randomized_select();int num = select.randomized_select(a, 0, a.length-1, 10);System.out.println(num);&#125;&#125; 算法分析：期望时间复杂度是线性的O(n),但是最坏的时间复杂度是O(n*n) 最坏情况为线性时间的选择算法算法思想： 将输入数组的n个元素划分为n/5组，每组5个元素，且至多只有一组由剩下的nmod5个元素组成。 寻找每一个组的中位数：首先对每组元素进行插入排序，然后确定每组的中位数。 对第2部的中位数数组利用递归调用前面的random_select()求取中位数x 利用修改的partition(),按中位数x进行划分，得到比x小的数有k个 如果i=k则返回x。如果ik，则在高区递归查找第i-k小的元素 代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108package select;public class GoodSelect &#123;//插入排序public void insertsort(int[] a,int p, int r)&#123;for (int i=p+1;i&lt;=r;i++) &#123;int temp = 0;//*从后往前插*for(int j = i;j&gt;p &amp;&amp; a[j]&lt;a[j-1];j--)&#123;temp = a[j];a[j] = a[j-1];a[j-1] = temp;&#125;&#125;&#125;//对数组A[]分组，每组5个元素，分别进行插入排序,返回中位数数组public int[] partInsertSort(int[] a,int p,int r) &#123;int i = 0;int[] b;if((r-p+1)%5==0)&#123;b = new int[(r-p+1)/5];&#125; else &#123;b = new int[(r-p+1)/5+1];&#125;int Length = r-p+1;if (Length &lt;= 5) //元素个数少于5个&#123; insertsort(a,p,r);b[0]=a[p+(Length-1)/2];&#125;else&#123;for (i=0;i&lt;Length/5;i++)&#123;insertsort(a,p+i*5,p+i*5+4);b[i]=a[i*5+2]; //B[i] 存储各组中位数&#125;if ( Length%5 != 0 )&#123;insertsort(a,Length-1-(Length-1)%5,Length-1);b[i]=a[Length-1-Length%5/2]; //B[i] 存储最后一组中位数&#125;&#125;return b; // 返回分组的个数&#125;//调用random_select算法，选出中位数数组的中位数public int selectmid(int[] a)&#123;Randomized_select randomized_select = new Randomized_select();int num = randomized_select.randomized_select(a, 0, a.length-1, (a.length+1)/2);return num; &#125;//安装精心挑选的中位数来分割数组public int partition(int[] a,int p,int r,int x)&#123;int j = p-1;int i = 0;int temp =0;int addr = 0;//记录最佳中位数的位置for(i = p; i&lt;r+1; i++)&#123;if(a[i]&lt;=x)&#123;j+=1;temp = a[j];a[j] = a[i];a[i] = temp; &#125;if(a[i] == x)&#123;addr = i;&#125; &#125;temp = a[j];a[j] = a[addr];a[addr] = temp;return j;&#125;public int goodselect(int[] a,int p,int r,int i)&#123;//如果分割到只剩一个元素了，那么就是这个了if(p == r)&#123;return a[p];&#125;int [] b = partInsertSort(a, p, r);int x = selectmid(b);int q = partition(a, p, r, x);//确定q是第几小的数int k = q-p+1;if(k == i) &#123;return a[q];&#125;else if(k&lt;i)&#123;//递归调用后半部分的数return goodselect(a, q+1, r, i-k);&#125; else &#123;//递归调用前半部分的数return goodselect(a, p, q-1, i);&#125;&#125;public static void main(String[] args) &#123;int[] a = new int[]&#123;2,1,4,6,5,8,9,7,11,13,12,15,16&#125;;GoodSelect select = new GoodSelect();int num = select.goodselect(a, 0, a.length-1, 13);System.out.println(num);&#125;&#125; 算法总结：毕竟是三个人发明的算法，真是好牛逼的，厉害，实现了最坏时间还是线性的。具体分析请参考算法导论原书。 总结第二个算法真的花了自己好长的时间来调试，还是说明自己的编码能力差劲，要好好努力，慢慢提高，加油！ ps：有一种体会，学算法是为了创造，大多数人只要把优秀的源码包里的算法理解了就好，并加以使用就好！]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[“线性时间排序（未完，待续）”]]></title>
    <url>%2F2017%2F05%2F10%2F%E7%AE%97%E6%B3%95%2F%E2%80%9C%E7%BA%BF%E6%80%A7%E6%97%B6%E9%97%B4%E6%8E%92%E5%BA%8F%EF%BC%88%E6%9C%AA%E5%AE%8C%EF%BC%8C%E5%BE%85%E7%BB%AD%EF%BC%89%E2%80%9D%2F</url>
    <content type="text"><![CDATA[引：排序慢慢来，今天要接触到线性时间排序了：计数排序，基数排序，桶排序。 计数排序前提条件：知道输入数组的最大值。代码如下：12345678910111213141516171819202122public int[] countingsort(int[] a,int k)&#123;//初始化临时数组,k为数组的最大值int[] c = new int[k+1];for(int i=0; i&lt;=k; i++) &#123;c[i]=0;&#125;//获得等于i的元素个数for(int i= 0; i&lt;a.length-1;i++) &#123;c[a[i]] = c[a[i]]+1;&#125;//获得小于等于i的元素个数(隐含了递归调用)for(int i = 1; i&lt;=k; i++) &#123;c[i] = c[i] +c[i-1];&#125;//按顺序分到输出数组int[] b = new int[a.length];for(int i = a.length-1; i&gt;=0; i--) &#123;b[c[a[i]]] = a[i];c[a[i]] = c[a[i]]-1;&#125;return b;&#125; 优劣：实现了线性时间，但是空间损失惨重，像是叫你排序这三个数：1，3，1000000000000，马上高低立见。 基数排序IBM创始人发明，利用进制数的位进行从低到高比较。其中会将原来的数转化为r进制数，使时间复杂度变为线性。写一下伪代码123redix-sort(A,d)for i = 1 to duse a stable sort to sort array A on digit i 桶排序桶排序假设数据服从均匀分布，讲一个区间分成若干个桶，先将数据放到桶中分开排序再合并。伪代码如下12345678910bucket-sort(A)n = A.lengthlet B[0.. n-1] be a new arrayfor i = 0 to n - 1make B[i] an empty listfor i = 1 to ninsert A[i] into list B[nA[i]]for i = 0 to n - 1sort list B[i] with insertion sortconcatenete the lists B[0],B[1].. B[n-1] together in order 它的期望时间为线形。 总结其中对于基数排序和桶排序理解得不是很好，需要加深理解，写出具体实现代码，未完，待续…]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>线性时间排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[堆排序]]></title>
    <url>%2F2017%2F05%2F10%2F%E7%AE%97%E6%B3%95%2F%E5%A0%86%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[引：真的是烦，连个hadoop集群环境都搭不好，发现一个人学还是很困难的，想想还是一个人看算法会简单些，所以来看看了，今天看堆排序！ 堆排序简单介绍堆排序是原址运算，后来由于Java的原因我用了变址，但是算法的思想还是没有变得的.堆分为大顶堆，小顶堆，我们下面以大顶堆为例。 维护堆我们需要一个函数在任何情况下子节点要比根节点小。函数如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546//取父节点public int parent(int i)&#123; return (int)Math.ceil(i/2)-1;&#125;//取左子树public int left(int i)&#123; if(i == 0)&#123; return i+1; &#125; else&#123; return 2*i+1; &#125;&#125;//取右子树public int right(int i)&#123; if(i == 0)&#123; return i+2; &#125; else&#123; return 2*i+2; &#125;&#125;//维护大顶堆public int[] max_heapify(int[] a,int i)&#123; int l = left(i); int r = right(i); int largest = 0; int temp = 0; if(l&gt;=a.length &amp;&amp; r&gt;=a.length)&#123; return a; &#125; if(l&lt;a.length &amp;&amp; a[l]&gt;a[i])&#123; largest = l; &#125; else&#123; largest = i; &#125; if(r&lt;a.length &amp;&amp; a[r]&gt;a[largest])&#123; largest = r; &#125; if(largest!=i) &#123; temp = a[i]; a[i] = a[largest]; a[largest] = temp; max_heapify(a, largest); &#125; return a; &#125; 建堆在对数组遍历建立二叉树的时候，我们容易得出Math.floor(n/2)到n都是叶节点，其余是根节点，所以我们在建堆得时候冲根节点不断往前维护就好。代码如下：12345678//建大堆public int[] bulid_max_heap(int[] a)&#123; heap_size = a.length; for(int i = (int)Math.floor(a.length/2)-1; i&gt;=0; i--)&#123; max_heapify(a, i); &#125; return a;&#125; 堆排序算法思想：先取出顶，再维护，再取顶，再维护，知道最后代码如下：12345678910111213//堆排序算法public int[] heapsort(int[] a) &#123; int[] b = new int[a.length];//无奈之举，java没有size这个属性，或者用list也可以 bulid_max_heap(a); for(int i = a.length-1; i&gt;=1; i--)&#123; b[i] = a[0]; a[0] = a[i]; a[i] = 0;//使最后一个元素不参与排序 max_heapify(a, 0); &#125; b[0] = a[0]; return b;&#125; 算法时间复杂度：nlgn 重要应用——优先队列优先队列应用于共享计算机的系统的作业调度，最大优先队列记录将要执行的各个作业以及它们之间的相对优先级，在任何时候都可以调用insert把一个新作业加入到队列中来。讲一下最大优先序列的几个操作。 maximum获取最大值代码如下：1234 //获取最大值public int maximum(int[] a)&#123; return a[1];&#125; 去掉并返回数组中的最大键值得元素代码如下:12345678910//去掉并返回数组中具有最大键值得元素public int extract_max(int[] a)&#123; if(a.length&lt;1)&#123; System.out.println("heap underflow"); &#125; int max = a[0]; a[0] = a[a.length]; max_heapify(a, 0); return max;&#125; 总结加油呀加油！堆排序还是强大的，期待运用！]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速排序及随机化算法]]></title>
    <url>%2F2017%2F05%2F06%2F%E7%AE%97%E6%B3%95%2F%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E5%8F%8A%E9%9A%8F%E6%9C%BA%E5%8C%96%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[引：算法一直很重要，最近没有心情去看项目的代码与技术，所以就拿起其了算法导论来看，最经典的快速排序及随机化算法，java实现。 快速排序算法 核心思想分治思想和原址运算：看一张图 算法具体实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697 public class QuickSort &#123; public int partition(int[] a,int p,int r)&#123; int x = a[r]; int i = -1; int temp = 0; for (int j = 0; j &lt; a.length-1; j++) &#123; if(a[j]&lt;x)&#123; i=i+1; temp = a[i]; a[i] = a[j]; a[j] = temp; &#125; &#125; temp = a[i+1]; a[i+1] = x; a[r] = temp; return i+1; &#125; public int[] quicksort(int[] b,int p,int r)&#123; if(p&lt;r)&#123; int q = partition(b,p,r); quicksort(b, p, q-1); quicksort(b, q+1, r); &#125; return b; &#125; public static void main(String[] args) &#123; QuickSort sort = new QuickSort(); int[] a = &#123;2,8,7,1,3,5,6,4&#125;; int[] b = sort.quicksort(a, 0, a.length-1); for (int i : b) &#123; System.out.print(i+" "); &#125; &#125; &#125;3.时间复杂度通过分析我们最看重的平均复杂度是nlgn## 随机化算法1. 核心思想在算法加入随机性，要么在使序列生成随机化，要么就是使主元随机化，这里我们使主元随机化。2. 算法具体实现```java import java.util.Random; public class RandomQuickSort &#123; public int partition(int[] a,int p,int r)&#123; int x = a[r]; int i = -1; int temp = 0; for (int j = 0; j &lt; a.length-1; j++) &#123; if(a[j]&lt;x)&#123; i=i+1; temp = a[i]; a[i] = a[j]; a[j] = temp; &#125; &#125; temp = a[i+1]; a[i+1] = x; a[r] = temp; return i+1; &#125; public int randompartition(int[] a,int p,int r)&#123; int temp = 0; Random random = new Random(); int i = random.nextInt(r); temp = a[i]; a[i] = a[r]; a[r] = temp; return partition(a, p, r); &#125; public int[] randomquicksort(int[] b,int p,int r)&#123; if(p&lt;r)&#123; int q = randompartition(b, p, r); randomquicksort(b, p, q-1); randomquicksort(b, q+1, r); &#125; return b; &#125; public static void main(String[] args) &#123; RandomQuickSort sort = new RandomQuickSort(); int[] a = &#123;2,8,7,1,3,5,6,4&#125;; int[] b = sort.randomquicksort(a, 0, a.length-1); for (int i : b) &#123; System.out.print(i+" "); &#125; &#125; &#125; 时间复杂度 通过分析我们最看重的平均复杂度是nlgn 基本排序算法 小结：同等情况下快速排序&gt;随机化算法&gt;归并排序&gt;插入排序；在有序的情况下随机化算法&gt;快速排序 总结慢慢走，不要急！]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[String,StringBuilder,StringBuffer区别]]></title>
    <url>%2F2017%2F05%2F04%2FJava%E5%9F%BA%E7%A1%80%2FString-StringBuilder-StringBuffer%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[引：最近心情非常的不静，我知道自己需要沉下心去沉淀，慢慢来，小朋友。今天谈谈3个字符串类 String查看String源码的时候，我们很容易看到&gt; public final class String 从源码中对String的定义可以知道它是final类，这意味着她不可被继承，也不可被更改。而且总它的方法中也没有可以拼接字符串的函数。 StringBuilder查看StringBuilder源码的时候，我们也可以看到这样的定义：&gt; public final class StringBuilder extends AbstractStringBuilder 我们发现他也是final类，但是它却又append()方法，这是为什么，我们找到它的append(): @Override public StringBuilder append(String str) { super.append(str); return this; } 我们看到他的append()方法是调用他的父类来的，所以我们继续看看他的父类是在搞什么鬼👻&gt; public AbstractStringBuilder append(String str) { if (str == null) return appendNull(); int len = str.length(); ensureCapacityInternal(count + len); str.getChars(0, len, value, count); count += len; return this; } 我们终于找到他怎么又这个添加字符串的方法了。具体AbstractStringBuilder是怎么实现添加的就让想要了解的人继续往下看源码就好了。 对比string: 我们可以从日常编写的代码可以了解到，用String拼接由于每次都是新建一个对象所以效率自然是低的，所以在使用字符串拼接的时候还是用StringBuilder比较好，但是对于单个常量字符串来说还是String好，因为它是放在常量池里，读取速度比放在堆中的对象自然是要快很多。 StringBuffer这又是一个什么鬼，继续看源码吧 public final class StringBuffer extends AbstractStringBuilder 这个和StringBuilder一样也是final类，但是我们可以很清楚的看到也是继承了AbstractStringBuilder，也就是说它也有append()方法，但是我们可以它的append()方法。 public synchronized StringBuffer append(String str) { toStringCache = null; super.append(str); return this; } 我们看到它的append()方法加入了synchronized关键字，所以它是个线程安全的类 和StringBuilder的区别： 由于他是线程安全的，所以自然牺牲了效率，在操作速度上没有StringBuilder快。 总结：点点滴滴积累]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[请不要无脑]]></title>
    <url>%2F2017%2F04%2F27%2F%E7%94%9F%E6%B4%BB%2F%E8%AF%B7%E4%B8%8D%E8%A6%81%E6%97%A0%E8%84%91%2F</url>
    <content type="text"><![CDATA[大喊一声密码. Decrypt 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]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[记一次失败的面试]]></title>
    <url>%2F2017%2F04%2F26%2F%E7%94%9F%E6%B4%BB%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%9D%A2%E8%AF%95%2F</url>
    <content type="text"><![CDATA[大喊一声密码. Decrypt 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]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSH项目初体验]]></title>
    <url>%2F2017%2F04%2F24%2F%E7%BC%96%E7%A8%8B%2FSSH%E9%A1%B9%E7%9B%AE%E5%88%9D%E4%BD%93%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[引：历时四天，终于在视频的帮助下完成了基于SSH（struts2+hibernate3+spring4）的一个网站商城项目，也是自己第一次采用idea开发项目简单，谈谈收获和感想。 代码流程 导包主要的文件：导三大框架的包这里的包我也不贴图了，都是最基本的jar包 框架配置这里我想说的是三个文件： web.xml：配置struts核心过滤器和配置Spring的核心监听器 struts.xml：配置各种action applicationContext.xml：作为大管家事情也就比较多了，有配置数据库C3P0连接池，配置Hibernate引入数据源，事务管理，管理action，service，dao 按层码代码 分层架构 web层主要使用action进行控制，这里使用了动态匹配，如userAction_*.action其中要点： 值栈：对于单个业务逻辑来说存取值实在是太方便了。 模型驱动：对于模块的对象使用模型存值也很方便 拦截器：对于后台范围一定要对访问进行控制，若未登录，请先登录 ognl表达式：可以进行运算，除模型驱动以及值栈内取值之外都要加# service层本次项目并未多少体现出来，我们只要注意添加spring事务注解 dao层此次使用的hibernate，要点如下 实体映射文件：对于主外键一定要设置正确，懒加载问题，级联删除问题 hql语句：join的用法，面向对象的语句编写 项目模块这里只是简单说说作为一个商场应该具有的模块 前台首页；前台用户 ；一级目录； 二级目录； 商品； 购物车； 订单 后台后台用户；一级目录；二级目录；商品；订单 查bug方法即使是按着视频来的，但是也还是会出错，有的时候还查了一个多小时，bug：码农的一生之敌呀！回到正题：首先看控制台错误，分析错误类型 前台传数据错误可以将表单的发送方式改为get，这个就可以从uri中看出错误了，自己好几次入坑，就是在参数填写的地方多了一个空格，欲哭无泪。 业务逻辑代码错误其实最简单也最烦，就是利用debug。按逻辑顺序进行查错。 数据库查询出错可以充分利用控制台输出的sql语句进行排错，将sql语句放到sql桌面程序中查询，是否与自己想要的结果一致，如果不一致，就很有可能是自己的hql语句写错，或者映射文件出错了。 感想关于这个项目架构都是比较简单的，业务逻辑也都是CRUD也算简单，可能还有最重要的高并发问题没有考虑，但是整个项目做下来，自己也算理解了整个项目系统，但是自己绝对不能以CRUD为终点，继续向前加油！！！！]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>ssh</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iis实现手机端访问电脑本地服务器]]></title>
    <url>%2F2017%2F04%2F24%2F%E5%B7%A5%E5%85%B7%2Fiis%E5%AE%9E%E7%8E%B0%E6%89%8B%E6%9C%BA%E7%AB%AF%E8%AE%BF%E9%97%AE%E7%94%B5%E8%84%91%E6%9C%AC%E5%9C%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[引：对于很多没有服务器的人来说,实现手机端访问自己写的网页还是有困难的，虽然我们可以可以利用githubpage来实现挂载页面，但是调试起来还是不方便，所以iis就成为了一种简单的方式。 iis简介iis（Internet Information Services）是由微软公司提供的基于运行Microsoft Windows的互联网基本服务,其中包括Web服务器、FTP服务器、NNTP服务器和SMTP服务器，分别用于网页浏览、文件传输、新闻服务和邮件发送等方面，它使得在网络（包括互联网和局域网）上发布信息成了一件很容易的事。 iis安装这里我就不多说了，网上一搜，安装教程一大把，这里推荐一个链接安装iis 有无线的时候使用大部分人，大部分时间，大部分地方，相信大家都会身处在无线之下，所以只要按照上面的链接使用就可以了。 没无线的时候使用这个时候就要借助流量与热点了 打开手机热点 查看电脑ip地址一般这个时候ip地址已经变了，所有之前按照有无线的时候电脑的ip设置访问地址就有问题了，所以要利用新的ip地址设置访问地址 用手机访问新的ip地址一下子就爽歪歪了 总结 iis对于windows用户来说真是出家旅行，调试代码必备之良品。 当不能访问的时候一定要随时关注电脑的ip地址是否已经发生变化，做到随时更改]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>服务器</tag>
      </tags>
  </entry>
</search>